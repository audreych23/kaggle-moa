{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# later when inputting kaggle change this to /kaggle/input\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audreych/Documents/code/machine_learning/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterative-stratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "from copy import deepcopy as dp\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def norm_fit(df_1,saveM = True, sc_name = 'zsco'):   \n",
    "    from sklearn.preprocessing import StandardScaler,MinMaxScaler,MaxAbsScaler,RobustScaler,Normalizer,QuantileTransformer,PowerTransformer\n",
    "    ss_1_dic = {'zsco':StandardScaler(),\n",
    "                'mima':MinMaxScaler(),\n",
    "                'maxb':MaxAbsScaler(), \n",
    "                'robu':RobustScaler(),\n",
    "                'norm':Normalizer(), \n",
    "                'quan':QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\"),\n",
    "                'powe':PowerTransformer()}\n",
    "    ss_1 = ss_1_dic[sc_name]\n",
    "    df_2 = pd.DataFrame(ss_1.fit_transform(df_1),index = df_1.index,columns = df_1.columns)\n",
    "    if saveM == False:\n",
    "        return(df_2)\n",
    "    else:\n",
    "        return(df_2,ss_1)\n",
    "\n",
    "def norm_tra(df_1,ss_x):\n",
    "    df_2 = pd.DataFrame(ss_x.transform(df_1),index = df_1.index,columns = df_1.columns)\n",
    "    return(df_2)\n",
    "\n",
    "def g_table(list1):\n",
    "    table_dic = {}\n",
    "    for i in list1:\n",
    "        if i not in table_dic.keys():\n",
    "            table_dic[i] = 1\n",
    "        else:\n",
    "            table_dic[i] += 1\n",
    "    return(table_dic)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "gene 772\n",
      "cell 100\n",
      "872\n"
     ]
    }
   ],
   "source": [
    "SEED = [0, 1, 2, 3 ,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "input_dir = '../input/lish-moa/'\n",
    "\n",
    "sc_dic = {}\n",
    "feat_dic = {}\n",
    "train_features = pd.read_csv(input_dir+'train_features.csv')\n",
    "train_targets_scored = pd.read_csv(input_dir+'train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv(input_dir+'train_targets_nonscored.csv')\n",
    "test_features = pd.read_csv(input_dir+'test_features.csv')\n",
    "sample_submission = pd.read_csv(input_dir+'sample_submission.csv')\n",
    "train_drug = pd.read_csv(input_dir+'train_drug.csv')\n",
    "\n",
    "target_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()\n",
    "target_nonsc_cols = train_targets_nonscored.drop('sig_id', axis=1).columns.values.tolist()\n",
    "\n",
    "######## non-score ########\n",
    "nonctr_id = train_features.loc[train_features['cp_type']!='ctl_vehicle','sig_id'].tolist()\n",
    "tmp_con1 = [i in nonctr_id for i in train_targets_scored['sig_id']]\n",
    "mat_cor = pd.DataFrame(np.corrcoef(train_targets_scored.drop('sig_id',axis = 1)[tmp_con1].T,\n",
    "                      train_targets_nonscored.drop('sig_id',axis = 1)[tmp_con1].T))\n",
    "mat_cor2 = mat_cor.iloc[(train_targets_scored.shape[1]-1):,0:train_targets_scored.shape[1]-1]\n",
    "mat_cor2.index = target_nonsc_cols\n",
    "mat_cor2.columns = target_cols\n",
    "mat_cor2 = mat_cor2.dropna()\n",
    "mat_cor2_max = mat_cor2.abs().max(axis = 1)\n",
    "\n",
    "q_n_cut = 0.9\n",
    "target_nonsc_cols2 = mat_cor2_max[mat_cor2_max > np.quantile(mat_cor2_max,q_n_cut)].index.tolist()\n",
    "print(len(target_nonsc_cols2))\n",
    "\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "feat_dic['gene'] = GENES\n",
    "feat_dic['cell'] = CELLS\n",
    "\n",
    "# sample norm \n",
    "q2 = train_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.25).copy()\n",
    "q7 = train_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.75).copy()\n",
    "qmean = (q2+q7)/2\n",
    "train_features[feat_dic['gene']] = (train_features[feat_dic['gene']].T - qmean.values).T\n",
    "q2 = test_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.25).copy()\n",
    "q7 = test_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.75).copy()\n",
    "qmean = (q2+q7)/2\n",
    "test_features[feat_dic['gene']] = (test_features[feat_dic['gene']].T - qmean.values).T\n",
    "\n",
    "q2 = train_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.25).copy()\n",
    "q7 = train_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.72).copy()\n",
    "qmean = (q2+q7)/2\n",
    "train_features[feat_dic['cell']] = (train_features[feat_dic['cell']].T - qmean.values).T\n",
    "qmean2 = train_features[feat_dic['cell']].abs().apply(np.quantile,axis = 1,q = 0.75).copy()+4\n",
    "train_features[feat_dic['cell']] = (train_features[feat_dic['cell']].T / qmean2.values).T.copy()\n",
    "\n",
    "q2 = test_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.25).copy()\n",
    "q7 = test_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.72).copy()\n",
    "qmean = (q2+q7)/2\n",
    "test_features[feat_dic['cell']] = (test_features[feat_dic['cell']].T - qmean.values).T\n",
    "qmean2 = test_features[feat_dic['cell']].abs().apply(np.quantile,axis = 1,q = 0.75).copy()+4\n",
    "test_features[feat_dic['cell']] = (test_features[feat_dic['cell']].T / qmean2.values).T.copy()\n",
    "\n",
    "# remove ctl\n",
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(train_targets_nonscored[['sig_id']+target_nonsc_cols2], on='sig_id')\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[['sig_id']+target_cols]\n",
    "target_ns = train[['sig_id']+target_nonsc_cols2]\n",
    "\n",
    "train0 = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "\n",
    "# drug ids\n",
    "tar_sig = target['sig_id'].tolist()\n",
    "train_drug = train_drug.loc[[i in tar_sig for i in train_drug['sig_id']]]\n",
    "target = target.merge(train_drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_drug.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc <= 19].index\n",
    "vc2 = vc.loc[vc > 19].index\n",
    "\n",
    "feature_cols = []\n",
    "for key_i in feat_dic.keys():\n",
    "    value_i = feat_dic[key_i]\n",
    "    print(key_i,len(value_i))\n",
    "    feature_cols += value_i\n",
    "    \n",
    "print(len(feature_cols))\n",
    "feature_cols0 = dp(feature_cols)\n",
    "    \n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "# global features\n",
    "n_comp1 = 50\n",
    "n_comp2 = 15\n",
    "hidden_size = 4096\n",
    "\n",
    "num_features=len(feature_cols) + n_comp1 + n_comp2\n",
    "num_targets=len(target_cols)\n",
    "num_targets_0=len(target_nonsc_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0, pos_weight=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight,\n",
    "                                                    pos_weight = self.pos_weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class TrainDataset:\n",
    "    def __init__(self, features, targets):\n",
    "        print(features)\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        cha_1 = 256\n",
    "        cha_2 = 512\n",
    "        cha_3 = 512\n",
    "\n",
    "        cha_1_reshape = int(hidden_size/cha_1)\n",
    "        cha_po_1 = int(hidden_size/cha_1/2)\n",
    "        cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "        self.cha_1 = cha_1\n",
    "        self.cha_2 = cha_2\n",
    "        self.cha_3 = cha_3\n",
    "        self.cha_1_reshape = cha_1_reshape\n",
    "        self.cha_po_1 = cha_po_1\n",
    "        self.cha_po_2 = cha_po_2\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "        self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "        self.dropout_c1 = nn.Dropout(0.1)\n",
    "        self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "        self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "        self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2 = nn.Dropout(0.1)\n",
    "        self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "        self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2_1 = nn.Dropout(0.3)\n",
    "        self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "        self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2_2 = nn.Dropout(0.2)\n",
    "        self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.flt = nn.Flatten()\n",
    "\n",
    "        self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n",
    "\n",
    "    def extractImageFeat(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.celu(self.dense1(x), alpha=0.06)\n",
    "        x = x.reshape(x.shape[0],self.cha_1,\n",
    "                        self.cha_1_reshape)\n",
    "        \n",
    "        return x \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "        x = x.reshape(x.shape[0],self.cha_1,\n",
    "                        self.cha_1_reshape)\n",
    "\n",
    "        x = self.batch_norm_c1(x)\n",
    "        x = self.dropout_c1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = self.ave_po_c1(x)\n",
    "\n",
    "        x = self.batch_norm_c2(x)\n",
    "        x = self.dropout_c2(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x_s = x\n",
    "\n",
    "        x = self.batch_norm_c2_1(x)\n",
    "        x = self.dropout_c2_1(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "\n",
    "        x = self.batch_norm_c2_2(x)\n",
    "        x = self.dropout_c2_2(x)\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x =  x * x_s\n",
    "\n",
    "        x = self.max_po_c2(x)\n",
    "\n",
    "        x = self.flt(x)\n",
    "\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        final_loss += loss.item()\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "\n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed, train, test, pos_weight):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True).copy()\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True).copy()\n",
    "\n",
    "    x_train, y_train,y_train_ns = train_df[feature_cols], train_df[target_cols].values,train_df[target_nonsc_cols2].values\n",
    "    x_valid, y_valid,y_valid_ns  = valid_df[feature_cols], valid_df[target_cols].values,valid_df[target_nonsc_cols2].values\n",
    "    x_test = test[feature_cols]\n",
    "\n",
    "    #------------ norm --------------\n",
    "    col_num = list(set(feat_dic['gene'] + feat_dic['cell']) & set(feature_cols))\n",
    "    col_num.sort()\n",
    "    x_train[col_num],ss = norm_fit(x_train[col_num],True,'quan')\n",
    "    x_valid[col_num]    = norm_tra(x_valid[col_num],ss)\n",
    "    x_test[col_num]     = norm_tra(x_test[col_num],ss)\n",
    "\n",
    "    #------------ pca --------------\n",
    "    def pca_pre(tr,va,te,\n",
    "                n_comp,feat_raw,feat_new):\n",
    "        pca = PCA(n_components=n_comp, random_state=42)\n",
    "        tr2 = pd.DataFrame(pca.fit_transform(tr[feat_raw]),columns=feat_new)\n",
    "        va2 = pd.DataFrame(pca.transform(va[feat_raw]),columns=feat_new)\n",
    "        te2 = pd.DataFrame(pca.transform(te[feat_raw]),columns=feat_new)\n",
    "        return(tr2,va2,te2)\n",
    "\n",
    "\n",
    "    pca_feat_g = [f'pca_G-{i}' for i in range(n_comp1)]\n",
    "    feat_dic['pca_g'] = pca_feat_g\n",
    "    x_tr_g_pca,x_va_g_pca,x_te_g_pca = pca_pre(x_train,x_valid,x_test,\n",
    "                                                n_comp1,feat_dic['gene'],pca_feat_g)\n",
    "    x_train = pd.concat([x_train,x_tr_g_pca],axis = 1)\n",
    "    x_valid = pd.concat([x_valid,x_va_g_pca],axis = 1)\n",
    "    x_test  = pd.concat([x_test,x_te_g_pca],axis = 1)\n",
    "\n",
    "    pca_feat_g = [f'pca_C-{i}' for i in range(n_comp2)]\n",
    "    feat_dic['pca_c'] = pca_feat_g\n",
    "    x_tr_c_pca,x_va_c_pca,x_te_c_pca = pca_pre(x_train,x_valid,x_test,\n",
    "                                                n_comp2,feat_dic['cell'],pca_feat_g)\n",
    "    x_train = pd.concat([x_train,x_tr_c_pca],axis = 1)\n",
    "    x_valid = pd.concat([x_valid,x_va_c_pca],axis = 1)\n",
    "    x_test  = pd.concat([x_test,x_te_c_pca], axis = 1)\n",
    "\n",
    "    x_train,x_valid,x_test = x_train.values,x_valid.values,x_test.values\n",
    "    print(x_train.shape)\n",
    "\n",
    "    train_dataset = TrainDataset(x_train, y_train_ns)\n",
    "    valid_dataset = TrainDataset(x_valid, y_valid_ns)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets_0,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, \n",
    "                                                max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "\n",
    "    loss_tr = nn.BCEWithLogitsLoss()   #SmoothBCEwLogits(smoothing = 0.001)\n",
    "    loss_va = nn.BCEWithLogitsLoss()    \n",
    "\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    # train warmup with non scored \n",
    "    for epoch in range(1):\n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n",
    "\n",
    "    model.dense3 = nn.utils.weight_norm(nn.Linear(model.cha_po_2, num_targets))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    train_dataset = TrainDataset(x_train, y_train)\n",
    "    valid_dataset = TrainDataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                                max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "\n",
    "    loss_tr = SmoothBCEwLogits(smoothing = 0.001, pos_weight=pos_weight)\n",
    "    loss_va = nn.BCEWithLogitsLoss()    \n",
    "\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    best_loss = np.inf\n",
    "\n",
    "    mod_name = f\"FOLD_mod11_{seed}_{fold}_.pth\"\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "\n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), mod_name)\n",
    "\n",
    "        elif(EARLY_STOP == True):\n",
    "\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(mod_name))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed, train, test, pos_weight):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed, train, test, pos_weight)\n",
    "\n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "\n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17556, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.736779404723126, valid_loss: 0.7167257717677525\n",
      "SEED: 0, FOLD: 0, EPOCH: 0,train_loss: 0.46687912573848944, valid_loss: 0.024165539762803487\n",
      "SEED: 0, FOLD: 0, EPOCH: 1,train_loss: 0.02069511819306923, valid_loss: 0.02094758376479149\n",
      "SEED: 0, FOLD: 0, EPOCH: 2,train_loss: 0.01883962676199018, valid_loss: 0.01805939469486475\n",
      "SEED: 0, FOLD: 0, EPOCH: 3,train_loss: 0.018191139821125114, valid_loss: 0.0190495602786541\n",
      "SEED: 0, FOLD: 0, EPOCH: 4,train_loss: 0.01803769728006876, valid_loss: 0.017824575092111314\n",
      "SEED: 0, FOLD: 0, EPOCH: 5,train_loss: 0.017784679726953957, valid_loss: 0.018006538067545208\n",
      "SEED: 0, FOLD: 0, EPOCH: 6,train_loss: 0.01783845548018597, valid_loss: 0.0177716533520392\n",
      "SEED: 0, FOLD: 0, EPOCH: 7,train_loss: 0.01785273516577655, valid_loss: 0.017828260468585152\n",
      "SEED: 0, FOLD: 0, EPOCH: 8,train_loss: 0.01782443625447543, valid_loss: 0.0177497642913035\n",
      "SEED: 0, FOLD: 0, EPOCH: 9,train_loss: 0.017907184393455584, valid_loss: 0.017747293785214426\n",
      "SEED: 0, FOLD: 0, EPOCH: 10,train_loss: 0.017727041488810293, valid_loss: 0.01813558784446546\n",
      "SEED: 0, FOLD: 0, EPOCH: 11,train_loss: 0.017719027343327583, valid_loss: 0.01760802229068109\n",
      "SEED: 0, FOLD: 0, EPOCH: 12,train_loss: 0.017617132872397055, valid_loss: 0.01774146288101162\n",
      "SEED: 0, FOLD: 0, EPOCH: 13,train_loss: 0.017583761883872576, valid_loss: 0.017686453381819383\n",
      "SEED: 0, FOLD: 0, EPOCH: 14,train_loss: 0.01737688148421222, valid_loss: 0.01765666234173945\n",
      "SEED: 0, FOLD: 0, EPOCH: 15,train_loss: 0.01734560088969875, valid_loss: 0.017438216081687382\n",
      "SEED: 0, FOLD: 0, EPOCH: 16,train_loss: 0.017095487382586882, valid_loss: 0.017315071129373142\n",
      "SEED: 0, FOLD: 0, EPOCH: 17,train_loss: 0.016896651106198198, valid_loss: 0.01741635517350265\n",
      "SEED: 0, FOLD: 0, EPOCH: 18,train_loss: 0.01656422450247666, valid_loss: 0.01730406643556697\n",
      "SEED: 0, FOLD: 0, EPOCH: 19,train_loss: 0.016186165387161833, valid_loss: 0.01737468796116965\n",
      "SEED: 0, FOLD: 0, EPOCH: 20,train_loss: 0.015736542547634548, valid_loss: 0.017198788188397884\n",
      "SEED: 0, FOLD: 0, EPOCH: 21,train_loss: 0.015264103924720615, valid_loss: 0.017388165688940457\n",
      "SEED: 0, FOLD: 0, EPOCH: 22,train_loss: 0.014728958057104677, valid_loss: 0.01719696330172675\n",
      "SEED: 0, FOLD: 0, EPOCH: 23,train_loss: 0.014324238847779192, valid_loss: 0.017194777354598047\n",
      "SEED: 0, FOLD: 0, EPOCH: 24,train_loss: 0.014046000121026367, valid_loss: 0.017178002638476235\n",
      "(17486, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7369105428674795, valid_loss: 0.7166308420045036\n",
      "SEED: 0, FOLD: 1, EPOCH: 0,train_loss: 0.4686234544310039, valid_loss: 0.025349475656236922\n",
      "SEED: 0, FOLD: 1, EPOCH: 1,train_loss: 0.020821763528850828, valid_loss: 0.01939063583101545\n",
      "SEED: 0, FOLD: 1, EPOCH: 2,train_loss: 0.018772624602989993, valid_loss: 0.019090036675333977\n",
      "SEED: 0, FOLD: 1, EPOCH: 3,train_loss: 0.01815733983161023, valid_loss: 0.01813375662480082\n",
      "SEED: 0, FOLD: 1, EPOCH: 4,train_loss: 0.01782549382697274, valid_loss: 0.01811238295797791\n",
      "SEED: 0, FOLD: 1, EPOCH: 5,train_loss: 0.01776871974342061, valid_loss: 0.019113618774073464\n",
      "SEED: 0, FOLD: 1, EPOCH: 6,train_loss: 0.017789289001783316, valid_loss: 0.01831435052944081\n",
      "SEED: 0, FOLD: 1, EPOCH: 7,train_loss: 0.017846850719112548, valid_loss: 0.018651188910007478\n",
      "SEED: 0, FOLD: 1, EPOCH: 8,train_loss: 0.017838541343536254, valid_loss: 0.018295314535498618\n",
      "SEED: 0, FOLD: 1, EPOCH: 9,train_loss: 0.017805981470176774, valid_loss: 0.018256023366536412\n",
      "SEED: 0, FOLD: 1, EPOCH: 10,train_loss: 0.01777832069345852, valid_loss: 0.01841504363609212\n",
      "SEED: 0, FOLD: 1, EPOCH: 11,train_loss: 0.017704545595023755, valid_loss: 0.018115038238465785\n",
      "SEED: 0, FOLD: 1, EPOCH: 12,train_loss: 0.01761150107222752, valid_loss: 0.01800167376973799\n",
      "SEED: 0, FOLD: 1, EPOCH: 13,train_loss: 0.017531410600636562, valid_loss: 0.018042496857898577\n",
      "SEED: 0, FOLD: 1, EPOCH: 14,train_loss: 0.017421920464312943, valid_loss: 0.018097378632852008\n",
      "SEED: 0, FOLD: 1, EPOCH: 15,train_loss: 0.017291406516230453, valid_loss: 0.018013693578541278\n",
      "SEED: 0, FOLD: 1, EPOCH: 16,train_loss: 0.017101213539930157, valid_loss: 0.01779878833996398\n",
      "SEED: 0, FOLD: 1, EPOCH: 17,train_loss: 0.016873595787443383, valid_loss: 0.017961435552154268\n",
      "SEED: 0, FOLD: 1, EPOCH: 18,train_loss: 0.01659414970254811, valid_loss: 0.017848544088857516\n",
      "SEED: 0, FOLD: 1, EPOCH: 19,train_loss: 0.01621467219733626, valid_loss: 0.017672006014202324\n",
      "SEED: 0, FOLD: 1, EPOCH: 20,train_loss: 0.01582849789818708, valid_loss: 0.0176281335364495\n",
      "SEED: 0, FOLD: 1, EPOCH: 21,train_loss: 0.015400224657606905, valid_loss: 0.01752312776765653\n",
      "SEED: 0, FOLD: 1, EPOCH: 22,train_loss: 0.014896387846147927, valid_loss: 0.017529181231345448\n",
      "SEED: 0, FOLD: 1, EPOCH: 23,train_loss: 0.014464557612736295, valid_loss: 0.017497572302818298\n",
      "SEED: 0, FOLD: 1, EPOCH: 24,train_loss: 0.014253160195683475, valid_loss: 0.017516121507755347\n",
      "(17606, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7369800542575725, valid_loss: 0.7167699652559617\n",
      "SEED: 0, FOLD: 2, EPOCH: 0,train_loss: 0.46787485836640647, valid_loss: 0.02309854476548293\n",
      "SEED: 0, FOLD: 2, EPOCH: 1,train_loss: 0.0206148029183564, valid_loss: 0.01862164307385683\n",
      "SEED: 0, FOLD: 2, EPOCH: 2,train_loss: 0.01898299532847992, valid_loss: 0.017901024425073582\n",
      "SEED: 0, FOLD: 2, EPOCH: 3,train_loss: 0.01815031220515569, valid_loss: 0.01768739168148707\n",
      "SEED: 0, FOLD: 2, EPOCH: 4,train_loss: 0.017943815726354933, valid_loss: 0.01814123977194814\n",
      "SEED: 0, FOLD: 2, EPOCH: 5,train_loss: 0.017916431151114513, valid_loss: 0.017968354198862526\n",
      "SEED: 0, FOLD: 2, EPOCH: 6,train_loss: 0.01793949999779031, valid_loss: 0.01794705627595677\n",
      "SEED: 0, FOLD: 2, EPOCH: 7,train_loss: 0.01790823184115731, valid_loss: 0.017697028103558457\n",
      "SEED: 0, FOLD: 2, EPOCH: 8,train_loss: 0.01795276450128227, valid_loss: 0.01792938125264995\n",
      "SEED: 0, FOLD: 2, EPOCH: 9,train_loss: 0.01788834904226056, valid_loss: 0.017776549985522732\n",
      "SEED: 0, FOLD: 2, EPOCH: 10,train_loss: 0.0178402170026, valid_loss: 0.01774567288949209\n",
      "SEED: 0, FOLD: 2, EPOCH: 11,train_loss: 0.01782382075148432, valid_loss: 0.01763933549142059\n",
      "SEED: 0, FOLD: 2, EPOCH: 12,train_loss: 0.017770162763316995, valid_loss: 0.01747473838793881\n",
      "SEED: 0, FOLD: 2, EPOCH: 13,train_loss: 0.017662642550641212, valid_loss: 0.01745632238795652\n",
      "SEED: 0, FOLD: 2, EPOCH: 14,train_loss: 0.01757333013296559, valid_loss: 0.017254368402063847\n",
      "SEED: 0, FOLD: 2, EPOCH: 15,train_loss: 0.017330551546984825, valid_loss: 0.017357949496192092\n",
      "SEED: 0, FOLD: 2, EPOCH: 16,train_loss: 0.017220286389245935, valid_loss: 0.017211006132557112\n",
      "SEED: 0, FOLD: 2, EPOCH: 17,train_loss: 0.016935886268544455, valid_loss: 0.017298970891929725\n",
      "SEED: 0, FOLD: 2, EPOCH: 18,train_loss: 0.0166901219231279, valid_loss: 0.01714892841546851\n",
      "SEED: 0, FOLD: 2, EPOCH: 19,train_loss: 0.016323819108631298, valid_loss: 0.017012246309176964\n",
      "SEED: 0, FOLD: 2, EPOCH: 20,train_loss: 0.015934302458080692, valid_loss: 0.016961338518954375\n",
      "SEED: 0, FOLD: 2, EPOCH: 21,train_loss: 0.015467604433280834, valid_loss: 0.0169421305112979\n",
      "SEED: 0, FOLD: 2, EPOCH: 22,train_loss: 0.014912921442663755, valid_loss: 0.016948446357513174\n",
      "SEED: 0, FOLD: 2, EPOCH: 23,train_loss: 0.014500830416986044, valid_loss: 0.01693356943809811\n",
      "SEED: 0, FOLD: 2, EPOCH: 24,train_loss: 0.014275409186771814, valid_loss: 0.016948256285532433\n",
      "(17580, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7371836334898851, valid_loss: 0.7167486837932042\n",
      "SEED: 0, FOLD: 3, EPOCH: 0,train_loss: 0.46728218549295614, valid_loss: 0.02484885065683297\n",
      "SEED: 0, FOLD: 3, EPOCH: 1,train_loss: 0.020799749463364697, valid_loss: 0.01872267286692347\n",
      "SEED: 0, FOLD: 3, EPOCH: 2,train_loss: 0.01902853578761004, valid_loss: 0.018435187052403178\n",
      "SEED: 0, FOLD: 3, EPOCH: 3,train_loss: 0.01834362414598033, valid_loss: 0.018047325951712472\n",
      "SEED: 0, FOLD: 3, EPOCH: 4,train_loss: 0.017843004403824823, valid_loss: 0.018138662885342327\n",
      "SEED: 0, FOLD: 3, EPOCH: 5,train_loss: 0.017899483165609232, valid_loss: 0.01814723861004625\n",
      "SEED: 0, FOLD: 3, EPOCH: 6,train_loss: 0.017841208955623966, valid_loss: 0.01806061387594257\n",
      "SEED: 0, FOLD: 3, EPOCH: 7,train_loss: 0.017827174477819084, valid_loss: 0.017865103935556754\n",
      "SEED: 0, FOLD: 3, EPOCH: 8,train_loss: 0.01788247498832103, valid_loss: 0.01783851185547454\n",
      "SEED: 0, FOLD: 3, EPOCH: 9,train_loss: 0.017846526132653587, valid_loss: 0.017865273728966714\n",
      "SEED: 0, FOLD: 3, EPOCH: 10,train_loss: 0.01780066475191194, valid_loss: 0.01790800549622093\n",
      "SEED: 0, FOLD: 3, EPOCH: 11,train_loss: 0.017765457411229178, valid_loss: 0.017682172491082122\n",
      "SEED: 0, FOLD: 3, EPOCH: 12,train_loss: 0.01771991180283004, valid_loss: 0.01765221410564014\n",
      "SEED: 0, FOLD: 3, EPOCH: 13,train_loss: 0.01764515445203237, valid_loss: 0.017918379099241325\n",
      "SEED: 0, FOLD: 3, EPOCH: 14,train_loss: 0.017486340798221638, valid_loss: 0.0174926581127303\n",
      "SEED: 0, FOLD: 3, EPOCH: 15,train_loss: 0.01730220667693926, valid_loss: 0.01746761572680303\n",
      "SEED: 0, FOLD: 3, EPOCH: 16,train_loss: 0.01716647552245337, valid_loss: 0.017498142618153776\n",
      "SEED: 0, FOLD: 3, EPOCH: 17,train_loss: 0.016920423270135685, valid_loss: 0.017213367351463862\n",
      "SEED: 0, FOLD: 3, EPOCH: 18,train_loss: 0.01668073588550307, valid_loss: 0.01746445707976818\n",
      "SEED: 0, FOLD: 3, EPOCH: 19,train_loss: 0.016372144431469664, valid_loss: 0.017258154574249472\n",
      "SEED: 0, FOLD: 3, EPOCH: 20,train_loss: 0.015915770758537277, valid_loss: 0.017201561480760574\n",
      "SEED: 0, FOLD: 3, EPOCH: 21,train_loss: 0.015410585092731577, valid_loss: 0.017224889461483275\n",
      "SEED: 0, FOLD: 3, EPOCH: 22,train_loss: 0.014901830963250519, valid_loss: 0.017158204157437597\n",
      "SEED: 0, FOLD: 3, EPOCH: 23,train_loss: 0.014444842995346888, valid_loss: 0.017208670558673995\n",
      "SEED: 0, FOLD: 3, EPOCH: 24,train_loss: 0.014231044407664001, valid_loss: 0.017205800568418844\n",
      "(17564, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7369988603868346, valid_loss: 0.7160299829074315\n",
      "SEED: 0, FOLD: 4, EPOCH: 0,train_loss: 0.4671587167388719, valid_loss: 0.027453665541751045\n",
      "SEED: 0, FOLD: 4, EPOCH: 1,train_loss: 0.02159413326855587, valid_loss: 0.01943387607378619\n",
      "SEED: 0, FOLD: 4, EPOCH: 2,train_loss: 0.019247061330015244, valid_loss: 0.018428117409348486\n",
      "SEED: 0, FOLD: 4, EPOCH: 3,train_loss: 0.018563034404339134, valid_loss: 0.01887824721634388\n",
      "SEED: 0, FOLD: 4, EPOCH: 4,train_loss: 0.018197217510770195, valid_loss: 0.018248139055711883\n",
      "SEED: 0, FOLD: 4, EPOCH: 5,train_loss: 0.017936844884863367, valid_loss: 0.01832232086786202\n",
      "SEED: 0, FOLD: 4, EPOCH: 6,train_loss: 0.01782961533256415, valid_loss: 0.018041715611304555\n",
      "SEED: 0, FOLD: 4, EPOCH: 7,train_loss: 0.017863480758893747, valid_loss: 0.018105156027844974\n",
      "SEED: 0, FOLD: 4, EPOCH: 8,train_loss: 0.01775542701985957, valid_loss: 0.01810409788574491\n",
      "SEED: 0, FOLD: 4, EPOCH: 9,train_loss: 0.017801000082028517, valid_loss: 0.018019274941512516\n",
      "SEED: 0, FOLD: 4, EPOCH: 10,train_loss: 0.01778210124567799, valid_loss: 0.018236398909773147\n",
      "SEED: 0, FOLD: 4, EPOCH: 11,train_loss: 0.017769932794128206, valid_loss: 0.017900061128394946\n",
      "SEED: 0, FOLD: 4, EPOCH: 12,train_loss: 0.017707310468498348, valid_loss: 0.017749702877232005\n",
      "SEED: 0, FOLD: 4, EPOCH: 13,train_loss: 0.017559977552003187, valid_loss: 0.01787297214780535\n",
      "SEED: 0, FOLD: 4, EPOCH: 14,train_loss: 0.01747471763603929, valid_loss: 0.01780384337263448\n",
      "SEED: 0, FOLD: 4, EPOCH: 15,train_loss: 0.0172911812753781, valid_loss: 0.017699033713766507\n",
      "SEED: 0, FOLD: 4, EPOCH: 16,train_loss: 0.017087638459127884, valid_loss: 0.01768570350749152\n",
      "SEED: 0, FOLD: 4, EPOCH: 17,train_loss: 0.016802765422271215, valid_loss: 0.017513922761593546\n",
      "SEED: 0, FOLD: 4, EPOCH: 18,train_loss: 0.016556708979001945, valid_loss: 0.017305257304438524\n",
      "SEED: 0, FOLD: 4, EPOCH: 19,train_loss: 0.01617282722145319, valid_loss: 0.017337128333747388\n",
      "SEED: 0, FOLD: 4, EPOCH: 20,train_loss: 0.015771142787475517, valid_loss: 0.017283346982938902\n",
      "SEED: 0, FOLD: 4, EPOCH: 21,train_loss: 0.015302970829973186, valid_loss: 0.017255763762763568\n",
      "SEED: 0, FOLD: 4, EPOCH: 22,train_loss: 0.01473727465296785, valid_loss: 0.017270480495478427\n",
      "SEED: 0, FOLD: 4, EPOCH: 23,train_loss: 0.014283842609628387, valid_loss: 0.017251470418913024\n",
      "SEED: 0, FOLD: 4, EPOCH: 24,train_loss: 0.014056652959814106, valid_loss: 0.017244287500424043\n",
      "(17577, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7343175355075062, valid_loss: 0.6997978414808\n",
      "SEED: 1, FOLD: 0, EPOCH: 0,train_loss: 0.4675089741746585, valid_loss: 0.023369410846914563\n",
      "SEED: 1, FOLD: 0, EPOCH: 1,train_loss: 0.020936691431679588, valid_loss: 0.019524203985929488\n",
      "SEED: 1, FOLD: 0, EPOCH: 2,train_loss: 0.019388981055522312, valid_loss: 0.0179280033867274\n",
      "SEED: 1, FOLD: 0, EPOCH: 3,train_loss: 0.01820250857702416, valid_loss: 0.017418710754386016\n",
      "SEED: 1, FOLD: 0, EPOCH: 4,train_loss: 0.01782371728019654, valid_loss: 0.01737290868269546\n",
      "SEED: 1, FOLD: 0, EPOCH: 5,train_loss: 0.01779305316048904, valid_loss: 0.01759505013802222\n",
      "SEED: 1, FOLD: 0, EPOCH: 6,train_loss: 0.01784762425645106, valid_loss: 0.01740198577088969\n",
      "SEED: 1, FOLD: 0, EPOCH: 7,train_loss: 0.01785014758048498, valid_loss: 0.01749285738915205\n",
      "SEED: 1, FOLD: 0, EPOCH: 8,train_loss: 0.017819309316953455, valid_loss: 0.017356384465737004\n",
      "SEED: 1, FOLD: 0, EPOCH: 9,train_loss: 0.017849957361223474, valid_loss: 0.017544084734150343\n",
      "SEED: 1, FOLD: 0, EPOCH: 10,train_loss: 0.017797179533627586, valid_loss: 0.017424757752035346\n",
      "SEED: 1, FOLD: 0, EPOCH: 11,train_loss: 0.017736071889437197, valid_loss: 0.017448068303721292\n",
      "SEED: 1, FOLD: 0, EPOCH: 12,train_loss: 0.01769438664685341, valid_loss: 0.01727187702698367\n",
      "SEED: 1, FOLD: 0, EPOCH: 13,train_loss: 0.01757840756866811, valid_loss: 0.017078572112534728\n",
      "SEED: 1, FOLD: 0, EPOCH: 14,train_loss: 0.017417135115280962, valid_loss: 0.017004916524248462\n",
      "SEED: 1, FOLD: 0, EPOCH: 15,train_loss: 0.01723404647782445, valid_loss: 0.017019972897001676\n",
      "SEED: 1, FOLD: 0, EPOCH: 16,train_loss: 0.01709788986414239, valid_loss: 0.016869201058787957\n",
      "SEED: 1, FOLD: 0, EPOCH: 17,train_loss: 0.016841579343367746, valid_loss: 0.016875155961939267\n",
      "SEED: 1, FOLD: 0, EPOCH: 18,train_loss: 0.01652669859375211, valid_loss: 0.01678958742746285\n",
      "SEED: 1, FOLD: 0, EPOCH: 19,train_loss: 0.01617655091230636, valid_loss: 0.016829553831900868\n",
      "SEED: 1, FOLD: 0, EPOCH: 20,train_loss: 0.015726694358053846, valid_loss: 0.016851116503987993\n",
      "SEED: 1, FOLD: 0, EPOCH: 21,train_loss: 0.015240114857105242, valid_loss: 0.01663775130042008\n",
      "SEED: 1, FOLD: 0, EPOCH: 22,train_loss: 0.014716805923946094, valid_loss: 0.016667804547718594\n",
      "SEED: 1, FOLD: 0, EPOCH: 23,train_loss: 0.014243627243769773, valid_loss: 0.016664158659321922\n",
      "SEED: 1, FOLD: 0, EPOCH: 24,train_loss: 0.013987318659876135, valid_loss: 0.016672574249761447\n",
      "(17532, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7347548486542528, valid_loss: 0.6960970384734018\n",
      "SEED: 1, FOLD: 1, EPOCH: 0,train_loss: 0.4680755430302263, valid_loss: 0.023574466737253327\n",
      "SEED: 1, FOLD: 1, EPOCH: 1,train_loss: 0.020991936203663367, valid_loss: 0.019067825164113726\n",
      "SEED: 1, FOLD: 1, EPOCH: 2,train_loss: 0.018982793877485894, valid_loss: 0.01839332724256175\n",
      "SEED: 1, FOLD: 1, EPOCH: 3,train_loss: 0.01819739880271419, valid_loss: 0.0179347712546587\n",
      "SEED: 1, FOLD: 1, EPOCH: 4,train_loss: 0.017918945657238908, valid_loss: 0.01784897819161415\n",
      "SEED: 1, FOLD: 1, EPOCH: 5,train_loss: 0.017868135518727513, valid_loss: 0.017899574818355697\n",
      "SEED: 1, FOLD: 1, EPOCH: 6,train_loss: 0.017985358045701564, valid_loss: 0.01787633023091725\n",
      "SEED: 1, FOLD: 1, EPOCH: 7,train_loss: 0.01789901397415321, valid_loss: 0.01800593345292977\n",
      "SEED: 1, FOLD: 1, EPOCH: 8,train_loss: 0.017916661231730975, valid_loss: 0.017724727732794626\n",
      "SEED: 1, FOLD: 1, EPOCH: 9,train_loss: 0.017850624934437065, valid_loss: 0.01774554375026907\n",
      "SEED: 1, FOLD: 1, EPOCH: 10,train_loss: 0.017825279153720307, valid_loss: 0.017633075213858058\n",
      "SEED: 1, FOLD: 1, EPOCH: 11,train_loss: 0.017806278766017324, valid_loss: 0.01771907303482294\n",
      "SEED: 1, FOLD: 1, EPOCH: 12,train_loss: 0.01765766557659546, valid_loss: 0.017526932672730516\n",
      "SEED: 1, FOLD: 1, EPOCH: 13,train_loss: 0.017586247709980848, valid_loss: 0.018247582603778158\n",
      "SEED: 1, FOLD: 1, EPOCH: 14,train_loss: 0.017497988526512236, valid_loss: 0.017590473379407612\n",
      "SEED: 1, FOLD: 1, EPOCH: 15,train_loss: 0.01736886934615182, valid_loss: 0.017251144642276423\n",
      "SEED: 1, FOLD: 1, EPOCH: 16,train_loss: 0.01714752065901556, valid_loss: 0.017338783772928374\n",
      "SEED: 1, FOLD: 1, EPOCH: 17,train_loss: 0.016927604257625385, valid_loss: 0.01730947427983795\n",
      "SEED: 1, FOLD: 1, EPOCH: 18,train_loss: 0.0166288714407243, valid_loss: 0.017177958014820305\n",
      "SEED: 1, FOLD: 1, EPOCH: 19,train_loss: 0.01633016760359063, valid_loss: 0.017219082000000135\n",
      "SEED: 1, FOLD: 1, EPOCH: 20,train_loss: 0.015869808104569023, valid_loss: 0.017018999638301984\n",
      "SEED: 1, FOLD: 1, EPOCH: 21,train_loss: 0.01537142463545077, valid_loss: 0.01708928437105247\n",
      "SEED: 1, FOLD: 1, EPOCH: 22,train_loss: 0.0148944526869994, valid_loss: 0.01707886058304991\n",
      "SEED: 1, FOLD: 1, EPOCH: 23,train_loss: 0.014435463809292682, valid_loss: 0.017086617196244852\n",
      "SEED: 1, FOLD: 1, EPOCH: 24,train_loss: 0.014212652748573, valid_loss: 0.01707524231501988\n",
      "(17585, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7343341168286144, valid_loss: 0.6962700247764587\n",
      "SEED: 1, FOLD: 2, EPOCH: 0,train_loss: 0.46678444706713373, valid_loss: 0.02776231137769563\n",
      "SEED: 1, FOLD: 2, EPOCH: 1,train_loss: 0.021115083517371746, valid_loss: 0.01923627315887383\n",
      "SEED: 1, FOLD: 2, EPOCH: 2,train_loss: 0.01902355758500272, valid_loss: 0.018008571304380893\n",
      "SEED: 1, FOLD: 2, EPOCH: 3,train_loss: 0.018103396466028862, valid_loss: 0.017880888735609394\n",
      "SEED: 1, FOLD: 2, EPOCH: 4,train_loss: 0.01778941465190787, valid_loss: 0.017719634595726216\n",
      "SEED: 1, FOLD: 2, EPOCH: 5,train_loss: 0.017709917989491984, valid_loss: 0.017612244002521038\n",
      "SEED: 1, FOLD: 2, EPOCH: 6,train_loss: 0.01776344959448645, valid_loss: 0.017852546381098882\n",
      "SEED: 1, FOLD: 2, EPOCH: 7,train_loss: 0.017805069954930874, valid_loss: 0.01787837456379618\n",
      "SEED: 1, FOLD: 2, EPOCH: 8,train_loss: 0.01780332145753546, valid_loss: 0.01782841073083026\n",
      "SEED: 1, FOLD: 2, EPOCH: 9,train_loss: 0.017819301542434572, valid_loss: 0.018563518513526236\n",
      "SEED: 1, FOLD: 2, EPOCH: 10,train_loss: 0.017745555783419506, valid_loss: 0.017779215265597614\n",
      "SEED: 1, FOLD: 2, EPOCH: 11,train_loss: 0.017668491411630228, valid_loss: 0.017604059034160204\n",
      "SEED: 1, FOLD: 2, EPOCH: 12,train_loss: 0.017639669225267742, valid_loss: 0.017630304529198577\n",
      "SEED: 1, FOLD: 2, EPOCH: 13,train_loss: 0.017530127759159044, valid_loss: 0.01770278715661594\n",
      "SEED: 1, FOLD: 2, EPOCH: 14,train_loss: 0.017465391675469236, valid_loss: 0.0175380514934659\n",
      "SEED: 1, FOLD: 2, EPOCH: 15,train_loss: 0.01730513082061341, valid_loss: 0.01731290939663138\n",
      "SEED: 1, FOLD: 2, EPOCH: 16,train_loss: 0.017127729554161215, valid_loss: 0.017350034655204842\n",
      "SEED: 1, FOLD: 2, EPOCH: 17,train_loss: 0.01687023461377923, valid_loss: 0.01723368423325675\n",
      "SEED: 1, FOLD: 2, EPOCH: 18,train_loss: 0.016562168560652197, valid_loss: 0.0172472941290055\n",
      "SEED: 1, FOLD: 2, EPOCH: 19,train_loss: 0.016268817491937374, valid_loss: 0.01706999923501696\n",
      "SEED: 1, FOLD: 2, EPOCH: 20,train_loss: 0.015725396863738264, valid_loss: 0.01719317747546094\n",
      "SEED: 1, FOLD: 2, EPOCH: 21,train_loss: 0.015243825192252794, valid_loss: 0.01716147820864405\n",
      "SEED: 1, FOLD: 2, EPOCH: 22,train_loss: 0.014698464342433474, valid_loss: 0.01715906241110393\n",
      "SEED: 1, FOLD: 2, EPOCH: 23,train_loss: 0.014249020067138084, valid_loss: 0.017129764493022646\n",
      "SEED: 1, FOLD: 2, EPOCH: 24,train_loss: 0.01397094451079982, valid_loss: 0.017122575055275646\n",
      "(17593, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7345684861791306, valid_loss: 0.6971183163779122\n",
      "SEED: 1, FOLD: 3, EPOCH: 0,train_loss: 0.4683806936432054, valid_loss: 0.024321717023849488\n",
      "SEED: 1, FOLD: 3, EPOCH: 1,train_loss: 0.020946218294725902, valid_loss: 0.019461645452039582\n",
      "SEED: 1, FOLD: 3, EPOCH: 2,train_loss: 0.018871326228954655, valid_loss: 0.018713766815406936\n",
      "SEED: 1, FOLD: 3, EPOCH: 3,train_loss: 0.01809849030594679, valid_loss: 0.018472569489053316\n",
      "SEED: 1, FOLD: 3, EPOCH: 4,train_loss: 0.017879825058406677, valid_loss: 0.018314032842006\n",
      "SEED: 1, FOLD: 3, EPOCH: 5,train_loss: 0.017797133574883144, valid_loss: 0.018486282495515687\n",
      "SEED: 1, FOLD: 3, EPOCH: 6,train_loss: 0.017719772205674562, valid_loss: 0.018294070128883635\n",
      "SEED: 1, FOLD: 3, EPOCH: 7,train_loss: 0.017770222928105057, valid_loss: 0.01832563022949866\n",
      "SEED: 1, FOLD: 3, EPOCH: 8,train_loss: 0.017750895116478205, valid_loss: 0.01858476187501635\n",
      "SEED: 1, FOLD: 3, EPOCH: 9,train_loss: 0.017788085809814325, valid_loss: 0.018394978610532624\n",
      "SEED: 1, FOLD: 3, EPOCH: 10,train_loss: 0.017723421437962763, valid_loss: 0.01831605884113482\n",
      "SEED: 1, FOLD: 3, EPOCH: 11,train_loss: 0.017708264412763325, valid_loss: 0.018390878183501106\n",
      "SEED: 1, FOLD: 3, EPOCH: 12,train_loss: 0.01758909840946612, valid_loss: 0.018149340179349695\n",
      "SEED: 1, FOLD: 3, EPOCH: 13,train_loss: 0.017509338101777044, valid_loss: 0.018339123763144016\n",
      "SEED: 1, FOLD: 3, EPOCH: 14,train_loss: 0.017389383571951286, valid_loss: 0.018077858723700047\n",
      "SEED: 1, FOLD: 3, EPOCH: 15,train_loss: 0.01718466418484847, valid_loss: 0.018131616339087487\n",
      "SEED: 1, FOLD: 3, EPOCH: 16,train_loss: 0.017042458185629137, valid_loss: 0.017890550488872187\n",
      "SEED: 1, FOLD: 3, EPOCH: 17,train_loss: 0.016794202376858913, valid_loss: 0.01789151629699128\n",
      "SEED: 1, FOLD: 3, EPOCH: 18,train_loss: 0.016622447725925325, valid_loss: 0.017903464766485352\n",
      "SEED: 1, FOLD: 3, EPOCH: 19,train_loss: 0.01616275056089828, valid_loss: 0.017871386078851564\n",
      "SEED: 1, FOLD: 3, EPOCH: 20,train_loss: 0.015742763276279405, valid_loss: 0.01788113053355898\n",
      "SEED: 1, FOLD: 3, EPOCH: 21,train_loss: 0.015259949827863686, valid_loss: 0.017749623847859247\n",
      "SEED: 1, FOLD: 3, EPOCH: 22,train_loss: 0.014748250498719837, valid_loss: 0.01775160027401788\n",
      "SEED: 1, FOLD: 3, EPOCH: 23,train_loss: 0.014282053228521692, valid_loss: 0.017774486195828235\n",
      "SEED: 1, FOLD: 3, EPOCH: 24,train_loss: 0.01405034638752324, valid_loss: 0.017751586250960828\n",
      "(17505, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.734495011559368, valid_loss: 0.6975872635841369\n",
      "SEED: 1, FOLD: 4, EPOCH: 0,train_loss: 0.46910980517846823, valid_loss: 0.02537475318780967\n",
      "SEED: 1, FOLD: 4, EPOCH: 1,train_loss: 0.020924853555259915, valid_loss: 0.019582399725914003\n",
      "SEED: 1, FOLD: 4, EPOCH: 2,train_loss: 0.019236238340228577, valid_loss: 0.018562723589794976\n",
      "SEED: 1, FOLD: 4, EPOCH: 3,train_loss: 0.01817060282358723, valid_loss: 0.01847739044044699\n",
      "SEED: 1, FOLD: 4, EPOCH: 4,train_loss: 0.017895035228154957, valid_loss: 0.018235306069254876\n",
      "SEED: 1, FOLD: 4, EPOCH: 5,train_loss: 0.017833876763436483, valid_loss: 0.018294956375445637\n",
      "SEED: 1, FOLD: 4, EPOCH: 6,train_loss: 0.017750516153165023, valid_loss: 0.01830607745796442\n",
      "SEED: 1, FOLD: 4, EPOCH: 7,train_loss: 0.017790786072231123, valid_loss: 0.018298335213746342\n",
      "SEED: 1, FOLD: 4, EPOCH: 8,train_loss: 0.017840111662164655, valid_loss: 0.018653008395007678\n",
      "SEED: 1, FOLD: 4, EPOCH: 9,train_loss: 0.01782336413017372, valid_loss: 0.01872547705258642\n",
      "SEED: 1, FOLD: 4, EPOCH: 10,train_loss: 0.01772270093325281, valid_loss: 0.018380294234624932\n",
      "SEED: 1, FOLD: 4, EPOCH: 11,train_loss: 0.017730314774017264, valid_loss: 0.01805935369006225\n",
      "SEED: 1, FOLD: 4, EPOCH: 12,train_loss: 0.0176879005968897, valid_loss: 0.01819381650005068\n",
      "SEED: 1, FOLD: 4, EPOCH: 13,train_loss: 0.017562400182559543, valid_loss: 0.017932607047259807\n",
      "SEED: 1, FOLD: 4, EPOCH: 14,train_loss: 0.01741086802424958, valid_loss: 0.018154873086937837\n",
      "SEED: 1, FOLD: 4, EPOCH: 15,train_loss: 0.017270198268611935, valid_loss: 0.017833658174744676\n",
      "SEED: 1, FOLD: 4, EPOCH: 16,train_loss: 0.017097044219500826, valid_loss: 0.01789132910115378\n",
      "SEED: 1, FOLD: 4, EPOCH: 17,train_loss: 0.016885021110031293, valid_loss: 0.017992102727293968\n",
      "SEED: 1, FOLD: 4, EPOCH: 18,train_loss: 0.01660954912811735, valid_loss: 0.01780526643352849\n",
      "SEED: 1, FOLD: 4, EPOCH: 19,train_loss: 0.016230031902337596, valid_loss: 0.017743022606841154\n",
      "SEED: 1, FOLD: 4, EPOCH: 20,train_loss: 0.0158346276730299, valid_loss: 0.017703553369002683\n",
      "SEED: 1, FOLD: 4, EPOCH: 21,train_loss: 0.01537717699351972, valid_loss: 0.017688303121498654\n",
      "SEED: 1, FOLD: 4, EPOCH: 22,train_loss: 0.014870009854109618, valid_loss: 0.01767020547496421\n",
      "SEED: 1, FOLD: 4, EPOCH: 23,train_loss: 0.014433360087556125, valid_loss: 0.017625835883830276\n",
      "SEED: 1, FOLD: 4, EPOCH: 24,train_loss: 0.014197510701135127, valid_loss: 0.01762048096529075\n",
      "(17579, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7376675195452096, valid_loss: 0.703517780985151\n",
      "SEED: 2, FOLD: 0, EPOCH: 0,train_loss: 0.4645664579626443, valid_loss: 0.02501989315663065\n",
      "SEED: 2, FOLD: 0, EPOCH: 1,train_loss: 0.021284343539804653, valid_loss: 0.019195250581417765\n",
      "SEED: 2, FOLD: 0, EPOCH: 2,train_loss: 0.019191668895275696, valid_loss: 0.018546509396817002\n",
      "SEED: 2, FOLD: 0, EPOCH: 3,train_loss: 0.018380517160277002, valid_loss: 0.017463121909115996\n",
      "SEED: 2, FOLD: 0, EPOCH: 4,train_loss: 0.017986490310210247, valid_loss: 0.018322157327617918\n",
      "SEED: 2, FOLD: 0, EPOCH: 5,train_loss: 0.01804875501472017, valid_loss: 0.017911937965878418\n",
      "SEED: 2, FOLD: 0, EPOCH: 6,train_loss: 0.01805423899297265, valid_loss: 0.017410297745040486\n",
      "SEED: 2, FOLD: 0, EPOCH: 7,train_loss: 0.017983938540345516, valid_loss: 0.017809842926050937\n",
      "SEED: 2, FOLD: 0, EPOCH: 8,train_loss: 0.017969804923927437, valid_loss: 0.01798191557505301\n",
      "SEED: 2, FOLD: 0, EPOCH: 9,train_loss: 0.017928830044263083, valid_loss: 0.01754824412720544\n",
      "SEED: 2, FOLD: 0, EPOCH: 10,train_loss: 0.017887426627988832, valid_loss: 0.017563401109405925\n",
      "SEED: 2, FOLD: 0, EPOCH: 11,train_loss: 0.01787017271651522, valid_loss: 0.017473068993006435\n",
      "SEED: 2, FOLD: 0, EPOCH: 12,train_loss: 0.017754941969516054, valid_loss: 0.017265888516392026\n",
      "SEED: 2, FOLD: 0, EPOCH: 13,train_loss: 0.017726878365636734, valid_loss: 0.01902777903846332\n",
      "SEED: 2, FOLD: 0, EPOCH: 14,train_loss: 0.017602436845123335, valid_loss: 0.016952018572815825\n",
      "SEED: 2, FOLD: 0, EPOCH: 15,train_loss: 0.017354707010900198, valid_loss: 0.01717286857643298\n",
      "SEED: 2, FOLD: 0, EPOCH: 16,train_loss: 0.01718713752790422, valid_loss: 0.017014189729733127\n",
      "SEED: 2, FOLD: 0, EPOCH: 17,train_loss: 0.016969185491240976, valid_loss: 0.016975846700370313\n",
      "SEED: 2, FOLD: 0, EPOCH: 18,train_loss: 0.0166993067410869, valid_loss: 0.016802790920649256\n",
      "SEED: 2, FOLD: 0, EPOCH: 19,train_loss: 0.016355046354558155, valid_loss: 0.016802911327353547\n",
      "SEED: 2, FOLD: 0, EPOCH: 20,train_loss: 0.015969286733509405, valid_loss: 0.016797254766736713\n",
      "SEED: 2, FOLD: 0, EPOCH: 21,train_loss: 0.015462950060980907, valid_loss: 0.01669745541044644\n",
      "SEED: 2, FOLD: 0, EPOCH: 22,train_loss: 0.014934580239966728, valid_loss: 0.016640895871179444\n",
      "SEED: 2, FOLD: 0, EPOCH: 23,train_loss: 0.0145205388965922, valid_loss: 0.016648013623697416\n",
      "SEED: 2, FOLD: 0, EPOCH: 24,train_loss: 0.014267868895515583, valid_loss: 0.01661794630012342\n",
      "(17572, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7380742547304734, valid_loss: 0.705209459577288\n",
      "SEED: 2, FOLD: 1, EPOCH: 0,train_loss: 0.46821850501810724, valid_loss: 0.024182651937007905\n",
      "SEED: 2, FOLD: 1, EPOCH: 1,train_loss: 0.021326126274315342, valid_loss: 0.01925636237221105\n",
      "SEED: 2, FOLD: 1, EPOCH: 2,train_loss: 0.019045563698138878, valid_loss: 0.017962081570710456\n",
      "SEED: 2, FOLD: 1, EPOCH: 3,train_loss: 0.018281925456139488, valid_loss: 0.017809630717550005\n",
      "SEED: 2, FOLD: 1, EPOCH: 4,train_loss: 0.018097296370652275, valid_loss: 0.01756614249731813\n",
      "SEED: 2, FOLD: 1, EPOCH: 5,train_loss: 0.017956302750963663, valid_loss: 0.01777110823563167\n",
      "SEED: 2, FOLD: 1, EPOCH: 6,train_loss: 0.017981967753798202, valid_loss: 0.017443788317697387\n",
      "SEED: 2, FOLD: 1, EPOCH: 7,train_loss: 0.01798298338806068, valid_loss: 0.017435119301080704\n",
      "SEED: 2, FOLD: 1, EPOCH: 8,train_loss: 0.017973382349895393, valid_loss: 0.017802718920367104\n",
      "SEED: 2, FOLD: 1, EPOCH: 9,train_loss: 0.01797380033151611, valid_loss: 0.017543054026152406\n",
      "SEED: 2, FOLD: 1, EPOCH: 10,train_loss: 0.017950551523624556, valid_loss: 0.017546614525573594\n",
      "SEED: 2, FOLD: 1, EPOCH: 11,train_loss: 0.017868985104766012, valid_loss: 0.017669624595769814\n",
      "SEED: 2, FOLD: 1, EPOCH: 12,train_loss: 0.017787919298786183, valid_loss: 0.017433213575610094\n",
      "SEED: 2, FOLD: 1, EPOCH: 13,train_loss: 0.017715155329231336, valid_loss: 0.017298941340829644\n",
      "SEED: 2, FOLD: 1, EPOCH: 14,train_loss: 0.017560758432238432, valid_loss: 0.017244331778160163\n",
      "SEED: 2, FOLD: 1, EPOCH: 15,train_loss: 0.017394706242434357, valid_loss: 0.017171558045915195\n",
      "SEED: 2, FOLD: 1, EPOCH: 16,train_loss: 0.017256448767485395, valid_loss: 0.017111200386924402\n",
      "SEED: 2, FOLD: 1, EPOCH: 17,train_loss: 0.016958721731182024, valid_loss: 0.016907386774463313\n",
      "SEED: 2, FOLD: 1, EPOCH: 18,train_loss: 0.01672554322504911, valid_loss: 0.016968036948570183\n",
      "SEED: 2, FOLD: 1, EPOCH: 19,train_loss: 0.01636136900228651, valid_loss: 0.01685728228517941\n",
      "SEED: 2, FOLD: 1, EPOCH: 20,train_loss: 0.0159324470947942, valid_loss: 0.016749046902571407\n",
      "SEED: 2, FOLD: 1, EPOCH: 21,train_loss: 0.01546332272498504, valid_loss: 0.01680394863443715\n",
      "SEED: 2, FOLD: 1, EPOCH: 22,train_loss: 0.014928264273465544, valid_loss: 0.01667415869555303\n",
      "SEED: 2, FOLD: 1, EPOCH: 23,train_loss: 0.014517438280787588, valid_loss: 0.016688722212399754\n",
      "SEED: 2, FOLD: 1, EPOCH: 24,train_loss: 0.01426157914776949, valid_loss: 0.016693754520799433\n",
      "(17584, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7376708854799685, valid_loss: 0.7041055287633623\n",
      "SEED: 2, FOLD: 2, EPOCH: 0,train_loss: 0.46666766264462384, valid_loss: 0.024030172984514916\n",
      "SEED: 2, FOLD: 2, EPOCH: 1,train_loss: 0.020811865085978872, valid_loss: 0.018670768663287162\n",
      "SEED: 2, FOLD: 2, EPOCH: 2,train_loss: 0.01895308043078884, valid_loss: 0.018106615410319396\n",
      "SEED: 2, FOLD: 2, EPOCH: 3,train_loss: 0.018260171461472477, valid_loss: 0.018143952531473977\n",
      "SEED: 2, FOLD: 2, EPOCH: 4,train_loss: 0.018014923709890118, valid_loss: 0.018073129946632044\n",
      "SEED: 2, FOLD: 2, EPOCH: 5,train_loss: 0.01782210884561789, valid_loss: 0.017934735624917916\n",
      "SEED: 2, FOLD: 2, EPOCH: 6,train_loss: 0.017900025195347658, valid_loss: 0.01803150089191539\n",
      "SEED: 2, FOLD: 2, EPOCH: 7,train_loss: 0.017853426639044632, valid_loss: 0.01803522032818624\n",
      "SEED: 2, FOLD: 2, EPOCH: 8,train_loss: 0.0177960861204327, valid_loss: 0.01830473371914455\n",
      "SEED: 2, FOLD: 2, EPOCH: 9,train_loss: 0.017795157929261524, valid_loss: 0.018146421760320663\n",
      "SEED: 2, FOLD: 2, EPOCH: 10,train_loss: 0.01775498026172104, valid_loss: 0.01811933754278081\n",
      "SEED: 2, FOLD: 2, EPOCH: 11,train_loss: 0.017678251759945484, valid_loss: 0.01790441181510687\n",
      "SEED: 2, FOLD: 2, EPOCH: 12,train_loss: 0.017661755978791178, valid_loss: 0.017641896594847953\n",
      "SEED: 2, FOLD: 2, EPOCH: 13,train_loss: 0.01757973253025093, valid_loss: 0.017611228089247432\n",
      "SEED: 2, FOLD: 2, EPOCH: 14,train_loss: 0.017390576953851225, valid_loss: 0.017649143455283983\n",
      "SEED: 2, FOLD: 2, EPOCH: 15,train_loss: 0.017232986814949825, valid_loss: 0.017549104349953788\n",
      "SEED: 2, FOLD: 2, EPOCH: 16,train_loss: 0.017054931004194245, valid_loss: 0.017556228089545454\n",
      "SEED: 2, FOLD: 2, EPOCH: 17,train_loss: 0.01682525939321604, valid_loss: 0.017563378012606077\n",
      "SEED: 2, FOLD: 2, EPOCH: 18,train_loss: 0.016550458616752556, valid_loss: 0.0174175904531564\n",
      "SEED: 2, FOLD: 2, EPOCH: 19,train_loss: 0.016172052948209253, valid_loss: 0.017476718606693403\n",
      "SEED: 2, FOLD: 2, EPOCH: 20,train_loss: 0.01574641630134505, valid_loss: 0.017435292819780963\n",
      "SEED: 2, FOLD: 2, EPOCH: 21,train_loss: 0.015267117650828499, valid_loss: 0.01743038794291871\n",
      "SEED: 2, FOLD: 2, EPOCH: 22,train_loss: 0.014744316362708376, valid_loss: 0.017428426444530486\n",
      "SEED: 2, FOLD: 2, EPOCH: 23,train_loss: 0.01432589319386128, valid_loss: 0.017441715353301593\n",
      "SEED: 2, FOLD: 2, EPOCH: 24,train_loss: 0.014069146645403858, valid_loss: 0.017445421644619534\n",
      "(17468, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7377382495107442, valid_loss: 0.7073004245758057\n",
      "SEED: 2, FOLD: 3, EPOCH: 0,train_loss: 0.467584020410576, valid_loss: 0.02386944256722927\n",
      "SEED: 2, FOLD: 3, EPOCH: 1,train_loss: 0.02060776619906843, valid_loss: 0.01877283017550196\n",
      "SEED: 2, FOLD: 3, EPOCH: 2,train_loss: 0.019017873359096313, valid_loss: 0.018505061524254934\n",
      "SEED: 2, FOLD: 3, EPOCH: 3,train_loss: 0.018274106030916646, valid_loss: 0.01809269857725927\n",
      "SEED: 2, FOLD: 3, EPOCH: 4,train_loss: 0.018159017429082065, valid_loss: 0.018112047814897128\n",
      "SEED: 2, FOLD: 3, EPOCH: 5,train_loss: 0.01787112943528995, valid_loss: 0.018019574587898594\n",
      "SEED: 2, FOLD: 3, EPOCH: 6,train_loss: 0.017833067355745465, valid_loss: 0.018280114127056938\n",
      "SEED: 2, FOLD: 3, EPOCH: 7,train_loss: 0.017808186230215715, valid_loss: 0.01824305685503142\n",
      "SEED: 2, FOLD: 3, EPOCH: 8,train_loss: 0.017818453381803347, valid_loss: 0.017850228079727717\n",
      "SEED: 2, FOLD: 3, EPOCH: 9,train_loss: 0.01775660477306721, valid_loss: 0.018060520477592944\n",
      "SEED: 2, FOLD: 3, EPOCH: 10,train_loss: 0.017718793246487195, valid_loss: 0.01810166101370539\n",
      "SEED: 2, FOLD: 3, EPOCH: 11,train_loss: 0.017622010911522556, valid_loss: 0.01807480212301016\n",
      "SEED: 2, FOLD: 3, EPOCH: 12,train_loss: 0.01763830287042108, valid_loss: 0.018223172266568458\n",
      "SEED: 2, FOLD: 3, EPOCH: 13,train_loss: 0.01757995256080027, valid_loss: 0.017715790016310556\n",
      "SEED: 2, FOLD: 3, EPOCH: 14,train_loss: 0.017400642047996503, valid_loss: 0.017826811277440617\n",
      "SEED: 2, FOLD: 3, EPOCH: 15,train_loss: 0.01729326350546449, valid_loss: 0.017866408904748304\n",
      "SEED: 2, FOLD: 3, EPOCH: 16,train_loss: 0.01706170965747459, valid_loss: 0.017630552048129695\n",
      "SEED: 2, FOLD: 3, EPOCH: 17,train_loss: 0.016900345621916064, valid_loss: 0.017616798356175422\n",
      "SEED: 2, FOLD: 3, EPOCH: 18,train_loss: 0.016574688595685647, valid_loss: 0.017404989738549505\n",
      "SEED: 2, FOLD: 3, EPOCH: 19,train_loss: 0.016276300979954916, valid_loss: 0.017321475994374072\n",
      "SEED: 2, FOLD: 3, EPOCH: 20,train_loss: 0.01587269452475283, valid_loss: 0.01736695556236165\n",
      "SEED: 2, FOLD: 3, EPOCH: 21,train_loss: 0.015337857689681279, valid_loss: 0.017381312352206024\n",
      "SEED: 2, FOLD: 3, EPOCH: 22,train_loss: 0.014867065848279609, valid_loss: 0.01731157765856811\n",
      "SEED: 2, FOLD: 3, EPOCH: 23,train_loss: 0.014410167069167552, valid_loss: 0.01731313176985298\n",
      "SEED: 2, FOLD: 3, EPOCH: 24,train_loss: 0.014214009243695841, valid_loss: 0.0173100583255291\n",
      "(17589, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7378755669662918, valid_loss: 0.7079552071435111\n",
      "SEED: 2, FOLD: 4, EPOCH: 0,train_loss: 0.46737065459129173, valid_loss: 0.025833638172064508\n",
      "SEED: 2, FOLD: 4, EPOCH: 1,train_loss: 0.02089663362805394, valid_loss: 0.020107740163803102\n",
      "SEED: 2, FOLD: 4, EPOCH: 2,train_loss: 0.019133408135478047, valid_loss: 0.01901278809777328\n",
      "SEED: 2, FOLD: 4, EPOCH: 3,train_loss: 0.01834648800338956, valid_loss: 0.019174419449908393\n",
      "SEED: 2, FOLD: 4, EPOCH: 4,train_loss: 0.017998143436684124, valid_loss: 0.018720730606998717\n",
      "SEED: 2, FOLD: 4, EPOCH: 5,train_loss: 0.017706071741986965, valid_loss: 0.018547821789979935\n",
      "SEED: 2, FOLD: 4, EPOCH: 6,train_loss: 0.017734339764422697, valid_loss: 0.018581019368554864\n",
      "SEED: 2, FOLD: 4, EPOCH: 7,train_loss: 0.0176328069705894, valid_loss: 0.018376571285937515\n",
      "SEED: 2, FOLD: 4, EPOCH: 8,train_loss: 0.017601347055988037, valid_loss: 0.019335749905024256\n",
      "SEED: 2, FOLD: 4, EPOCH: 9,train_loss: 0.01756416329358151, valid_loss: 0.01864714263273137\n",
      "SEED: 2, FOLD: 4, EPOCH: 10,train_loss: 0.017490840361764032, valid_loss: 0.018428649620286057\n",
      "SEED: 2, FOLD: 4, EPOCH: 11,train_loss: 0.017436110421313322, valid_loss: 0.018586975069982664\n",
      "SEED: 2, FOLD: 4, EPOCH: 12,train_loss: 0.017387691945971354, valid_loss: 0.01841046983110053\n",
      "SEED: 2, FOLD: 4, EPOCH: 13,train_loss: 0.017224317598764017, valid_loss: 0.018133822216519286\n",
      "SEED: 2, FOLD: 4, EPOCH: 14,train_loss: 0.017050550231521112, valid_loss: 0.018169788111533438\n",
      "SEED: 2, FOLD: 4, EPOCH: 15,train_loss: 0.016920983960069177, valid_loss: 0.018197330965527465\n",
      "SEED: 2, FOLD: 4, EPOCH: 16,train_loss: 0.01666189060020058, valid_loss: 0.018131135404109953\n",
      "SEED: 2, FOLD: 4, EPOCH: 17,train_loss: 0.016472004968133093, valid_loss: 0.01824084044034992\n",
      "SEED: 2, FOLD: 4, EPOCH: 18,train_loss: 0.01615677590387455, valid_loss: 0.017967822030186653\n",
      "SEED: 2, FOLD: 4, EPOCH: 19,train_loss: 0.01569480965912774, valid_loss: 0.01802265638751643\n",
      "SEED: 2, FOLD: 4, EPOCH: 20,train_loss: 0.015219159869720106, valid_loss: 0.018015176696436746\n",
      "SEED: 2, FOLD: 4, EPOCH: 21,train_loss: 0.014743355399780516, valid_loss: 0.018087047897279263\n",
      "SEED: 2, FOLD: 4, EPOCH: 22,train_loss: 0.01418639344257721, valid_loss: 0.018107281305960246\n",
      "SEED: 2, FOLD: 4, EPOCH: 23,train_loss: 0.013681787194387205, valid_loss: 0.018039994074829986\n",
      "SEED: 2, FOLD: 4, EPOCH: 24,train_loss: 0.013419297523796558, valid_loss: 0.018049467700932707\n",
      "(17591, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7345065003719883, valid_loss: 0.6981497696467809\n",
      "SEED: 3, FOLD: 0, EPOCH: 0,train_loss: 0.46689722603321937, valid_loss: 0.02328245203409876\n",
      "SEED: 3, FOLD: 0, EPOCH: 1,train_loss: 0.020773719496809055, valid_loss: 0.018408745041649258\n",
      "SEED: 3, FOLD: 0, EPOCH: 2,train_loss: 0.01966549998716168, valid_loss: 0.01839225839025208\n",
      "SEED: 3, FOLD: 0, EPOCH: 3,train_loss: 0.01829636339908061, valid_loss: 0.01789775994340224\n",
      "SEED: 3, FOLD: 0, EPOCH: 4,train_loss: 0.01787707010500025, valid_loss: 0.018019183878121632\n",
      "SEED: 3, FOLD: 0, EPOCH: 5,train_loss: 0.017712920890662117, valid_loss: 0.017707520151244743\n",
      "SEED: 3, FOLD: 0, EPOCH: 6,train_loss: 0.017780414330300646, valid_loss: 0.017765541461163332\n",
      "SEED: 3, FOLD: 0, EPOCH: 7,train_loss: 0.01776098057060786, valid_loss: 0.01752715509917055\n",
      "SEED: 3, FOLD: 0, EPOCH: 8,train_loss: 0.017778758857183267, valid_loss: 0.017666646931320428\n",
      "SEED: 3, FOLD: 0, EPOCH: 9,train_loss: 0.017702940480270678, valid_loss: 0.017526364136886383\n",
      "SEED: 3, FOLD: 0, EPOCH: 10,train_loss: 0.017775250160121832, valid_loss: 0.017746160186028908\n",
      "SEED: 3, FOLD: 0, EPOCH: 11,train_loss: 0.017652424322306248, valid_loss: 0.017869629611128143\n",
      "SEED: 3, FOLD: 0, EPOCH: 12,train_loss: 0.017657446222838716, valid_loss: 0.017664362503481763\n",
      "SEED: 3, FOLD: 0, EPOCH: 13,train_loss: 0.017488290899959597, valid_loss: 0.017590422801939506\n",
      "SEED: 3, FOLD: 0, EPOCH: 14,train_loss: 0.01741589156343885, valid_loss: 0.017342291579448752\n",
      "SEED: 3, FOLD: 0, EPOCH: 15,train_loss: 0.017280994826738817, valid_loss: 0.01740482480464769\n",
      "SEED: 3, FOLD: 0, EPOCH: 16,train_loss: 0.01707320347212363, valid_loss: 0.017357227991202047\n",
      "SEED: 3, FOLD: 0, EPOCH: 17,train_loss: 0.01681731378092714, valid_loss: 0.017180162139369973\n",
      "SEED: 3, FOLD: 0, EPOCH: 18,train_loss: 0.016548925875753597, valid_loss: 0.017063455104029606\n",
      "SEED: 3, FOLD: 0, EPOCH: 19,train_loss: 0.016175416460179764, valid_loss: 0.017107590510776\n",
      "SEED: 3, FOLD: 0, EPOCH: 20,train_loss: 0.01578290235467147, valid_loss: 0.017161673477052577\n",
      "SEED: 3, FOLD: 0, EPOCH: 21,train_loss: 0.01531163369561883, valid_loss: 0.016992112804603363\n",
      "SEED: 3, FOLD: 0, EPOCH: 22,train_loss: 0.014813747405465962, valid_loss: 0.017112120580194252\n",
      "SEED: 3, FOLD: 0, EPOCH: 23,train_loss: 0.014420944535969824, valid_loss: 0.017035836054544364\n",
      "SEED: 3, FOLD: 0, EPOCH: 24,train_loss: 0.0141552175341201, valid_loss: 0.017065129918046297\n",
      "(17572, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7347343805907429, valid_loss: 0.6954673750059945\n",
      "SEED: 3, FOLD: 1, EPOCH: 0,train_loss: 0.465605361967523, valid_loss: 0.023631288430520467\n",
      "SEED: 3, FOLD: 1, EPOCH: 1,train_loss: 0.020956821645191616, valid_loss: 0.019062584851469312\n",
      "SEED: 3, FOLD: 1, EPOCH: 2,train_loss: 0.019152177065826843, valid_loss: 0.017961683071085383\n",
      "SEED: 3, FOLD: 1, EPOCH: 3,train_loss: 0.01824228348804341, valid_loss: 0.01790678740612098\n",
      "SEED: 3, FOLD: 1, EPOCH: 4,train_loss: 0.017888656864617613, valid_loss: 0.017915785578744754\n",
      "SEED: 3, FOLD: 1, EPOCH: 5,train_loss: 0.017979784598709015, valid_loss: 0.01796813506100859\n",
      "SEED: 3, FOLD: 1, EPOCH: 6,train_loss: 0.017950626454599525, valid_loss: 0.0183409185814006\n",
      "SEED: 3, FOLD: 1, EPOCH: 7,train_loss: 0.017893233478231275, valid_loss: 0.017783145393644062\n",
      "SEED: 3, FOLD: 1, EPOCH: 8,train_loss: 0.017891516774028973, valid_loss: 0.017857636431498188\n",
      "SEED: 3, FOLD: 1, EPOCH: 9,train_loss: 0.017894912774310164, valid_loss: 0.017766389144318443\n",
      "SEED: 3, FOLD: 1, EPOCH: 10,train_loss: 0.017834111474508394, valid_loss: 0.017719576507806777\n",
      "SEED: 3, FOLD: 1, EPOCH: 11,train_loss: 0.017780253042777378, valid_loss: 0.017820389116449016\n",
      "SEED: 3, FOLD: 1, EPOCH: 12,train_loss: 0.01770759114752645, valid_loss: 0.01776063625833818\n",
      "SEED: 3, FOLD: 1, EPOCH: 13,train_loss: 0.017633601024314976, valid_loss: 0.017475493757852487\n",
      "SEED: 3, FOLD: 1, EPOCH: 14,train_loss: 0.017499563554166885, valid_loss: 0.017602199928036757\n",
      "SEED: 3, FOLD: 1, EPOCH: 15,train_loss: 0.017350728454851153, valid_loss: 0.017661579538668905\n",
      "SEED: 3, FOLD: 1, EPOCH: 16,train_loss: 0.01719277760391866, valid_loss: 0.017418793934796537\n",
      "SEED: 3, FOLD: 1, EPOCH: 17,train_loss: 0.016937808383364176, valid_loss: 0.017219713809234757\n",
      "SEED: 3, FOLD: 1, EPOCH: 18,train_loss: 0.016642149119381455, valid_loss: 0.01728591075433152\n",
      "SEED: 3, FOLD: 1, EPOCH: 19,train_loss: 0.016348535944100306, valid_loss: 0.017137677701456206\n",
      "SEED: 3, FOLD: 1, EPOCH: 20,train_loss: 0.015939526563591284, valid_loss: 0.017208667392177242\n",
      "SEED: 3, FOLD: 1, EPOCH: 21,train_loss: 0.015461678603205128, valid_loss: 0.017191023193299772\n",
      "SEED: 3, FOLD: 1, EPOCH: 22,train_loss: 0.01493595643778858, valid_loss: 0.01717908475548029\n",
      "SEED: 3, FOLD: 1, EPOCH: 23,train_loss: 0.014510288578120695, valid_loss: 0.017120787714208874\n",
      "SEED: 3, FOLD: 1, EPOCH: 24,train_loss: 0.014253613444558088, valid_loss: 0.017120347038975785\n",
      "(17520, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7344431237582743, valid_loss: 0.6929103561810085\n",
      "SEED: 3, FOLD: 2, EPOCH: 0,train_loss: 0.46690518116700824, valid_loss: 0.02411137143416064\n",
      "SEED: 3, FOLD: 2, EPOCH: 1,train_loss: 0.021009410235242252, valid_loss: 0.019535962332572255\n",
      "SEED: 3, FOLD: 2, EPOCH: 2,train_loss: 0.019225075772970262, valid_loss: 0.018946529286248345\n",
      "SEED: 3, FOLD: 2, EPOCH: 3,train_loss: 0.018290652030140814, valid_loss: 0.01858159527182579\n",
      "SEED: 3, FOLD: 2, EPOCH: 4,train_loss: 0.018017885676265635, valid_loss: 0.018317481156970773\n",
      "SEED: 3, FOLD: 2, EPOCH: 5,train_loss: 0.017878826836763072, valid_loss: 0.018229247576424055\n",
      "SEED: 3, FOLD: 2, EPOCH: 6,train_loss: 0.017887096906447932, valid_loss: 0.018157773864056384\n",
      "SEED: 3, FOLD: 2, EPOCH: 7,train_loss: 0.017824489779661605, valid_loss: 0.018110680181000913\n",
      "SEED: 3, FOLD: 2, EPOCH: 8,train_loss: 0.01784047730484583, valid_loss: 0.01786496878734657\n",
      "SEED: 3, FOLD: 2, EPOCH: 9,train_loss: 0.017834554120463177, valid_loss: 0.017963667107479913\n",
      "SEED: 3, FOLD: 2, EPOCH: 10,train_loss: 0.017784514226508837, valid_loss: 0.018006308908973423\n",
      "SEED: 3, FOLD: 2, EPOCH: 11,train_loss: 0.01768113467434462, valid_loss: 0.0181694452517799\n",
      "SEED: 3, FOLD: 2, EPOCH: 12,train_loss: 0.017619432147293196, valid_loss: 0.01790717699165855\n",
      "SEED: 3, FOLD: 2, EPOCH: 13,train_loss: 0.017537247484726626, valid_loss: 0.017717015104634422\n",
      "SEED: 3, FOLD: 2, EPOCH: 14,train_loss: 0.017379359484915317, valid_loss: 0.017863353049116477\n",
      "SEED: 3, FOLD: 2, EPOCH: 15,train_loss: 0.017279979099866248, valid_loss: 0.017730976694396564\n",
      "SEED: 3, FOLD: 2, EPOCH: 16,train_loss: 0.01707627147735253, valid_loss: 0.0178220343376909\n",
      "SEED: 3, FOLD: 2, EPOCH: 17,train_loss: 0.016820982812366783, valid_loss: 0.01771095868732248\n",
      "SEED: 3, FOLD: 2, EPOCH: 18,train_loss: 0.01656225318238683, valid_loss: 0.017528349480458668\n",
      "SEED: 3, FOLD: 2, EPOCH: 19,train_loss: 0.016209687915270346, valid_loss: 0.017499729698257787\n",
      "SEED: 3, FOLD: 2, EPOCH: 20,train_loss: 0.015767825488680904, valid_loss: 0.01735232472419739\n",
      "SEED: 3, FOLD: 2, EPOCH: 21,train_loss: 0.015267866058615001, valid_loss: 0.01748545752572162\n",
      "SEED: 3, FOLD: 2, EPOCH: 22,train_loss: 0.014730455211098612, valid_loss: 0.01737505274691752\n",
      "SEED: 3, FOLD: 2, EPOCH: 23,train_loss: 0.01429168421122497, valid_loss: 0.01735854380364929\n",
      "SEED: 3, FOLD: 2, EPOCH: 24,train_loss: 0.014046088085394271, valid_loss: 0.01737881654075214\n",
      "(17578, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7343765847060991, valid_loss: 0.6910368919372558\n",
      "SEED: 3, FOLD: 3, EPOCH: 0,train_loss: 0.46597632278512785, valid_loss: 0.02357594221830368\n",
      "SEED: 3, FOLD: 3, EPOCH: 1,train_loss: 0.020838911591124706, valid_loss: 0.018869758317513124\n",
      "SEED: 3, FOLD: 3, EPOCH: 2,train_loss: 0.018961527175607458, valid_loss: 0.018251106914665017\n",
      "SEED: 3, FOLD: 3, EPOCH: 3,train_loss: 0.01827711151048973, valid_loss: 0.017918701895645688\n",
      "SEED: 3, FOLD: 3, EPOCH: 4,train_loss: 0.01792906743703761, valid_loss: 0.018373287921505315\n",
      "SEED: 3, FOLD: 3, EPOCH: 5,train_loss: 0.017982605939218098, valid_loss: 0.017994784217860018\n",
      "SEED: 3, FOLD: 3, EPOCH: 6,train_loss: 0.017911410526089046, valid_loss: 0.018901393163417067\n",
      "SEED: 3, FOLD: 3, EPOCH: 7,train_loss: 0.017917209277874317, valid_loss: 0.018123246117361953\n",
      "SEED: 3, FOLD: 3, EPOCH: 8,train_loss: 0.017954525294835152, valid_loss: 0.017847532725759913\n",
      "SEED: 3, FOLD: 3, EPOCH: 9,train_loss: 0.01793674878317161, valid_loss: 0.018027636674898012\n",
      "SEED: 3, FOLD: 3, EPOCH: 10,train_loss: 0.017831258914446917, valid_loss: 0.017925584582345826\n",
      "SEED: 3, FOLD: 3, EPOCH: 11,train_loss: 0.017770473069200914, valid_loss: 0.017743537628224917\n",
      "SEED: 3, FOLD: 3, EPOCH: 12,train_loss: 0.01770257540182143, valid_loss: 0.017808289719479425\n",
      "SEED: 3, FOLD: 3, EPOCH: 13,train_loss: 0.017602872677093397, valid_loss: 0.01790310809654849\n",
      "SEED: 3, FOLD: 3, EPOCH: 14,train_loss: 0.017472274156044357, valid_loss: 0.017669569754174778\n",
      "SEED: 3, FOLD: 3, EPOCH: 15,train_loss: 0.01729305188401022, valid_loss: 0.017702687584928104\n",
      "SEED: 3, FOLD: 3, EPOCH: 16,train_loss: 0.017192814870319074, valid_loss: 0.017574470836137022\n",
      "SEED: 3, FOLD: 3, EPOCH: 17,train_loss: 0.01692645147820746, valid_loss: 0.017446257626371725\n",
      "SEED: 3, FOLD: 3, EPOCH: 18,train_loss: 0.01659570177477123, valid_loss: 0.017163268982299737\n",
      "SEED: 3, FOLD: 3, EPOCH: 19,train_loss: 0.016226755556367014, valid_loss: 0.01717072475169386\n",
      "SEED: 3, FOLD: 3, EPOCH: 20,train_loss: 0.015840028304660667, valid_loss: 0.01712042045380388\n",
      "SEED: 3, FOLD: 3, EPOCH: 21,train_loss: 0.01534473361528438, valid_loss: 0.017133252934685775\n",
      "SEED: 3, FOLD: 3, EPOCH: 22,train_loss: 0.014796943079842173, valid_loss: 0.01715102389987026\n",
      "SEED: 3, FOLD: 3, EPOCH: 23,train_loss: 0.014309771325223255, valid_loss: 0.017171292565762997\n",
      "SEED: 3, FOLD: 3, EPOCH: 24,train_loss: 0.014083497347715109, valid_loss: 0.01718914391739028\n",
      "(17531, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7345513409941736, valid_loss: 0.6935538223811558\n",
      "SEED: 3, FOLD: 4, EPOCH: 0,train_loss: 0.46801952037443645, valid_loss: 0.02365109734237194\n",
      "SEED: 3, FOLD: 4, EPOCH: 1,train_loss: 0.02089518890546186, valid_loss: 0.018456356919237544\n",
      "SEED: 3, FOLD: 4, EPOCH: 2,train_loss: 0.01895182729311233, valid_loss: 0.017639400224600518\n",
      "SEED: 3, FOLD: 4, EPOCH: 3,train_loss: 0.018282426351232686, valid_loss: 0.017700537693287645\n",
      "SEED: 3, FOLD: 4, EPOCH: 4,train_loss: 0.017988919933075016, valid_loss: 0.018029033445886203\n",
      "SEED: 3, FOLD: 4, EPOCH: 5,train_loss: 0.01790337809735406, valid_loss: 0.017422795588416713\n",
      "SEED: 3, FOLD: 4, EPOCH: 6,train_loss: 0.017916520540840433, valid_loss: 0.017733227115656648\n",
      "SEED: 3, FOLD: 4, EPOCH: 7,train_loss: 0.017899805272038837, valid_loss: 0.01757240133093936\n",
      "SEED: 3, FOLD: 4, EPOCH: 8,train_loss: 0.01788671876229074, valid_loss: 0.01724646022277219\n",
      "SEED: 3, FOLD: 4, EPOCH: 9,train_loss: 0.017860209188648384, valid_loss: 0.01768921392836741\n",
      "SEED: 3, FOLD: 4, EPOCH: 10,train_loss: 0.01785675288062461, valid_loss: 0.0177825177354472\n",
      "SEED: 3, FOLD: 4, EPOCH: 11,train_loss: 0.017803299159192255, valid_loss: 0.017365765811077186\n",
      "SEED: 3, FOLD: 4, EPOCH: 12,train_loss: 0.017760114859871185, valid_loss: 0.01740898375532457\n",
      "SEED: 3, FOLD: 4, EPOCH: 13,train_loss: 0.017644489761849826, valid_loss: 0.017284709215164184\n",
      "SEED: 3, FOLD: 4, EPOCH: 14,train_loss: 0.01746740429424239, valid_loss: 0.017067402521414417\n",
      "SEED: 3, FOLD: 4, EPOCH: 15,train_loss: 0.017326205547382362, valid_loss: 0.017182572984269687\n",
      "SEED: 3, FOLD: 4, EPOCH: 16,train_loss: 0.017167771235108376, valid_loss: 0.017126947268843652\n",
      "SEED: 3, FOLD: 4, EPOCH: 17,train_loss: 0.016946589961702372, valid_loss: 0.016992417377020633\n",
      "SEED: 3, FOLD: 4, EPOCH: 18,train_loss: 0.01664081670642987, valid_loss: 0.01700586029993636\n",
      "SEED: 3, FOLD: 4, EPOCH: 19,train_loss: 0.016263098027693094, valid_loss: 0.017025470254676683\n",
      "SEED: 3, FOLD: 4, EPOCH: 20,train_loss: 0.01582802691408535, valid_loss: 0.016876701744539396\n",
      "SEED: 3, FOLD: 4, EPOCH: 21,train_loss: 0.015317814852906404, valid_loss: 0.016893212922981807\n",
      "SEED: 3, FOLD: 4, EPOCH: 22,train_loss: 0.01480186066461088, valid_loss: 0.01692999063857964\n",
      "SEED: 3, FOLD: 4, EPOCH: 23,train_loss: 0.014283398519793567, valid_loss: 0.01695199047348329\n",
      "SEED: 3, FOLD: 4, EPOCH: 24,train_loss: 0.014052324411697197, valid_loss: 0.016955853386649063\n",
      "(17588, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7340588345043901, valid_loss: 0.7063287224088396\n",
      "SEED: 4, FOLD: 0, EPOCH: 0,train_loss: 0.4676025369461032, valid_loss: 0.02383009275155408\n",
      "SEED: 4, FOLD: 0, EPOCH: 1,train_loss: 0.02080494793050963, valid_loss: 0.019053980442030088\n",
      "SEED: 4, FOLD: 0, EPOCH: 2,train_loss: 0.01897573203145378, valid_loss: 0.019044032533253943\n",
      "SEED: 4, FOLD: 0, EPOCH: 3,train_loss: 0.018321859663811283, valid_loss: 0.017759469364370617\n",
      "SEED: 4, FOLD: 0, EPOCH: 4,train_loss: 0.018039639499308407, valid_loss: 0.01791533747954028\n",
      "SEED: 4, FOLD: 0, EPOCH: 5,train_loss: 0.01789063369801295, valid_loss: 0.018528186210564204\n",
      "SEED: 4, FOLD: 0, EPOCH: 6,train_loss: 0.01796232016109254, valid_loss: 0.018105613812804223\n",
      "SEED: 4, FOLD: 0, EPOCH: 7,train_loss: 0.01788329511232998, valid_loss: 0.018742762452789715\n",
      "SEED: 4, FOLD: 0, EPOCH: 8,train_loss: 0.017889442279988874, valid_loss: 0.01799683485712324\n",
      "SEED: 4, FOLD: 0, EPOCH: 9,train_loss: 0.017854723465237497, valid_loss: 0.018074124945061547\n",
      "SEED: 4, FOLD: 0, EPOCH: 10,train_loss: 0.01783010204309139, valid_loss: 0.01771422563386815\n",
      "SEED: 4, FOLD: 0, EPOCH: 11,train_loss: 0.017775232809177345, valid_loss: 0.017910232448152135\n",
      "SEED: 4, FOLD: 0, EPOCH: 12,train_loss: 0.01772330715523466, valid_loss: 0.017856704949268273\n",
      "SEED: 4, FOLD: 0, EPOCH: 13,train_loss: 0.017567688889423574, valid_loss: 0.01776022599743945\n",
      "SEED: 4, FOLD: 0, EPOCH: 14,train_loss: 0.017471363288822813, valid_loss: 0.017536049096712043\n",
      "SEED: 4, FOLD: 0, EPOCH: 15,train_loss: 0.017305352428145168, valid_loss: 0.01767647082784346\n",
      "SEED: 4, FOLD: 0, EPOCH: 16,train_loss: 0.01713453825779151, valid_loss: 0.01747000270656177\n",
      "SEED: 4, FOLD: 0, EPOCH: 17,train_loss: 0.016917257515740566, valid_loss: 0.017294900598270553\n",
      "SEED: 4, FOLD: 0, EPOCH: 18,train_loss: 0.016620182411988146, valid_loss: 0.01744852443890912\n",
      "SEED: 4, FOLD: 0, EPOCH: 19,train_loss: 0.016315998563515968, valid_loss: 0.017330042831599713\n",
      "SEED: 4, FOLD: 0, EPOCH: 20,train_loss: 0.015864401650817497, valid_loss: 0.017259112346385205\n",
      "SEED: 4, FOLD: 0, EPOCH: 21,train_loss: 0.01538928734489541, valid_loss: 0.017244783576045718\n",
      "SEED: 4, FOLD: 0, EPOCH: 22,train_loss: 0.01487819847745308, valid_loss: 0.01716503652610949\n",
      "SEED: 4, FOLD: 0, EPOCH: 23,train_loss: 0.014435298659879229, valid_loss: 0.017139393171029433\n",
      "SEED: 4, FOLD: 0, EPOCH: 24,train_loss: 0.014192131725882275, valid_loss: 0.017167453574282784\n",
      "(17601, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.734112490778384, valid_loss: 0.7054686669041129\n",
      "SEED: 4, FOLD: 1, EPOCH: 0,train_loss: 0.46862252755765466, valid_loss: 0.023376391871887094\n",
      "SEED: 4, FOLD: 1, EPOCH: 1,train_loss: 0.020822377834954987, valid_loss: 0.018733395811389473\n",
      "SEED: 4, FOLD: 1, EPOCH: 2,train_loss: 0.01903616330599871, valid_loss: 0.018544585142722902\n",
      "SEED: 4, FOLD: 1, EPOCH: 3,train_loss: 0.01821059701235398, valid_loss: 0.018297183601295248\n",
      "SEED: 4, FOLD: 1, EPOCH: 4,train_loss: 0.01789023611775559, valid_loss: 0.018322469666600227\n",
      "SEED: 4, FOLD: 1, EPOCH: 5,train_loss: 0.01782054811095198, valid_loss: 0.018150750985916925\n",
      "SEED: 4, FOLD: 1, EPOCH: 6,train_loss: 0.017817940367250772, valid_loss: 0.018090198720421863\n",
      "SEED: 4, FOLD: 1, EPOCH: 7,train_loss: 0.017824663348711918, valid_loss: 0.018380911116871762\n",
      "SEED: 4, FOLD: 1, EPOCH: 8,train_loss: 0.01784287496348438, valid_loss: 0.018010828342727003\n",
      "SEED: 4, FOLD: 1, EPOCH: 9,train_loss: 0.01782001042738557, valid_loss: 0.017989589038359767\n",
      "SEED: 4, FOLD: 1, EPOCH: 10,train_loss: 0.017771345340525328, valid_loss: 0.01823813024470035\n",
      "SEED: 4, FOLD: 1, EPOCH: 11,train_loss: 0.01773766476822936, valid_loss: 0.01799743326709551\n",
      "SEED: 4, FOLD: 1, EPOCH: 12,train_loss: 0.017666939180344343, valid_loss: 0.01864852479604237\n",
      "SEED: 4, FOLD: 1, EPOCH: 13,train_loss: 0.01756940478378016, valid_loss: 0.01774639025440111\n",
      "SEED: 4, FOLD: 1, EPOCH: 14,train_loss: 0.017441865535911875, valid_loss: 0.01782441380269387\n",
      "SEED: 4, FOLD: 1, EPOCH: 15,train_loss: 0.01727927268307278, valid_loss: 0.018252412158557597\n",
      "SEED: 4, FOLD: 1, EPOCH: 16,train_loss: 0.017138703631750053, valid_loss: 0.01752315234283314\n",
      "SEED: 4, FOLD: 1, EPOCH: 17,train_loss: 0.01686454889620992, valid_loss: 0.0176318436039283\n",
      "SEED: 4, FOLD: 1, EPOCH: 18,train_loss: 0.016636499365710693, valid_loss: 0.01748152422335218\n",
      "SEED: 4, FOLD: 1, EPOCH: 19,train_loss: 0.016271428130837023, valid_loss: 0.01746903880334952\n",
      "SEED: 4, FOLD: 1, EPOCH: 20,train_loss: 0.01585500698833578, valid_loss: 0.017510915503782386\n",
      "SEED: 4, FOLD: 1, EPOCH: 21,train_loss: 0.015413891800773748, valid_loss: 0.017508569173514843\n",
      "SEED: 4, FOLD: 1, EPOCH: 22,train_loss: 0.014921931144983872, valid_loss: 0.017450263449812636\n",
      "SEED: 4, FOLD: 1, EPOCH: 23,train_loss: 0.01447167211090741, valid_loss: 0.01738374266663895\n",
      "SEED: 4, FOLD: 1, EPOCH: 24,train_loss: 0.014261518537566282, valid_loss: 0.01741577512310708\n",
      "(17580, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7341920081256093, valid_loss: 0.70968325648989\n",
      "SEED: 4, FOLD: 2, EPOCH: 0,train_loss: 0.46690142504277005, valid_loss: 0.02534401219870363\n",
      "SEED: 4, FOLD: 2, EPOCH: 1,train_loss: 0.020935193406067032, valid_loss: 0.018374697278652874\n",
      "SEED: 4, FOLD: 2, EPOCH: 2,train_loss: 0.019245609614080277, valid_loss: 0.018387637792953423\n",
      "SEED: 4, FOLD: 2, EPOCH: 3,train_loss: 0.018366507618971493, valid_loss: 0.017614691850862334\n",
      "SEED: 4, FOLD: 2, EPOCH: 4,train_loss: 0.018004389688966498, valid_loss: 0.017718725372105837\n",
      "SEED: 4, FOLD: 2, EPOCH: 5,train_loss: 0.01796594573913709, valid_loss: 0.017819626855530908\n",
      "SEED: 4, FOLD: 2, EPOCH: 6,train_loss: 0.017941536408835564, valid_loss: 0.01746572713766779\n",
      "SEED: 4, FOLD: 2, EPOCH: 7,train_loss: 0.017946869789528242, valid_loss: 0.017531250909503016\n",
      "SEED: 4, FOLD: 2, EPOCH: 8,train_loss: 0.017944945656842945, valid_loss: 0.01744111676567367\n",
      "SEED: 4, FOLD: 2, EPOCH: 9,train_loss: 0.01792114985215923, valid_loss: 0.017772867078227655\n",
      "SEED: 4, FOLD: 2, EPOCH: 10,train_loss: 0.017954043942787077, valid_loss: 0.01862535189305033\n",
      "SEED: 4, FOLD: 2, EPOCH: 11,train_loss: 0.017839147398869198, valid_loss: 0.01737108559214643\n",
      "SEED: 4, FOLD: 2, EPOCH: 12,train_loss: 0.017800521166266306, valid_loss: 0.017048426438122988\n",
      "SEED: 4, FOLD: 2, EPOCH: 13,train_loss: 0.017712052209653717, valid_loss: 0.01716643518635205\n",
      "SEED: 4, FOLD: 2, EPOCH: 14,train_loss: 0.01755879896328501, valid_loss: 0.017218382629965032\n",
      "SEED: 4, FOLD: 2, EPOCH: 15,train_loss: 0.017459297073546095, valid_loss: 0.01701997865789703\n",
      "SEED: 4, FOLD: 2, EPOCH: 16,train_loss: 0.017275800651776186, valid_loss: 0.016920877460922513\n",
      "SEED: 4, FOLD: 2, EPOCH: 17,train_loss: 0.01699345081747658, valid_loss: 0.01685639818065933\n",
      "SEED: 4, FOLD: 2, EPOCH: 18,train_loss: 0.01669665181712396, valid_loss: 0.016940909344702958\n",
      "SEED: 4, FOLD: 2, EPOCH: 19,train_loss: 0.01638623296647616, valid_loss: 0.016763214394450186\n",
      "SEED: 4, FOLD: 2, EPOCH: 20,train_loss: 0.01600620545365888, valid_loss: 0.01665890079789928\n",
      "SEED: 4, FOLD: 2, EPOCH: 21,train_loss: 0.015512908835881863, valid_loss: 0.01661833259942276\n",
      "SEED: 4, FOLD: 2, EPOCH: 22,train_loss: 0.01504031696991212, valid_loss: 0.01669199937688453\n",
      "SEED: 4, FOLD: 2, EPOCH: 23,train_loss: 0.014575581194535978, valid_loss: 0.016654282967959132\n",
      "SEED: 4, FOLD: 2, EPOCH: 24,train_loss: 0.014367160664034494, valid_loss: 0.016634034498461656\n",
      "(17538, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7345617914545364, valid_loss: 0.7038540431431362\n",
      "SEED: 4, FOLD: 3, EPOCH: 0,train_loss: 0.46821645515012567, valid_loss: 0.026648135270391192\n",
      "SEED: 4, FOLD: 3, EPOCH: 1,train_loss: 0.021336930291052315, valid_loss: 0.032465765039835656\n",
      "SEED: 4, FOLD: 3, EPOCH: 2,train_loss: 0.020664557153224083, valid_loss: 0.026624699415905135\n",
      "SEED: 4, FOLD: 3, EPOCH: 3,train_loss: 0.019243543387215206, valid_loss: 0.01842582928282874\n",
      "SEED: 4, FOLD: 3, EPOCH: 4,train_loss: 0.01852173322096359, valid_loss: 0.018213540581720217\n",
      "SEED: 4, FOLD: 3, EPOCH: 5,train_loss: 0.018400372174716947, valid_loss: 0.018483798950910568\n",
      "SEED: 4, FOLD: 3, EPOCH: 6,train_loss: 0.018520011789286913, valid_loss: 0.018546183087996073\n",
      "SEED: 4, FOLD: 3, EPOCH: 7,train_loss: 0.01826914754844662, valid_loss: 0.0181608147919178\n",
      "SEED: 4, FOLD: 3, EPOCH: 8,train_loss: 0.01812463477793811, valid_loss: 0.024131000893456597\n",
      "SEED: 4, FOLD: 3, EPOCH: 9,train_loss: 0.01832370686115346, valid_loss: 0.01765460590166705\n",
      "SEED: 4, FOLD: 3, EPOCH: 10,train_loss: 0.018112076594885708, valid_loss: 0.01833768667919295\n",
      "SEED: 4, FOLD: 3, EPOCH: 11,train_loss: 0.017990551963178576, valid_loss: 0.01808693991707904\n",
      "SEED: 4, FOLD: 3, EPOCH: 12,train_loss: 0.01775597079076629, valid_loss: 0.017646836037082333\n",
      "SEED: 4, FOLD: 3, EPOCH: 13,train_loss: 0.01787309546995422, valid_loss: 0.017657501596425262\n",
      "SEED: 4, FOLD: 3, EPOCH: 14,train_loss: 0.017818620037017525, valid_loss: 0.017440908082893915\n",
      "SEED: 4, FOLD: 3, EPOCH: 15,train_loss: 0.017594914559436882, valid_loss: 0.017326215840876104\n",
      "SEED: 4, FOLD: 3, EPOCH: 16,train_loss: 0.01739439962134845, valid_loss: 0.017367933903421673\n",
      "SEED: 4, FOLD: 3, EPOCH: 17,train_loss: 0.017321637008285175, valid_loss: 0.01726427690259048\n",
      "SEED: 4, FOLD: 3, EPOCH: 18,train_loss: 0.01705870867126446, valid_loss: 0.017053243704140186\n",
      "SEED: 4, FOLD: 3, EPOCH: 19,train_loss: 0.016715874800971454, valid_loss: 0.01685855540313891\n",
      "SEED: 4, FOLD: 3, EPOCH: 20,train_loss: 0.01631079878712046, valid_loss: 0.017073193644838672\n",
      "SEED: 4, FOLD: 3, EPOCH: 21,train_loss: 0.015961043691883486, valid_loss: 0.01686563388045345\n",
      "SEED: 4, FOLD: 3, EPOCH: 22,train_loss: 0.015433373975742987, valid_loss: 0.016942242107221058\n",
      "SEED: 4, FOLD: 3, EPOCH: 23,train_loss: 0.01515481085853948, valid_loss: 0.016930983614708697\n",
      "SEED: 4, FOLD: 3, EPOCH: 24,train_loss: 0.014943710251616827, valid_loss: 0.016869548947683402\n",
      "(17485, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7337405990510091, valid_loss: 0.7045751401356288\n",
      "SEED: 4, FOLD: 4, EPOCH: 0,train_loss: 0.46835863282972007, valid_loss: 0.02500745148531028\n",
      "SEED: 4, FOLD: 4, EPOCH: 1,train_loss: 0.020936407937403142, valid_loss: 0.019119464393172945\n",
      "SEED: 4, FOLD: 4, EPOCH: 2,train_loss: 0.0189318645976647, valid_loss: 0.018280430670295444\n",
      "SEED: 4, FOLD: 4, EPOCH: 3,train_loss: 0.018018481715915413, valid_loss: 0.018283364629106864\n",
      "SEED: 4, FOLD: 4, EPOCH: 4,train_loss: 0.017857791488840632, valid_loss: 0.018026271595486573\n",
      "SEED: 4, FOLD: 4, EPOCH: 5,train_loss: 0.017840044756494734, valid_loss: 0.018123190850019455\n",
      "SEED: 4, FOLD: 4, EPOCH: 6,train_loss: 0.017722173804675577, valid_loss: 0.018129911007625715\n",
      "SEED: 4, FOLD: 4, EPOCH: 7,train_loss: 0.017736006439765438, valid_loss: 0.018173769861459733\n",
      "SEED: 4, FOLD: 4, EPOCH: 8,train_loss: 0.017755769084404856, valid_loss: 0.017932343004005296\n",
      "SEED: 4, FOLD: 4, EPOCH: 9,train_loss: 0.01771639517243326, valid_loss: 0.018287344835698605\n",
      "SEED: 4, FOLD: 4, EPOCH: 10,train_loss: 0.01775995777226495, valid_loss: 0.018108641542494298\n",
      "SEED: 4, FOLD: 4, EPOCH: 11,train_loss: 0.017677992799856365, valid_loss: 0.018085727760834353\n",
      "SEED: 4, FOLD: 4, EPOCH: 12,train_loss: 0.017670240966997444, valid_loss: 0.01776857235069786\n",
      "SEED: 4, FOLD: 4, EPOCH: 13,train_loss: 0.017540010147775613, valid_loss: 0.017826124600001745\n",
      "SEED: 4, FOLD: 4, EPOCH: 14,train_loss: 0.017416574516381227, valid_loss: 0.018060334346124102\n",
      "SEED: 4, FOLD: 4, EPOCH: 15,train_loss: 0.017291392695947285, valid_loss: 0.017956294332231795\n",
      "SEED: 4, FOLD: 4, EPOCH: 16,train_loss: 0.017078777571229168, valid_loss: 0.01755899124379669\n",
      "SEED: 4, FOLD: 4, EPOCH: 17,train_loss: 0.016856019718259792, valid_loss: 0.01774841280920165\n",
      "SEED: 4, FOLD: 4, EPOCH: 18,train_loss: 0.016570881450970243, valid_loss: 0.01756978375571115\n",
      "SEED: 4, FOLD: 4, EPOCH: 19,train_loss: 0.016240934113951496, valid_loss: 0.01745394633284637\n",
      "SEED: 4, FOLD: 4, EPOCH: 20,train_loss: 0.015807497790967025, valid_loss: 0.01742909893925701\n",
      "SEED: 4, FOLD: 4, EPOCH: 21,train_loss: 0.015357966500803502, valid_loss: 0.01744192202708551\n",
      "SEED: 4, FOLD: 4, EPOCH: 22,train_loss: 0.014822088481083403, valid_loss: 0.01741748335106032\n",
      "SEED: 4, FOLD: 4, EPOCH: 23,train_loss: 0.014364118184758363, valid_loss: 0.01743021926709584\n",
      "SEED: 4, FOLD: 4, EPOCH: 24,train_loss: 0.014130086875962514, valid_loss: 0.01745301234935011\n",
      "(17564, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7360968727996384, valid_loss: 0.7028307284627642\n",
      "SEED: 5, FOLD: 0, EPOCH: 0,train_loss: 0.46593162109670433, valid_loss: 0.02354907366846289\n",
      "SEED: 5, FOLD: 0, EPOCH: 1,train_loss: 0.020737596099143444, valid_loss: 0.02089801180575575\n",
      "SEED: 5, FOLD: 0, EPOCH: 2,train_loss: 0.018883530752382416, valid_loss: 0.01858135730560337\n",
      "SEED: 5, FOLD: 0, EPOCH: 3,train_loss: 0.018173739739248285, valid_loss: 0.018106084955590112\n",
      "SEED: 5, FOLD: 0, EPOCH: 4,train_loss: 0.017869367311452177, valid_loss: 0.018467907873647552\n",
      "SEED: 5, FOLD: 0, EPOCH: 5,train_loss: 0.017909244404754776, valid_loss: 0.018582871024097714\n",
      "SEED: 5, FOLD: 0, EPOCH: 6,train_loss: 0.0178766878105808, valid_loss: 0.018213371373713018\n",
      "SEED: 5, FOLD: 0, EPOCH: 7,train_loss: 0.017875538140103436, valid_loss: 0.01888399693582739\n",
      "SEED: 5, FOLD: 0, EPOCH: 8,train_loss: 0.017914326780516167, valid_loss: 0.017965825647115706\n",
      "SEED: 5, FOLD: 0, EPOCH: 9,train_loss: 0.017852979057562956, valid_loss: 0.018094144628516266\n",
      "SEED: 5, FOLD: 0, EPOCH: 10,train_loss: 0.017849922531108925, valid_loss: 0.018543929766331402\n",
      "SEED: 5, FOLD: 0, EPOCH: 11,train_loss: 0.017804515757260546, valid_loss: 0.01794630762721811\n",
      "SEED: 5, FOLD: 0, EPOCH: 12,train_loss: 0.01766302668745967, valid_loss: 0.017882834295076984\n",
      "SEED: 5, FOLD: 0, EPOCH: 13,train_loss: 0.017644353676587343, valid_loss: 0.017902547121047975\n",
      "SEED: 5, FOLD: 0, EPOCH: 14,train_loss: 0.017448737758441246, valid_loss: 0.018130380447421754\n",
      "SEED: 5, FOLD: 0, EPOCH: 15,train_loss: 0.017375289799942486, valid_loss: 0.017744366052959648\n",
      "SEED: 5, FOLD: 0, EPOCH: 16,train_loss: 0.01709206036521473, valid_loss: 0.01767944677599839\n",
      "SEED: 5, FOLD: 0, EPOCH: 17,train_loss: 0.016914870967899544, valid_loss: 0.01763492412865162\n",
      "SEED: 5, FOLD: 0, EPOCH: 18,train_loss: 0.016664701696161344, valid_loss: 0.017485962408993926\n",
      "SEED: 5, FOLD: 0, EPOCH: 19,train_loss: 0.016338549075189276, valid_loss: 0.017400321470839638\n",
      "SEED: 5, FOLD: 0, EPOCH: 20,train_loss: 0.015918310812633972, valid_loss: 0.017320486690316883\n",
      "SEED: 5, FOLD: 0, EPOCH: 21,train_loss: 0.01547294404303682, valid_loss: 0.017237779631146363\n",
      "SEED: 5, FOLD: 0, EPOCH: 22,train_loss: 0.01498051929841007, valid_loss: 0.017256199941039087\n",
      "SEED: 5, FOLD: 0, EPOCH: 23,train_loss: 0.01460366476111222, valid_loss: 0.017272218423230307\n",
      "SEED: 5, FOLD: 0, EPOCH: 24,train_loss: 0.014376419461399748, valid_loss: 0.017281598704201834\n",
      "(17535, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7367819295312367, valid_loss: 0.7027316519192287\n",
      "SEED: 5, FOLD: 1, EPOCH: 0,train_loss: 0.4680083334364378, valid_loss: 0.02329029573925904\n",
      "SEED: 5, FOLD: 1, EPOCH: 1,train_loss: 0.021076366672441907, valid_loss: 0.019082533781017576\n",
      "SEED: 5, FOLD: 1, EPOCH: 2,train_loss: 0.01915864748404409, valid_loss: 0.017964887166661874\n",
      "SEED: 5, FOLD: 1, EPOCH: 3,train_loss: 0.01831965121257044, valid_loss: 0.01776640811668975\n",
      "SEED: 5, FOLD: 1, EPOCH: 4,train_loss: 0.018053119064029986, valid_loss: 0.018440046134803975\n",
      "SEED: 5, FOLD: 1, EPOCH: 5,train_loss: 0.017946708383188195, valid_loss: 0.017639888689986297\n",
      "SEED: 5, FOLD: 1, EPOCH: 6,train_loss: 0.017938756091642555, valid_loss: 0.017720323428511618\n",
      "SEED: 5, FOLD: 1, EPOCH: 7,train_loss: 0.017988173012370174, valid_loss: 0.017724802158772944\n",
      "SEED: 5, FOLD: 1, EPOCH: 8,train_loss: 0.017950679080384058, valid_loss: 0.017673500441014768\n",
      "SEED: 5, FOLD: 1, EPOCH: 9,train_loss: 0.01792329117438219, valid_loss: 0.017553206692848888\n",
      "SEED: 5, FOLD: 1, EPOCH: 10,train_loss: 0.01788219097104386, valid_loss: 0.01905980317720345\n",
      "SEED: 5, FOLD: 1, EPOCH: 11,train_loss: 0.017889585685882257, valid_loss: 0.017582757265440056\n",
      "SEED: 5, FOLD: 1, EPOCH: 12,train_loss: 0.01777898147702217, valid_loss: 0.017615858438823906\n",
      "SEED: 5, FOLD: 1, EPOCH: 13,train_loss: 0.017663516770422893, valid_loss: 0.017461054851966244\n",
      "SEED: 5, FOLD: 1, EPOCH: 14,train_loss: 0.017535185461768705, valid_loss: 0.017443519192082542\n",
      "SEED: 5, FOLD: 1, EPOCH: 15,train_loss: 0.017389574081358248, valid_loss: 0.01724206225148269\n",
      "SEED: 5, FOLD: 1, EPOCH: 16,train_loss: 0.017197449453664523, valid_loss: 0.01724408785147326\n",
      "SEED: 5, FOLD: 1, EPOCH: 17,train_loss: 0.016952250839421784, valid_loss: 0.017128602521760124\n",
      "SEED: 5, FOLD: 1, EPOCH: 18,train_loss: 0.016688930666087752, valid_loss: 0.01730484917227711\n",
      "SEED: 5, FOLD: 1, EPOCH: 19,train_loss: 0.016351025503971717, valid_loss: 0.017193089904529706\n",
      "SEED: 5, FOLD: 1, EPOCH: 20,train_loss: 0.015898869270934677, valid_loss: 0.017012065116848264\n",
      "SEED: 5, FOLD: 1, EPOCH: 21,train_loss: 0.015480143582298808, valid_loss: 0.016984250529536178\n",
      "SEED: 5, FOLD: 1, EPOCH: 22,train_loss: 0.014973163210453779, valid_loss: 0.01702351775020361\n",
      "SEED: 5, FOLD: 1, EPOCH: 23,train_loss: 0.014547152193195193, valid_loss: 0.017003215397042887\n",
      "SEED: 5, FOLD: 1, EPOCH: 24,train_loss: 0.014308030621903221, valid_loss: 0.017002662218042783\n",
      "(17572, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.736134406881056, valid_loss: 0.7013909016336713\n",
      "SEED: 5, FOLD: 2, EPOCH: 0,train_loss: 0.4659917995036728, valid_loss: 0.02311089608286108\n",
      "SEED: 5, FOLD: 2, EPOCH: 1,train_loss: 0.02111056999073944, valid_loss: 0.018210599571466445\n",
      "SEED: 5, FOLD: 2, EPOCH: 2,train_loss: 0.01892017415198295, valid_loss: 0.017519778039838587\n",
      "SEED: 5, FOLD: 2, EPOCH: 3,train_loss: 0.018325961127445316, valid_loss: 0.017958282466445652\n",
      "SEED: 5, FOLD: 2, EPOCH: 4,train_loss: 0.0181047804383696, valid_loss: 0.017476632605705943\n",
      "SEED: 5, FOLD: 2, EPOCH: 5,train_loss: 0.01799828406639289, valid_loss: 0.017759043749954018\n",
      "SEED: 5, FOLD: 2, EPOCH: 6,train_loss: 0.017945485000593075, valid_loss: 0.017479600730751242\n",
      "SEED: 5, FOLD: 2, EPOCH: 7,train_loss: 0.01807154038840014, valid_loss: 0.01727755538054875\n",
      "SEED: 5, FOLD: 2, EPOCH: 8,train_loss: 0.017948399196662333, valid_loss: 0.017136908349181926\n",
      "SEED: 5, FOLD: 2, EPOCH: 9,train_loss: 0.018006060933829216, valid_loss: 0.017606579352702413\n",
      "SEED: 5, FOLD: 2, EPOCH: 10,train_loss: 0.017887074216876343, valid_loss: 0.01743600174252476\n",
      "SEED: 5, FOLD: 2, EPOCH: 11,train_loss: 0.017835317247047806, valid_loss: 0.017594967463186808\n",
      "SEED: 5, FOLD: 2, EPOCH: 12,train_loss: 0.01786489806988317, valid_loss: 0.01732369802360024\n",
      "SEED: 5, FOLD: 2, EPOCH: 13,train_loss: 0.01766313698844633, valid_loss: 0.017554058799786228\n",
      "SEED: 5, FOLD: 2, EPOCH: 14,train_loss: 0.017592422711406496, valid_loss: 0.017277305253914424\n",
      "SEED: 5, FOLD: 2, EPOCH: 15,train_loss: 0.017409087442185566, valid_loss: 0.017180963259722504\n",
      "SEED: 5, FOLD: 2, EPOCH: 16,train_loss: 0.0172563962759855, valid_loss: 0.017017560452222823\n",
      "SEED: 5, FOLD: 2, EPOCH: 17,train_loss: 0.01705781607956126, valid_loss: 0.017111066515956605\n",
      "SEED: 5, FOLD: 2, EPOCH: 18,train_loss: 0.016745075063806944, valid_loss: 0.016932663188448976\n",
      "SEED: 5, FOLD: 2, EPOCH: 19,train_loss: 0.016458970987224493, valid_loss: 0.016746417299977372\n",
      "SEED: 5, FOLD: 2, EPOCH: 20,train_loss: 0.01607033301927689, valid_loss: 0.016769618248300894\n",
      "SEED: 5, FOLD: 2, EPOCH: 21,train_loss: 0.015563473989512178, valid_loss: 0.016685438475438526\n",
      "SEED: 5, FOLD: 2, EPOCH: 22,train_loss: 0.015074403430132763, valid_loss: 0.016656830427902086\n",
      "SEED: 5, FOLD: 2, EPOCH: 23,train_loss: 0.014663245900115673, valid_loss: 0.01665879919060639\n",
      "SEED: 5, FOLD: 2, EPOCH: 24,train_loss: 0.01445204834116326, valid_loss: 0.01666744742542505\n",
      "(17516, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7361484491912118, valid_loss: 0.7032452940940856\n",
      "SEED: 5, FOLD: 3, EPOCH: 0,train_loss: 0.46766281877066535, valid_loss: 0.024296330341270992\n",
      "SEED: 5, FOLD: 3, EPOCH: 1,train_loss: 0.02086739349484879, valid_loss: 0.02001945168844291\n",
      "SEED: 5, FOLD: 3, EPOCH: 2,train_loss: 0.018896927866731247, valid_loss: 0.018494209806833948\n",
      "SEED: 5, FOLD: 3, EPOCH: 3,train_loss: 0.018305835416064644, valid_loss: 0.018415662832558154\n",
      "SEED: 5, FOLD: 3, EPOCH: 4,train_loss: 0.017951119487194248, valid_loss: 0.018077328694718224\n",
      "SEED: 5, FOLD: 3, EPOCH: 5,train_loss: 0.017908126693626826, valid_loss: 0.01834673115185329\n",
      "SEED: 5, FOLD: 3, EPOCH: 6,train_loss: 0.017825222397427055, valid_loss: 0.018223994837275572\n",
      "SEED: 5, FOLD: 3, EPOCH: 7,train_loss: 0.017847009329465185, valid_loss: 0.018170088556196007\n",
      "SEED: 5, FOLD: 3, EPOCH: 8,train_loss: 0.017829154074246432, valid_loss: 0.018050989295755115\n",
      "SEED: 5, FOLD: 3, EPOCH: 9,train_loss: 0.017839228000192747, valid_loss: 0.018337234748261315\n",
      "SEED: 5, FOLD: 3, EPOCH: 10,train_loss: 0.017805639545630365, valid_loss: 0.0181830923472132\n",
      "SEED: 5, FOLD: 3, EPOCH: 11,train_loss: 0.0177210217246609, valid_loss: 0.018040285658623492\n",
      "SEED: 5, FOLD: 3, EPOCH: 12,train_loss: 0.01764931753413738, valid_loss: 0.01776044507111822\n",
      "SEED: 5, FOLD: 3, EPOCH: 13,train_loss: 0.017530723563293472, valid_loss: 0.018333843749548707\n",
      "SEED: 5, FOLD: 3, EPOCH: 14,train_loss: 0.017457585401126068, valid_loss: 0.01795998580221619\n",
      "SEED: 5, FOLD: 3, EPOCH: 15,train_loss: 0.017272410628786924, valid_loss: 0.01784894210951669\n",
      "SEED: 5, FOLD: 3, EPOCH: 16,train_loss: 0.017057815546265048, valid_loss: 0.01772820164582559\n",
      "SEED: 5, FOLD: 3, EPOCH: 17,train_loss: 0.016891971046961572, valid_loss: 0.017763038245694977\n",
      "SEED: 5, FOLD: 3, EPOCH: 18,train_loss: 0.016580970169310153, valid_loss: 0.017573979204254492\n",
      "SEED: 5, FOLD: 3, EPOCH: 19,train_loss: 0.016219067040586125, valid_loss: 0.01746217760124377\n",
      "SEED: 5, FOLD: 3, EPOCH: 20,train_loss: 0.01579056861028619, valid_loss: 0.017394340996231352\n",
      "SEED: 5, FOLD: 3, EPOCH: 21,train_loss: 0.015335853130006008, valid_loss: 0.017396349566323417\n",
      "SEED: 5, FOLD: 3, EPOCH: 22,train_loss: 0.014789915799985837, valid_loss: 0.017340010005448547\n",
      "SEED: 5, FOLD: 3, EPOCH: 23,train_loss: 0.014349590878199488, valid_loss: 0.017312082116092954\n",
      "SEED: 5, FOLD: 3, EPOCH: 24,train_loss: 0.014110142412683824, valid_loss: 0.01731904149055481\n",
      "(17605, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7362750125104103, valid_loss: 0.7021718077799853\n",
      "SEED: 5, FOLD: 4, EPOCH: 0,train_loss: 0.46570800734764856, valid_loss: 0.0246675371137612\n",
      "SEED: 5, FOLD: 4, EPOCH: 1,train_loss: 0.02095330015256785, valid_loss: 0.019772838034174022\n",
      "SEED: 5, FOLD: 4, EPOCH: 2,train_loss: 0.0189892570555642, valid_loss: 0.01848288346081972\n",
      "SEED: 5, FOLD: 4, EPOCH: 3,train_loss: 0.018309560293952625, valid_loss: 0.018566266030949706\n",
      "SEED: 5, FOLD: 4, EPOCH: 4,train_loss: 0.017975943925642016, valid_loss: 0.01857912025469191\n",
      "SEED: 5, FOLD: 4, EPOCH: 5,train_loss: 0.017900185673025207, valid_loss: 0.01844315236324773\n",
      "SEED: 5, FOLD: 4, EPOCH: 6,train_loss: 0.01788578874202094, valid_loss: 0.01828332097433946\n",
      "SEED: 5, FOLD: 4, EPOCH: 7,train_loss: 0.017861046301929848, valid_loss: 0.01837838430176763\n",
      "SEED: 5, FOLD: 4, EPOCH: 8,train_loss: 0.017791356709178374, valid_loss: 0.018021454240250236\n",
      "SEED: 5, FOLD: 4, EPOCH: 9,train_loss: 0.017850894798133253, valid_loss: 0.018234219073372727\n",
      "SEED: 5, FOLD: 4, EPOCH: 10,train_loss: 0.01781337947814145, valid_loss: 0.01799667122609475\n",
      "SEED: 5, FOLD: 4, EPOCH: 11,train_loss: 0.017709945591733507, valid_loss: 0.01816374885247034\n",
      "SEED: 5, FOLD: 4, EPOCH: 12,train_loss: 0.017636263257135517, valid_loss: 0.017981517238213736\n",
      "SEED: 5, FOLD: 4, EPOCH: 13,train_loss: 0.017625847851614588, valid_loss: 0.017957688802305388\n",
      "SEED: 5, FOLD: 4, EPOCH: 14,train_loss: 0.01748122166896212, valid_loss: 0.017712770112077978\n",
      "SEED: 5, FOLD: 4, EPOCH: 15,train_loss: 0.01732504785573785, valid_loss: 0.018231512814321938\n",
      "SEED: 5, FOLD: 4, EPOCH: 16,train_loss: 0.01713869774012246, valid_loss: 0.01762181315023233\n",
      "SEED: 5, FOLD: 4, EPOCH: 17,train_loss: 0.01692121580540054, valid_loss: 0.01756748746094458\n",
      "SEED: 5, FOLD: 4, EPOCH: 18,train_loss: 0.016669476141586252, valid_loss: 0.017606833292280927\n",
      "SEED: 5, FOLD: 4, EPOCH: 19,train_loss: 0.016312197606632675, valid_loss: 0.017547849237042314\n",
      "SEED: 5, FOLD: 4, EPOCH: 20,train_loss: 0.015920987541692844, valid_loss: 0.01764434217201436\n",
      "SEED: 5, FOLD: 4, EPOCH: 21,train_loss: 0.015497809451451336, valid_loss: 0.017533319591380218\n",
      "SEED: 5, FOLD: 4, EPOCH: 22,train_loss: 0.014976036728130302, valid_loss: 0.017498330487047926\n",
      "SEED: 5, FOLD: 4, EPOCH: 23,train_loss: 0.014562552281911823, valid_loss: 0.01747189714189838\n",
      "SEED: 5, FOLD: 4, EPOCH: 24,train_loss: 0.01436909215281839, valid_loss: 0.017475630923667374\n",
      "(17517, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7342957893427271, valid_loss: 0.6831454191889081\n",
      "SEED: 6, FOLD: 0, EPOCH: 0,train_loss: 0.4690769885931789, valid_loss: 0.024121794317449843\n",
      "SEED: 6, FOLD: 0, EPOCH: 1,train_loss: 0.02099986876068759, valid_loss: 0.019298134398247513\n",
      "SEED: 6, FOLD: 0, EPOCH: 2,train_loss: 0.018804122863786063, valid_loss: 0.01835115849971771\n",
      "SEED: 6, FOLD: 0, EPOCH: 3,train_loss: 0.018116391916507785, valid_loss: 0.018196026076163566\n",
      "SEED: 6, FOLD: 0, EPOCH: 4,train_loss: 0.01778396332541304, valid_loss: 0.018002807322357383\n",
      "SEED: 6, FOLD: 0, EPOCH: 5,train_loss: 0.017761800451761615, valid_loss: 0.018337760253676345\n",
      "SEED: 6, FOLD: 0, EPOCH: 6,train_loss: 0.01782102078661649, valid_loss: 0.01786242135401283\n",
      "SEED: 6, FOLD: 0, EPOCH: 7,train_loss: 0.017812117682701915, valid_loss: 0.018397055193781854\n",
      "SEED: 6, FOLD: 0, EPOCH: 8,train_loss: 0.0178145785768428, valid_loss: 0.018099604892943585\n",
      "SEED: 6, FOLD: 0, EPOCH: 9,train_loss: 0.017759597969044298, valid_loss: 0.017795612051018646\n",
      "SEED: 6, FOLD: 0, EPOCH: 10,train_loss: 0.017764532693872487, valid_loss: 0.01814547444560698\n",
      "SEED: 6, FOLD: 0, EPOCH: 11,train_loss: 0.01774425720320131, valid_loss: 0.01768064152981554\n",
      "SEED: 6, FOLD: 0, EPOCH: 12,train_loss: 0.01763511101042267, valid_loss: 0.01769839408142226\n",
      "SEED: 6, FOLD: 0, EPOCH: 13,train_loss: 0.017540331984305903, valid_loss: 0.017796774288373333\n",
      "SEED: 6, FOLD: 0, EPOCH: 14,train_loss: 0.017444069497287273, valid_loss: 0.01757474954106978\n",
      "SEED: 6, FOLD: 0, EPOCH: 15,train_loss: 0.017268764378543754, valid_loss: 0.017699104653937477\n",
      "SEED: 6, FOLD: 0, EPOCH: 16,train_loss: 0.017112165322377734, valid_loss: 0.01761114128998348\n",
      "SEED: 6, FOLD: 0, EPOCH: 17,train_loss: 0.01690953247330702, valid_loss: 0.01746766319764512\n",
      "SEED: 6, FOLD: 0, EPOCH: 18,train_loss: 0.01656006571639628, valid_loss: 0.017426020918147905\n",
      "SEED: 6, FOLD: 0, EPOCH: 19,train_loss: 0.01627287757413013, valid_loss: 0.017493808402546815\n",
      "SEED: 6, FOLD: 0, EPOCH: 20,train_loss: 0.015839041455438102, valid_loss: 0.01745254953524896\n",
      "SEED: 6, FOLD: 0, EPOCH: 21,train_loss: 0.015365694160063337, valid_loss: 0.01741822042635509\n",
      "SEED: 6, FOLD: 0, EPOCH: 22,train_loss: 0.014825795763546097, valid_loss: 0.017446139880589077\n",
      "SEED: 6, FOLD: 0, EPOCH: 23,train_loss: 0.014394808043963718, valid_loss: 0.017421990766056945\n",
      "SEED: 6, FOLD: 0, EPOCH: 24,train_loss: 0.014157860220348747, valid_loss: 0.017427388791527068\n",
      "(17539, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7339991758699003, valid_loss: 0.6857712694576809\n",
      "SEED: 6, FOLD: 1, EPOCH: 0,train_loss: 0.46571034272673767, valid_loss: 0.023493796533771923\n",
      "SEED: 6, FOLD: 1, EPOCH: 1,train_loss: 0.021041154901942482, valid_loss: 0.02377023638359138\n",
      "SEED: 6, FOLD: 1, EPOCH: 2,train_loss: 0.019620496833669968, valid_loss: 0.019994233974388667\n",
      "SEED: 6, FOLD: 1, EPOCH: 3,train_loss: 0.018842213530687317, valid_loss: 0.020425146552068847\n",
      "SEED: 6, FOLD: 1, EPOCH: 4,train_loss: 0.018402155677693478, valid_loss: 0.020641508006623812\n",
      "SEED: 6, FOLD: 1, EPOCH: 5,train_loss: 0.018274966762333675, valid_loss: 0.018212952970394065\n",
      "SEED: 6, FOLD: 1, EPOCH: 6,train_loss: 0.018077560558753168, valid_loss: 0.018548105391008513\n",
      "SEED: 6, FOLD: 1, EPOCH: 7,train_loss: 0.018067905611857987, valid_loss: 0.018632976604359492\n",
      "SEED: 6, FOLD: 1, EPOCH: 8,train_loss: 0.018048637317142624, valid_loss: 0.01824652062995093\n",
      "SEED: 6, FOLD: 1, EPOCH: 9,train_loss: 0.01802281425267026, valid_loss: 0.01830591426364013\n",
      "SEED: 6, FOLD: 1, EPOCH: 10,train_loss: 0.018052249566476414, valid_loss: 0.01783871751810823\n",
      "SEED: 6, FOLD: 1, EPOCH: 11,train_loss: 0.01794133420385744, valid_loss: 0.018054563232830594\n",
      "SEED: 6, FOLD: 1, EPOCH: 12,train_loss: 0.017897122755538727, valid_loss: 0.017932519928685258\n",
      "SEED: 6, FOLD: 1, EPOCH: 13,train_loss: 0.017764484138646418, valid_loss: 0.01799767767744405\n",
      "SEED: 6, FOLD: 1, EPOCH: 14,train_loss: 0.01775505459880915, valid_loss: 0.017620261226381575\n",
      "SEED: 6, FOLD: 1, EPOCH: 15,train_loss: 0.017484813503435125, valid_loss: 0.017762458963053566\n",
      "SEED: 6, FOLD: 1, EPOCH: 16,train_loss: 0.01747631741201748, valid_loss: 0.017557051458529063\n",
      "SEED: 6, FOLD: 1, EPOCH: 17,train_loss: 0.01720431793238158, valid_loss: 0.017535095954579968\n",
      "SEED: 6, FOLD: 1, EPOCH: 18,train_loss: 0.016890063490448654, valid_loss: 0.01732158607670239\n",
      "SEED: 6, FOLD: 1, EPOCH: 19,train_loss: 0.01657120443786076, valid_loss: 0.017203993456704276\n",
      "SEED: 6, FOLD: 1, EPOCH: 20,train_loss: 0.016131491022373455, valid_loss: 0.017141192938600266\n",
      "SEED: 6, FOLD: 1, EPOCH: 21,train_loss: 0.015865415314455397, valid_loss: 0.017165306982185158\n",
      "SEED: 6, FOLD: 1, EPOCH: 22,train_loss: 0.015416428352287714, valid_loss: 0.0171916645818523\n",
      "SEED: 6, FOLD: 1, EPOCH: 23,train_loss: 0.015082026224421419, valid_loss: 0.017105574666389397\n",
      "SEED: 6, FOLD: 1, EPOCH: 24,train_loss: 0.014911072936071001, valid_loss: 0.01712728485997234\n",
      "(17535, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7340316972593321, valid_loss: 0.6865424956594195\n",
      "SEED: 6, FOLD: 2, EPOCH: 0,train_loss: 0.46668697168955403, valid_loss: 0.02507516954626356\n",
      "SEED: 6, FOLD: 2, EPOCH: 1,train_loss: 0.021204398061237195, valid_loss: 0.018906079179474285\n",
      "SEED: 6, FOLD: 2, EPOCH: 2,train_loss: 0.018928683899941234, valid_loss: 0.01824159286916256\n",
      "SEED: 6, FOLD: 2, EPOCH: 3,train_loss: 0.01813812075305159, valid_loss: 0.018239697574504783\n",
      "SEED: 6, FOLD: 2, EPOCH: 4,train_loss: 0.01790202207808947, valid_loss: 0.01827000786683389\n",
      "SEED: 6, FOLD: 2, EPOCH: 5,train_loss: 0.01792412523832852, valid_loss: 0.017695584387651512\n",
      "SEED: 6, FOLD: 2, EPOCH: 6,train_loss: 0.017813780909254603, valid_loss: 0.017966329998203686\n",
      "SEED: 6, FOLD: 2, EPOCH: 7,train_loss: 0.01788967422270862, valid_loss: 0.01782422736287117\n",
      "SEED: 6, FOLD: 2, EPOCH: 8,train_loss: 0.017859693167962296, valid_loss: 0.017759539719138826\n",
      "SEED: 6, FOLD: 2, EPOCH: 9,train_loss: 0.017838287813058736, valid_loss: 0.018134249853236334\n",
      "SEED: 6, FOLD: 2, EPOCH: 10,train_loss: 0.01782479551178913, valid_loss: 0.017930350958236627\n",
      "SEED: 6, FOLD: 2, EPOCH: 11,train_loss: 0.0176868101609123, valid_loss: 0.017831060104072094\n",
      "SEED: 6, FOLD: 2, EPOCH: 12,train_loss: 0.017658162331820406, valid_loss: 0.01783323966498886\n",
      "SEED: 6, FOLD: 2, EPOCH: 13,train_loss: 0.017599123951564304, valid_loss: 0.018095063205276218\n",
      "SEED: 6, FOLD: 2, EPOCH: 14,train_loss: 0.017465202464130674, valid_loss: 0.017470870752419744\n",
      "SEED: 6, FOLD: 2, EPOCH: 15,train_loss: 0.017307760309509552, valid_loss: 0.017143864557147025\n",
      "SEED: 6, FOLD: 2, EPOCH: 16,train_loss: 0.01714400996719181, valid_loss: 0.017332285775669982\n",
      "SEED: 6, FOLD: 2, EPOCH: 17,train_loss: 0.01689144073693204, valid_loss: 0.01738202598478113\n",
      "SEED: 6, FOLD: 2, EPOCH: 18,train_loss: 0.016656985723950565, valid_loss: 0.017263003731412548\n",
      "SEED: 6, FOLD: 2, EPOCH: 19,train_loss: 0.01622365251944883, valid_loss: 0.01716099227113383\n",
      "SEED: 6, FOLD: 2, EPOCH: 20,train_loss: 0.015808423226495293, valid_loss: 0.017090465633996896\n",
      "SEED: 6, FOLD: 2, EPOCH: 21,train_loss: 0.015321752294408578, valid_loss: 0.017081670596131256\n",
      "SEED: 6, FOLD: 2, EPOCH: 22,train_loss: 0.014771302543362997, valid_loss: 0.01704714551035847\n",
      "SEED: 6, FOLD: 2, EPOCH: 23,train_loss: 0.01431088853137989, valid_loss: 0.01704216862895659\n",
      "SEED: 6, FOLD: 2, EPOCH: 24,train_loss: 0.014047935407907858, valid_loss: 0.017058788798749447\n",
      "(17586, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7343091623506685, valid_loss: 0.680975832257952\n",
      "SEED: 6, FOLD: 3, EPOCH: 0,train_loss: 0.46699426985899173, valid_loss: 0.02404744273849896\n",
      "SEED: 6, FOLD: 3, EPOCH: 1,train_loss: 0.0212202166625555, valid_loss: 0.018743827805987427\n",
      "SEED: 6, FOLD: 3, EPOCH: 2,train_loss: 0.01904528391668978, valid_loss: 0.018090746604970523\n",
      "SEED: 6, FOLD: 3, EPOCH: 3,train_loss: 0.018195847710729508, valid_loss: 0.018365430778690746\n",
      "SEED: 6, FOLD: 3, EPOCH: 4,train_loss: 0.017837939979643492, valid_loss: 0.017753217768456255\n",
      "SEED: 6, FOLD: 3, EPOCH: 5,train_loss: 0.017879504298764295, valid_loss: 0.01816209490810122\n",
      "SEED: 6, FOLD: 3, EPOCH: 6,train_loss: 0.017920000141189583, valid_loss: 0.017780073971620628\n",
      "SEED: 6, FOLD: 3, EPOCH: 7,train_loss: 0.017863278277218342, valid_loss: 0.018091139969016824\n",
      "SEED: 6, FOLD: 3, EPOCH: 8,train_loss: 0.01789237198460361, valid_loss: 0.01792573465832642\n",
      "SEED: 6, FOLD: 3, EPOCH: 9,train_loss: 0.017813991782241974, valid_loss: 0.017648697830736637\n",
      "SEED: 6, FOLD: 3, EPOCH: 10,train_loss: 0.01777452895876722, valid_loss: 0.017635575868189333\n",
      "SEED: 6, FOLD: 3, EPOCH: 11,train_loss: 0.01775931159331315, valid_loss: 0.01758356560021639\n",
      "SEED: 6, FOLD: 3, EPOCH: 12,train_loss: 0.01767006944325091, valid_loss: 0.017549627859677588\n",
      "SEED: 6, FOLD: 3, EPOCH: 13,train_loss: 0.017561589279954416, valid_loss: 0.01755435602473361\n",
      "SEED: 6, FOLD: 3, EPOCH: 14,train_loss: 0.01750815956029987, valid_loss: 0.01755711218076093\n",
      "SEED: 6, FOLD: 3, EPOCH: 15,train_loss: 0.017253678285287344, valid_loss: 0.017340905671673162\n",
      "SEED: 6, FOLD: 3, EPOCH: 16,train_loss: 0.017183006464409224, valid_loss: 0.01733626944145986\n",
      "SEED: 6, FOLD: 3, EPOCH: 17,train_loss: 0.01692372343192498, valid_loss: 0.01729995629617146\n",
      "SEED: 6, FOLD: 3, EPOCH: 18,train_loss: 0.016534006223082542, valid_loss: 0.017195910082331727\n",
      "SEED: 6, FOLD: 3, EPOCH: 19,train_loss: 0.016255295140317816, valid_loss: 0.017074383635606084\n",
      "SEED: 6, FOLD: 3, EPOCH: 20,train_loss: 0.01584981711230416, valid_loss: 0.01706499851175717\n",
      "SEED: 6, FOLD: 3, EPOCH: 21,train_loss: 0.01533608311328335, valid_loss: 0.017037030069955758\n",
      "SEED: 6, FOLD: 3, EPOCH: 22,train_loss: 0.014833057818907326, valid_loss: 0.01705382780304977\n",
      "SEED: 6, FOLD: 3, EPOCH: 23,train_loss: 0.014354218465640493, valid_loss: 0.01705127592597689\n",
      "SEED: 6, FOLD: 3, EPOCH: 24,train_loss: 0.014116178448919369, valid_loss: 0.01704814588384969\n",
      "(17615, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.734051596859227, valid_loss: 0.6818730427938349\n",
      "SEED: 6, FOLD: 4, EPOCH: 0,train_loss: 0.4662704980135828, valid_loss: 0.02396498993039131\n",
      "SEED: 6, FOLD: 4, EPOCH: 1,train_loss: 0.020831909462593605, valid_loss: 0.018820387420847136\n",
      "SEED: 6, FOLD: 4, EPOCH: 2,train_loss: 0.01921340569421865, valid_loss: 0.018509432098225635\n",
      "SEED: 6, FOLD: 4, EPOCH: 3,train_loss: 0.018349413287596428, valid_loss: 0.017800370477797353\n",
      "SEED: 6, FOLD: 4, EPOCH: 4,train_loss: 0.017931876521881506, valid_loss: 0.017925660728531724\n",
      "SEED: 6, FOLD: 4, EPOCH: 5,train_loss: 0.01788603418601164, valid_loss: 0.017969153355807066\n",
      "SEED: 6, FOLD: 4, EPOCH: 6,train_loss: 0.017871636276443798, valid_loss: 0.018148738836102626\n",
      "SEED: 6, FOLD: 4, EPOCH: 7,train_loss: 0.01789408795994477, valid_loss: 0.017719018382622916\n",
      "SEED: 6, FOLD: 4, EPOCH: 8,train_loss: 0.01784596994411254, valid_loss: 0.017944009235019192\n",
      "SEED: 6, FOLD: 4, EPOCH: 9,train_loss: 0.017835678930893755, valid_loss: 0.017665813156567952\n",
      "SEED: 6, FOLD: 4, EPOCH: 10,train_loss: 0.017840007731717997, valid_loss: 0.017844142967506367\n",
      "SEED: 6, FOLD: 4, EPOCH: 11,train_loss: 0.017788651939211548, valid_loss: 0.01766654523089528\n",
      "SEED: 6, FOLD: 4, EPOCH: 12,train_loss: 0.017704023750147957, valid_loss: 0.017738078666083953\n",
      "SEED: 6, FOLD: 4, EPOCH: 13,train_loss: 0.017638542351947315, valid_loss: 0.017636292367516196\n",
      "SEED: 6, FOLD: 4, EPOCH: 14,train_loss: 0.017468636308837195, valid_loss: 0.017280626220299918\n",
      "SEED: 6, FOLD: 4, EPOCH: 15,train_loss: 0.017365563647362633, valid_loss: 0.017430448877241683\n",
      "SEED: 6, FOLD: 4, EPOCH: 16,train_loss: 0.01716320259847503, valid_loss: 0.017330249387990024\n",
      "SEED: 6, FOLD: 4, EPOCH: 17,train_loss: 0.01697497367453964, valid_loss: 0.017125435721348312\n",
      "SEED: 6, FOLD: 4, EPOCH: 18,train_loss: 0.016642520555119583, valid_loss: 0.017251808661967516\n",
      "SEED: 6, FOLD: 4, EPOCH: 19,train_loss: 0.016318826079098642, valid_loss: 0.017179750179981485\n",
      "SEED: 6, FOLD: 4, EPOCH: 20,train_loss: 0.01588778469738537, valid_loss: 0.017127679250038722\n",
      "SEED: 6, FOLD: 4, EPOCH: 21,train_loss: 0.015398439762277016, valid_loss: 0.01706341643105535\n",
      "SEED: 6, FOLD: 4, EPOCH: 22,train_loss: 0.014921924990156422, valid_loss: 0.017078627037870532\n",
      "SEED: 6, FOLD: 4, EPOCH: 23,train_loss: 0.014478737562624872, valid_loss: 0.017028203973656193\n",
      "SEED: 6, FOLD: 4, EPOCH: 24,train_loss: 0.014248320697874262, valid_loss: 0.01702936738729477\n",
      "(17569, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7356484540994617, valid_loss: 0.6903154168810163\n",
      "SEED: 7, FOLD: 0, EPOCH: 0,train_loss: 0.4655978061339777, valid_loss: 0.023940065928867885\n",
      "SEED: 7, FOLD: 0, EPOCH: 1,train_loss: 0.021085544097898663, valid_loss: 0.02107993300471987\n",
      "SEED: 7, FOLD: 0, EPOCH: 2,train_loss: 0.018979544440905254, valid_loss: 0.01807837464979717\n",
      "SEED: 7, FOLD: 0, EPOCH: 3,train_loss: 0.01835024833301271, valid_loss: 0.01776001365589244\n",
      "SEED: 7, FOLD: 0, EPOCH: 4,train_loss: 0.017998367757199034, valid_loss: 0.01771104982388871\n",
      "SEED: 7, FOLD: 0, EPOCH: 5,train_loss: 0.0179083951195513, valid_loss: 0.01748919737126146\n",
      "SEED: 7, FOLD: 0, EPOCH: 6,train_loss: 0.017893369849501312, valid_loss: 0.017599567132336753\n",
      "SEED: 7, FOLD: 0, EPOCH: 7,train_loss: 0.018012129067294838, valid_loss: 0.017543165146240165\n",
      "SEED: 7, FOLD: 0, EPOCH: 8,train_loss: 0.01798366820709645, valid_loss: 0.017511999819959913\n",
      "SEED: 7, FOLD: 0, EPOCH: 9,train_loss: 0.01791387112757218, valid_loss: 0.017662291281989644\n",
      "SEED: 7, FOLD: 0, EPOCH: 10,train_loss: 0.017868823574289032, valid_loss: 0.017431097770375863\n",
      "SEED: 7, FOLD: 0, EPOCH: 11,train_loss: 0.017800814863564312, valid_loss: 0.017390320769378118\n",
      "SEED: 7, FOLD: 0, EPOCH: 12,train_loss: 0.017743846927971943, valid_loss: 0.01733309669154031\n",
      "SEED: 7, FOLD: 0, EPOCH: 13,train_loss: 0.017657843992060076, valid_loss: 0.01724721970302718\n",
      "SEED: 7, FOLD: 0, EPOCH: 14,train_loss: 0.017593862900537424, valid_loss: 0.017127065493592195\n",
      "SEED: 7, FOLD: 0, EPOCH: 15,train_loss: 0.01742991317819426, valid_loss: 0.01702926073755537\n",
      "SEED: 7, FOLD: 0, EPOCH: 16,train_loss: 0.017268510299154383, valid_loss: 0.016944186948239803\n",
      "SEED: 7, FOLD: 0, EPOCH: 17,train_loss: 0.017007301770744547, valid_loss: 0.01687107676906245\n",
      "SEED: 7, FOLD: 0, EPOCH: 18,train_loss: 0.016714268795929958, valid_loss: 0.01707714820014579\n",
      "SEED: 7, FOLD: 0, EPOCH: 19,train_loss: 0.016410221109517675, valid_loss: 0.01686917809503419\n",
      "SEED: 7, FOLD: 0, EPOCH: 20,train_loss: 0.015988510257254045, valid_loss: 0.01695729637784617\n",
      "SEED: 7, FOLD: 0, EPOCH: 21,train_loss: 0.015504139887195999, valid_loss: 0.016822708610977444\n",
      "SEED: 7, FOLD: 0, EPOCH: 22,train_loss: 0.01499031641372088, valid_loss: 0.016681258832769736\n",
      "SEED: 7, FOLD: 0, EPOCH: 23,train_loss: 0.014592317823806534, valid_loss: 0.01674474110560758\n",
      "SEED: 7, FOLD: 0, EPOCH: 24,train_loss: 0.01433958766469057, valid_loss: 0.016761581865804537\n",
      "(17564, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7355124103850212, valid_loss: 0.691426248209817\n",
      "SEED: 7, FOLD: 1, EPOCH: 0,train_loss: 0.46691169970385404, valid_loss: 0.023983944047774586\n",
      "SEED: 7, FOLD: 1, EPOCH: 1,train_loss: 0.02067873354299345, valid_loss: 0.018916328544063228\n",
      "SEED: 7, FOLD: 1, EPOCH: 2,train_loss: 0.018949150364252106, valid_loss: 0.018268315680325033\n",
      "SEED: 7, FOLD: 1, EPOCH: 3,train_loss: 0.018313035335175802, valid_loss: 0.018226372211107185\n",
      "SEED: 7, FOLD: 1, EPOCH: 4,train_loss: 0.017923840065149292, valid_loss: 0.018573419962610516\n",
      "SEED: 7, FOLD: 1, EPOCH: 5,train_loss: 0.017818343164264294, valid_loss: 0.018488776231450694\n",
      "SEED: 7, FOLD: 1, EPOCH: 6,train_loss: 0.018001242311320442, valid_loss: 0.018914800988776344\n",
      "SEED: 7, FOLD: 1, EPOCH: 7,train_loss: 0.017941221007672342, valid_loss: 0.017964930193764824\n",
      "SEED: 7, FOLD: 1, EPOCH: 8,train_loss: 0.017873841277121202, valid_loss: 0.018497667301978382\n",
      "SEED: 7, FOLD: 1, EPOCH: 9,train_loss: 0.017969866188755935, valid_loss: 0.018365715736789363\n",
      "SEED: 7, FOLD: 1, EPOCH: 10,train_loss: 0.01785710096305263, valid_loss: 0.0179307669667261\n",
      "SEED: 7, FOLD: 1, EPOCH: 11,train_loss: 0.017798814693114895, valid_loss: 0.0180174142654453\n",
      "SEED: 7, FOLD: 1, EPOCH: 12,train_loss: 0.017698332768581484, valid_loss: 0.017805660276540687\n",
      "SEED: 7, FOLD: 1, EPOCH: 13,train_loss: 0.017619684466795214, valid_loss: 0.017815803204263958\n",
      "SEED: 7, FOLD: 1, EPOCH: 14,train_loss: 0.017486841843018065, valid_loss: 0.018097603294466223\n",
      "SEED: 7, FOLD: 1, EPOCH: 15,train_loss: 0.017364190668677507, valid_loss: 0.01777273722525154\n",
      "SEED: 7, FOLD: 1, EPOCH: 16,train_loss: 0.017226125761542633, valid_loss: 0.017682947245027336\n",
      "SEED: 7, FOLD: 1, EPOCH: 17,train_loss: 0.01692640383903315, valid_loss: 0.01766859010926315\n",
      "SEED: 7, FOLD: 1, EPOCH: 18,train_loss: 0.016668531645521307, valid_loss: 0.01780008351696389\n",
      "SEED: 7, FOLD: 1, EPOCH: 19,train_loss: 0.016387850181132122, valid_loss: 0.01758911976856845\n",
      "SEED: 7, FOLD: 1, EPOCH: 20,train_loss: 0.016013966515606295, valid_loss: 0.017398364788719586\n",
      "SEED: 7, FOLD: 1, EPOCH: 21,train_loss: 0.015504864091728476, valid_loss: 0.017395275990877833\n",
      "SEED: 7, FOLD: 1, EPOCH: 22,train_loss: 0.01501468046689811, valid_loss: 0.0174510497333748\n",
      "SEED: 7, FOLD: 1, EPOCH: 23,train_loss: 0.014625727786156147, valid_loss: 0.017375115784151213\n",
      "SEED: 7, FOLD: 1, EPOCH: 24,train_loss: 0.014421932514001062, valid_loss: 0.017402543367019723\n",
      "(17556, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7356690941513448, valid_loss: 0.6896167056901115\n",
      "SEED: 7, FOLD: 2, EPOCH: 0,train_loss: 0.46708906756417046, valid_loss: 0.023272869203771862\n",
      "SEED: 7, FOLD: 2, EPOCH: 1,train_loss: 0.02100090461148732, valid_loss: 0.01870318544762475\n",
      "SEED: 7, FOLD: 2, EPOCH: 2,train_loss: 0.01924671513446863, valid_loss: 0.017911349050700666\n",
      "SEED: 7, FOLD: 2, EPOCH: 3,train_loss: 0.018269471938897303, valid_loss: 0.017719867053840842\n",
      "SEED: 7, FOLD: 2, EPOCH: 4,train_loss: 0.018063581305677475, valid_loss: 0.017852558727775303\n",
      "SEED: 7, FOLD: 2, EPOCH: 5,train_loss: 0.018057431998676148, valid_loss: 0.01776840915637357\n",
      "SEED: 7, FOLD: 2, EPOCH: 6,train_loss: 0.01794225105718858, valid_loss: 0.017656319801296505\n",
      "SEED: 7, FOLD: 2, EPOCH: 7,train_loss: 0.017957834695614336, valid_loss: 0.017615291316594395\n",
      "SEED: 7, FOLD: 2, EPOCH: 8,train_loss: 0.017891627844369064, valid_loss: 0.01765230537525245\n",
      "SEED: 7, FOLD: 2, EPOCH: 9,train_loss: 0.017946082248311977, valid_loss: 0.017933367911194053\n",
      "SEED: 7, FOLD: 2, EPOCH: 10,train_loss: 0.017853539484296587, valid_loss: 0.017472870328596662\n",
      "SEED: 7, FOLD: 2, EPOCH: 11,train_loss: 0.017805747411119333, valid_loss: 0.01752311283988612\n",
      "SEED: 7, FOLD: 2, EPOCH: 12,train_loss: 0.017707751719686, valid_loss: 0.01739745448742594\n",
      "SEED: 7, FOLD: 2, EPOCH: 13,train_loss: 0.017593773581303547, valid_loss: 0.017253295837768485\n",
      "SEED: 7, FOLD: 2, EPOCH: 14,train_loss: 0.01751175467464803, valid_loss: 0.017463861299412593\n",
      "SEED: 7, FOLD: 2, EPOCH: 15,train_loss: 0.017380455292869305, valid_loss: 0.017123316654137202\n",
      "SEED: 7, FOLD: 2, EPOCH: 16,train_loss: 0.017166621632118156, valid_loss: 0.017022239815975938\n",
      "SEED: 7, FOLD: 2, EPOCH: 17,train_loss: 0.01690862597087803, valid_loss: 0.017011264099606446\n",
      "SEED: 7, FOLD: 2, EPOCH: 18,train_loss: 0.016654601205896208, valid_loss: 0.01730035524815321\n",
      "SEED: 7, FOLD: 2, EPOCH: 19,train_loss: 0.016264807176438793, valid_loss: 0.01697892344423703\n",
      "SEED: 7, FOLD: 2, EPOCH: 20,train_loss: 0.015889393597625305, valid_loss: 0.016796608828008174\n",
      "SEED: 7, FOLD: 2, EPOCH: 21,train_loss: 0.015419863940527042, valid_loss: 0.016783476780567852\n",
      "SEED: 7, FOLD: 2, EPOCH: 22,train_loss: 0.014869261141596497, valid_loss: 0.01683919903423105\n",
      "SEED: 7, FOLD: 2, EPOCH: 23,train_loss: 0.01446054563385205, valid_loss: 0.016796494222113063\n",
      "SEED: 7, FOLD: 2, EPOCH: 24,train_loss: 0.014201868440200022, valid_loss: 0.016819114690380436\n",
      "(17532, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7359926565720217, valid_loss: 0.6914134417261396\n",
      "SEED: 7, FOLD: 3, EPOCH: 0,train_loss: 0.4682114162638675, valid_loss: 0.024697168011750495\n",
      "SEED: 7, FOLD: 3, EPOCH: 1,train_loss: 0.020623939356555904, valid_loss: 0.01919226220675877\n",
      "SEED: 7, FOLD: 3, EPOCH: 2,train_loss: 0.01902101874813764, valid_loss: 0.01851475943944284\n",
      "SEED: 7, FOLD: 3, EPOCH: 3,train_loss: 0.017993155159871942, valid_loss: 0.018310476573450224\n",
      "SEED: 7, FOLD: 3, EPOCH: 4,train_loss: 0.01774764709500936, valid_loss: 0.01847165506333113\n",
      "SEED: 7, FOLD: 3, EPOCH: 5,train_loss: 0.017652718812553553, valid_loss: 0.018321640683071953\n",
      "SEED: 7, FOLD: 3, EPOCH: 6,train_loss: 0.017679834391677033, valid_loss: 0.018612945984516824\n",
      "SEED: 7, FOLD: 3, EPOCH: 7,train_loss: 0.017746813472931403, valid_loss: 0.01830469737095492\n",
      "SEED: 7, FOLD: 3, EPOCH: 8,train_loss: 0.017701244926637542, valid_loss: 0.01814796474895307\n",
      "SEED: 7, FOLD: 3, EPOCH: 9,train_loss: 0.017682190223114333, valid_loss: 0.018329823203384877\n",
      "SEED: 7, FOLD: 3, EPOCH: 10,train_loss: 0.017668132411900662, valid_loss: 0.018184051316763674\n",
      "SEED: 7, FOLD: 3, EPOCH: 11,train_loss: 0.01756682406675859, valid_loss: 0.018239412776061465\n",
      "SEED: 7, FOLD: 3, EPOCH: 12,train_loss: 0.017540299381217817, valid_loss: 0.018106872428740775\n",
      "SEED: 7, FOLD: 3, EPOCH: 13,train_loss: 0.017353165928736654, valid_loss: 0.018862018680998256\n",
      "SEED: 7, FOLD: 3, EPOCH: 14,train_loss: 0.017292801617053304, valid_loss: 0.018127704677837236\n",
      "SEED: 7, FOLD: 3, EPOCH: 15,train_loss: 0.017133315161795077, valid_loss: 0.017813411168754102\n",
      "SEED: 7, FOLD: 3, EPOCH: 16,train_loss: 0.016908507243505795, valid_loss: 0.017897343103374753\n",
      "SEED: 7, FOLD: 3, EPOCH: 17,train_loss: 0.016708623074049498, valid_loss: 0.017897287969078336\n",
      "SEED: 7, FOLD: 3, EPOCH: 18,train_loss: 0.016378791363787476, valid_loss: 0.017782882946942535\n",
      "SEED: 7, FOLD: 3, EPOCH: 19,train_loss: 0.016039157408649904, valid_loss: 0.01779667048582009\n",
      "SEED: 7, FOLD: 3, EPOCH: 20,train_loss: 0.015653043992164797, valid_loss: 0.017745272628962992\n",
      "SEED: 7, FOLD: 3, EPOCH: 21,train_loss: 0.01508327674827654, valid_loss: 0.01769399395478623\n",
      "SEED: 7, FOLD: 3, EPOCH: 22,train_loss: 0.014530683643300167, valid_loss: 0.01768727164183344\n",
      "SEED: 7, FOLD: 3, EPOCH: 23,train_loss: 0.014060985276570721, valid_loss: 0.017632694409361906\n",
      "SEED: 7, FOLD: 3, EPOCH: 24,train_loss: 0.013817347205468337, valid_loss: 0.017660789457815036\n",
      "(17571, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.736025295395782, valid_loss: 0.692817371232169\n",
      "SEED: 7, FOLD: 4, EPOCH: 0,train_loss: 0.4665057763484293, valid_loss: 0.023998425794499262\n",
      "SEED: 7, FOLD: 4, EPOCH: 1,train_loss: 0.02099323955674966, valid_loss: 0.018916285570178715\n",
      "SEED: 7, FOLD: 4, EPOCH: 2,train_loss: 0.01893239745033392, valid_loss: 0.018176396270947796\n",
      "SEED: 7, FOLD: 4, EPOCH: 3,train_loss: 0.018345190252622833, valid_loss: 0.017841323811028684\n",
      "SEED: 7, FOLD: 4, EPOCH: 4,train_loss: 0.018028592191420605, valid_loss: 0.018418471754661627\n",
      "SEED: 7, FOLD: 4, EPOCH: 5,train_loss: 0.01786982318710374, valid_loss: 0.018185732779758317\n",
      "SEED: 7, FOLD: 4, EPOCH: 6,train_loss: 0.01782884542573837, valid_loss: 0.018073539888220174\n",
      "SEED: 7, FOLD: 4, EPOCH: 7,train_loss: 0.017815924175353586, valid_loss: 0.018309575292680944\n",
      "SEED: 7, FOLD: 4, EPOCH: 8,train_loss: 0.01781008928420319, valid_loss: 0.01779153517314366\n",
      "SEED: 7, FOLD: 4, EPOCH: 9,train_loss: 0.0177503220156591, valid_loss: 0.01794557651238782\n",
      "SEED: 7, FOLD: 4, EPOCH: 10,train_loss: 0.01773149451996753, valid_loss: 0.01776842602661678\n",
      "SEED: 7, FOLD: 4, EPOCH: 11,train_loss: 0.01774525738901634, valid_loss: 0.017768171136932714\n",
      "SEED: 7, FOLD: 4, EPOCH: 12,train_loss: 0.017663451404297266, valid_loss: 0.017902629050825323\n",
      "SEED: 7, FOLD: 4, EPOCH: 13,train_loss: 0.017535024626261515, valid_loss: 0.017691987460213048\n",
      "SEED: 7, FOLD: 4, EPOCH: 14,train_loss: 0.01744483185230174, valid_loss: 0.017568626760372092\n",
      "SEED: 7, FOLD: 4, EPOCH: 15,train_loss: 0.017312765681603247, valid_loss: 0.01760994110788618\n",
      "SEED: 7, FOLD: 4, EPOCH: 16,train_loss: 0.017089156251724646, valid_loss: 0.01745966523885727\n",
      "SEED: 7, FOLD: 4, EPOCH: 17,train_loss: 0.016913859679809084, valid_loss: 0.0174959520144122\n",
      "SEED: 7, FOLD: 4, EPOCH: 18,train_loss: 0.01653662409660393, valid_loss: 0.017425789630838802\n",
      "SEED: 7, FOLD: 4, EPOCH: 19,train_loss: 0.016257643713143425, valid_loss: 0.017350813666624682\n",
      "SEED: 7, FOLD: 4, EPOCH: 20,train_loss: 0.01588569403342579, valid_loss: 0.017286336847714016\n",
      "SEED: 7, FOLD: 4, EPOCH: 21,train_loss: 0.015361513355341942, valid_loss: 0.017254038740481648\n",
      "SEED: 7, FOLD: 4, EPOCH: 22,train_loss: 0.014899260755898296, valid_loss: 0.01729004955185311\n",
      "SEED: 7, FOLD: 4, EPOCH: 23,train_loss: 0.014457333778989489, valid_loss: 0.01728595971528973\n",
      "SEED: 7, FOLD: 4, EPOCH: 24,train_loss: 0.014243476086066685, valid_loss: 0.017301956032003674\n",
      "(17505, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7353917377708602, valid_loss: 0.7018885101590838\n",
      "SEED: 8, FOLD: 0, EPOCH: 0,train_loss: 0.467685771140739, valid_loss: 0.024627419135400227\n",
      "SEED: 8, FOLD: 0, EPOCH: 1,train_loss: 0.020978495981680216, valid_loss: 0.019200796367866653\n",
      "SEED: 8, FOLD: 0, EPOCH: 2,train_loss: 0.01896797777255521, valid_loss: 0.018576370711837497\n",
      "SEED: 8, FOLD: 0, EPOCH: 3,train_loss: 0.01827777473487123, valid_loss: 0.017915823150958333\n",
      "SEED: 8, FOLD: 0, EPOCH: 4,train_loss: 0.017889953333966053, valid_loss: 0.01793603003025055\n",
      "SEED: 8, FOLD: 0, EPOCH: 5,train_loss: 0.017888857065326107, valid_loss: 0.01804802151662963\n",
      "SEED: 8, FOLD: 0, EPOCH: 6,train_loss: 0.01788462147143853, valid_loss: 0.01842304973730019\n",
      "SEED: 8, FOLD: 0, EPOCH: 7,train_loss: 0.017872120450883017, valid_loss: 0.017935786183391297\n",
      "SEED: 8, FOLD: 0, EPOCH: 8,train_loss: 0.01787102704419054, valid_loss: 0.018006118041064056\n",
      "SEED: 8, FOLD: 0, EPOCH: 9,train_loss: 0.017830289560404135, valid_loss: 0.018228455978844847\n",
      "SEED: 8, FOLD: 0, EPOCH: 10,train_loss: 0.017867505326051348, valid_loss: 0.018145181691007956\n",
      "SEED: 8, FOLD: 0, EPOCH: 11,train_loss: 0.01769457178285522, valid_loss: 0.017815754482788698\n",
      "SEED: 8, FOLD: 0, EPOCH: 12,train_loss: 0.017649596794950265, valid_loss: 0.01775865283395563\n",
      "SEED: 8, FOLD: 0, EPOCH: 13,train_loss: 0.017571949563159123, valid_loss: 0.017703797987529208\n",
      "SEED: 8, FOLD: 0, EPOCH: 14,train_loss: 0.017383921279633133, valid_loss: 0.017794455508036273\n",
      "SEED: 8, FOLD: 0, EPOCH: 15,train_loss: 0.017282511060037753, valid_loss: 0.017541671384658133\n",
      "SEED: 8, FOLD: 0, EPOCH: 16,train_loss: 0.01707074562101251, valid_loss: 0.0175674953098808\n",
      "SEED: 8, FOLD: 0, EPOCH: 17,train_loss: 0.01684037420599565, valid_loss: 0.017658047564327716\n",
      "SEED: 8, FOLD: 0, EPOCH: 18,train_loss: 0.016541419503190657, valid_loss: 0.017548152564891745\n",
      "SEED: 8, FOLD: 0, EPOCH: 19,train_loss: 0.01619498849758049, valid_loss: 0.017560905830136368\n",
      "SEED: 8, FOLD: 0, EPOCH: 20,train_loss: 0.015762487521571833, valid_loss: 0.017402401646333082\n",
      "SEED: 8, FOLD: 0, EPOCH: 21,train_loss: 0.01533002224172989, valid_loss: 0.01738371428634439\n",
      "SEED: 8, FOLD: 0, EPOCH: 22,train_loss: 0.014757967764770027, valid_loss: 0.017477788110928875\n",
      "SEED: 8, FOLD: 0, EPOCH: 23,train_loss: 0.014323621104559758, valid_loss: 0.01746715363115072\n",
      "SEED: 8, FOLD: 0, EPOCH: 24,train_loss: 0.014096487823357113, valid_loss: 0.01746270555470671\n",
      "(17567, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7351628114347872, valid_loss: 0.6992931927953447\n",
      "SEED: 8, FOLD: 1, EPOCH: 0,train_loss: 0.46578611368718353, valid_loss: 0.023767418733664922\n",
      "SEED: 8, FOLD: 1, EPOCH: 1,train_loss: 0.020627486708479515, valid_loss: 0.018707799831671375\n",
      "SEED: 8, FOLD: 1, EPOCH: 2,train_loss: 0.018888712617690148, valid_loss: 0.018264692995165074\n",
      "SEED: 8, FOLD: 1, EPOCH: 3,train_loss: 0.01821650085511847, valid_loss: 0.0192191747416343\n",
      "SEED: 8, FOLD: 1, EPOCH: 4,train_loss: 0.017927596898938435, valid_loss: 0.01790598761290312\n",
      "SEED: 8, FOLD: 1, EPOCH: 5,train_loss: 0.017918454476402723, valid_loss: 0.01846618881183011\n",
      "SEED: 8, FOLD: 1, EPOCH: 6,train_loss: 0.01792192643346346, valid_loss: 0.017769588796155793\n",
      "SEED: 8, FOLD: 1, EPOCH: 7,train_loss: 0.017781197977508757, valid_loss: 0.017899252846837042\n",
      "SEED: 8, FOLD: 1, EPOCH: 8,train_loss: 0.017857214800365593, valid_loss: 0.018158860690891742\n",
      "SEED: 8, FOLD: 1, EPOCH: 9,train_loss: 0.017875910169728424, valid_loss: 0.017993639303105217\n",
      "SEED: 8, FOLD: 1, EPOCH: 10,train_loss: 0.017766315631730402, valid_loss: 0.018100771786911145\n",
      "SEED: 8, FOLD: 1, EPOCH: 11,train_loss: 0.01774322616773239, valid_loss: 0.01803001926413604\n",
      "SEED: 8, FOLD: 1, EPOCH: 12,train_loss: 0.017715429576734703, valid_loss: 0.017920076474547388\n",
      "SEED: 8, FOLD: 1, EPOCH: 13,train_loss: 0.017605128650809976, valid_loss: 0.017743857337960176\n",
      "SEED: 8, FOLD: 1, EPOCH: 14,train_loss: 0.017490534867713417, valid_loss: 0.017751732308949743\n",
      "SEED: 8, FOLD: 1, EPOCH: 15,train_loss: 0.017365583704541557, valid_loss: 0.017575181727962835\n",
      "SEED: 8, FOLD: 1, EPOCH: 16,train_loss: 0.01707862923596648, valid_loss: 0.017430424370935987\n",
      "SEED: 8, FOLD: 1, EPOCH: 17,train_loss: 0.016913598875744618, valid_loss: 0.017541044391691685\n",
      "SEED: 8, FOLD: 1, EPOCH: 18,train_loss: 0.016661506254171978, valid_loss: 0.01736804015402283\n",
      "SEED: 8, FOLD: 1, EPOCH: 19,train_loss: 0.016285033295929865, valid_loss: 0.017374605499207975\n",
      "SEED: 8, FOLD: 1, EPOCH: 20,train_loss: 0.015888814692911896, valid_loss: 0.01733525070760931\n",
      "SEED: 8, FOLD: 1, EPOCH: 21,train_loss: 0.015391257780509583, valid_loss: 0.017288764220263278\n",
      "SEED: 8, FOLD: 1, EPOCH: 22,train_loss: 0.01490572133384969, valid_loss: 0.017328469109322342\n",
      "SEED: 8, FOLD: 1, EPOCH: 23,train_loss: 0.014479329640828613, valid_loss: 0.017300439120403358\n",
      "SEED: 8, FOLD: 1, EPOCH: 24,train_loss: 0.014237984542505465, valid_loss: 0.017310173250734806\n",
      "(17582, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7356032081272291, valid_loss: 0.7007815224783761\n",
      "SEED: 8, FOLD: 2, EPOCH: 0,train_loss: 0.4663175412359229, valid_loss: 0.024017969518899916\n",
      "SEED: 8, FOLD: 2, EPOCH: 1,train_loss: 0.020778584793425987, valid_loss: 0.018948741416846004\n",
      "SEED: 8, FOLD: 2, EPOCH: 2,train_loss: 0.018851948240636917, valid_loss: 0.018017211662871496\n",
      "SEED: 8, FOLD: 2, EPOCH: 3,train_loss: 0.01815480436535849, valid_loss: 0.01795209946909121\n",
      "SEED: 8, FOLD: 2, EPOCH: 4,train_loss: 0.017952712380961664, valid_loss: 0.018256948914911066\n",
      "SEED: 8, FOLD: 2, EPOCH: 5,train_loss: 0.017936173327051212, valid_loss: 0.01794616425676005\n",
      "SEED: 8, FOLD: 2, EPOCH: 6,train_loss: 0.017944266486481047, valid_loss: 0.01801925775195871\n",
      "SEED: 8, FOLD: 2, EPOCH: 7,train_loss: 0.01793053574131235, valid_loss: 0.01787957264376538\n",
      "SEED: 8, FOLD: 2, EPOCH: 8,train_loss: 0.017972575041694916, valid_loss: 0.01791693836982761\n",
      "SEED: 8, FOLD: 2, EPOCH: 9,train_loss: 0.017871642896932535, valid_loss: 0.018178028879421097\n",
      "SEED: 8, FOLD: 2, EPOCH: 10,train_loss: 0.017851182036911665, valid_loss: 0.017740995117596216\n",
      "SEED: 8, FOLD: 2, EPOCH: 11,train_loss: 0.017786570844928854, valid_loss: 0.017852400163454667\n",
      "SEED: 8, FOLD: 2, EPOCH: 12,train_loss: 0.01769388049328025, valid_loss: 0.017989031012569157\n",
      "SEED: 8, FOLD: 2, EPOCH: 13,train_loss: 0.01755679078211171, valid_loss: 0.017907430843583174\n",
      "SEED: 8, FOLD: 2, EPOCH: 14,train_loss: 0.017533576352170843, valid_loss: 0.01771668004138129\n",
      "SEED: 8, FOLD: 2, EPOCH: 15,train_loss: 0.01736344619775596, valid_loss: 0.017669686701680933\n",
      "SEED: 8, FOLD: 2, EPOCH: 16,train_loss: 0.017192322112943813, valid_loss: 0.017415521666407585\n",
      "SEED: 8, FOLD: 2, EPOCH: 17,train_loss: 0.01700336558987265, valid_loss: 0.017387560568749905\n",
      "SEED: 8, FOLD: 2, EPOCH: 18,train_loss: 0.01664081285370217, valid_loss: 0.017363617436162063\n",
      "SEED: 8, FOLD: 2, EPOCH: 19,train_loss: 0.016356542301566704, valid_loss: 0.0174248834539737\n",
      "SEED: 8, FOLD: 2, EPOCH: 20,train_loss: 0.015931465021887983, valid_loss: 0.017318113387695382\n",
      "SEED: 8, FOLD: 2, EPOCH: 21,train_loss: 0.01545317484524803, valid_loss: 0.01718874139977353\n",
      "SEED: 8, FOLD: 2, EPOCH: 22,train_loss: 0.014950136431371388, valid_loss: 0.017236962621765477\n",
      "SEED: 8, FOLD: 2, EPOCH: 23,train_loss: 0.014557115591900505, valid_loss: 0.017246802869652\n",
      "SEED: 8, FOLD: 2, EPOCH: 24,train_loss: 0.014299734981487627, valid_loss: 0.017236034918044294\n",
      "(17583, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7356360377608866, valid_loss: 0.6996472307613918\n",
      "SEED: 8, FOLD: 3, EPOCH: 0,train_loss: 0.46725158066745254, valid_loss: 0.02330995015799999\n",
      "SEED: 8, FOLD: 3, EPOCH: 1,train_loss: 0.020855690636064694, valid_loss: 0.018381368448691707\n",
      "SEED: 8, FOLD: 3, EPOCH: 2,train_loss: 0.018856027797944305, valid_loss: 0.01809526024652379\n",
      "SEED: 8, FOLD: 3, EPOCH: 3,train_loss: 0.01825851637978053, valid_loss: 0.01766819299331733\n",
      "SEED: 8, FOLD: 3, EPOCH: 4,train_loss: 0.018028084944555725, valid_loss: 0.017780628321426257\n",
      "SEED: 8, FOLD: 3, EPOCH: 5,train_loss: 0.017889987893294598, valid_loss: 0.017800017313233444\n",
      "SEED: 8, FOLD: 3, EPOCH: 6,train_loss: 0.01786696955399669, valid_loss: 0.01795067566313914\n",
      "SEED: 8, FOLD: 3, EPOCH: 7,train_loss: 0.01791024556302506, valid_loss: 0.018410475951220306\n",
      "SEED: 8, FOLD: 3, EPOCH: 8,train_loss: 0.01794938921280529, valid_loss: 0.017546465008386542\n",
      "SEED: 8, FOLD: 3, EPOCH: 9,train_loss: 0.017836686041530058, valid_loss: 0.017968308074133736\n",
      "SEED: 8, FOLD: 3, EPOCH: 10,train_loss: 0.017839141149559746, valid_loss: 0.01771074751658099\n",
      "SEED: 8, FOLD: 3, EPOCH: 11,train_loss: 0.017799525568936613, valid_loss: 0.01768006019826446\n",
      "SEED: 8, FOLD: 3, EPOCH: 12,train_loss: 0.01770773384909051, valid_loss: 0.017656901106238364\n",
      "SEED: 8, FOLD: 3, EPOCH: 13,train_loss: 0.017580205689359835, valid_loss: 0.01750827178891216\n",
      "SEED: 8, FOLD: 3, EPOCH: 14,train_loss: 0.01751462121129684, valid_loss: 0.017385727193738734\n",
      "SEED: 8, FOLD: 3, EPOCH: 15,train_loss: 0.017312541988718767, valid_loss: 0.017227712406643798\n",
      "SEED: 8, FOLD: 3, EPOCH: 16,train_loss: 0.01710978172638494, valid_loss: 0.0174521894593324\n",
      "SEED: 8, FOLD: 3, EPOCH: 17,train_loss: 0.01696007609691309, valid_loss: 0.017353716545871326\n",
      "SEED: 8, FOLD: 3, EPOCH: 18,train_loss: 0.01663219173560324, valid_loss: 0.017216939638767925\n",
      "SEED: 8, FOLD: 3, EPOCH: 19,train_loss: 0.016269856213551502, valid_loss: 0.017026919073292186\n",
      "SEED: 8, FOLD: 3, EPOCH: 20,train_loss: 0.01589813821044737, valid_loss: 0.016924854341362205\n",
      "SEED: 8, FOLD: 3, EPOCH: 21,train_loss: 0.01538219957517973, valid_loss: 0.01707436873444489\n",
      "SEED: 8, FOLD: 3, EPOCH: 22,train_loss: 0.014877681485444738, valid_loss: 0.017047622986137868\n",
      "SEED: 8, FOLD: 3, EPOCH: 23,train_loss: 0.014465466695095318, valid_loss: 0.017029156269771712\n",
      "SEED: 8, FOLD: 3, EPOCH: 24,train_loss: 0.014205726599185795, valid_loss: 0.017030074766704015\n",
      "(17555, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7357634785382644, valid_loss: 0.7039131351879665\n",
      "SEED: 8, FOLD: 4, EPOCH: 0,train_loss: 0.4660309439767962, valid_loss: 0.02324518992432526\n",
      "SEED: 8, FOLD: 4, EPOCH: 1,train_loss: 0.021039436841248604, valid_loss: 0.01994041446596384\n",
      "SEED: 8, FOLD: 4, EPOCH: 2,train_loss: 0.019337720534615757, valid_loss: 0.018055248180670398\n",
      "SEED: 8, FOLD: 4, EPOCH: 3,train_loss: 0.01837238412944303, valid_loss: 0.017883467647646156\n",
      "SEED: 8, FOLD: 4, EPOCH: 4,train_loss: 0.018034805294018293, valid_loss: 0.017941503865378242\n",
      "SEED: 8, FOLD: 4, EPOCH: 5,train_loss: 0.01796139025574793, valid_loss: 0.017861987384302277\n",
      "SEED: 8, FOLD: 4, EPOCH: 6,train_loss: 0.0180762296785479, valid_loss: 0.017862196559352533\n",
      "SEED: 8, FOLD: 4, EPOCH: 7,train_loss: 0.018058360790482897, valid_loss: 0.017820363199072226\n",
      "SEED: 8, FOLD: 4, EPOCH: 8,train_loss: 0.018002199582701574, valid_loss: 0.01783540884831122\n",
      "SEED: 8, FOLD: 4, EPOCH: 9,train_loss: 0.01789948219379437, valid_loss: 0.017885245781924044\n",
      "SEED: 8, FOLD: 4, EPOCH: 10,train_loss: 0.018029495047918266, valid_loss: 0.01782379922057901\n",
      "SEED: 8, FOLD: 4, EPOCH: 11,train_loss: 0.017911157071374466, valid_loss: 0.01753832453063556\n",
      "SEED: 8, FOLD: 4, EPOCH: 12,train_loss: 0.017799385182181562, valid_loss: 0.017654463489140782\n",
      "SEED: 8, FOLD: 4, EPOCH: 13,train_loss: 0.017681669659804607, valid_loss: 0.017631233323897634\n",
      "SEED: 8, FOLD: 4, EPOCH: 14,train_loss: 0.017625462918447844, valid_loss: 0.017375018554074424\n",
      "SEED: 8, FOLD: 4, EPOCH: 15,train_loss: 0.01745267060544828, valid_loss: 0.01707608505551304\n",
      "SEED: 8, FOLD: 4, EPOCH: 16,train_loss: 0.017276658649569836, valid_loss: 0.017335108534565994\n",
      "SEED: 8, FOLD: 4, EPOCH: 17,train_loss: 0.017049824184589626, valid_loss: 0.017147060270820344\n",
      "SEED: 8, FOLD: 4, EPOCH: 18,train_loss: 0.016795353721017422, valid_loss: 0.017142905720642636\n",
      "SEED: 8, FOLD: 4, EPOCH: 19,train_loss: 0.016449788821510214, valid_loss: 0.01705941797367164\n",
      "SEED: 8, FOLD: 4, EPOCH: 20,train_loss: 0.016091154085175283, valid_loss: 0.016924839307154927\n",
      "SEED: 8, FOLD: 4, EPOCH: 21,train_loss: 0.01562603318091968, valid_loss: 0.016937505533652645\n",
      "SEED: 8, FOLD: 4, EPOCH: 22,train_loss: 0.015155249842159126, valid_loss: 0.016959599458745547\n",
      "SEED: 8, FOLD: 4, EPOCH: 23,train_loss: 0.014724929101657177, valid_loss: 0.016933146198945388\n",
      "SEED: 8, FOLD: 4, EPOCH: 24,train_loss: 0.01454626635202895, valid_loss: 0.01693106120718377\n",
      "(17576, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7358415921529134, valid_loss: 0.7080209936414447\n",
      "SEED: 9, FOLD: 0, EPOCH: 0,train_loss: 0.4666329572868088, valid_loss: 0.024028376223785536\n",
      "SEED: 9, FOLD: 0, EPOCH: 1,train_loss: 0.021114281081743, valid_loss: 0.01909351274371147\n",
      "SEED: 9, FOLD: 0, EPOCH: 2,train_loss: 0.019159242011390736, valid_loss: 0.018115269738648618\n",
      "SEED: 9, FOLD: 0, EPOCH: 3,train_loss: 0.018466797286131674, valid_loss: 0.017844368011823722\n",
      "SEED: 9, FOLD: 0, EPOCH: 4,train_loss: 0.018034635732571285, valid_loss: 0.017753835208714007\n",
      "SEED: 9, FOLD: 0, EPOCH: 5,train_loss: 0.017885492271001356, valid_loss: 0.017699944068278586\n",
      "SEED: 9, FOLD: 0, EPOCH: 6,train_loss: 0.01791863014543618, valid_loss: 0.017717418766447477\n",
      "SEED: 9, FOLD: 0, EPOCH: 7,train_loss: 0.017977177138453808, valid_loss: 0.017870407471699375\n",
      "SEED: 9, FOLD: 0, EPOCH: 8,train_loss: 0.017891418384523062, valid_loss: 0.017741745923246656\n",
      "SEED: 9, FOLD: 0, EPOCH: 9,train_loss: 0.017883031912471935, valid_loss: 0.01767448740346091\n",
      "SEED: 9, FOLD: 0, EPOCH: 10,train_loss: 0.01784084796014687, valid_loss: 0.01764935428010566\n",
      "SEED: 9, FOLD: 0, EPOCH: 11,train_loss: 0.017802727273732857, valid_loss: 0.017465200913803918\n",
      "SEED: 9, FOLD: 0, EPOCH: 12,train_loss: 0.01768185043086608, valid_loss: 0.017651980157409396\n",
      "SEED: 9, FOLD: 0, EPOCH: 13,train_loss: 0.017670095790231575, valid_loss: 0.017563178203999996\n",
      "SEED: 9, FOLD: 0, EPOCH: 14,train_loss: 0.01754368010206499, valid_loss: 0.01767435749726636\n",
      "SEED: 9, FOLD: 0, EPOCH: 15,train_loss: 0.017412191985741905, valid_loss: 0.017563996064875808\n",
      "SEED: 9, FOLD: 0, EPOCH: 16,train_loss: 0.017248101977874405, valid_loss: 0.0174115746148995\n",
      "SEED: 9, FOLD: 0, EPOCH: 17,train_loss: 0.017051780974303467, valid_loss: 0.01728862931153604\n",
      "SEED: 9, FOLD: 0, EPOCH: 18,train_loss: 0.016709987985213167, valid_loss: 0.01717847205166306\n",
      "SEED: 9, FOLD: 0, EPOCH: 19,train_loss: 0.016386613108055746, valid_loss: 0.017211220200572697\n",
      "SEED: 9, FOLD: 0, EPOCH: 20,train_loss: 0.01601965280006761, valid_loss: 0.01718473093850272\n",
      "SEED: 9, FOLD: 0, EPOCH: 21,train_loss: 0.015538167869807154, valid_loss: 0.017222302061106476\n",
      "SEED: 9, FOLD: 0, EPOCH: 22,train_loss: 0.015065693944368673, valid_loss: 0.01719688908862216\n",
      "SEED: 9, FOLD: 0, EPOCH: 23,train_loss: 0.014652044188393198, valid_loss: 0.017156599940998215\n",
      "SEED: 9, FOLD: 0, EPOCH: 24,train_loss: 0.014404105825646631, valid_loss: 0.017143639203693186\n",
      "(17531, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7358161332833506, valid_loss: 0.7041864378111703\n",
      "SEED: 9, FOLD: 1, EPOCH: 0,train_loss: 0.46666324108730267, valid_loss: 0.02390936245875699\n",
      "SEED: 9, FOLD: 1, EPOCH: 1,train_loss: 0.020680852003232407, valid_loss: 0.01888182642204421\n",
      "SEED: 9, FOLD: 1, EPOCH: 2,train_loss: 0.018939955499920533, valid_loss: 0.018063177620725974\n",
      "SEED: 9, FOLD: 1, EPOCH: 3,train_loss: 0.018369645430930774, valid_loss: 0.01812087031347411\n",
      "SEED: 9, FOLD: 1, EPOCH: 4,train_loss: 0.018046927964654718, valid_loss: 0.017875710103128637\n",
      "SEED: 9, FOLD: 1, EPOCH: 5,train_loss: 0.01788362771626154, valid_loss: 0.017829584915723118\n",
      "SEED: 9, FOLD: 1, EPOCH: 6,train_loss: 0.017889537433855726, valid_loss: 0.01777718870767525\n",
      "SEED: 9, FOLD: 1, EPOCH: 7,train_loss: 0.01791137293742521, valid_loss: 0.018491411954164504\n",
      "SEED: 9, FOLD: 1, EPOCH: 8,train_loss: 0.01789367638773074, valid_loss: 0.018143810225384575\n",
      "SEED: 9, FOLD: 1, EPOCH: 9,train_loss: 0.01787387173160584, valid_loss: 0.017810327745974065\n",
      "SEED: 9, FOLD: 1, EPOCH: 10,train_loss: 0.017844006256030425, valid_loss: 0.017756125197878905\n",
      "SEED: 9, FOLD: 1, EPOCH: 11,train_loss: 0.017789296126061113, valid_loss: 0.017708386959774152\n",
      "SEED: 9, FOLD: 1, EPOCH: 12,train_loss: 0.017767883776041278, valid_loss: 0.01761197466403246\n",
      "SEED: 9, FOLD: 1, EPOCH: 13,train_loss: 0.017602799242756664, valid_loss: 0.017585049755871295\n",
      "SEED: 9, FOLD: 1, EPOCH: 14,train_loss: 0.017479766126259837, valid_loss: 0.017822032900793212\n",
      "SEED: 9, FOLD: 1, EPOCH: 15,train_loss: 0.017402689264964882, valid_loss: 0.017430506540196282\n",
      "SEED: 9, FOLD: 1, EPOCH: 16,train_loss: 0.017154494728757082, valid_loss: 0.017508678909923348\n",
      "SEED: 9, FOLD: 1, EPOCH: 17,train_loss: 0.01693765524720406, valid_loss: 0.017287692507462843\n",
      "SEED: 9, FOLD: 1, EPOCH: 18,train_loss: 0.016628825343655843, valid_loss: 0.0174291979521513\n",
      "SEED: 9, FOLD: 1, EPOCH: 19,train_loss: 0.016310683009724547, valid_loss: 0.017212382145226003\n",
      "SEED: 9, FOLD: 1, EPOCH: 20,train_loss: 0.015879121880951155, valid_loss: 0.017397860464240824\n",
      "SEED: 9, FOLD: 1, EPOCH: 21,train_loss: 0.015396644177771833, valid_loss: 0.017305397668055125\n",
      "SEED: 9, FOLD: 1, EPOCH: 22,train_loss: 0.01490296740220846, valid_loss: 0.017285222959305558\n",
      "SEED: 9, FOLD: 1, EPOCH: 23,train_loss: 0.014411132123294102, valid_loss: 0.017256429844668932\n",
      "SEED: 9, FOLD: 1, EPOCH: 24,train_loss: 0.01418920791959458, valid_loss: 0.017249776422977446\n",
      "(17558, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7356605935787809, valid_loss: 0.7054235458374023\n",
      "SEED: 9, FOLD: 2, EPOCH: 0,train_loss: 0.46604358412973257, valid_loss: 0.023776520629014287\n",
      "SEED: 9, FOLD: 2, EPOCH: 1,train_loss: 0.020923459834918594, valid_loss: 0.01952389505292688\n",
      "SEED: 9, FOLD: 2, EPOCH: 2,train_loss: 0.019016744487959404, valid_loss: 0.01827780774661473\n",
      "SEED: 9, FOLD: 2, EPOCH: 3,train_loss: 0.018176455745824438, valid_loss: 0.018288642061608178\n",
      "SEED: 9, FOLD: 2, EPOCH: 4,train_loss: 0.018064778230652428, valid_loss: 0.0186493594199419\n",
      "SEED: 9, FOLD: 2, EPOCH: 5,train_loss: 0.018058701053909634, valid_loss: 0.01823888724403722\n",
      "SEED: 9, FOLD: 2, EPOCH: 6,train_loss: 0.017968800580264, valid_loss: 0.018131016993096896\n",
      "SEED: 9, FOLD: 2, EPOCH: 7,train_loss: 0.017947564144497333, valid_loss: 0.01810046788305044\n",
      "SEED: 9, FOLD: 2, EPOCH: 8,train_loss: 0.01794922723016445, valid_loss: 0.018090213648974895\n",
      "SEED: 9, FOLD: 2, EPOCH: 9,train_loss: 0.017877869442969128, valid_loss: 0.01788218306111438\n",
      "SEED: 9, FOLD: 2, EPOCH: 10,train_loss: 0.017908007844580687, valid_loss: 0.01798448748886585\n",
      "SEED: 9, FOLD: 2, EPOCH: 11,train_loss: 0.01784710905285201, valid_loss: 0.01825215169893844\n",
      "SEED: 9, FOLD: 2, EPOCH: 12,train_loss: 0.017815641006049904, valid_loss: 0.017674119850354535\n",
      "SEED: 9, FOLD: 2, EPOCH: 13,train_loss: 0.01765360162201999, valid_loss: 0.01775617870901312\n",
      "SEED: 9, FOLD: 2, EPOCH: 14,train_loss: 0.01759215523286358, valid_loss: 0.01738637246723686\n",
      "SEED: 9, FOLD: 2, EPOCH: 15,train_loss: 0.017393890214894993, valid_loss: 0.017403570243290492\n",
      "SEED: 9, FOLD: 2, EPOCH: 16,train_loss: 0.01723751646426061, valid_loss: 0.017471587684537684\n",
      "SEED: 9, FOLD: 2, EPOCH: 17,train_loss: 0.016993256920165775, valid_loss: 0.017455653686608587\n",
      "SEED: 9, FOLD: 2, EPOCH: 18,train_loss: 0.016793022141454443, valid_loss: 0.01741010948483433\n",
      "SEED: 9, FOLD: 2, EPOCH: 19,train_loss: 0.01646154193693529, valid_loss: 0.017230966500937937\n",
      "SEED: 9, FOLD: 2, EPOCH: 20,train_loss: 0.01603043875724509, valid_loss: 0.01731662516083036\n",
      "SEED: 9, FOLD: 2, EPOCH: 21,train_loss: 0.01560607808979525, valid_loss: 0.01706944757274219\n",
      "SEED: 9, FOLD: 2, EPOCH: 22,train_loss: 0.015143916820702345, valid_loss: 0.01708602782871042\n",
      "SEED: 9, FOLD: 2, EPOCH: 23,train_loss: 0.014796733377042456, valid_loss: 0.01709021119666951\n",
      "SEED: 9, FOLD: 2, EPOCH: 24,train_loss: 0.014580165434196808, valid_loss: 0.017098793014883994\n",
      "(17600, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7355350182540175, valid_loss: 0.7054894215920392\n",
      "SEED: 9, FOLD: 3, EPOCH: 0,train_loss: 0.46700347731888725, valid_loss: 0.023902732440653968\n",
      "SEED: 9, FOLD: 3, EPOCH: 1,train_loss: 0.02074639894662128, valid_loss: 0.020104784354129258\n",
      "SEED: 9, FOLD: 3, EPOCH: 2,train_loss: 0.01892892575647304, valid_loss: 0.018407285651739907\n",
      "SEED: 9, FOLD: 3, EPOCH: 3,train_loss: 0.01815362915099747, valid_loss: 0.01875769253820181\n",
      "SEED: 9, FOLD: 3, EPOCH: 4,train_loss: 0.01791221408875308, valid_loss: 0.018091350574703777\n",
      "SEED: 9, FOLD: 3, EPOCH: 5,train_loss: 0.017814873366792133, valid_loss: 0.01815268145326306\n",
      "SEED: 9, FOLD: 3, EPOCH: 6,train_loss: 0.01781581960402537, valid_loss: 0.01849272014463649\n",
      "SEED: 9, FOLD: 3, EPOCH: 7,train_loss: 0.01786263435539128, valid_loss: 0.01818380658240879\n",
      "SEED: 9, FOLD: 3, EPOCH: 8,train_loss: 0.01788620940962995, valid_loss: 0.01859221640316879\n",
      "SEED: 9, FOLD: 3, EPOCH: 9,train_loss: 0.01786451629511472, valid_loss: 0.018370521473972237\n",
      "SEED: 9, FOLD: 3, EPOCH: 10,train_loss: 0.01778704815449706, valid_loss: 0.01827460971167859\n",
      "SEED: 9, FOLD: 3, EPOCH: 11,train_loss: 0.017731770198198334, valid_loss: 0.018022037001655382\n",
      "SEED: 9, FOLD: 3, EPOCH: 12,train_loss: 0.01763854987676377, valid_loss: 0.017978598719791454\n",
      "SEED: 9, FOLD: 3, EPOCH: 13,train_loss: 0.017599352966130213, valid_loss: 0.01812955895986627\n",
      "SEED: 9, FOLD: 3, EPOCH: 14,train_loss: 0.017506248418889616, valid_loss: 0.018058714758166495\n",
      "SEED: 9, FOLD: 3, EPOCH: 15,train_loss: 0.017323795010916132, valid_loss: 0.017713537028826335\n",
      "SEED: 9, FOLD: 3, EPOCH: 16,train_loss: 0.01718047834203943, valid_loss: 0.01781874108950005\n",
      "SEED: 9, FOLD: 3, EPOCH: 17,train_loss: 0.016943439402604017, valid_loss: 0.017575970303048107\n",
      "SEED: 9, FOLD: 3, EPOCH: 18,train_loss: 0.0166978409068416, valid_loss: 0.017712223946171647\n",
      "SEED: 9, FOLD: 3, EPOCH: 19,train_loss: 0.01637177606639655, valid_loss: 0.017503749305272803\n",
      "SEED: 9, FOLD: 3, EPOCH: 20,train_loss: 0.015955751471599375, valid_loss: 0.01742281825007761\n",
      "SEED: 9, FOLD: 3, EPOCH: 21,train_loss: 0.015515814805268377, valid_loss: 0.017435187419109485\n",
      "SEED: 9, FOLD: 3, EPOCH: 22,train_loss: 0.015057030100159454, valid_loss: 0.017412638866945225\n",
      "SEED: 9, FOLD: 3, EPOCH: 23,train_loss: 0.014674988042131283, valid_loss: 0.017377526828033084\n",
      "SEED: 9, FOLD: 3, EPOCH: 24,train_loss: 0.014479389360201532, valid_loss: 0.017374808133086738\n",
      "(17527, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7359882567050683, valid_loss: 0.7038859571729388\n",
      "SEED: 9, FOLD: 4, EPOCH: 0,train_loss: 0.46754662165023986, valid_loss: 0.02387246558708804\n",
      "SEED: 9, FOLD: 4, EPOCH: 1,train_loss: 0.02089734775197767, valid_loss: 0.01861545933144433\n",
      "SEED: 9, FOLD: 4, EPOCH: 2,train_loss: 0.019001664675391505, valid_loss: 0.017912537711007256\n",
      "SEED: 9, FOLD: 4, EPOCH: 3,train_loss: 0.018173194979827334, valid_loss: 0.018061645116124833\n",
      "SEED: 9, FOLD: 4, EPOCH: 4,train_loss: 0.01793284895727887, valid_loss: 0.017745101398655348\n",
      "SEED: 9, FOLD: 4, EPOCH: 5,train_loss: 0.018004157097779052, valid_loss: 0.018434607290795872\n",
      "SEED: 9, FOLD: 4, EPOCH: 6,train_loss: 0.017931406236641162, valid_loss: 0.017809598413961274\n",
      "SEED: 9, FOLD: 4, EPOCH: 7,train_loss: 0.017948531348557367, valid_loss: 0.017772748959915978\n",
      "SEED: 9, FOLD: 4, EPOCH: 8,train_loss: 0.017987700573501797, valid_loss: 0.017549627859677588\n",
      "SEED: 9, FOLD: 4, EPOCH: 9,train_loss: 0.017893982527736763, valid_loss: 0.017852790227958135\n",
      "SEED: 9, FOLD: 4, EPOCH: 10,train_loss: 0.01788204080377617, valid_loss: 0.017874670906790666\n",
      "SEED: 9, FOLD: 4, EPOCH: 11,train_loss: 0.017784635624746338, valid_loss: 0.01772693661706788\n",
      "SEED: 9, FOLD: 4, EPOCH: 12,train_loss: 0.017743310027749, valid_loss: 0.017611489125660486\n",
      "SEED: 9, FOLD: 4, EPOCH: 13,train_loss: 0.017622032454305322, valid_loss: 0.01738511584699154\n",
      "SEED: 9, FOLD: 4, EPOCH: 14,train_loss: 0.017560706671028242, valid_loss: 0.017356291679399356\n",
      "SEED: 9, FOLD: 4, EPOCH: 15,train_loss: 0.017355081543707063, valid_loss: 0.017283136557255472\n",
      "SEED: 9, FOLD: 4, EPOCH: 16,train_loss: 0.017168307826466805, valid_loss: 0.017494946691606728\n",
      "SEED: 9, FOLD: 4, EPOCH: 17,train_loss: 0.016930574027780632, valid_loss: 0.01724289876541921\n",
      "SEED: 9, FOLD: 4, EPOCH: 18,train_loss: 0.01670024399203758, valid_loss: 0.017406129597553183\n",
      "SEED: 9, FOLD: 4, EPOCH: 19,train_loss: 0.016346810154453682, valid_loss: 0.01714829688093492\n",
      "SEED: 9, FOLD: 4, EPOCH: 20,train_loss: 0.01592348401781416, valid_loss: 0.017077711038291456\n",
      "SEED: 9, FOLD: 4, EPOCH: 21,train_loss: 0.01547427854779428, valid_loss: 0.017070113867521285\n",
      "SEED: 9, FOLD: 4, EPOCH: 22,train_loss: 0.014972459857970693, valid_loss: 0.01699481223310743\n",
      "SEED: 9, FOLD: 4, EPOCH: 23,train_loss: 0.014540166342563002, valid_loss: 0.01699764858931303\n",
      "SEED: 9, FOLD: 4, EPOCH: 24,train_loss: 0.014312040910505466, valid_loss: 0.016988281799214227\n",
      "(17607, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7343962123428566, valid_loss: 0.705938491751166\n",
      "SEED: 10, FOLD: 0, EPOCH: 0,train_loss: 0.46561857505930937, valid_loss: 0.024167122812393832\n",
      "SEED: 10, FOLD: 0, EPOCH: 1,train_loss: 0.020874872736200905, valid_loss: 0.01905787139035323\n",
      "SEED: 10, FOLD: 0, EPOCH: 2,train_loss: 0.01881040385721818, valid_loss: 0.018581659889177364\n",
      "SEED: 10, FOLD: 0, EPOCH: 3,train_loss: 0.018553014979630276, valid_loss: 0.018349851865102264\n",
      "SEED: 10, FOLD: 0, EPOCH: 4,train_loss: 0.018002453786523445, valid_loss: 0.018218425650368717\n",
      "SEED: 10, FOLD: 0, EPOCH: 5,train_loss: 0.0179491447136346, valid_loss: 0.018255991039468962\n",
      "SEED: 10, FOLD: 0, EPOCH: 6,train_loss: 0.01789237672894977, valid_loss: 0.018288152073236072\n",
      "SEED: 10, FOLD: 0, EPOCH: 7,train_loss: 0.01788820071901748, valid_loss: 0.018406403908396467\n",
      "SEED: 10, FOLD: 0, EPOCH: 8,train_loss: 0.017840817422214626, valid_loss: 0.018169349388164634\n",
      "SEED: 10, FOLD: 0, EPOCH: 9,train_loss: 0.017821915852634804, valid_loss: 0.018246626727940404\n",
      "SEED: 10, FOLD: 0, EPOCH: 10,train_loss: 0.017783468865883955, valid_loss: 0.01843576308558969\n",
      "SEED: 10, FOLD: 0, EPOCH: 11,train_loss: 0.017752264660067747, valid_loss: 0.018031350117834175\n",
      "SEED: 10, FOLD: 0, EPOCH: 12,train_loss: 0.017655650693653286, valid_loss: 0.017883459188263204\n",
      "SEED: 10, FOLD: 0, EPOCH: 13,train_loss: 0.017562957534539528, valid_loss: 0.017937647507471198\n",
      "SEED: 10, FOLD: 0, EPOCH: 14,train_loss: 0.017384805325148762, valid_loss: 0.018145238542381453\n",
      "SEED: 10, FOLD: 0, EPOCH: 15,train_loss: 0.01730097664952062, valid_loss: 0.017719850108465728\n",
      "SEED: 10, FOLD: 0, EPOCH: 16,train_loss: 0.017069379367150257, valid_loss: 0.01777305029442205\n",
      "SEED: 10, FOLD: 0, EPOCH: 17,train_loss: 0.016855178441366424, valid_loss: 0.017706402550067973\n",
      "SEED: 10, FOLD: 0, EPOCH: 18,train_loss: 0.0165763383636764, valid_loss: 0.017616293228724423\n",
      "SEED: 10, FOLD: 0, EPOCH: 19,train_loss: 0.0161865651405052, valid_loss: 0.017555299625896355\n",
      "SEED: 10, FOLD: 0, EPOCH: 20,train_loss: 0.015780891635981592, valid_loss: 0.017489724299486947\n",
      "SEED: 10, FOLD: 0, EPOCH: 21,train_loss: 0.015320291546969742, valid_loss: 0.017551915966631734\n",
      "SEED: 10, FOLD: 0, EPOCH: 22,train_loss: 0.014818399287490309, valid_loss: 0.01759882364422083\n",
      "SEED: 10, FOLD: 0, EPOCH: 23,train_loss: 0.014388981106542591, valid_loss: 0.01755522643489873\n",
      "SEED: 10, FOLD: 0, EPOCH: 24,train_loss: 0.014135892853896687, valid_loss: 0.017546562669689163\n",
      "(17453, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7344255699728527, valid_loss: 0.7015954454739889\n",
      "SEED: 10, FOLD: 1, EPOCH: 0,train_loss: 0.4674730705110914, valid_loss: 0.023810804821550846\n",
      "SEED: 10, FOLD: 1, EPOCH: 1,train_loss: 0.020838306958440446, valid_loss: 0.02111424955849846\n",
      "SEED: 10, FOLD: 1, EPOCH: 2,train_loss: 0.019126932197896233, valid_loss: 0.0182395633827481\n",
      "SEED: 10, FOLD: 1, EPOCH: 3,train_loss: 0.018308958562131782, valid_loss: 0.017955297474852867\n",
      "SEED: 10, FOLD: 1, EPOCH: 4,train_loss: 0.017975982693261908, valid_loss: 0.01813911080049972\n",
      "SEED: 10, FOLD: 1, EPOCH: 5,train_loss: 0.017924884415782282, valid_loss: 0.017849756870418787\n",
      "SEED: 10, FOLD: 1, EPOCH: 6,train_loss: 0.017953766652648032, valid_loss: 0.018132564844563603\n",
      "SEED: 10, FOLD: 1, EPOCH: 7,train_loss: 0.01792772693464356, valid_loss: 0.017715589712477393\n",
      "SEED: 10, FOLD: 1, EPOCH: 8,train_loss: 0.01793656087596051, valid_loss: 0.01763644356591006\n",
      "SEED: 10, FOLD: 1, EPOCH: 9,train_loss: 0.017906042842371184, valid_loss: 0.017867775866761804\n",
      "SEED: 10, FOLD: 1, EPOCH: 10,train_loss: 0.01783097181197283, valid_loss: 0.017631194114478096\n",
      "SEED: 10, FOLD: 1, EPOCH: 11,train_loss: 0.017823747583549387, valid_loss: 0.017928957525226805\n",
      "SEED: 10, FOLD: 1, EPOCH: 12,train_loss: 0.01776835258479101, valid_loss: 0.01772526736992101\n",
      "SEED: 10, FOLD: 1, EPOCH: 13,train_loss: 0.017641000442859465, valid_loss: 0.017639809106994007\n",
      "SEED: 10, FOLD: 1, EPOCH: 14,train_loss: 0.01753807681728236, valid_loss: 0.017716727012561426\n",
      "SEED: 10, FOLD: 1, EPOCH: 15,train_loss: 0.01740114751142742, valid_loss: 0.017705282946634624\n",
      "SEED: 10, FOLD: 1, EPOCH: 16,train_loss: 0.017225753223645862, valid_loss: 0.01732810917827818\n",
      "SEED: 10, FOLD: 1, EPOCH: 17,train_loss: 0.016980474665217155, valid_loss: 0.01728245194277002\n",
      "SEED: 10, FOLD: 1, EPOCH: 18,train_loss: 0.01674833095013878, valid_loss: 0.01719891968079739\n",
      "SEED: 10, FOLD: 1, EPOCH: 19,train_loss: 0.01633586545549605, valid_loss: 0.017156554696460564\n",
      "SEED: 10, FOLD: 1, EPOCH: 20,train_loss: 0.015936893145859676, valid_loss: 0.01709645003494289\n",
      "SEED: 10, FOLD: 1, EPOCH: 21,train_loss: 0.015522425566004576, valid_loss: 0.017027908651572134\n",
      "SEED: 10, FOLD: 1, EPOCH: 22,train_loss: 0.014998182477633449, valid_loss: 0.01702615199610591\n",
      "SEED: 10, FOLD: 1, EPOCH: 23,train_loss: 0.014584087521979844, valid_loss: 0.017062773669345513\n",
      "SEED: 10, FOLD: 1, EPOCH: 24,train_loss: 0.014360890125543096, valid_loss: 0.01704395277839568\n",
      "(17567, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.73437733710676, valid_loss: 0.7034176536968776\n",
      "SEED: 10, FOLD: 2, EPOCH: 0,train_loss: 0.4670697548089252, valid_loss: 0.0234522887638637\n",
      "SEED: 10, FOLD: 2, EPOCH: 1,train_loss: 0.020741295636348103, valid_loss: 0.019961985040988242\n",
      "SEED: 10, FOLD: 2, EPOCH: 2,train_loss: 0.01916452931861083, valid_loss: 0.018214564930115428\n",
      "SEED: 10, FOLD: 2, EPOCH: 3,train_loss: 0.018399888798054577, valid_loss: 0.01831855486546244\n",
      "SEED: 10, FOLD: 2, EPOCH: 4,train_loss: 0.017998572783139738, valid_loss: 0.01824144183525017\n",
      "SEED: 10, FOLD: 2, EPOCH: 5,train_loss: 0.017967535581007815, valid_loss: 0.018484942242503168\n",
      "SEED: 10, FOLD: 2, EPOCH: 6,train_loss: 0.01787610841995996, valid_loss: 0.017967564719063894\n",
      "SEED: 10, FOLD: 2, EPOCH: 7,train_loss: 0.017926689952719902, valid_loss: 0.017995349424225943\n",
      "SEED: 10, FOLD: 2, EPOCH: 8,train_loss: 0.01787588297240976, valid_loss: 0.018643431471926826\n",
      "SEED: 10, FOLD: 2, EPOCH: 9,train_loss: 0.017966085154077282, valid_loss: 0.01776360065809318\n",
      "SEED: 10, FOLD: 2, EPOCH: 10,train_loss: 0.017791267767872498, valid_loss: 0.018011668590562684\n",
      "SEED: 10, FOLD: 2, EPOCH: 11,train_loss: 0.01774002587341744, valid_loss: 0.017988731286355426\n",
      "SEED: 10, FOLD: 2, EPOCH: 12,train_loss: 0.0177206720792405, valid_loss: 0.017815785722008773\n",
      "SEED: 10, FOLD: 2, EPOCH: 13,train_loss: 0.017616165457698313, valid_loss: 0.017606535527322973\n",
      "SEED: 10, FOLD: 2, EPOCH: 14,train_loss: 0.01749045657587872, valid_loss: 0.017745077264096056\n",
      "SEED: 10, FOLD: 2, EPOCH: 15,train_loss: 0.017329284421883633, valid_loss: 0.01756968429046018\n",
      "SEED: 10, FOLD: 2, EPOCH: 16,train_loss: 0.01715597812005359, valid_loss: 0.017515976806836468\n",
      "SEED: 10, FOLD: 2, EPOCH: 17,train_loss: 0.016889242165168558, valid_loss: 0.017353561813277858\n",
      "SEED: 10, FOLD: 2, EPOCH: 18,train_loss: 0.016593470076180023, valid_loss: 0.01742045788892678\n",
      "SEED: 10, FOLD: 2, EPOCH: 19,train_loss: 0.016252296214140413, valid_loss: 0.01731821508812053\n",
      "SEED: 10, FOLD: 2, EPOCH: 20,train_loss: 0.01582454016054238, valid_loss: 0.017442273215523788\n",
      "SEED: 10, FOLD: 2, EPOCH: 21,train_loss: 0.015331716944827982, valid_loss: 0.01733723022043705\n",
      "SEED: 10, FOLD: 2, EPOCH: 22,train_loss: 0.01485631762045449, valid_loss: 0.017374337118651186\n",
      "SEED: 10, FOLD: 2, EPOCH: 23,train_loss: 0.014385636619197718, valid_loss: 0.01740743906370231\n",
      "SEED: 10, FOLD: 2, EPOCH: 24,train_loss: 0.01415738868324653, valid_loss: 0.01737748472286122\n",
      "(17588, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7345363152199897, valid_loss: 0.7004985553877694\n",
      "SEED: 10, FOLD: 3, EPOCH: 0,train_loss: 0.46632910120314447, valid_loss: 0.02421454308288438\n",
      "SEED: 10, FOLD: 3, EPOCH: 1,train_loss: 0.020867939808986324, valid_loss: 0.01868953529213156\n",
      "SEED: 10, FOLD: 3, EPOCH: 2,train_loss: 0.019108820585129055, valid_loss: 0.018585966527462007\n",
      "SEED: 10, FOLD: 3, EPOCH: 3,train_loss: 0.018390138134144356, valid_loss: 0.017878062331250735\n",
      "SEED: 10, FOLD: 3, EPOCH: 4,train_loss: 0.018111677563654772, valid_loss: 0.017981142976454326\n",
      "SEED: 10, FOLD: 3, EPOCH: 5,train_loss: 0.017908974597905424, valid_loss: 0.017771655933133193\n",
      "SEED: 10, FOLD: 3, EPOCH: 6,train_loss: 0.017888812179528715, valid_loss: 0.017873358513627733\n",
      "SEED: 10, FOLD: 3, EPOCH: 7,train_loss: 0.017969616560562365, valid_loss: 0.018557784812791005\n",
      "SEED: 10, FOLD: 3, EPOCH: 8,train_loss: 0.017945950088239668, valid_loss: 0.017792613857558797\n",
      "SEED: 10, FOLD: 3, EPOCH: 9,train_loss: 0.017917726620815803, valid_loss: 0.018225814082792828\n",
      "SEED: 10, FOLD: 3, EPOCH: 10,train_loss: 0.01784488334711911, valid_loss: 0.01776094420679978\n",
      "SEED: 10, FOLD: 3, EPOCH: 11,train_loss: 0.017781088290655094, valid_loss: 0.017827547980206353\n",
      "SEED: 10, FOLD: 3, EPOCH: 12,train_loss: 0.017789821572385837, valid_loss: 0.017853973912341253\n",
      "SEED: 10, FOLD: 3, EPOCH: 13,train_loss: 0.017651831731200218, valid_loss: 0.01754309202411345\n",
      "SEED: 10, FOLD: 3, EPOCH: 14,train_loss: 0.017514538215608267, valid_loss: 0.01761544926890305\n",
      "SEED: 10, FOLD: 3, EPOCH: 15,train_loss: 0.017418481598513714, valid_loss: 0.017574138593460832\n",
      "SEED: 10, FOLD: 3, EPOCH: 16,train_loss: 0.017169497853171997, valid_loss: 0.017411745366241252\n",
      "SEED: 10, FOLD: 3, EPOCH: 17,train_loss: 0.01696602766658517, valid_loss: 0.017367916660649435\n",
      "SEED: 10, FOLD: 3, EPOCH: 18,train_loss: 0.01674507590064752, valid_loss: 0.017161839694849083\n",
      "SEED: 10, FOLD: 3, EPOCH: 19,train_loss: 0.016352487835979115, valid_loss: 0.017138472864670413\n",
      "SEED: 10, FOLD: 3, EPOCH: 20,train_loss: 0.015935265243161415, valid_loss: 0.017006834942315308\n",
      "SEED: 10, FOLD: 3, EPOCH: 21,train_loss: 0.01548062734629797, valid_loss: 0.017028621690613883\n",
      "SEED: 10, FOLD: 3, EPOCH: 22,train_loss: 0.014976106415354256, valid_loss: 0.017097033879586627\n",
      "SEED: 10, FOLD: 3, EPOCH: 23,train_loss: 0.014494191544751326, valid_loss: 0.017016745012785706\n",
      "SEED: 10, FOLD: 3, EPOCH: 24,train_loss: 0.0142787531139734, valid_loss: 0.017039889230259828\n",
      "(17577, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7347601989041204, valid_loss: 0.7042381746428353\n",
      "SEED: 10, FOLD: 4, EPOCH: 0,train_loss: 0.4667854841420616, valid_loss: 0.025331680849194526\n",
      "SEED: 10, FOLD: 4, EPOCH: 1,train_loss: 0.02087095844140951, valid_loss: 0.019119051125432763\n",
      "SEED: 10, FOLD: 4, EPOCH: 2,train_loss: 0.018943929788319096, valid_loss: 0.018319265517805303\n",
      "SEED: 10, FOLD: 4, EPOCH: 3,train_loss: 0.018294516363707575, valid_loss: 0.01805455431874309\n",
      "SEED: 10, FOLD: 4, EPOCH: 4,train_loss: 0.01792522403749003, valid_loss: 0.018530812726489137\n",
      "SEED: 10, FOLD: 4, EPOCH: 5,train_loss: 0.017909180528173845, valid_loss: 0.01828645920114858\n",
      "SEED: 10, FOLD: 4, EPOCH: 6,train_loss: 0.01795441460242306, valid_loss: 0.01772728149912187\n",
      "SEED: 10, FOLD: 4, EPOCH: 7,train_loss: 0.01793698601397699, valid_loss: 0.017873064721269268\n",
      "SEED: 10, FOLD: 4, EPOCH: 8,train_loss: 0.017955026521846867, valid_loss: 0.018284798174032144\n",
      "SEED: 10, FOLD: 4, EPOCH: 9,train_loss: 0.017888097052016983, valid_loss: 0.01820527889898845\n",
      "SEED: 10, FOLD: 4, EPOCH: 10,train_loss: 0.01785398469697954, valid_loss: 0.017859198738421712\n",
      "SEED: 10, FOLD: 4, EPOCH: 11,train_loss: 0.017828214508683785, valid_loss: 0.0178724683289017\n",
      "SEED: 10, FOLD: 4, EPOCH: 12,train_loss: 0.01778074992361708, valid_loss: 0.01807829202818019\n",
      "SEED: 10, FOLD: 4, EPOCH: 13,train_loss: 0.017705745205445135, valid_loss: 0.017688467566456114\n",
      "SEED: 10, FOLD: 4, EPOCH: 14,train_loss: 0.017498140155837155, valid_loss: 0.017582347137587412\n",
      "SEED: 10, FOLD: 4, EPOCH: 15,train_loss: 0.017345987712505503, valid_loss: 0.017777148447930814\n",
      "SEED: 10, FOLD: 4, EPOCH: 16,train_loss: 0.017223567850347878, valid_loss: 0.017301657689469202\n",
      "SEED: 10, FOLD: 4, EPOCH: 17,train_loss: 0.016942275499088177, valid_loss: 0.017203001039368764\n",
      "SEED: 10, FOLD: 4, EPOCH: 18,train_loss: 0.01665959093530757, valid_loss: 0.0173445960772889\n",
      "SEED: 10, FOLD: 4, EPOCH: 19,train_loss: 0.016372745013053434, valid_loss: 0.017199270932802133\n",
      "SEED: 10, FOLD: 4, EPOCH: 20,train_loss: 0.015971686238881903, valid_loss: 0.017105151606457574\n",
      "SEED: 10, FOLD: 4, EPOCH: 21,train_loss: 0.01548301967103844, valid_loss: 0.01706530044653586\n",
      "SEED: 10, FOLD: 4, EPOCH: 22,train_loss: 0.015001429292116907, valid_loss: 0.017015422933868\n",
      "SEED: 10, FOLD: 4, EPOCH: 23,train_loss: 0.014562630236310803, valid_loss: 0.016969973540731837\n",
      "SEED: 10, FOLD: 4, EPOCH: 24,train_loss: 0.014332506056551052, valid_loss: 0.01696960013359785\n",
      "(17543, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7343289260415063, valid_loss: 0.6933776804379055\n",
      "SEED: 11, FOLD: 0, EPOCH: 0,train_loss: 0.46676036500898394, valid_loss: 0.0239938137786729\n",
      "SEED: 11, FOLD: 0, EPOCH: 1,train_loss: 0.020820588791284008, valid_loss: 0.022776083914296967\n",
      "SEED: 11, FOLD: 0, EPOCH: 2,train_loss: 0.019245001662900482, valid_loss: 0.018120573753757137\n",
      "SEED: 11, FOLD: 0, EPOCH: 3,train_loss: 0.018233077418383047, valid_loss: 0.018096898150231158\n",
      "SEED: 11, FOLD: 0, EPOCH: 4,train_loss: 0.017991258897751137, valid_loss: 0.018595739640295504\n",
      "SEED: 11, FOLD: 0, EPOCH: 5,train_loss: 0.017972362963347765, valid_loss: 0.017878428660333158\n",
      "SEED: 11, FOLD: 0, EPOCH: 6,train_loss: 0.017927076519075512, valid_loss: 0.01800433567592076\n",
      "SEED: 11, FOLD: 0, EPOCH: 7,train_loss: 0.017976808213237404, valid_loss: 0.018112278303929738\n",
      "SEED: 11, FOLD: 0, EPOCH: 8,train_loss: 0.0179853822927976, valid_loss: 0.018099751483116832\n",
      "SEED: 11, FOLD: 0, EPOCH: 9,train_loss: 0.0179310564181187, valid_loss: 0.017838003592831747\n",
      "SEED: 11, FOLD: 0, EPOCH: 10,train_loss: 0.01788662631145638, valid_loss: 0.017704918049275875\n",
      "SEED: 11, FOLD: 0, EPOCH: 11,train_loss: 0.017917964472502903, valid_loss: 0.017980701715818472\n",
      "SEED: 11, FOLD: 0, EPOCH: 12,train_loss: 0.017774607345083918, valid_loss: 0.01760112103074789\n",
      "SEED: 11, FOLD: 0, EPOCH: 13,train_loss: 0.017680385764148356, valid_loss: 0.01760336554476193\n",
      "SEED: 11, FOLD: 0, EPOCH: 14,train_loss: 0.01750468396568212, valid_loss: 0.017626791261136532\n",
      "SEED: 11, FOLD: 0, EPOCH: 15,train_loss: 0.01743590106944675, valid_loss: 0.0173904345237783\n",
      "SEED: 11, FOLD: 0, EPOCH: 16,train_loss: 0.017352269537261, valid_loss: 0.017502697663647787\n",
      "SEED: 11, FOLD: 0, EPOCH: 17,train_loss: 0.01705524438749189, valid_loss: 0.0172817913549287\n",
      "SEED: 11, FOLD: 0, EPOCH: 18,train_loss: 0.016689347177473963, valid_loss: 0.017633941849427563\n",
      "SEED: 11, FOLD: 0, EPOCH: 19,train_loss: 0.01653976537341225, valid_loss: 0.01722805808697428\n",
      "SEED: 11, FOLD: 0, EPOCH: 20,train_loss: 0.016136769104101088, valid_loss: 0.01712978431688888\n",
      "SEED: 11, FOLD: 0, EPOCH: 21,train_loss: 0.015649108715571354, valid_loss: 0.01706727743148804\n",
      "SEED: 11, FOLD: 0, EPOCH: 22,train_loss: 0.015206052685507399, valid_loss: 0.01703771472509418\n",
      "SEED: 11, FOLD: 0, EPOCH: 23,train_loss: 0.014793090583027704, valid_loss: 0.0170858162854399\n",
      "SEED: 11, FOLD: 0, EPOCH: 24,train_loss: 0.014617158342962679, valid_loss: 0.01704616772809199\n",
      "(17543, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7342153433440388, valid_loss: 0.6936715466635568\n",
      "SEED: 11, FOLD: 1, EPOCH: 0,train_loss: 0.46779149766687467, valid_loss: 0.024061765734638488\n",
      "SEED: 11, FOLD: 1, EPOCH: 1,train_loss: 0.02096874153484469, valid_loss: 0.018666162182177815\n",
      "SEED: 11, FOLD: 1, EPOCH: 2,train_loss: 0.018926264812656933, valid_loss: 0.025278903916478156\n",
      "SEED: 11, FOLD: 1, EPOCH: 3,train_loss: 0.018780301331771887, valid_loss: 0.018540335366768496\n",
      "SEED: 11, FOLD: 1, EPOCH: 4,train_loss: 0.01809875281068726, valid_loss: 0.017748089507222176\n",
      "SEED: 11, FOLD: 1, EPOCH: 5,train_loss: 0.01798224901996445, valid_loss: 0.01833789904734918\n",
      "SEED: 11, FOLD: 1, EPOCH: 6,train_loss: 0.018009511072296595, valid_loss: 0.01823570853365319\n",
      "SEED: 11, FOLD: 1, EPOCH: 7,train_loss: 0.01797998077708526, valid_loss: 0.01856042343590941\n",
      "SEED: 11, FOLD: 1, EPOCH: 8,train_loss: 0.017942077945917845, valid_loss: 0.01785203559058053\n",
      "SEED: 11, FOLD: 1, EPOCH: 9,train_loss: 0.018038895284838003, valid_loss: 0.0178790399272527\n",
      "SEED: 11, FOLD: 1, EPOCH: 10,train_loss: 0.017935418658822342, valid_loss: 0.01795775916959558\n",
      "SEED: 11, FOLD: 1, EPOCH: 11,train_loss: 0.01792699815300496, valid_loss: 0.017859728341656073\n",
      "SEED: 11, FOLD: 1, EPOCH: 12,train_loss: 0.01780477062245642, valid_loss: 0.017712697785879885\n",
      "SEED: 11, FOLD: 1, EPOCH: 13,train_loss: 0.017702127287191324, valid_loss: 0.01774080722991909\n",
      "SEED: 11, FOLD: 1, EPOCH: 14,train_loss: 0.017547669496549213, valid_loss: 0.01732983174068587\n",
      "SEED: 11, FOLD: 1, EPOCH: 15,train_loss: 0.01748574814637718, valid_loss: 0.017270339759332794\n",
      "SEED: 11, FOLD: 1, EPOCH: 16,train_loss: 0.017312769231426973, valid_loss: 0.017135548192475522\n",
      "SEED: 11, FOLD: 1, EPOCH: 17,train_loss: 0.01708051436783179, valid_loss: 0.01735226432127612\n",
      "SEED: 11, FOLD: 1, EPOCH: 18,train_loss: 0.016801323093797848, valid_loss: 0.01714708541652986\n",
      "SEED: 11, FOLD: 1, EPOCH: 19,train_loss: 0.016435526365387268, valid_loss: 0.01723360044083425\n",
      "SEED: 11, FOLD: 1, EPOCH: 20,train_loss: 0.016169999186219513, valid_loss: 0.017062495994780744\n",
      "SEED: 11, FOLD: 1, EPOCH: 21,train_loss: 0.015624666627010574, valid_loss: 0.0170209103929145\n",
      "SEED: 11, FOLD: 1, EPOCH: 22,train_loss: 0.015176113411460234, valid_loss: 0.017012694158724376\n",
      "SEED: 11, FOLD: 1, EPOCH: 23,train_loss: 0.014818736385770035, valid_loss: 0.01697720776179007\n",
      "SEED: 11, FOLD: 1, EPOCH: 24,train_loss: 0.014597541632373695, valid_loss: 0.016968016299818242\n",
      "(17611, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7338531237581501, valid_loss: 0.6947739352198208\n",
      "SEED: 11, FOLD: 2, EPOCH: 0,train_loss: 0.4663727025541922, valid_loss: 0.024052037638338172\n",
      "SEED: 11, FOLD: 2, EPOCH: 1,train_loss: 0.020768929245895233, valid_loss: 0.01916742533007089\n",
      "SEED: 11, FOLD: 2, EPOCH: 2,train_loss: 0.018851256375943405, valid_loss: 0.01833405438810587\n",
      "SEED: 11, FOLD: 2, EPOCH: 3,train_loss: 0.018226380709666704, valid_loss: 0.018573320744668737\n",
      "SEED: 11, FOLD: 2, EPOCH: 4,train_loss: 0.01793521492863479, valid_loss: 0.018708979272667098\n",
      "SEED: 11, FOLD: 2, EPOCH: 5,train_loss: 0.01791060160494585, valid_loss: 0.018245022990466916\n",
      "SEED: 11, FOLD: 2, EPOCH: 6,train_loss: 0.01794457842555383, valid_loss: 0.018471172435537857\n",
      "SEED: 11, FOLD: 2, EPOCH: 7,train_loss: 0.01795444952701961, valid_loss: 0.018148450947859707\n",
      "SEED: 11, FOLD: 2, EPOCH: 8,train_loss: 0.017916478378617245, valid_loss: 0.01841244665796266\n",
      "SEED: 11, FOLD: 2, EPOCH: 9,train_loss: 0.017898072711313547, valid_loss: 0.01808178553576855\n",
      "SEED: 11, FOLD: 2, EPOCH: 10,train_loss: 0.0178317046602783, valid_loss: 0.01814079421627171\n",
      "SEED: 11, FOLD: 2, EPOCH: 11,train_loss: 0.017749432211174913, valid_loss: 0.0179454740958617\n",
      "SEED: 11, FOLD: 2, EPOCH: 12,train_loss: 0.01772038525213366, valid_loss: 0.017862528644721296\n",
      "SEED: 11, FOLD: 2, EPOCH: 13,train_loss: 0.01764546674878701, valid_loss: 0.017842705498504287\n",
      "SEED: 11, FOLD: 2, EPOCH: 14,train_loss: 0.01751248044488223, valid_loss: 0.017732249545481277\n",
      "SEED: 11, FOLD: 2, EPOCH: 15,train_loss: 0.017386750243874132, valid_loss: 0.01771412244724\n",
      "SEED: 11, FOLD: 2, EPOCH: 16,train_loss: 0.017191807348011196, valid_loss: 0.017713618190849528\n",
      "SEED: 11, FOLD: 2, EPOCH: 17,train_loss: 0.01697238527940235, valid_loss: 0.017660066951066256\n",
      "SEED: 11, FOLD: 2, EPOCH: 18,train_loss: 0.0167193284150267, valid_loss: 0.017485140877611497\n",
      "SEED: 11, FOLD: 2, EPOCH: 19,train_loss: 0.016387951992236187, valid_loss: 0.017555032007615354\n",
      "SEED: 11, FOLD: 2, EPOCH: 20,train_loss: 0.016035341650949442, valid_loss: 0.017546081449836493\n",
      "SEED: 11, FOLD: 2, EPOCH: 21,train_loss: 0.015567127190044393, valid_loss: 0.017390008851447526\n",
      "SEED: 11, FOLD: 2, EPOCH: 22,train_loss: 0.015121588044786367, valid_loss: 0.01746735940961277\n",
      "SEED: 11, FOLD: 2, EPOCH: 23,train_loss: 0.014687908570403639, valid_loss: 0.017439059036619523\n",
      "SEED: 11, FOLD: 2, EPOCH: 24,train_loss: 0.014478681183865538, valid_loss: 0.017423613106503207\n",
      "(17565, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7341769851636195, valid_loss: 0.6964738590376718\n",
      "SEED: 11, FOLD: 3, EPOCH: 0,train_loss: 0.46748852457149304, valid_loss: 0.023791104980877466\n",
      "SEED: 11, FOLD: 3, EPOCH: 1,train_loss: 0.021294648016708485, valid_loss: 0.018988312727638654\n",
      "SEED: 11, FOLD: 3, EPOCH: 2,train_loss: 0.019009339069758636, valid_loss: 0.01855043705020632\n",
      "SEED: 11, FOLD: 3, EPOCH: 3,train_loss: 0.018446496485368065, valid_loss: 0.01855366283229419\n",
      "SEED: 11, FOLD: 3, EPOCH: 4,train_loss: 0.01786184862283045, valid_loss: 0.018654954699533325\n",
      "SEED: 11, FOLD: 3, EPOCH: 5,train_loss: 0.0179374602596289, valid_loss: 0.017971661500632764\n",
      "SEED: 11, FOLD: 3, EPOCH: 6,train_loss: 0.017797367620295372, valid_loss: 0.01780688940946545\n",
      "SEED: 11, FOLD: 3, EPOCH: 7,train_loss: 0.017853714356981756, valid_loss: 0.017740082927048206\n",
      "SEED: 11, FOLD: 3, EPOCH: 8,train_loss: 0.01783317644014091, valid_loss: 0.017735027761331627\n",
      "SEED: 11, FOLD: 3, EPOCH: 9,train_loss: 0.017830172303956057, valid_loss: 0.01772545145026275\n",
      "SEED: 11, FOLD: 3, EPOCH: 10,train_loss: 0.01774328733133017, valid_loss: 0.017680445765810352\n",
      "SEED: 11, FOLD: 3, EPOCH: 11,train_loss: 0.01769703281098518, valid_loss: 0.01755930097507579\n",
      "SEED: 11, FOLD: 3, EPOCH: 12,train_loss: 0.017693492887622637, valid_loss: 0.017650013736316136\n",
      "SEED: 11, FOLD: 3, EPOCH: 13,train_loss: 0.0176114277050331, valid_loss: 0.017679619656077453\n",
      "SEED: 11, FOLD: 3, EPOCH: 14,train_loss: 0.01741909712175096, valid_loss: 0.017669567625437463\n",
      "SEED: 11, FOLD: 3, EPOCH: 15,train_loss: 0.017231484537647255, valid_loss: 0.017579362887356963\n",
      "SEED: 11, FOLD: 3, EPOCH: 16,train_loss: 0.01706973667782934, valid_loss: 0.017484554728227002\n",
      "SEED: 11, FOLD: 3, EPOCH: 17,train_loss: 0.016863368390856878, valid_loss: 0.01734791046806744\n",
      "SEED: 11, FOLD: 3, EPOCH: 18,train_loss: 0.016614051886658737, valid_loss: 0.017469496013862745\n",
      "SEED: 11, FOLD: 3, EPOCH: 19,train_loss: 0.016212414909640083, valid_loss: 0.017202231075082508\n",
      "SEED: 11, FOLD: 3, EPOCH: 20,train_loss: 0.01578266200596008, valid_loss: 0.017353060096502303\n",
      "SEED: 11, FOLD: 3, EPOCH: 21,train_loss: 0.015301175982407902, valid_loss: 0.017273702738540512\n",
      "SEED: 11, FOLD: 3, EPOCH: 22,train_loss: 0.014752556623864, valid_loss: 0.017263913420694214\n",
      "SEED: 11, FOLD: 3, EPOCH: 23,train_loss: 0.014346178708786982, valid_loss: 0.017242459314210073\n",
      "SEED: 11, FOLD: 3, EPOCH: 24,train_loss: 0.014107931533531435, valid_loss: 0.017268298539732184\n",
      "(17530, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.73386922108866, valid_loss: 0.6960305060659137\n",
      "SEED: 11, FOLD: 4, EPOCH: 0,train_loss: 0.46851927716366565, valid_loss: 0.02391481745455946\n",
      "SEED: 11, FOLD: 4, EPOCH: 1,train_loss: 0.02120790045953145, valid_loss: 0.018985618171947344\n",
      "SEED: 11, FOLD: 4, EPOCH: 2,train_loss: 0.019147541917806123, valid_loss: 0.01809305985059057\n",
      "SEED: 11, FOLD: 4, EPOCH: 3,train_loss: 0.01828561364978987, valid_loss: 0.01861605995467731\n",
      "SEED: 11, FOLD: 4, EPOCH: 4,train_loss: 0.01809186083230659, valid_loss: 0.01809893697500229\n",
      "SEED: 11, FOLD: 4, EPOCH: 5,train_loss: 0.01803306840278589, valid_loss: 0.017773852231247084\n",
      "SEED: 11, FOLD: 4, EPOCH: 6,train_loss: 0.017986151518939186, valid_loss: 0.017911123910120556\n",
      "SEED: 11, FOLD: 4, EPOCH: 7,train_loss: 0.017916879433132436, valid_loss: 0.01785860066967351\n",
      "SEED: 11, FOLD: 4, EPOCH: 8,train_loss: 0.018023658088360824, valid_loss: 0.017824234973107065\n",
      "SEED: 11, FOLD: 4, EPOCH: 9,train_loss: 0.017923146282343098, valid_loss: 0.017793510747807367\n",
      "SEED: 11, FOLD: 4, EPOCH: 10,train_loss: 0.017893468655210777, valid_loss: 0.017611596680113247\n",
      "SEED: 11, FOLD: 4, EPOCH: 11,train_loss: 0.01785276366574486, valid_loss: 0.01830977994416441\n",
      "SEED: 11, FOLD: 4, EPOCH: 12,train_loss: 0.017755424168749447, valid_loss: 0.017713684615279945\n",
      "SEED: 11, FOLD: 4, EPOCH: 13,train_loss: 0.017708675942662424, valid_loss: 0.017517062090337276\n",
      "SEED: 11, FOLD: 4, EPOCH: 14,train_loss: 0.01759535601077071, valid_loss: 0.01741221472620964\n",
      "SEED: 11, FOLD: 4, EPOCH: 15,train_loss: 0.017382464969843407, valid_loss: 0.0178242418382849\n",
      "SEED: 11, FOLD: 4, EPOCH: 16,train_loss: 0.01729917524885522, valid_loss: 0.017380759492516516\n",
      "SEED: 11, FOLD: 4, EPOCH: 17,train_loss: 0.01703526809077411, valid_loss: 0.017250165210238526\n",
      "SEED: 11, FOLD: 4, EPOCH: 18,train_loss: 0.01673422129756778, valid_loss: 0.017179384002728122\n",
      "SEED: 11, FOLD: 4, EPOCH: 19,train_loss: 0.01641079192695609, valid_loss: 0.01720571057604892\n",
      "SEED: 11, FOLD: 4, EPOCH: 20,train_loss: 0.0161031674607283, valid_loss: 0.017146062638078417\n",
      "SEED: 11, FOLD: 4, EPOCH: 21,train_loss: 0.015560387980437627, valid_loss: 0.01702999650899853\n",
      "SEED: 11, FOLD: 4, EPOCH: 22,train_loss: 0.015083090925629991, valid_loss: 0.017053176036902835\n",
      "SEED: 11, FOLD: 4, EPOCH: 23,train_loss: 0.01468367915410195, valid_loss: 0.016997820724334034\n",
      "SEED: 11, FOLD: 4, EPOCH: 24,train_loss: 0.014448494799978976, valid_loss: 0.017012876085937025\n",
      "(17574, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7350559882495714, valid_loss: 0.6995994874409267\n",
      "SEED: 12, FOLD: 0, EPOCH: 0,train_loss: 0.4672917964044904, valid_loss: 0.026075306907296182\n",
      "SEED: 12, FOLD: 0, EPOCH: 1,train_loss: 0.021040616853945496, valid_loss: 0.0191392363182136\n",
      "SEED: 12, FOLD: 0, EPOCH: 2,train_loss: 0.019017198703427246, valid_loss: 0.01934913301042148\n",
      "SEED: 12, FOLD: 0, EPOCH: 3,train_loss: 0.01826875303885427, valid_loss: 0.01819314608084304\n",
      "SEED: 12, FOLD: 0, EPOCH: 4,train_loss: 0.017924937514075333, valid_loss: 0.018312721513211727\n",
      "SEED: 12, FOLD: 0, EPOCH: 5,train_loss: 0.017766800715817488, valid_loss: 0.01836333658014025\n",
      "SEED: 12, FOLD: 0, EPOCH: 6,train_loss: 0.017806202321704746, valid_loss: 0.01858494986913034\n",
      "SEED: 12, FOLD: 0, EPOCH: 7,train_loss: 0.01787046716292051, valid_loss: 0.018569543505353586\n",
      "SEED: 12, FOLD: 0, EPOCH: 8,train_loss: 0.01783704547130543, valid_loss: 0.01834309705133949\n",
      "SEED: 12, FOLD: 0, EPOCH: 9,train_loss: 0.017803121675345777, valid_loss: 0.01805063323783023\n",
      "SEED: 12, FOLD: 0, EPOCH: 10,train_loss: 0.017747125892049593, valid_loss: 0.018281972674386842\n",
      "SEED: 12, FOLD: 0, EPOCH: 11,train_loss: 0.017690337269796408, valid_loss: 0.018092020308332783\n",
      "SEED: 12, FOLD: 0, EPOCH: 12,train_loss: 0.0175925120913788, valid_loss: 0.017824457372937884\n",
      "SEED: 12, FOLD: 0, EPOCH: 13,train_loss: 0.01753278021984126, valid_loss: 0.017976249647991997\n",
      "SEED: 12, FOLD: 0, EPOCH: 14,train_loss: 0.017386620270385258, valid_loss: 0.018068372883966993\n",
      "SEED: 12, FOLD: 0, EPOCH: 15,train_loss: 0.017278885664553312, valid_loss: 0.018185108793633324\n",
      "SEED: 12, FOLD: 0, EPOCH: 16,train_loss: 0.017115092154700254, valid_loss: 0.017915197435234273\n",
      "SEED: 12, FOLD: 0, EPOCH: 17,train_loss: 0.016790200321786644, valid_loss: 0.017683695150273186\n",
      "SEED: 12, FOLD: 0, EPOCH: 18,train_loss: 0.016576238455709772, valid_loss: 0.017821843789092132\n",
      "SEED: 12, FOLD: 0, EPOCH: 19,train_loss: 0.016190178631602423, valid_loss: 0.0176690101357443\n",
      "SEED: 12, FOLD: 0, EPOCH: 20,train_loss: 0.015850544718188652, valid_loss: 0.01755536249173539\n",
      "SEED: 12, FOLD: 0, EPOCH: 21,train_loss: 0.015332525960453178, valid_loss: 0.017457776277193002\n",
      "SEED: 12, FOLD: 0, EPOCH: 22,train_loss: 0.0147774671609311, valid_loss: 0.017471791990101338\n",
      "SEED: 12, FOLD: 0, EPOCH: 23,train_loss: 0.014323273295725601, valid_loss: 0.01751964172082288\n",
      "SEED: 12, FOLD: 0, EPOCH: 24,train_loss: 0.014068325603569763, valid_loss: 0.01750481171267373\n",
      "(17599, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7352862159411112, valid_loss: 0.7022675801725948\n",
      "SEED: 12, FOLD: 1, EPOCH: 0,train_loss: 0.4657542237984961, valid_loss: 0.02542767657295746\n",
      "SEED: 12, FOLD: 1, EPOCH: 1,train_loss: 0.021120665689417416, valid_loss: 0.01911711791420684\n",
      "SEED: 12, FOLD: 1, EPOCH: 2,train_loss: 0.019053029841271, valid_loss: 0.018373684683705076\n",
      "SEED: 12, FOLD: 1, EPOCH: 3,train_loss: 0.01836117473093496, valid_loss: 0.01805430941064568\n",
      "SEED: 12, FOLD: 1, EPOCH: 4,train_loss: 0.01798191219838201, valid_loss: 0.01810424528358614\n",
      "SEED: 12, FOLD: 1, EPOCH: 5,train_loss: 0.017909411793115778, valid_loss: 0.017999217188095346\n",
      "SEED: 12, FOLD: 1, EPOCH: 6,train_loss: 0.017846835291256077, valid_loss: 0.018005118650548598\n",
      "SEED: 12, FOLD: 1, EPOCH: 7,train_loss: 0.01782304192285823, valid_loss: 0.018033970859559142\n",
      "SEED: 12, FOLD: 1, EPOCH: 8,train_loss: 0.01789609325941706, valid_loss: 0.018043984878150857\n",
      "SEED: 12, FOLD: 1, EPOCH: 9,train_loss: 0.01779647351688017, valid_loss: 0.017971637275289085\n",
      "SEED: 12, FOLD: 1, EPOCH: 10,train_loss: 0.017791143605026646, valid_loss: 0.01817108383950065\n",
      "SEED: 12, FOLD: 1, EPOCH: 11,train_loss: 0.017751125463594992, valid_loss: 0.01757425025982015\n",
      "SEED: 12, FOLD: 1, EPOCH: 12,train_loss: 0.017649036501466795, valid_loss: 0.01785817605388515\n",
      "SEED: 12, FOLD: 1, EPOCH: 13,train_loss: 0.017556549394098314, valid_loss: 0.017614342628375572\n",
      "SEED: 12, FOLD: 1, EPOCH: 14,train_loss: 0.017482996283881905, valid_loss: 0.017628194517729914\n",
      "SEED: 12, FOLD: 1, EPOCH: 15,train_loss: 0.017340485350755247, valid_loss: 0.017656113459345174\n",
      "SEED: 12, FOLD: 1, EPOCH: 16,train_loss: 0.017171993696441252, valid_loss: 0.017640334362273708\n",
      "SEED: 12, FOLD: 1, EPOCH: 17,train_loss: 0.01693054462067675, valid_loss: 0.017324125750319046\n",
      "SEED: 12, FOLD: 1, EPOCH: 18,train_loss: 0.016633939362414505, valid_loss: 0.017223872463492787\n",
      "SEED: 12, FOLD: 1, EPOCH: 19,train_loss: 0.016253471900911434, valid_loss: 0.017185204032370272\n",
      "SEED: 12, FOLD: 1, EPOCH: 20,train_loss: 0.0158206801119166, valid_loss: 0.017173616297762182\n",
      "SEED: 12, FOLD: 1, EPOCH: 21,train_loss: 0.015332917743564947, valid_loss: 0.01713805218391559\n",
      "SEED: 12, FOLD: 1, EPOCH: 22,train_loss: 0.014819208478582079, valid_loss: 0.017116201986723086\n",
      "SEED: 12, FOLD: 1, EPOCH: 23,train_loss: 0.014341484026416489, valid_loss: 0.017114271190674865\n",
      "SEED: 12, FOLD: 1, EPOCH: 24,train_loss: 0.014101986975773521, valid_loss: 0.017108875135069385\n",
      "(17500, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7351109842314337, valid_loss: 0.6981082762990679\n",
      "SEED: 12, FOLD: 2, EPOCH: 0,train_loss: 0.4688339334416346, valid_loss: 0.02438227885535785\n",
      "SEED: 12, FOLD: 2, EPOCH: 1,train_loss: 0.020691142492268208, valid_loss: 0.018887130011405264\n",
      "SEED: 12, FOLD: 2, EPOCH: 2,train_loss: 0.019188230340606974, valid_loss: 0.01820799761584827\n",
      "SEED: 12, FOLD: 2, EPOCH: 3,train_loss: 0.018354185666535457, valid_loss: 0.018453684928161757\n",
      "SEED: 12, FOLD: 2, EPOCH: 4,train_loss: 0.017967935080510856, valid_loss: 0.018036446826798575\n",
      "SEED: 12, FOLD: 2, EPOCH: 5,train_loss: 0.017944449055803953, valid_loss: 0.01822656760258334\n",
      "SEED: 12, FOLD: 2, EPOCH: 6,train_loss: 0.01783712165443784, valid_loss: 0.017744346761277743\n",
      "SEED: 12, FOLD: 2, EPOCH: 7,train_loss: 0.017841453888337976, valid_loss: 0.018197689790810857\n",
      "SEED: 12, FOLD: 2, EPOCH: 8,train_loss: 0.017856463484031006, valid_loss: 0.018000484417591778\n",
      "SEED: 12, FOLD: 2, EPOCH: 9,train_loss: 0.017823309406474995, valid_loss: 0.017574558619941984\n",
      "SEED: 12, FOLD: 2, EPOCH: 10,train_loss: 0.017802269245586255, valid_loss: 0.018446857961160797\n",
      "SEED: 12, FOLD: 2, EPOCH: 11,train_loss: 0.017762498590197875, valid_loss: 0.01762009771274669\n",
      "SEED: 12, FOLD: 2, EPOCH: 12,train_loss: 0.01769247027046054, valid_loss: 0.01750405590449061\n",
      "SEED: 12, FOLD: 2, EPOCH: 13,train_loss: 0.017563110815673848, valid_loss: 0.017764710182590144\n",
      "SEED: 12, FOLD: 2, EPOCH: 14,train_loss: 0.017424695438494647, valid_loss: 0.017407482942300184\n",
      "SEED: 12, FOLD: 2, EPOCH: 15,train_loss: 0.017361142162750236, valid_loss: 0.017474924826196263\n",
      "SEED: 12, FOLD: 2, EPOCH: 16,train_loss: 0.017167662052831947, valid_loss: 0.017261605763009617\n",
      "SEED: 12, FOLD: 2, EPOCH: 17,train_loss: 0.0169069177002041, valid_loss: 0.01737880488591535\n",
      "SEED: 12, FOLD: 2, EPOCH: 18,train_loss: 0.01663361457822314, valid_loss: 0.017213146761059762\n",
      "SEED: 12, FOLD: 2, EPOCH: 19,train_loss: 0.016237888709526426, valid_loss: 0.017314426308231694\n",
      "SEED: 12, FOLD: 2, EPOCH: 20,train_loss: 0.015795262877142776, valid_loss: 0.017017091624438763\n",
      "SEED: 12, FOLD: 2, EPOCH: 21,train_loss: 0.01531944681557208, valid_loss: 0.017034977568047387\n",
      "SEED: 12, FOLD: 2, EPOCH: 22,train_loss: 0.014742599473926274, valid_loss: 0.01712030175008944\n",
      "SEED: 12, FOLD: 2, EPOCH: 23,train_loss: 0.014268955005074505, valid_loss: 0.01709559511925493\n",
      "SEED: 12, FOLD: 2, EPOCH: 24,train_loss: 0.0139964892304618, valid_loss: 0.017091825285128186\n",
      "(17623, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7355296918447467, valid_loss: 0.6988349644576802\n",
      "SEED: 12, FOLD: 3, EPOCH: 0,train_loss: 0.4670228035175714, valid_loss: 0.022832876728738054\n",
      "SEED: 12, FOLD: 3, EPOCH: 1,train_loss: 0.021100457433773125, valid_loss: 0.018603107125005302\n",
      "SEED: 12, FOLD: 3, EPOCH: 2,train_loss: 0.01897260461650465, valid_loss: 0.017697860897683045\n",
      "SEED: 12, FOLD: 3, EPOCH: 3,train_loss: 0.018215693668394848, valid_loss: 0.017498108037911794\n",
      "SEED: 12, FOLD: 3, EPOCH: 4,train_loss: 0.01795304594291509, valid_loss: 0.017998327227199778\n",
      "SEED: 12, FOLD: 3, EPOCH: 5,train_loss: 0.017955770824050556, valid_loss: 0.017768032684483948\n",
      "SEED: 12, FOLD: 3, EPOCH: 6,train_loss: 0.017865092952506267, valid_loss: 0.01803359394783483\n",
      "SEED: 12, FOLD: 3, EPOCH: 7,train_loss: 0.01794680224839544, valid_loss: 0.017589316648595473\n",
      "SEED: 12, FOLD: 3, EPOCH: 8,train_loss: 0.01790454346632612, valid_loss: 0.01746854049098842\n",
      "SEED: 12, FOLD: 3, EPOCH: 9,train_loss: 0.017846003687684086, valid_loss: 0.01776697812601924\n",
      "SEED: 12, FOLD: 3, EPOCH: 10,train_loss: 0.01789973445398652, valid_loss: 0.017495100057738668\n",
      "SEED: 12, FOLD: 3, EPOCH: 11,train_loss: 0.017813270229954218, valid_loss: 0.017491731683121008\n",
      "SEED: 12, FOLD: 3, EPOCH: 12,train_loss: 0.017698449264887884, valid_loss: 0.017327459446866724\n",
      "SEED: 12, FOLD: 3, EPOCH: 13,train_loss: 0.017595509600326204, valid_loss: 0.017349495086818933\n",
      "SEED: 12, FOLD: 3, EPOCH: 14,train_loss: 0.017515571234558804, valid_loss: 0.017351508277523166\n",
      "SEED: 12, FOLD: 3, EPOCH: 15,train_loss: 0.017380371298371017, valid_loss: 0.017230370328487718\n",
      "SEED: 12, FOLD: 3, EPOCH: 16,train_loss: 0.017144836046719465, valid_loss: 0.017057230778257635\n",
      "SEED: 12, FOLD: 3, EPOCH: 17,train_loss: 0.0169264173972002, valid_loss: 0.017100744935519555\n",
      "SEED: 12, FOLD: 3, EPOCH: 18,train_loss: 0.01660211669092161, valid_loss: 0.017284181982497957\n",
      "SEED: 12, FOLD: 3, EPOCH: 19,train_loss: 0.016286656085023846, valid_loss: 0.01694600804544547\n",
      "SEED: 12, FOLD: 3, EPOCH: 20,train_loss: 0.015866245035136093, valid_loss: 0.016931380200035432\n",
      "SEED: 12, FOLD: 3, EPOCH: 21,train_loss: 0.015387012947188772, valid_loss: 0.016907737069927594\n",
      "SEED: 12, FOLD: 3, EPOCH: 22,train_loss: 0.014867748322802177, valid_loss: 0.016924538540051264\n",
      "SEED: 12, FOLD: 3, EPOCH: 23,train_loss: 0.014403347384886465, valid_loss: 0.016935578492634436\n",
      "SEED: 12, FOLD: 3, EPOCH: 24,train_loss: 0.01414955849421845, valid_loss: 0.016971467528492212\n",
      "(17496, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7351700694021517, valid_loss: 0.6992262942450387\n",
      "SEED: 12, FOLD: 4, EPOCH: 0,train_loss: 0.46858178375519977, valid_loss: 0.024698717040675028\n",
      "SEED: 12, FOLD: 4, EPOCH: 1,train_loss: 0.020912018924081413, valid_loss: 0.01903305250619139\n",
      "SEED: 12, FOLD: 4, EPOCH: 2,train_loss: 0.019042915882148445, valid_loss: 0.018389269124184336\n",
      "SEED: 12, FOLD: 4, EPOCH: 3,train_loss: 0.01811341919603139, valid_loss: 0.01823161473231656\n",
      "SEED: 12, FOLD: 4, EPOCH: 4,train_loss: 0.017913204393465155, valid_loss: 0.01823737741048847\n",
      "SEED: 12, FOLD: 4, EPOCH: 5,train_loss: 0.01776684701007648, valid_loss: 0.018153419478663377\n",
      "SEED: 12, FOLD: 4, EPOCH: 6,train_loss: 0.017876484907184638, valid_loss: 0.018739178031682967\n",
      "SEED: 12, FOLD: 4, EPOCH: 7,train_loss: 0.017824053472030338, valid_loss: 0.018154108258230345\n",
      "SEED: 12, FOLD: 4, EPOCH: 8,train_loss: 0.017844572384590213, valid_loss: 0.018554098584822248\n",
      "SEED: 12, FOLD: 4, EPOCH: 9,train_loss: 0.017767520546641227, valid_loss: 0.01845593662666423\n",
      "SEED: 12, FOLD: 4, EPOCH: 10,train_loss: 0.017769700840768152, valid_loss: 0.018090546051306385\n",
      "SEED: 12, FOLD: 4, EPOCH: 11,train_loss: 0.017634478384071457, valid_loss: 0.018046635362718787\n",
      "SEED: 12, FOLD: 4, EPOCH: 12,train_loss: 0.017644960297285205, valid_loss: 0.018153364504022256\n",
      "SEED: 12, FOLD: 4, EPOCH: 13,train_loss: 0.017527033867192093, valid_loss: 0.018098907438772065\n",
      "SEED: 12, FOLD: 4, EPOCH: 14,train_loss: 0.017426799214615003, valid_loss: 0.017968025564083032\n",
      "SEED: 12, FOLD: 4, EPOCH: 15,train_loss: 0.01724192085437966, valid_loss: 0.017957876303366253\n",
      "SEED: 12, FOLD: 4, EPOCH: 16,train_loss: 0.017115661704464116, valid_loss: 0.01755438196871962\n",
      "SEED: 12, FOLD: 4, EPOCH: 17,train_loss: 0.016803588079166237, valid_loss: 0.01769623870828322\n",
      "SEED: 12, FOLD: 4, EPOCH: 18,train_loss: 0.016548928077312283, valid_loss: 0.017416514296616826\n",
      "SEED: 12, FOLD: 4, EPOCH: 19,train_loss: 0.01618663057766474, valid_loss: 0.01754717222814049\n",
      "SEED: 12, FOLD: 4, EPOCH: 20,train_loss: 0.015753127668515172, valid_loss: 0.017424375031675612\n",
      "SEED: 12, FOLD: 4, EPOCH: 21,train_loss: 0.015242292328200636, valid_loss: 0.017375902166324002\n",
      "SEED: 12, FOLD: 4, EPOCH: 22,train_loss: 0.014773803423192814, valid_loss: 0.017363849787839822\n",
      "SEED: 12, FOLD: 4, EPOCH: 23,train_loss: 0.01433486035977402, valid_loss: 0.01740384064614773\n",
      "SEED: 12, FOLD: 4, EPOCH: 24,train_loss: 0.014081411328792136, valid_loss: 0.0173823797543134\n",
      "(17543, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7364648191825204, valid_loss: 0.6978754128728594\n",
      "SEED: 13, FOLD: 0, EPOCH: 0,train_loss: 0.4674841022739808, valid_loss: 0.02449004916208131\n",
      "SEED: 13, FOLD: 0, EPOCH: 1,train_loss: 0.021236271786409012, valid_loss: 0.018546102116150515\n",
      "SEED: 13, FOLD: 0, EPOCH: 2,train_loss: 0.019145490547669106, valid_loss: 0.056928360089659694\n",
      "SEED: 13, FOLD: 0, EPOCH: 3,train_loss: 0.018404647168042004, valid_loss: 0.018395363459629673\n",
      "SEED: 13, FOLD: 0, EPOCH: 4,train_loss: 0.01813405788625064, valid_loss: 0.01900726942611592\n",
      "SEED: 13, FOLD: 0, EPOCH: 5,train_loss: 0.018112616701240557, valid_loss: 0.01765414880854743\n",
      "SEED: 13, FOLD: 0, EPOCH: 6,train_loss: 0.0180041480647481, valid_loss: 0.01783503235450813\n",
      "SEED: 13, FOLD: 0, EPOCH: 7,train_loss: 0.017970572954610638, valid_loss: 0.017727910886917796\n",
      "SEED: 13, FOLD: 0, EPOCH: 8,train_loss: 0.017951309532467007, valid_loss: 0.017852449576769555\n",
      "SEED: 13, FOLD: 0, EPOCH: 9,train_loss: 0.018082799511435238, valid_loss: 0.01771261425954955\n",
      "SEED: 13, FOLD: 0, EPOCH: 10,train_loss: 0.017993599507093862, valid_loss: 0.017742521502077578\n",
      "SEED: 13, FOLD: 0, EPOCH: 11,train_loss: 0.018028253385716158, valid_loss: 0.0176319917930024\n",
      "SEED: 13, FOLD: 0, EPOCH: 12,train_loss: 0.017883937441460464, valid_loss: 0.01762939358928374\n",
      "SEED: 13, FOLD: 0, EPOCH: 13,train_loss: 0.017788568687071835, valid_loss: 0.018289219534822872\n",
      "SEED: 13, FOLD: 0, EPOCH: 14,train_loss: 0.017858327744339687, valid_loss: 0.017383116111159325\n",
      "SEED: 13, FOLD: 0, EPOCH: 15,train_loss: 0.017595029085118702, valid_loss: 0.017509211786091328\n",
      "SEED: 13, FOLD: 0, EPOCH: 16,train_loss: 0.01730788719124984, valid_loss: 0.017221956247729913\n",
      "SEED: 13, FOLD: 0, EPOCH: 17,train_loss: 0.017083121875327997, valid_loss: 0.017224557511508466\n",
      "SEED: 13, FOLD: 0, EPOCH: 18,train_loss: 0.016859802768390247, valid_loss: 0.01718171358640705\n",
      "SEED: 13, FOLD: 0, EPOCH: 19,train_loss: 0.01659180526284204, valid_loss: 0.01708134434052876\n",
      "SEED: 13, FOLD: 0, EPOCH: 20,train_loss: 0.01612225123613641, valid_loss: 0.017106352719877448\n",
      "SEED: 13, FOLD: 0, EPOCH: 21,train_loss: 0.01577003261047429, valid_loss: 0.017042179671781402\n",
      "SEED: 13, FOLD: 0, EPOCH: 22,train_loss: 0.015306834435171408, valid_loss: 0.017102747516972678\n",
      "SEED: 13, FOLD: 0, EPOCH: 23,train_loss: 0.015029979100369888, valid_loss: 0.01699071555797543\n",
      "SEED: 13, FOLD: 0, EPOCH: 24,train_loss: 0.014735440257936716, valid_loss: 0.017008783934371812\n",
      "(17653, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7358235652032106, valid_loss: 0.6974033765933093\n",
      "SEED: 13, FOLD: 1, EPOCH: 0,train_loss: 0.46774935770941817, valid_loss: 0.02388072178206023\n",
      "SEED: 13, FOLD: 1, EPOCH: 1,train_loss: 0.02072223188166601, valid_loss: 0.01905012738836162\n",
      "SEED: 13, FOLD: 1, EPOCH: 2,train_loss: 0.018882547653671623, valid_loss: 0.0181306047255502\n",
      "SEED: 13, FOLD: 1, EPOCH: 3,train_loss: 0.018191316860147577, valid_loss: 0.01841474280637853\n",
      "SEED: 13, FOLD: 1, EPOCH: 4,train_loss: 0.017922701961968258, valid_loss: 0.018542795825530502\n",
      "SEED: 13, FOLD: 1, EPOCH: 5,train_loss: 0.017893028938198004, valid_loss: 0.018579426769386318\n",
      "SEED: 13, FOLD: 1, EPOCH: 6,train_loss: 0.017851923801598772, valid_loss: 0.017900722046547076\n",
      "SEED: 13, FOLD: 1, EPOCH: 7,train_loss: 0.01785351493922265, valid_loss: 0.018038985209868234\n",
      "SEED: 13, FOLD: 1, EPOCH: 8,train_loss: 0.017847029526002596, valid_loss: 0.017902517033850446\n",
      "SEED: 13, FOLD: 1, EPOCH: 9,train_loss: 0.017802047684950674, valid_loss: 0.01826484884847613\n",
      "SEED: 13, FOLD: 1, EPOCH: 10,train_loss: 0.017816557447709467, valid_loss: 0.01784146105980172\n",
      "SEED: 13, FOLD: 1, EPOCH: 11,train_loss: 0.017761859111487865, valid_loss: 0.01788127005976789\n",
      "SEED: 13, FOLD: 1, EPOCH: 12,train_loss: 0.017702281454820997, valid_loss: 0.01799082668388591\n",
      "SEED: 13, FOLD: 1, EPOCH: 13,train_loss: 0.01752810024291925, valid_loss: 0.01782453219022821\n",
      "SEED: 13, FOLD: 1, EPOCH: 14,train_loss: 0.017449939650469933, valid_loss: 0.017548473853179637\n",
      "SEED: 13, FOLD: 1, EPOCH: 15,train_loss: 0.017347040727896536, valid_loss: 0.017577400266685906\n",
      "SEED: 13, FOLD: 1, EPOCH: 16,train_loss: 0.017074953373251617, valid_loss: 0.01751302040236838\n",
      "SEED: 13, FOLD: 1, EPOCH: 17,train_loss: 0.016914704517609833, valid_loss: 0.01770414543502471\n",
      "SEED: 13, FOLD: 1, EPOCH: 18,train_loss: 0.016653624984125297, valid_loss: 0.017426333280608934\n",
      "SEED: 13, FOLD: 1, EPOCH: 19,train_loss: 0.01623449038606191, valid_loss: 0.01758143776918159\n",
      "SEED: 13, FOLD: 1, EPOCH: 20,train_loss: 0.015848378738577383, valid_loss: 0.017433620989322662\n",
      "SEED: 13, FOLD: 1, EPOCH: 21,train_loss: 0.015384151850003695, valid_loss: 0.017386068754336414\n",
      "SEED: 13, FOLD: 1, EPOCH: 22,train_loss: 0.014877010440534872, valid_loss: 0.017351473572061342\n",
      "SEED: 13, FOLD: 1, EPOCH: 23,train_loss: 0.014416783454193585, valid_loss: 0.01740802309530623\n",
      "SEED: 13, FOLD: 1, EPOCH: 24,train_loss: 0.014167334411995134, valid_loss: 0.01740371813888059\n",
      "(17591, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7359492338222006, valid_loss: 0.6975084151540484\n",
      "SEED: 13, FOLD: 2, EPOCH: 0,train_loss: 0.46746181796534336, valid_loss: 0.024024161909307753\n",
      "SEED: 13, FOLD: 2, EPOCH: 1,train_loss: 0.02080136653629766, valid_loss: 0.019061290472745896\n",
      "SEED: 13, FOLD: 2, EPOCH: 2,train_loss: 0.018982791260856648, valid_loss: 0.018473830659474645\n",
      "SEED: 13, FOLD: 2, EPOCH: 3,train_loss: 0.018264388955751623, valid_loss: 0.018038896577698842\n",
      "SEED: 13, FOLD: 2, EPOCH: 4,train_loss: 0.017922329216979553, valid_loss: 0.01818849497607776\n",
      "SEED: 13, FOLD: 2, EPOCH: 5,train_loss: 0.017960785024300003, valid_loss: 0.018478501534887722\n",
      "SEED: 13, FOLD: 2, EPOCH: 6,train_loss: 0.01790205608594461, valid_loss: 0.01809656989893743\n",
      "SEED: 13, FOLD: 2, EPOCH: 7,train_loss: 0.017929876013996378, valid_loss: 0.017982165728296553\n",
      "SEED: 13, FOLD: 2, EPOCH: 8,train_loss: 0.017942103010642786, valid_loss: 0.01768521469618593\n",
      "SEED: 13, FOLD: 2, EPOCH: 9,train_loss: 0.01785151731978724, valid_loss: 0.018285241004611763\n",
      "SEED: 13, FOLD: 2, EPOCH: 10,train_loss: 0.017814077963323696, valid_loss: 0.01782850929136787\n",
      "SEED: 13, FOLD: 2, EPOCH: 11,train_loss: 0.017824618982664055, valid_loss: 0.018008304493767873\n",
      "SEED: 13, FOLD: 2, EPOCH: 12,train_loss: 0.017681909603593143, valid_loss: 0.017427111523491995\n",
      "SEED: 13, FOLD: 2, EPOCH: 13,train_loss: 0.017558069143822227, valid_loss: 0.017595571013433592\n",
      "SEED: 13, FOLD: 2, EPOCH: 14,train_loss: 0.017560508871532005, valid_loss: 0.01720627091292824\n",
      "SEED: 13, FOLD: 2, EPOCH: 15,train_loss: 0.017335283063838015, valid_loss: 0.017331182051982197\n",
      "SEED: 13, FOLD: 2, EPOCH: 16,train_loss: 0.017200842202789543, valid_loss: 0.017241172545722553\n",
      "SEED: 13, FOLD: 2, EPOCH: 17,train_loss: 0.016979196189862232, valid_loss: 0.017131856722491127\n",
      "SEED: 13, FOLD: 2, EPOCH: 18,train_loss: 0.016678741782147816, valid_loss: 0.01706537857119526\n",
      "SEED: 13, FOLD: 2, EPOCH: 19,train_loss: 0.01626364625585468, valid_loss: 0.016991022921034268\n",
      "SEED: 13, FOLD: 2, EPOCH: 20,train_loss: 0.015948983307495928, valid_loss: 0.017006416246294974\n",
      "SEED: 13, FOLD: 2, EPOCH: 21,train_loss: 0.015401527805226868, valid_loss: 0.016965691718672002\n",
      "SEED: 13, FOLD: 2, EPOCH: 22,train_loss: 0.01492107237783679, valid_loss: 0.01698088880096163\n",
      "SEED: 13, FOLD: 2, EPOCH: 23,train_loss: 0.014485803830936768, valid_loss: 0.016977101005613802\n",
      "SEED: 13, FOLD: 2, EPOCH: 24,train_loss: 0.014245655212173428, valid_loss: 0.016942762689931053\n",
      "(17494, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.736212934020662, valid_loss: 0.6970513326781137\n",
      "SEED: 13, FOLD: 3, EPOCH: 0,train_loss: 0.4703148950407975, valid_loss: 0.02394937298127583\n",
      "SEED: 13, FOLD: 3, EPOCH: 1,train_loss: 0.021040385507427862, valid_loss: 0.019090290154729572\n",
      "SEED: 13, FOLD: 3, EPOCH: 2,train_loss: 0.01903125768133106, valid_loss: 0.01765241487217801\n",
      "SEED: 13, FOLD: 3, EPOCH: 3,train_loss: 0.01834087778073158, valid_loss: 0.017668471006410464\n",
      "SEED: 13, FOLD: 3, EPOCH: 4,train_loss: 0.018004823557651827, valid_loss: 0.017765344546309538\n",
      "SEED: 13, FOLD: 3, EPOCH: 5,train_loss: 0.017933863255936298, valid_loss: 0.017538660019636155\n",
      "SEED: 13, FOLD: 3, EPOCH: 6,train_loss: 0.017949729199337697, valid_loss: 0.017569547119949545\n",
      "SEED: 13, FOLD: 3, EPOCH: 7,train_loss: 0.017968127911869625, valid_loss: 0.017349048597472053\n",
      "SEED: 13, FOLD: 3, EPOCH: 8,train_loss: 0.01789227683423427, valid_loss: 0.01745319648512772\n",
      "SEED: 13, FOLD: 3, EPOCH: 9,train_loss: 0.017912567110501067, valid_loss: 0.017683342950684685\n",
      "SEED: 13, FOLD: 3, EPOCH: 10,train_loss: 0.017883549600730846, valid_loss: 0.017382415171180454\n",
      "SEED: 13, FOLD: 3, EPOCH: 11,train_loss: 0.01782363086911666, valid_loss: 0.01735000011644193\n",
      "SEED: 13, FOLD: 3, EPOCH: 12,train_loss: 0.017764038338332715, valid_loss: 0.01726105104067496\n",
      "SEED: 13, FOLD: 3, EPOCH: 13,train_loss: 0.01767861560313371, valid_loss: 0.017281767672726087\n",
      "SEED: 13, FOLD: 3, EPOCH: 14,train_loss: 0.017519019911215253, valid_loss: 0.01715058439544269\n",
      "SEED: 13, FOLD: 3, EPOCH: 15,train_loss: 0.017409437607946623, valid_loss: 0.01731827687472105\n",
      "SEED: 13, FOLD: 3, EPOCH: 16,train_loss: 0.017260917204085492, valid_loss: 0.017107304212238106\n",
      "SEED: 13, FOLD: 3, EPOCH: 17,train_loss: 0.01699498334532454, valid_loss: 0.017054412088223867\n",
      "SEED: 13, FOLD: 3, EPOCH: 18,train_loss: 0.016688235471174664, valid_loss: 0.017017753661743233\n",
      "SEED: 13, FOLD: 3, EPOCH: 19,train_loss: 0.01643733829123913, valid_loss: 0.016889670571046216\n",
      "SEED: 13, FOLD: 3, EPOCH: 20,train_loss: 0.015979656575750695, valid_loss: 0.016897887284202235\n",
      "SEED: 13, FOLD: 3, EPOCH: 21,train_loss: 0.01549773649006647, valid_loss: 0.016935217274086815\n",
      "SEED: 13, FOLD: 3, EPOCH: 22,train_loss: 0.015023401632469936, valid_loss: 0.01684893010450261\n",
      "SEED: 13, FOLD: 3, EPOCH: 23,train_loss: 0.014603794735931132, valid_loss: 0.016826071989323413\n",
      "SEED: 13, FOLD: 3, EPOCH: 24,train_loss: 0.01437478325581246, valid_loss: 0.016834534358765398\n",
      "(17511, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7358215525202507, valid_loss: 0.6976013234683446\n",
      "SEED: 13, FOLD: 4, EPOCH: 0,train_loss: 0.4691552374865452, valid_loss: 0.024304111089025224\n",
      "SEED: 13, FOLD: 4, EPOCH: 1,train_loss: 0.020595010560359398, valid_loss: 0.019409815381680216\n",
      "SEED: 13, FOLD: 4, EPOCH: 2,train_loss: 0.018841451883696726, valid_loss: 0.018839501323444502\n",
      "SEED: 13, FOLD: 4, EPOCH: 3,train_loss: 0.017964420969305683, valid_loss: 0.01856754645705223\n",
      "SEED: 13, FOLD: 4, EPOCH: 4,train_loss: 0.017732734105339015, valid_loss: 0.018632861280015536\n",
      "SEED: 13, FOLD: 4, EPOCH: 5,train_loss: 0.01771615924191301, valid_loss: 0.01886039599776268\n",
      "SEED: 13, FOLD: 4, EPOCH: 6,train_loss: 0.017735754914690545, valid_loss: 0.018604919420821327\n",
      "SEED: 13, FOLD: 4, EPOCH: 7,train_loss: 0.01768072464768469, valid_loss: 0.01836125637803759\n",
      "SEED: 13, FOLD: 4, EPOCH: 8,train_loss: 0.01772945735902682, valid_loss: 0.019256470991032466\n",
      "SEED: 13, FOLD: 4, EPOCH: 9,train_loss: 0.017691388522295185, valid_loss: 0.018588343688419887\n",
      "SEED: 13, FOLD: 4, EPOCH: 10,train_loss: 0.01767097532504449, valid_loss: 0.01848376930824348\n",
      "SEED: 13, FOLD: 4, EPOCH: 11,train_loss: 0.017613056319745354, valid_loss: 0.018406269326806068\n",
      "SEED: 13, FOLD: 4, EPOCH: 12,train_loss: 0.01752277218267648, valid_loss: 0.018556832681809153\n",
      "SEED: 13, FOLD: 4, EPOCH: 13,train_loss: 0.017492177753444135, valid_loss: 0.01850999849183219\n",
      "SEED: 13, FOLD: 4, EPOCH: 14,train_loss: 0.017322807538792166, valid_loss: 0.018127390582646643\n",
      "SEED: 13, FOLD: 4, EPOCH: 15,train_loss: 0.017202183502270794, valid_loss: 0.01802962709750448\n",
      "SEED: 13, FOLD: 4, EPOCH: 16,train_loss: 0.01700946825291336, valid_loss: 0.01805622529770647\n",
      "SEED: 13, FOLD: 4, EPOCH: 17,train_loss: 0.01676964415849125, valid_loss: 0.018056852317282133\n",
      "SEED: 13, FOLD: 4, EPOCH: 18,train_loss: 0.01654660360493364, valid_loss: 0.017789253033697605\n",
      "SEED: 13, FOLD: 4, EPOCH: 19,train_loss: 0.016177474602676222, valid_loss: 0.017761665343173912\n",
      "SEED: 13, FOLD: 4, EPOCH: 20,train_loss: 0.015706276412319094, valid_loss: 0.017775914658393177\n",
      "SEED: 13, FOLD: 4, EPOCH: 21,train_loss: 0.015268666628938521, valid_loss: 0.017773014599723476\n",
      "SEED: 13, FOLD: 4, EPOCH: 22,train_loss: 0.014718032265285941, valid_loss: 0.017828034795820714\n",
      "SEED: 13, FOLD: 4, EPOCH: 23,train_loss: 0.014268109778853228, valid_loss: 0.017821243511778967\n",
      "SEED: 13, FOLD: 4, EPOCH: 24,train_loss: 0.01402504114692446, valid_loss: 0.01784620311643396\n",
      "(17631, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7358559568723043, valid_loss: 0.704323444296332\n",
      "SEED: 14, FOLD: 0, EPOCH: 0,train_loss: 0.4672077343245779, valid_loss: 0.02490228244706112\n",
      "SEED: 14, FOLD: 0, EPOCH: 1,train_loss: 0.020730461439360744, valid_loss: 0.01978683630552362\n",
      "SEED: 14, FOLD: 0, EPOCH: 2,train_loss: 0.019232897965264492, valid_loss: 0.01868369145428433\n",
      "SEED: 14, FOLD: 0, EPOCH: 3,train_loss: 0.018356167819296967, valid_loss: 0.018202595056637245\n",
      "SEED: 14, FOLD: 0, EPOCH: 4,train_loss: 0.017932994574632332, valid_loss: 0.018089087679982185\n",
      "SEED: 14, FOLD: 0, EPOCH: 5,train_loss: 0.017839131282939426, valid_loss: 0.018413056920775595\n",
      "SEED: 14, FOLD: 0, EPOCH: 6,train_loss: 0.017885376307843388, valid_loss: 0.018228721503606615\n",
      "SEED: 14, FOLD: 0, EPOCH: 7,train_loss: 0.017849498266435188, valid_loss: 0.018019436228582087\n",
      "SEED: 14, FOLD: 0, EPOCH: 8,train_loss: 0.017904349211333454, valid_loss: 0.018216045272043523\n",
      "SEED: 14, FOLD: 0, EPOCH: 9,train_loss: 0.017822812149382156, valid_loss: 0.018175915267099354\n",
      "SEED: 14, FOLD: 0, EPOCH: 10,train_loss: 0.0178092362669607, valid_loss: 0.01859979462974212\n",
      "SEED: 14, FOLD: 0, EPOCH: 11,train_loss: 0.017731700585210237, valid_loss: 0.018113736583686927\n",
      "SEED: 14, FOLD: 0, EPOCH: 12,train_loss: 0.017711086502379698, valid_loss: 0.017935664146481192\n",
      "SEED: 14, FOLD: 0, EPOCH: 13,train_loss: 0.01756510293732087, valid_loss: 0.017670920200865057\n",
      "SEED: 14, FOLD: 0, EPOCH: 14,train_loss: 0.01748022626734514, valid_loss: 0.01764648303608684\n",
      "SEED: 14, FOLD: 0, EPOCH: 15,train_loss: 0.017324728742781757, valid_loss: 0.017765969257144368\n",
      "SEED: 14, FOLD: 0, EPOCH: 16,train_loss: 0.01716528425290101, valid_loss: 0.017461825792184648\n",
      "SEED: 14, FOLD: 0, EPOCH: 17,train_loss: 0.01689255413720789, valid_loss: 0.01752669465563753\n",
      "SEED: 14, FOLD: 0, EPOCH: 18,train_loss: 0.016660085879266262, valid_loss: 0.01742609981995295\n",
      "SEED: 14, FOLD: 0, EPOCH: 19,train_loss: 0.016338414222379957, valid_loss: 0.01732267296927817\n",
      "SEED: 14, FOLD: 0, EPOCH: 20,train_loss: 0.01591932724999345, valid_loss: 0.01734338185804732\n",
      "SEED: 14, FOLD: 0, EPOCH: 21,train_loss: 0.015458238263870928, valid_loss: 0.017367255627451575\n",
      "SEED: 14, FOLD: 0, EPOCH: 22,train_loss: 0.014962645564768194, valid_loss: 0.017212192856651896\n",
      "SEED: 14, FOLD: 0, EPOCH: 23,train_loss: 0.014528704834157143, valid_loss: 0.017221956760348642\n",
      "SEED: 14, FOLD: 0, EPOCH: 24,train_loss: 0.014265254659551209, valid_loss: 0.017247810631113893\n",
      "(17512, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7361351482189484, valid_loss: 0.7058438897132874\n",
      "SEED: 14, FOLD: 1, EPOCH: 0,train_loss: 0.4673545998487159, valid_loss: 0.023777415603399278\n",
      "SEED: 14, FOLD: 1, EPOCH: 1,train_loss: 0.020878512045218997, valid_loss: 0.01936002230005605\n",
      "SEED: 14, FOLD: 1, EPOCH: 2,train_loss: 0.019668880306238676, valid_loss: 0.01904020756483078\n",
      "SEED: 14, FOLD: 1, EPOCH: 3,train_loss: 0.018452843746347147, valid_loss: 0.0184149139427713\n",
      "SEED: 14, FOLD: 1, EPOCH: 4,train_loss: 0.018068503765185383, valid_loss: 0.018614029538418564\n",
      "SEED: 14, FOLD: 1, EPOCH: 5,train_loss: 0.017905421595830116, valid_loss: 0.018370768587504114\n",
      "SEED: 14, FOLD: 1, EPOCH: 6,train_loss: 0.017840801989727647, valid_loss: 0.01866754125803709\n",
      "SEED: 14, FOLD: 1, EPOCH: 7,train_loss: 0.0178644745440705, valid_loss: 0.01845027982656445\n",
      "SEED: 14, FOLD: 1, EPOCH: 8,train_loss: 0.017810886005198, valid_loss: 0.01824300227952855\n",
      "SEED: 14, FOLD: 1, EPOCH: 9,train_loss: 0.01781154725102395, valid_loss: 0.018175206360008037\n",
      "SEED: 14, FOLD: 1, EPOCH: 10,train_loss: 0.017763762646456703, valid_loss: 0.018153160411332334\n",
      "SEED: 14, FOLD: 1, EPOCH: 11,train_loss: 0.01770784375495719, valid_loss: 0.018143374499465736\n",
      "SEED: 14, FOLD: 1, EPOCH: 12,train_loss: 0.01762824699309838, valid_loss: 0.018305964767932892\n",
      "SEED: 14, FOLD: 1, EPOCH: 13,train_loss: 0.017546795294993985, valid_loss: 0.017980240232178143\n",
      "SEED: 14, FOLD: 1, EPOCH: 14,train_loss: 0.017463316794240128, valid_loss: 0.01798631197639874\n",
      "SEED: 14, FOLD: 1, EPOCH: 15,train_loss: 0.017278963020139367, valid_loss: 0.017770210467278957\n",
      "SEED: 14, FOLD: 1, EPOCH: 16,train_loss: 0.01707079629311814, valid_loss: 0.017832551178123268\n",
      "SEED: 14, FOLD: 1, EPOCH: 17,train_loss: 0.016823614621195044, valid_loss: 0.017701303932283606\n",
      "SEED: 14, FOLD: 1, EPOCH: 18,train_loss: 0.01663872866762163, valid_loss: 0.017610927112400532\n",
      "SEED: 14, FOLD: 1, EPOCH: 19,train_loss: 0.0162243913573614, valid_loss: 0.01751831224454301\n",
      "SEED: 14, FOLD: 1, EPOCH: 20,train_loss: 0.015844304508862705, valid_loss: 0.01748614287269967\n",
      "SEED: 14, FOLD: 1, EPOCH: 21,train_loss: 0.015399702348793945, valid_loss: 0.017498171968119484\n",
      "SEED: 14, FOLD: 1, EPOCH: 22,train_loss: 0.014895041221684783, valid_loss: 0.017481488787702153\n",
      "SEED: 14, FOLD: 1, EPOCH: 23,train_loss: 0.014445160427232729, valid_loss: 0.017440054406012807\n",
      "SEED: 14, FOLD: 1, EPOCH: 24,train_loss: 0.01422844793865063, valid_loss: 0.01744748641337667\n",
      "(17631, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7360703793988712, valid_loss: 0.7041927365695729\n",
      "SEED: 14, FOLD: 2, EPOCH: 0,train_loss: 0.46560124650705553, valid_loss: 0.022865187924574402\n",
      "SEED: 14, FOLD: 2, EPOCH: 1,train_loss: 0.021055672020799873, valid_loss: 0.018710094777976766\n",
      "SEED: 14, FOLD: 2, EPOCH: 2,train_loss: 0.01891536767715993, valid_loss: 0.018161532140391713\n",
      "SEED: 14, FOLD: 2, EPOCH: 3,train_loss: 0.018193635536168797, valid_loss: 0.0179707027204773\n",
      "SEED: 14, FOLD: 2, EPOCH: 4,train_loss: 0.017845528510709602, valid_loss: 0.01839355905266369\n",
      "SEED: 14, FOLD: 2, EPOCH: 5,train_loss: 0.017895729065049385, valid_loss: 0.018237720188849112\n",
      "SEED: 14, FOLD: 2, EPOCH: 6,train_loss: 0.017814233359219372, valid_loss: 0.018073157736045474\n",
      "SEED: 14, FOLD: 2, EPOCH: 7,train_loss: 0.017885045506114115, valid_loss: 0.017924950786811465\n",
      "SEED: 14, FOLD: 2, EPOCH: 8,train_loss: 0.017883391774165026, valid_loss: 0.017714175532626754\n",
      "SEED: 14, FOLD: 2, EPOCH: 9,train_loss: 0.017849970932887947, valid_loss: 0.01786630625343498\n",
      "SEED: 14, FOLD: 2, EPOCH: 10,train_loss: 0.017767849283805794, valid_loss: 0.017740666482816723\n",
      "SEED: 14, FOLD: 2, EPOCH: 11,train_loss: 0.017732994738912235, valid_loss: 0.017659339341608918\n",
      "SEED: 14, FOLD: 2, EPOCH: 12,train_loss: 0.017703327964451433, valid_loss: 0.01770911688971169\n",
      "SEED: 14, FOLD: 2, EPOCH: 13,train_loss: 0.017585240169495777, valid_loss: 0.01750100379371468\n",
      "SEED: 14, FOLD: 2, EPOCH: 14,train_loss: 0.017486843719160643, valid_loss: 0.017586398102781352\n",
      "SEED: 14, FOLD: 2, EPOCH: 15,train_loss: 0.017304436519634033, valid_loss: 0.01738728514379438\n",
      "SEED: 14, FOLD: 2, EPOCH: 16,train_loss: 0.01715910006179542, valid_loss: 0.017475634950267917\n",
      "SEED: 14, FOLD: 2, EPOCH: 17,train_loss: 0.016894315227704203, valid_loss: 0.017503516282886267\n",
      "SEED: 14, FOLD: 2, EPOCH: 18,train_loss: 0.01662725618487035, valid_loss: 0.017433778656756178\n",
      "SEED: 14, FOLD: 2, EPOCH: 19,train_loss: 0.016281836119520922, valid_loss: 0.017254215254284003\n",
      "SEED: 14, FOLD: 2, EPOCH: 20,train_loss: 0.015830983637251717, valid_loss: 0.01718468391610419\n",
      "SEED: 14, FOLD: 2, EPOCH: 21,train_loss: 0.015344241465293411, valid_loss: 0.017160390941973996\n",
      "SEED: 14, FOLD: 2, EPOCH: 22,train_loss: 0.014820557121403408, valid_loss: 0.017166482668150875\n",
      "SEED: 14, FOLD: 2, EPOCH: 23,train_loss: 0.01436965538026846, valid_loss: 0.01718112694866517\n",
      "SEED: 14, FOLD: 2, EPOCH: 24,train_loss: 0.01412334857319576, valid_loss: 0.017163495533168316\n",
      "(17507, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7364798758151757, valid_loss: 0.7013734034129552\n",
      "SEED: 14, FOLD: 3, EPOCH: 0,train_loss: 0.4676709476532075, valid_loss: 0.023329791692750793\n",
      "SEED: 14, FOLD: 3, EPOCH: 1,train_loss: 0.02122982193029275, valid_loss: 0.01870620096368449\n",
      "SEED: 14, FOLD: 3, EPOCH: 2,train_loss: 0.019079994641407562, valid_loss: 0.018170710732894283\n",
      "SEED: 14, FOLD: 3, EPOCH: 3,train_loss: 0.01816112593659302, valid_loss: 0.018083530850708483\n",
      "SEED: 14, FOLD: 3, EPOCH: 4,train_loss: 0.01787584979957255, valid_loss: 0.0180831856493439\n",
      "SEED: 14, FOLD: 3, EPOCH: 5,train_loss: 0.017878775117769294, valid_loss: 0.018071259877511434\n",
      "SEED: 14, FOLD: 3, EPOCH: 6,train_loss: 0.017826701827129744, valid_loss: 0.0181550141956125\n",
      "SEED: 14, FOLD: 3, EPOCH: 7,train_loss: 0.017873393215347817, valid_loss: 0.018014542146452834\n",
      "SEED: 14, FOLD: 3, EPOCH: 8,train_loss: 0.017854605250767548, valid_loss: 0.01802089884877205\n",
      "SEED: 14, FOLD: 3, EPOCH: 9,train_loss: 0.01787221747838015, valid_loss: 0.017898426497621196\n",
      "SEED: 14, FOLD: 3, EPOCH: 10,train_loss: 0.017736817812071228, valid_loss: 0.017997694920216287\n",
      "SEED: 14, FOLD: 3, EPOCH: 11,train_loss: 0.01768329055694333, valid_loss: 0.01800289052937712\n",
      "SEED: 14, FOLD: 3, EPOCH: 12,train_loss: 0.017643553673894734, valid_loss: 0.01799145732074976\n",
      "SEED: 14, FOLD: 3, EPOCH: 13,train_loss: 0.01756341652740745, valid_loss: 0.017712214349636008\n",
      "SEED: 14, FOLD: 3, EPOCH: 14,train_loss: 0.017403053378101684, valid_loss: 0.01781698116766555\n",
      "SEED: 14, FOLD: 3, EPOCH: 15,train_loss: 0.01732135325479899, valid_loss: 0.017588748410344125\n",
      "SEED: 14, FOLD: 3, EPOCH: 16,train_loss: 0.017097224481403828, valid_loss: 0.01760120200259345\n",
      "SEED: 14, FOLD: 3, EPOCH: 17,train_loss: 0.01685990467259701, valid_loss: 0.017605798478637424\n",
      "SEED: 14, FOLD: 3, EPOCH: 18,train_loss: 0.016604019628062735, valid_loss: 0.017494518203394753\n",
      "SEED: 14, FOLD: 3, EPOCH: 19,train_loss: 0.016215226748944635, valid_loss: 0.017511087097227575\n",
      "SEED: 14, FOLD: 3, EPOCH: 20,train_loss: 0.015749814981309167, valid_loss: 0.01740828968052353\n",
      "SEED: 14, FOLD: 3, EPOCH: 21,train_loss: 0.015286565656318281, valid_loss: 0.0174325093626976\n",
      "SEED: 14, FOLD: 3, EPOCH: 22,train_loss: 0.014781354450668296, valid_loss: 0.01740852567766394\n",
      "SEED: 14, FOLD: 3, EPOCH: 23,train_loss: 0.01435530108202548, valid_loss: 0.017398439294525555\n",
      "SEED: 14, FOLD: 3, EPOCH: 24,train_loss: 0.014105692811745361, valid_loss: 0.017399757674762182\n",
      "(17511, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7363336482187257, valid_loss: 0.7017004983765739\n",
      "SEED: 14, FOLD: 4, EPOCH: 0,train_loss: 0.4690565674626914, valid_loss: 0.023872869621430124\n",
      "SEED: 14, FOLD: 4, EPOCH: 1,train_loss: 0.020858754682606156, valid_loss: 0.01842881685921124\n",
      "SEED: 14, FOLD: 4, EPOCH: 2,train_loss: 0.019104856236355147, valid_loss: 0.018607790182743753\n",
      "SEED: 14, FOLD: 4, EPOCH: 3,train_loss: 0.01862025579070523, valid_loss: 0.017717513628304003\n",
      "SEED: 14, FOLD: 4, EPOCH: 4,train_loss: 0.018117661499520286, valid_loss: 0.01773095732288701\n",
      "SEED: 14, FOLD: 4, EPOCH: 5,train_loss: 0.018066148409606332, valid_loss: 0.017454745673707552\n",
      "SEED: 14, FOLD: 4, EPOCH: 6,train_loss: 0.017981800359476656, valid_loss: 0.017435404791363646\n",
      "SEED: 14, FOLD: 4, EPOCH: 7,train_loss: 0.018007605465768028, valid_loss: 0.01770222019404173\n",
      "SEED: 14, FOLD: 4, EPOCH: 8,train_loss: 0.017935540425135708, valid_loss: 0.017505529123757566\n",
      "SEED: 14, FOLD: 4, EPOCH: 9,train_loss: 0.017916508161727965, valid_loss: 0.0173975246027112\n",
      "SEED: 14, FOLD: 4, EPOCH: 10,train_loss: 0.017904814767794017, valid_loss: 0.017879267462662288\n",
      "SEED: 14, FOLD: 4, EPOCH: 11,train_loss: 0.017826764640418716, valid_loss: 0.01726670419531209\n",
      "SEED: 14, FOLD: 4, EPOCH: 12,train_loss: 0.01779001134101057, valid_loss: 0.01741610507347754\n",
      "SEED: 14, FOLD: 4, EPOCH: 13,train_loss: 0.017668983613541963, valid_loss: 0.017491372408611434\n",
      "SEED: 14, FOLD: 4, EPOCH: 14,train_loss: 0.01755955858142489, valid_loss: 0.01711343912673848\n",
      "SEED: 14, FOLD: 4, EPOCH: 15,train_loss: 0.017407342247719313, valid_loss: 0.01744910499879292\n",
      "SEED: 14, FOLD: 4, EPOCH: 16,train_loss: 0.01724549174906999, valid_loss: 0.017147954526756493\n",
      "SEED: 14, FOLD: 4, EPOCH: 17,train_loss: 0.016994401554230355, valid_loss: 0.017124761720853192\n",
      "SEED: 14, FOLD: 4, EPOCH: 18,train_loss: 0.016752105179059243, valid_loss: 0.01700639950909785\n",
      "SEED: 14, FOLD: 4, EPOCH: 19,train_loss: 0.01637237700531735, valid_loss: 0.016921084986201356\n",
      "SEED: 14, FOLD: 4, EPOCH: 20,train_loss: 0.015981319734323634, valid_loss: 0.017007379473320077\n",
      "SEED: 14, FOLD: 4, EPOCH: 21,train_loss: 0.015472200332059913, valid_loss: 0.016957188583910467\n",
      "SEED: 14, FOLD: 4, EPOCH: 22,train_loss: 0.014965807230476915, valid_loss: 0.016906659784061567\n",
      "SEED: 14, FOLD: 4, EPOCH: 23,train_loss: 0.01453588293851727, valid_loss: 0.01692806290728705\n",
      "SEED: 14, FOLD: 4, EPOCH: 24,train_loss: 0.01428239799383348, valid_loss: 0.016945188732019494\n",
      "(17536, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7376549235225593, valid_loss: 0.709812787600926\n",
      "SEED: 15, FOLD: 0, EPOCH: 0,train_loss: 0.46624566856635746, valid_loss: 0.023241463197129112\n",
      "SEED: 15, FOLD: 0, EPOCH: 1,train_loss: 0.020801155997888884, valid_loss: 0.019296579834605965\n",
      "SEED: 15, FOLD: 0, EPOCH: 2,train_loss: 0.01909979578977736, valid_loss: 0.01864668298512697\n",
      "SEED: 15, FOLD: 0, EPOCH: 3,train_loss: 0.018205851656350778, valid_loss: 0.018234010892254966\n",
      "SEED: 15, FOLD: 0, EPOCH: 4,train_loss: 0.017916952844464432, valid_loss: 0.0185510749529515\n",
      "SEED: 15, FOLD: 0, EPOCH: 5,train_loss: 0.01781340947469873, valid_loss: 0.018310150850032056\n",
      "SEED: 15, FOLD: 0, EPOCH: 6,train_loss: 0.017798401360964253, valid_loss: 0.01847530406500612\n",
      "SEED: 15, FOLD: 0, EPOCH: 7,train_loss: 0.017848462661741858, valid_loss: 0.018443834595382215\n",
      "SEED: 15, FOLD: 0, EPOCH: 8,train_loss: 0.017820376596909805, valid_loss: 0.0183705278805324\n",
      "SEED: 15, FOLD: 0, EPOCH: 9,train_loss: 0.017837853544819964, valid_loss: 0.0182679859655244\n",
      "SEED: 15, FOLD: 0, EPOCH: 10,train_loss: 0.017774864983656546, valid_loss: 0.018103438961718763\n",
      "SEED: 15, FOLD: 0, EPOCH: 11,train_loss: 0.017726688360265138, valid_loss: 0.018406019812183722\n",
      "SEED: 15, FOLD: 0, EPOCH: 12,train_loss: 0.017610474149730517, valid_loss: 0.017911380396357604\n",
      "SEED: 15, FOLD: 0, EPOCH: 13,train_loss: 0.017511521588439924, valid_loss: 0.017870386796338216\n",
      "SEED: 15, FOLD: 0, EPOCH: 14,train_loss: 0.01739579870154823, valid_loss: 0.018148187707577434\n",
      "SEED: 15, FOLD: 0, EPOCH: 15,train_loss: 0.017232384546286, valid_loss: 0.018001042678952216\n",
      "SEED: 15, FOLD: 0, EPOCH: 16,train_loss: 0.017070192653332313, valid_loss: 0.017743448221257754\n",
      "SEED: 15, FOLD: 0, EPOCH: 17,train_loss: 0.016863867117051224, valid_loss: 0.017569086620850223\n",
      "SEED: 15, FOLD: 0, EPOCH: 18,train_loss: 0.016596369200596844, valid_loss: 0.017740210784333094\n",
      "SEED: 15, FOLD: 0, EPOCH: 19,train_loss: 0.016213042342042835, valid_loss: 0.017657427516366755\n",
      "SEED: 15, FOLD: 0, EPOCH: 20,train_loss: 0.01577042850128708, valid_loss: 0.017695734091103078\n",
      "SEED: 15, FOLD: 0, EPOCH: 21,train_loss: 0.015336111364682225, valid_loss: 0.017621818610600064\n",
      "SEED: 15, FOLD: 0, EPOCH: 22,train_loss: 0.014856289385607208, valid_loss: 0.017632064702255385\n",
      "SEED: 15, FOLD: 0, EPOCH: 23,train_loss: 0.014415698520240992, valid_loss: 0.017657360487750597\n",
      "SEED: 15, FOLD: 0, EPOCH: 24,train_loss: 0.014193690538297605, valid_loss: 0.017667615466884206\n",
      "(17541, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7376892726490463, valid_loss: 0.7098238979067121\n",
      "SEED: 15, FOLD: 1, EPOCH: 0,train_loss: 0.46673729420518095, valid_loss: 0.023825046260442052\n",
      "SEED: 15, FOLD: 1, EPOCH: 1,train_loss: 0.020901915077390015, valid_loss: 0.019112011763666358\n",
      "SEED: 15, FOLD: 1, EPOCH: 2,train_loss: 0.019312035130417866, valid_loss: 0.02066106641931193\n",
      "SEED: 15, FOLD: 1, EPOCH: 3,train_loss: 0.018566053826361895, valid_loss: 0.018128314135330063\n",
      "SEED: 15, FOLD: 1, EPOCH: 4,train_loss: 0.018136319461400093, valid_loss: 0.018331519886851312\n",
      "SEED: 15, FOLD: 1, EPOCH: 5,train_loss: 0.01819855432309534, valid_loss: 0.01867175844631025\n",
      "SEED: 15, FOLD: 1, EPOCH: 6,train_loss: 0.018315476000956867, valid_loss: 0.018007727206817696\n",
      "SEED: 15, FOLD: 1, EPOCH: 7,train_loss: 0.01802306900313799, valid_loss: 0.0186343750251191\n",
      "SEED: 15, FOLD: 1, EPOCH: 8,train_loss: 0.01811237343033587, valid_loss: 0.018414652267737048\n",
      "SEED: 15, FOLD: 1, EPOCH: 9,train_loss: 0.018013551628783993, valid_loss: 0.017959759703704288\n",
      "SEED: 15, FOLD: 1, EPOCH: 10,train_loss: 0.018041091599920088, valid_loss: 0.018164569272526673\n",
      "SEED: 15, FOLD: 1, EPOCH: 11,train_loss: 0.018095889385195747, valid_loss: 0.018343430518039636\n",
      "SEED: 15, FOLD: 1, EPOCH: 12,train_loss: 0.017893337145231773, valid_loss: 0.018166678345629145\n",
      "SEED: 15, FOLD: 1, EPOCH: 13,train_loss: 0.017754340247399567, valid_loss: 0.017989267302410943\n",
      "SEED: 15, FOLD: 1, EPOCH: 14,train_loss: 0.017730623449914266, valid_loss: 0.017712224780448847\n",
      "SEED: 15, FOLD: 1, EPOCH: 15,train_loss: 0.017594278196169846, valid_loss: 0.01760301903954574\n",
      "SEED: 15, FOLD: 1, EPOCH: 16,train_loss: 0.017327009437038847, valid_loss: 0.017470468021929263\n",
      "SEED: 15, FOLD: 1, EPOCH: 17,train_loss: 0.01713264926566162, valid_loss: 0.01766403620796544\n",
      "SEED: 15, FOLD: 1, EPOCH: 18,train_loss: 0.016836345762662266, valid_loss: 0.017314951946692806\n",
      "SEED: 15, FOLD: 1, EPOCH: 19,train_loss: 0.01653085161756346, valid_loss: 0.017269272437053066\n",
      "SEED: 15, FOLD: 1, EPOCH: 20,train_loss: 0.016234809897192146, valid_loss: 0.017087342989231858\n",
      "SEED: 15, FOLD: 1, EPOCH: 21,train_loss: 0.01584201592250147, valid_loss: 0.01710760412471635\n",
      "SEED: 15, FOLD: 1, EPOCH: 22,train_loss: 0.015387080940485432, valid_loss: 0.017085112657930168\n",
      "SEED: 15, FOLD: 1, EPOCH: 23,train_loss: 0.015118160973424498, valid_loss: 0.017111271806061267\n",
      "SEED: 15, FOLD: 1, EPOCH: 24,train_loss: 0.014942715268420137, valid_loss: 0.017099269346467088\n",
      "(17620, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7373423412226249, valid_loss: 0.7105596188236686\n",
      "SEED: 15, FOLD: 2, EPOCH: 0,train_loss: 0.46576006020810723, valid_loss: 0.023286946008310598\n",
      "SEED: 15, FOLD: 2, EPOCH: 1,train_loss: 0.020979112284123035, valid_loss: 0.01843488865586765\n",
      "SEED: 15, FOLD: 2, EPOCH: 2,train_loss: 0.019261165454551792, valid_loss: 0.01797318149029332\n",
      "SEED: 15, FOLD: 2, EPOCH: 3,train_loss: 0.01827575173228979, valid_loss: 0.017575785846394652\n",
      "SEED: 15, FOLD: 2, EPOCH: 4,train_loss: 0.017914160593426313, valid_loss: 0.017557847067056334\n",
      "SEED: 15, FOLD: 2, EPOCH: 5,train_loss: 0.017853471443758928, valid_loss: 0.01796295737628551\n",
      "SEED: 15, FOLD: 2, EPOCH: 6,train_loss: 0.017894184932220673, valid_loss: 0.0178441501715604\n",
      "SEED: 15, FOLD: 2, EPOCH: 7,train_loss: 0.017912944920523012, valid_loss: 0.0177481777363402\n",
      "SEED: 15, FOLD: 2, EPOCH: 8,train_loss: 0.017935838887764923, valid_loss: 0.01744059963590082\n",
      "SEED: 15, FOLD: 2, EPOCH: 9,train_loss: 0.017856082379602005, valid_loss: 0.017829012290081558\n",
      "SEED: 15, FOLD: 2, EPOCH: 10,train_loss: 0.01792179392920672, valid_loss: 0.01747706118861542\n",
      "SEED: 15, FOLD: 2, EPOCH: 11,train_loss: 0.01778149995547922, valid_loss: 0.017596627530806205\n",
      "SEED: 15, FOLD: 2, EPOCH: 12,train_loss: 0.017773599451596754, valid_loss: 0.017608819447238657\n",
      "SEED: 15, FOLD: 2, EPOCH: 13,train_loss: 0.017627954793473084, valid_loss: 0.01749254694646772\n",
      "SEED: 15, FOLD: 2, EPOCH: 14,train_loss: 0.017492888832761757, valid_loss: 0.017502872163758558\n",
      "SEED: 15, FOLD: 2, EPOCH: 15,train_loss: 0.01740032747603845, valid_loss: 0.017342778525370008\n",
      "SEED: 15, FOLD: 2, EPOCH: 16,train_loss: 0.01719789451285117, valid_loss: 0.017348477534730646\n",
      "SEED: 15, FOLD: 2, EPOCH: 17,train_loss: 0.01694603763061805, valid_loss: 0.017390842193408924\n",
      "SEED: 15, FOLD: 2, EPOCH: 18,train_loss: 0.016658979036129902, valid_loss: 0.017164911335224613\n",
      "SEED: 15, FOLD: 2, EPOCH: 19,train_loss: 0.016321283798880766, valid_loss: 0.01722884547951467\n",
      "SEED: 15, FOLD: 2, EPOCH: 20,train_loss: 0.015890258850286835, valid_loss: 0.017068659010178903\n",
      "SEED: 15, FOLD: 2, EPOCH: 21,train_loss: 0.015419743610950916, valid_loss: 0.017140055732691988\n",
      "SEED: 15, FOLD: 2, EPOCH: 22,train_loss: 0.014897370110333397, valid_loss: 0.0170487916261396\n",
      "SEED: 15, FOLD: 2, EPOCH: 23,train_loss: 0.014463844196196052, valid_loss: 0.017069479834069225\n",
      "SEED: 15, FOLD: 2, EPOCH: 24,train_loss: 0.01419994550878587, valid_loss: 0.017041405471151367\n",
      "(17538, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7374413441056791, valid_loss: 0.7138678669929505\n",
      "SEED: 15, FOLD: 3, EPOCH: 0,train_loss: 0.46631716158025077, valid_loss: 0.025676655769348144\n",
      "SEED: 15, FOLD: 3, EPOCH: 1,train_loss: 0.02120939420833104, valid_loss: 0.01973083285348756\n",
      "SEED: 15, FOLD: 3, EPOCH: 2,train_loss: 0.019471315275607765, valid_loss: 0.02374982801931245\n",
      "SEED: 15, FOLD: 3, EPOCH: 3,train_loss: 0.019577595634736877, valid_loss: 0.019098907709121704\n",
      "SEED: 15, FOLD: 3, EPOCH: 4,train_loss: 0.01868732494936473, valid_loss: 0.01822459234723023\n",
      "SEED: 15, FOLD: 3, EPOCH: 5,train_loss: 0.018378496075561947, valid_loss: 0.018530422236238207\n",
      "SEED: 15, FOLD: 3, EPOCH: 6,train_loss: 0.018152974917134947, valid_loss: 0.018099034737263407\n",
      "SEED: 15, FOLD: 3, EPOCH: 7,train_loss: 0.018077800907464563, valid_loss: 0.01893417297729424\n",
      "SEED: 15, FOLD: 3, EPOCH: 8,train_loss: 0.018092474407529917, valid_loss: 0.017995366720216614\n",
      "SEED: 15, FOLD: 3, EPOCH: 9,train_loss: 0.01777518709001226, valid_loss: 0.017947665016566004\n",
      "SEED: 15, FOLD: 3, EPOCH: 10,train_loss: 0.01784677428962744, valid_loss: 0.018126871596489635\n",
      "SEED: 15, FOLD: 3, EPOCH: 11,train_loss: 0.017754418775439262, valid_loss: 0.018589643016457557\n",
      "SEED: 15, FOLD: 3, EPOCH: 12,train_loss: 0.01772407543562029, valid_loss: 0.01795307206256049\n",
      "SEED: 15, FOLD: 3, EPOCH: 13,train_loss: 0.017592179551855592, valid_loss: 0.017954922627125468\n",
      "SEED: 15, FOLD: 3, EPOCH: 14,train_loss: 0.017458344499270122, valid_loss: 0.018052093418581144\n",
      "SEED: 15, FOLD: 3, EPOCH: 15,train_loss: 0.017540249447135822, valid_loss: 0.01787129363843373\n",
      "SEED: 15, FOLD: 3, EPOCH: 16,train_loss: 0.017398611021538574, valid_loss: 0.017571179941296578\n",
      "SEED: 15, FOLD: 3, EPOCH: 17,train_loss: 0.017051027851530176, valid_loss: 0.017387708090245722\n",
      "SEED: 15, FOLD: 3, EPOCH: 18,train_loss: 0.016658727174111897, valid_loss: 0.017391295757676874\n",
      "SEED: 15, FOLD: 3, EPOCH: 19,train_loss: 0.016258117142200903, valid_loss: 0.017373136643852507\n",
      "SEED: 15, FOLD: 3, EPOCH: 20,train_loss: 0.01593337743880524, valid_loss: 0.017200252546795778\n",
      "SEED: 15, FOLD: 3, EPOCH: 21,train_loss: 0.015426528032707132, valid_loss: 0.017268266794937\n",
      "SEED: 15, FOLD: 3, EPOCH: 22,train_loss: 0.01488382144547675, valid_loss: 0.017240001527326448\n",
      "SEED: 15, FOLD: 3, EPOCH: 23,train_loss: 0.014689626712082089, valid_loss: 0.017273251632494584\n",
      "SEED: 15, FOLD: 3, EPOCH: 24,train_loss: 0.014367722690213417, valid_loss: 0.017276990493493422\n",
      "(17557, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7374171718307163, valid_loss: 0.7118211524827139\n",
      "SEED: 15, FOLD: 4, EPOCH: 0,train_loss: 0.4667678267789492, valid_loss: 0.02310302582170282\n",
      "SEED: 15, FOLD: 4, EPOCH: 1,train_loss: 0.020865873946551827, valid_loss: 0.018828685714730193\n",
      "SEED: 15, FOLD: 4, EPOCH: 2,train_loss: 0.01894966534514358, valid_loss: 0.017823924416942256\n",
      "SEED: 15, FOLD: 4, EPOCH: 3,train_loss: 0.01831596865710141, valid_loss: 0.01787754464894533\n",
      "SEED: 15, FOLD: 4, EPOCH: 4,train_loss: 0.018049746853015993, valid_loss: 0.017816809378564356\n",
      "SEED: 15, FOLD: 4, EPOCH: 5,train_loss: 0.01793048713032318, valid_loss: 0.01779872107186488\n",
      "SEED: 15, FOLD: 4, EPOCH: 6,train_loss: 0.01803675786578569, valid_loss: 0.018305551393755844\n",
      "SEED: 15, FOLD: 4, EPOCH: 7,train_loss: 0.01798393835813023, valid_loss: 0.017886979984385626\n",
      "SEED: 15, FOLD: 4, EPOCH: 8,train_loss: 0.01791299710833076, valid_loss: 0.018154884316027166\n",
      "SEED: 15, FOLD: 4, EPOCH: 9,train_loss: 0.017952032933902483, valid_loss: 0.017844689610813345\n",
      "SEED: 15, FOLD: 4, EPOCH: 10,train_loss: 0.017882862378019785, valid_loss: 0.0178513551396983\n",
      "SEED: 15, FOLD: 4, EPOCH: 11,train_loss: 0.017803381433359522, valid_loss: 0.0178023686632514\n",
      "SEED: 15, FOLD: 4, EPOCH: 12,train_loss: 0.017753588258410277, valid_loss: 0.017608613813562053\n",
      "SEED: 15, FOLD: 4, EPOCH: 13,train_loss: 0.01771328878332523, valid_loss: 0.017654881892459732\n",
      "SEED: 15, FOLD: 4, EPOCH: 14,train_loss: 0.01752010327966317, valid_loss: 0.01742258577474526\n",
      "SEED: 15, FOLD: 4, EPOCH: 15,train_loss: 0.0173595506441442, valid_loss: 0.017618265748023988\n",
      "SEED: 15, FOLD: 4, EPOCH: 16,train_loss: 0.017259516382077032, valid_loss: 0.01733165918184178\n",
      "SEED: 15, FOLD: 4, EPOCH: 17,train_loss: 0.01704897427175572, valid_loss: 0.017237784207931588\n",
      "SEED: 15, FOLD: 4, EPOCH: 18,train_loss: 0.016650082131820745, valid_loss: 0.017209427883582457\n",
      "SEED: 15, FOLD: 4, EPOCH: 19,train_loss: 0.016308164278018303, valid_loss: 0.017227253637143544\n",
      "SEED: 15, FOLD: 4, EPOCH: 20,train_loss: 0.01599400775993, valid_loss: 0.01722417910184179\n",
      "SEED: 15, FOLD: 4, EPOCH: 21,train_loss: 0.015475602381849203, valid_loss: 0.017093767412006855\n",
      "SEED: 15, FOLD: 4, EPOCH: 22,train_loss: 0.015023850822362347, valid_loss: 0.017068336504910672\n",
      "SEED: 15, FOLD: 4, EPOCH: 23,train_loss: 0.01460673896919774, valid_loss: 0.017085408712072033\n",
      "SEED: 15, FOLD: 4, EPOCH: 24,train_loss: 0.01438290705445452, valid_loss: 0.0170723773006882\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "for seed in SEED:\n",
    "    seed_everything(seed=seed)\n",
    "    folds = train0.copy()\n",
    "    feature_cols = dp(feature_cols0)\n",
    "    \n",
    "    # kfold - leave drug out\n",
    "    target2 = target.copy()\n",
    "    dct1 = {}; dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n",
    "    tmp = target2.groupby('drug_id')[target_cols].mean().loc[vc1]\n",
    "    tmp_idx = tmp.index.tolist()\n",
    "    tmp_idx.sort()\n",
    "    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n",
    "    tmp = tmp.loc[tmp_idx2]\n",
    "    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values}\n",
    "        dct1.update(dd)\n",
    "\n",
    "    # STRATIFY DRUGS MORE THAN 19X\n",
    "    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n",
    "    tmp = target2.loc[target2.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "    tmp_idx = tmp.index.tolist()\n",
    "    tmp_idx.sort()\n",
    "    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n",
    "    tmp = tmp.loc[tmp_idx2]\n",
    "    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "        dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "        dct2.update(dd)\n",
    "\n",
    "    target2['kfold'] = target2.drug_id.map(dct1)\n",
    "    target2.loc[target2.kfold.isna(),'kfold'] = target2.loc[target2.kfold.isna(),'sig_id'].map(dct2)\n",
    "    target2.kfold = target2.kfold.astype(int)\n",
    "\n",
    "    folds['kfold'] = target2['kfold'].copy()\n",
    "\n",
    "    train = folds.copy()\n",
    "    test_ = test.copy()\n",
    "\n",
    " \n",
    "    \n",
    "    tar_freq = np.array([np.min(list(g_table(train[target_cols].iloc[:,i]).values())) for i in range(len(target_cols))])\n",
    "    tar_weight0 = np.array([np.log(i+100) for i in tar_freq])\n",
    "    tar_weight0_min = dp(np.min(tar_weight0))\n",
    "    tar_weight = tar_weight0_min/tar_weight0\n",
    "    pos_weight = torch.tensor(tar_weight).to(DEVICE)\n",
    "\n",
    "\n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed, train, test_, pos_weight)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    oof_tmp = dp(oof)\n",
    "    oof_tmp = oof_tmp * len(SEED) / (SEED.index(seed)+1)\n",
    "    sc_dic[seed] = np.mean([log_loss(train[target_cols].iloc[:,i],oof_tmp[:,i]) for i in range(len(target_cols))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.017223512168052894, 1: 0.01697182150896404, 2: 0.016896567752147998, 3: 0.01684248535754461, 4: 0.016799085029176982, 5: 0.01677708318126701, 6: 0.016759477996880438, 7: 0.016755402930102734, 8: 0.01674692335089487, 9: 0.016741782538587168, 10: 0.016730602098595813, 11: 0.016726474930070373, 12: 0.01672244407588409, 13: 0.01672248669966805, 14: 0.0167219164503182, 15: 0.016717577179875657}\n"
     ]
    }
   ],
   "source": [
    "print(sc_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016717577179875657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print(np.mean([log_loss(train[target_cols].iloc[:,i],oof[:,i]) for i in range(len(target_cols))]))\n",
    "\n",
    "train0[target_cols] = oof\n",
    "test[target_cols] = predictions\n",
    "\n",
    "### for blend test ###\n",
    "train0.to_csv('train_pred.csv', index=False)\n",
    "### for blend test ###\n",
    "\n",
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newly added stuff here to test out the idea\n",
    "1. load the model\n",
    "2. take only the first layer of the input (after reshape)\n",
    "3. (since it a pseudo image) lets apply data augmentation, use all training data for this (there will be k-fold later but maybe we don't need to care rn)\n",
    "(branch choices)\n",
    "a. fine tune the FCN part by freezing the first MLP layer to reshape\n",
    "b. have a new model CNN model or something (check other kaggle)\n",
    "c. reconstruct it using encoder and feed it to tabNet or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df and valid_df is dataframe ready to be trained after kfold is done \n",
    "# or it could also be the whole train dataset for data augmentation\n",
    "def preprocessData(x_train, x_valid=None, x_test=None):\n",
    "    assert x_train is not None, \"x_train must not be None\"\n",
    "    #------------ norm --------------\n",
    "    col_num = list(set(feat_dic['gene'] + feat_dic['cell']) & set(feature_cols))\n",
    "    col_num.sort()\n",
    "    x_train[col_num],ss = norm_fit(x_train[col_num],True,'quan')\n",
    "    \n",
    "    if x_valid is not None:\n",
    "        x_valid[col_num]    = norm_tra(x_valid[col_num],ss)\n",
    "        \n",
    "    if x_test is not None:\n",
    "        x_test[col_num]     = norm_tra(x_test[col_num],ss)\n",
    "\n",
    "    #------------ pca --------------\n",
    "    def pca_pre(tr,va,te,\n",
    "                n_comp,feat_raw,feat_new):\n",
    "        tr2 = None \n",
    "        va2 = None\n",
    "        te2 = None\n",
    "        pca = PCA(n_components=n_comp, random_state=42)\n",
    "        tr2 = pd.DataFrame(pca.fit_transform(tr[feat_raw]),columns=feat_new)\n",
    "        if va is not None:\n",
    "            va2 = pd.DataFrame(pca.transform(va[feat_raw]),columns=feat_new)\n",
    "\n",
    "        if te is not None:\n",
    "            te2 = pd.DataFrame(pca.transform(te[feat_raw]),columns=feat_new)\n",
    "\n",
    "        return(tr2,va2,te2)\n",
    "\n",
    "\n",
    "    pca_feat_g = [f'pca_G-{i}' for i in range(n_comp1)]\n",
    "    feat_dic['pca_g'] = pca_feat_g\n",
    "    x_tr_g_pca, x_va_g_pca, x_te_g_pca = pca_pre(x_train,x_valid,x_test,\n",
    "                                                n_comp1,feat_dic['gene'],pca_feat_g)\n",
    "    \n",
    "    x_train = pd.concat([x_train,x_tr_g_pca],axis = 1)\n",
    "    if x_valid is not None:\n",
    "        x_valid = pd.concat([x_valid,x_va_g_pca],axis = 1)\n",
    "\n",
    "    if x_test is not None:\n",
    "        x_test  = pd.concat([x_test,x_te_g_pca],axis = 1)\n",
    "\n",
    "    pca_feat_g = [f'pca_C-{i}' for i in range(n_comp2)]\n",
    "    feat_dic['pca_c'] = pca_feat_g\n",
    "    x_tr_c_pca,x_va_c_pca,x_te_c_pca = pca_pre(x_train,x_valid,x_test,\n",
    "                                                n_comp2,feat_dic['cell'],pca_feat_g)\n",
    "    \n",
    "    x_train_pre = None\n",
    "    x_valid_pre = None\n",
    "    x_test_pre = None\n",
    "\n",
    "    x_train = pd.concat([x_train,x_tr_c_pca],axis = 1)\n",
    "    x_train_pre = x_train.values\n",
    "\n",
    "    if x_valid is not None:\n",
    "        x_valid = pd.concat([x_valid,x_va_c_pca],axis = 1)\n",
    "        x_valid_pre = x_valid.values\n",
    "\n",
    "    if x_test is not None:\n",
    "        x_test  = pd.concat([x_test,x_te_c_pca], axis = 1)\n",
    "        x_test_pre = x_test.values\n",
    "\n",
    "    print(x_train_pre.shape)\n",
    "\n",
    "    # return preprocessed data \n",
    "    return x_train_pre, x_valid_pre, x_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 937)\n",
      "[[ 1.11131675  0.89035944 -0.43197694 ... -0.58240415 -1.26113787\n",
      "   0.09958907]\n",
      " [ 0.11782169  0.66961362  0.26188399 ... -0.15785287  0.58990842\n",
      "  -0.26198874]\n",
      " [ 0.78636997  0.95889742  1.43716156 ... -0.1033361   1.67417345\n",
      "  -0.99816694]\n",
      " ...\n",
      " [-1.94902713  0.56332567 -0.59266583 ...  1.56667931 -1.85958986\n",
      "   0.78132428]\n",
      " [ 0.73121725  0.26566306  0.32119296 ...  1.95293467  0.33389567\n",
      "  -0.1134507 ]\n",
      " [-1.25377336  1.56726322 -0.27624082 ...  0.56235807  2.95709886\n",
      "   0.28014344]]\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x708b3a09ac40>\n",
      "{'x': tensor([[-0.8790, -0.9882,  0.8078,  ...,  0.0516,  0.0974,  0.5211],\n",
      "        [ 1.4524, -1.2699,  0.3945,  ..., -0.4674, -1.3133, -0.4027],\n",
      "        [ 0.4768,  0.6497,  0.2056,  ...,  1.0533,  1.3238,  0.5788],\n",
      "        ...,\n",
      "        [ 0.6413,  0.9010,  2.1881,  ...,  0.0418, -0.4787, -1.1542],\n",
      "        [ 0.6761,  0.6910,  0.3702,  ...,  0.0354,  1.2080,  0.0709],\n",
      "        [ 0.1723,  0.5115, -1.7239,  ...,  0.6559, -0.6793, -1.1802]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1543, -0.4638,  0.2821,  ..., -1.2372,  0.0849, -0.3923],\n",
      "        [ 0.1436, -0.4296, -0.6178,  ...,  1.3862, -0.1640, -1.7062],\n",
      "        [-1.9401, -1.1232, -0.1653,  ...,  2.2467, -1.2495, -0.1516],\n",
      "        ...,\n",
      "        [ 0.2699, -0.4725, -0.8263,  ...,  0.8727, -0.8128, -0.0467],\n",
      "        [ 0.5963, -0.0081,  1.0795,  ...,  1.6216, -1.7951,  0.2039],\n",
      "        [-0.8404, -1.3250,  0.3099,  ..., -0.0905, -1.5270,  0.5591]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.7779,  0.4807,  1.0232,  ..., -0.9718,  1.1296,  0.1994],\n",
      "        [ 1.9621,  0.5791,  1.8034,  ...,  1.3307, -0.3258,  0.6570],\n",
      "        [-0.3165, -0.6645, -0.3572,  ...,  0.4618, -0.7155,  1.2120],\n",
      "        ...,\n",
      "        [-1.8028, -2.3884,  1.1571,  ..., -0.3533,  0.4506,  0.5682],\n",
      "        [-2.3609, -1.0382, -1.1126,  ...,  1.3237,  0.0182, -1.4213],\n",
      "        [ 0.0936,  0.0545,  2.3898,  ..., -1.1617, -1.4961, -0.5086]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2915,  0.5530, -0.1923,  ...,  0.7065, -0.5803,  0.6365],\n",
      "        [-0.7637,  0.2773,  1.7489,  ...,  0.2119, -1.3537,  0.3092],\n",
      "        [-1.4704, -1.5693, -0.5109,  ...,  0.9623, -0.1099, -1.7430],\n",
      "        ...,\n",
      "        [ 0.9129,  1.3380,  0.1631,  ..., -0.7789,  0.2079,  0.2446],\n",
      "        [-1.0025, -0.7695,  1.1997,  ..., -0.4809,  0.0647,  0.2078],\n",
      "        [ 0.9850, -0.7733,  0.6057,  ...,  0.1802, -0.9694,  1.9730]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9129,  1.0546, -0.5258,  ..., -1.0611,  0.6136, -0.7133],\n",
      "        [ 0.2808,  0.8871, -1.7155,  ...,  0.7034,  1.2758, -1.5739],\n",
      "        [-0.6586, -1.1857, -0.3850,  ...,  0.0250, -0.8708,  0.8652],\n",
      "        ...,\n",
      "        [-2.3372, -2.3531,  2.5423,  ..., -1.4956, -0.8129, -0.0611],\n",
      "        [ 1.0548,  0.0416, -0.9045,  ..., -0.2341,  0.5086, -0.5847],\n",
      "        [-0.1007, -0.2482, -0.0552,  ..., -0.4190,  1.2438,  0.9583]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 3.6054e-01,  4.0944e-01,  9.4888e-01,  ..., -5.0309e-01,\n",
      "          1.0586e+00, -9.2606e-01],\n",
      "        [-9.8256e-02, -6.1390e-01,  1.0316e+00,  ..., -3.7919e-01,\n",
      "          6.6443e-01, -7.7363e-01],\n",
      "        [-8.6372e-04, -1.4285e+00,  1.5189e+00,  ...,  1.9648e-01,\n",
      "         -1.0727e+00,  2.9729e-01],\n",
      "        ...,\n",
      "        [-2.7238e-01,  1.4240e+00,  2.3782e+00,  ..., -5.1827e-01,\n",
      "         -1.3515e+00,  5.4377e-01],\n",
      "        [-1.6456e+00, -1.8589e+00, -4.7262e-01,  ...,  1.5310e-01,\n",
      "         -1.1096e-01, -2.8972e-01],\n",
      "        [ 4.3781e-01, -3.1356e-01,  7.3976e-01,  ..., -8.4122e-02,\n",
      "          2.6659e+00,  1.0761e+00]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2976, -0.2154, -1.2399,  ...,  0.7720,  1.0294, -0.1834],\n",
      "        [-0.4212,  0.6583, -0.5857,  ...,  1.1663,  1.4178, -1.0672],\n",
      "        [-0.9582, -0.2099, -0.2027,  ..., -0.5102, -0.3951,  0.0936],\n",
      "        ...,\n",
      "        [ 0.6407,  0.8152,  0.6622,  ...,  2.4254, -1.8663, -0.0891],\n",
      "        [-1.4401, -0.8971, -0.3692,  ...,  0.8453,  0.5180,  0.9341],\n",
      "        [-0.5178,  1.0591, -0.0567,  ..., -0.1091,  0.0394,  1.3104]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.9497, -0.4200, -1.1585,  ...,  0.7514, -0.2318,  0.8976],\n",
      "        [-0.1556,  0.7033, -1.3463,  ...,  2.4895,  1.5167,  0.8255],\n",
      "        [ 2.3786,  1.3371,  0.6653,  ...,  1.3042,  0.7390, -0.6108],\n",
      "        ...,\n",
      "        [ 0.3457,  1.0650, -0.5668,  ..., -0.3229,  0.1343, -0.2736],\n",
      "        [ 0.9107, -0.9160,  1.1237,  ...,  1.5748,  0.2658, -0.5163],\n",
      "        [-0.8363,  1.4036, -1.6259,  ..., -1.4164,  0.8764,  0.3653]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 2.3193,  2.4289,  1.5160,  ...,  1.6391, -1.0841, -0.1585],\n",
      "        [ 0.9950, -0.1247, -0.8940,  ...,  0.8507, -0.6445,  0.2828],\n",
      "        [-0.0256,  0.5022,  0.5562,  ..., -0.6793,  0.2837, -1.5666],\n",
      "        ...,\n",
      "        [ 1.1009, -0.0261,  1.8124,  ...,  0.7573, -0.6125,  0.6293],\n",
      "        [-0.8668, -0.1885, -0.3148,  ...,  0.4563, -0.4065, -0.0949],\n",
      "        [ 0.4093, -0.2215, -0.6601,  ..., -0.6983, -1.5201, -0.8954]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2798, -0.2411, -0.6940,  ...,  0.1914, -0.3378,  1.0594],\n",
      "        [ 1.2258,  0.1597, -0.6770,  ...,  0.6374, -1.0104, -2.5505],\n",
      "        [-0.9049,  1.6622, -0.4056,  ...,  0.3189,  3.7379,  0.3574],\n",
      "        ...,\n",
      "        [ 1.2110,  1.7202,  0.5426,  ..., -0.1708,  1.2152, -1.5203],\n",
      "        [ 0.8884,  0.7833,  0.0484,  ..., -0.6359, -1.1545,  1.6104],\n",
      "        [ 0.4083, -0.2495,  0.2613,  ...,  0.3587,  0.3229,  1.3107]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1345,  0.9651, -0.7222,  ..., -0.5845,  0.7525, -1.2824],\n",
      "        [ 0.3064,  1.3302,  0.2390,  ..., -0.3170, -0.1559,  1.3782],\n",
      "        [-1.5996, -0.9766, -0.5975,  ...,  0.0677, -0.2281,  2.2007],\n",
      "        ...,\n",
      "        [-0.4623, -0.2663, -0.5434,  ..., -0.3755,  1.8462,  1.2476],\n",
      "        [ 0.2721, -0.1096,  1.6597,  ..., -0.5422, -0.1603, -0.9858],\n",
      "        [ 0.6944,  0.3220,  1.1041,  ..., -2.5683,  0.1554, -1.6363]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5152, -0.2354,  2.0394,  ..., -0.1542, -0.0552, -0.0643],\n",
      "        [-1.9768, -1.6136,  0.6769,  ..., -0.2939, -0.2898, -1.3130],\n",
      "        [ 1.0206, -0.4440,  0.3596,  ..., -0.5880,  0.6730,  2.8406],\n",
      "        ...,\n",
      "        [-0.4155, -0.9415, -0.0328,  ...,  0.8647, -2.3178,  1.0344],\n",
      "        [ 0.0888, -1.0793, -1.1811,  ...,  0.0899, -0.0393,  0.1915],\n",
      "        [ 0.0489, -2.3398, -0.4766,  ..., -1.2722,  1.3396, -0.8714]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6457,  0.5113,  1.2992,  ...,  2.8429, -0.1258, -1.0352],\n",
      "        [ 0.8519, -0.7474,  0.2419,  ...,  0.4500, -0.5875, -0.2208],\n",
      "        [ 0.9178, -0.1038,  0.6391,  ...,  0.4376,  0.1110, -1.0899],\n",
      "        ...,\n",
      "        [-0.8818, -0.3795, -0.5362,  ...,  0.2657, -1.3687,  0.6911],\n",
      "        [-0.6116, -1.0310,  0.2222,  ...,  2.1734, -1.2911,  1.3190],\n",
      "        [ 0.0373,  0.0843, -0.9231,  ...,  0.7394, -0.5331,  0.3366]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3529,  0.6257,  0.1047,  ..., -0.2825, -0.7138, -0.5484],\n",
      "        [ 0.4842, -1.3318, -0.8336,  ..., -0.6931,  0.3103,  0.8444],\n",
      "        [ 2.2242, -1.0324,  0.3926,  ...,  0.5260,  3.2806, -0.5925],\n",
      "        ...,\n",
      "        [-1.4705, -0.9795, -0.9378,  ..., -0.3687, -1.0961,  0.6742],\n",
      "        [ 0.1160,  0.8400, -0.7336,  ...,  1.4856,  0.1440,  0.0358],\n",
      "        [ 0.3954,  0.4341, -0.0296,  ..., -1.2327, -0.5737,  1.3298]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.6463, -1.1838, -0.8837,  ...,  1.4759,  1.3010,  0.1974],\n",
      "        [-0.5120,  0.2917, -0.4182,  ...,  0.7771,  0.3434, -0.6249],\n",
      "        [ 0.4846, -0.1764, -0.5980,  ...,  0.5577,  0.2587, -1.3173],\n",
      "        ...,\n",
      "        [-1.4630,  0.0340, -0.3591,  ...,  0.1472, -0.1493,  0.5810],\n",
      "        [ 0.6933, -0.8520,  0.3442,  ...,  0.6041, -1.1822, -1.4052],\n",
      "        [-0.2023,  1.0047,  0.1329,  ...,  0.3547,  0.2545, -0.5919]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7814,  0.5258, -0.5428,  ..., -1.9608,  0.2321, -0.7316],\n",
      "        [ 0.4845,  1.4121, -0.3931,  ...,  2.0401,  0.8256, -2.0822],\n",
      "        [ 0.4080,  0.5745,  0.9526,  ..., -0.1150, -0.8811, -0.8265],\n",
      "        ...,\n",
      "        [-0.0356, -0.4045, -1.0663,  ..., -0.3282,  2.0090, -2.1327],\n",
      "        [-1.4580, -1.9008,  0.6067,  ..., -0.5860,  1.0033, -1.5914],\n",
      "        [ 0.8494,  0.4289,  0.3456,  ..., -0.1831, -0.3729, -0.0663]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1255,  0.2489,  1.6756,  ...,  1.1698, -0.9311, -0.0360],\n",
      "        [-0.1324, -0.6381,  0.0827,  ..., -0.5643,  0.8376, -0.6849],\n",
      "        [-0.5053, -0.7810, -0.0810,  ..., -0.0161,  0.2890, -0.4334],\n",
      "        ...,\n",
      "        [-1.4531, -1.2537, -0.8648,  ..., -1.1908,  0.7386, -0.4184],\n",
      "        [-1.2621,  0.1523,  0.8618,  ..., -1.8008, -0.3016, -0.2497],\n",
      "        [-0.0197, -0.5848, -0.3916,  ..., -0.9802,  0.8238,  1.1821]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.7460, -0.6083, -0.2601,  ...,  1.2179, -0.1843, -0.4792],\n",
      "        [ 0.7180, -0.3058, -0.2423,  ..., -0.4517, -0.9335,  0.1284],\n",
      "        [-0.0148, -0.0030, -0.6862,  ..., -0.3343,  1.2902,  1.4639],\n",
      "        ...,\n",
      "        [ 1.9278,  0.1566,  1.4757,  ...,  0.1373,  0.2755, -0.2418],\n",
      "        [ 1.7962,  1.5947,  0.5527,  ...,  0.5000, -0.0550,  0.0260],\n",
      "        [-0.2857, -1.5310,  0.0949,  ..., -0.1235,  0.0269, -0.9584]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0517, -0.0609, -0.7150,  ..., -0.2418, -0.3659, -0.4323],\n",
      "        [ 1.9812, -0.3389,  1.2531,  ...,  1.3246, -1.1469,  0.1926],\n",
      "        [-0.5020,  1.3601,  0.5953,  ..., -0.3454,  0.4617, -0.6962],\n",
      "        ...,\n",
      "        [ 1.8888,  0.6615,  0.7609,  ..., -0.9749,  0.9730, -1.2971],\n",
      "        [ 0.2036, -1.1975, -1.9917,  ...,  2.1037, -0.7774,  0.5505],\n",
      "        [ 1.0753, -1.2557,  0.4480,  ...,  2.1810, -0.4592, -0.7413]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9503,  0.3357,  0.8185,  ..., -1.0274, -1.1598,  0.6024],\n",
      "        [-1.8760,  1.1058, -0.8942,  ...,  0.9137, -2.3677, -0.1767],\n",
      "        [-0.3759,  0.1982, -1.7695,  ..., -0.4087,  0.8950, -0.6666],\n",
      "        ...,\n",
      "        [-0.1315, -0.7986, -1.0766,  ..., -0.7411, -0.0259,  1.0510],\n",
      "        [-0.1534,  1.4013,  0.2381,  ...,  0.4407, -1.1193, -0.3353],\n",
      "        [ 0.0565, -0.5654,  1.7492,  ...,  1.5481,  0.3975, -0.0500]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.8885, -2.2595,  2.1751,  ..., -0.9273,  0.4420,  0.1927],\n",
      "        [-0.0855,  0.6332, -0.9273,  ...,  0.7345,  0.4662,  0.1030],\n",
      "        [ 0.0308,  1.6902, -0.2989,  ...,  0.0614,  1.1211, -0.7261],\n",
      "        ...,\n",
      "        [-0.0462, -1.0409, -1.1961,  ..., -0.4878,  0.6589,  0.0638],\n",
      "        [ 1.6931,  1.2403, -0.8483,  ...,  2.5595, -0.5622, -0.6582],\n",
      "        [ 0.0686, -1.2161,  0.6903,  ..., -2.3063,  1.6556,  0.5757]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0202,  0.2596,  0.9963,  ..., -0.7581,  1.3199, -1.0359],\n",
      "        [ 0.0600,  1.1266,  1.7654,  ..., -3.2380, -2.0359, -1.1472],\n",
      "        [ 1.0181,  1.5839,  0.3754,  ..., -1.7003, -0.6727,  0.4912],\n",
      "        ...,\n",
      "        [-0.1989, -0.8016,  0.3115,  ...,  0.6708, -0.1873, -0.0072],\n",
      "        [ 1.3442, -0.7521, -0.4157,  ..., -0.6139, -0.5584, -0.9473],\n",
      "        [-0.0427,  0.2202,  0.3936,  ..., -1.0874, -1.3067, -0.7917]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9515, -1.1876, -0.5504,  ...,  1.2713, -0.1168, -0.3184],\n",
      "        [-0.5803,  0.8011,  0.9719,  ..., -0.3077, -1.6080,  0.1698],\n",
      "        [ 0.1487, -1.7038, -2.3874,  ...,  1.0551,  0.7550, -0.0064],\n",
      "        ...,\n",
      "        [ 0.6064, -0.9421,  0.4295,  ..., -1.2945, -0.8111, -1.1951],\n",
      "        [-1.4740,  1.0832,  1.7881,  ...,  1.0488, -0.0599, -0.4264],\n",
      "        [-0.3666, -0.3677,  0.2500,  ..., -2.2966, -0.4871, -0.1453]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-3.2868, -0.0500,  0.3275,  ..., -0.5549,  0.6213,  0.5877],\n",
      "        [ 0.1432, -0.4931, -0.4921,  ..., -0.3392, -0.8207,  1.8436],\n",
      "        [-0.2900,  0.2089, -0.2227,  ...,  0.7429,  0.9257,  0.1269],\n",
      "        ...,\n",
      "        [-1.0306,  0.1295, -0.0792,  ...,  0.4192,  0.9151,  0.5305],\n",
      "        [ 2.0889, -1.8773,  1.0937,  ...,  0.5427,  1.5331, -0.3583],\n",
      "        [-0.5447,  0.3004, -0.6787,  ...,  0.0721,  2.2960, -0.4815]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2122, -0.5046,  1.0327,  ...,  0.3426, -0.0384, -0.2171],\n",
      "        [ 0.1272,  0.0065, -1.7302,  ..., -1.1596, -1.5684,  0.6042],\n",
      "        [-0.0357,  0.0709,  0.2030,  ...,  0.9366,  1.9743, -0.1820],\n",
      "        ...,\n",
      "        [ 0.0888, -0.0118,  2.3490,  ...,  0.8482, -0.4333, -1.1048],\n",
      "        [-0.7503, -1.5958, -0.7344,  ...,  0.3430, -1.7229,  0.7278],\n",
      "        [-0.0168, -0.6325,  0.4883,  ...,  1.0437, -1.1703,  0.3888]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.9829e-01, -7.1628e-01,  7.3193e-02,  ..., -7.0813e-01,\n",
      "          4.0469e-01,  1.1749e+00],\n",
      "        [-3.2813e-01, -2.3334e-02, -9.4652e-01,  ..., -1.2447e+00,\n",
      "          2.5082e+00, -2.9084e-01],\n",
      "        [-2.0710e+00,  1.7071e-01,  3.4584e-01,  ..., -1.3034e+00,\n",
      "          2.0732e+00,  1.0822e+00],\n",
      "        ...,\n",
      "        [ 1.6781e+00,  1.7991e+00, -1.8551e-02,  ..., -5.6621e-01,\n",
      "         -1.1690e+00, -3.3296e+00],\n",
      "        [ 7.6451e-01, -7.1925e-01,  7.6978e-01,  ..., -3.1736e-03,\n",
      "          6.9032e-01, -4.4281e-01],\n",
      "        [ 5.6334e-01,  2.4797e-01, -1.8073e-01,  ...,  1.3932e+00,\n",
      "          5.8318e-01,  2.6518e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.6482, -0.4644, -0.2853,  ...,  1.5683, -0.5233, -0.2298],\n",
      "        [-0.0289, -0.5249,  0.3380,  ...,  0.0850,  0.8479,  0.1878],\n",
      "        [-0.4827,  0.1612, -1.5279,  ...,  0.8465,  1.4118, -0.1645],\n",
      "        ...,\n",
      "        [-1.0196,  0.4028, -0.0791,  ...,  1.1137,  0.3925,  2.4145],\n",
      "        [ 2.5484, -2.9680,  1.4958,  ...,  0.6978, -1.3566, -1.2435],\n",
      "        [-0.4951,  0.5385, -0.8435,  ...,  2.1320,  0.6878,  0.0768]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1137, -0.7415,  0.4430,  ...,  2.3687, -0.7706, -0.1375],\n",
      "        [ 1.2935, -0.1675,  1.2991,  ...,  0.7939, -0.0565,  1.2501],\n",
      "        [-1.3826,  0.4850, -0.3362,  ...,  0.1088, -1.0819,  0.6429],\n",
      "        ...,\n",
      "        [-0.3382, -1.6870,  1.0286,  ..., -1.0865, -0.5943, -2.4848],\n",
      "        [-1.0856,  0.4765, -0.4475,  ..., -1.1074,  0.2974,  0.1766],\n",
      "        [-0.2436,  1.3120,  1.2910,  ...,  0.5327,  1.6418,  1.1170]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5852,  0.8417,  0.3291,  ...,  1.4704, -0.6838,  0.0351],\n",
      "        [-1.0400,  1.8696, -0.9402,  ...,  0.2260,  0.3560, -0.8610],\n",
      "        [-0.2012, -0.0902, -0.4126,  ...,  0.2239,  0.8211,  0.5433],\n",
      "        ...,\n",
      "        [-0.1344,  1.0100,  1.3747,  ..., -0.8763, -0.3555, -0.9972],\n",
      "        [ 1.2650,  1.4731,  1.1476,  ...,  0.4831, -1.4067,  0.8320],\n",
      "        [ 0.1499,  2.3651,  2.0638,  ..., -1.5488,  3.8399,  0.8289]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1656, -1.0175, -0.3352,  ...,  0.2598,  0.2575, -0.4741],\n",
      "        [ 0.4312, -1.0625, -0.2620,  ...,  2.1490, -1.1938,  0.2051],\n",
      "        [-0.9978,  1.2876, -0.7204,  ...,  0.2092, -0.3836,  1.4617],\n",
      "        ...,\n",
      "        [-1.0390, -1.1001,  0.0420,  ...,  0.3779, -0.6773,  0.1311],\n",
      "        [-0.9047, -0.3972, -1.8219,  ..., -0.1632, -1.5926, -0.7376],\n",
      "        [ 0.7923, -1.5699, -1.2959,  ..., -0.4364, -0.4024,  1.0143]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5398, -0.0529, -0.2768,  ...,  0.4171,  1.6618, -0.1256],\n",
      "        [ 1.7070,  0.4725, -0.5950,  ...,  5.9526,  1.1997, -0.5115],\n",
      "        [-1.1230,  0.4078, -0.0386,  ..., -1.2806,  0.1107,  0.9536],\n",
      "        ...,\n",
      "        [-1.2361, -1.2832, -0.7399,  ...,  1.4855,  0.6870, -0.6928],\n",
      "        [-0.5223,  0.0774,  1.1137,  ...,  0.0137,  0.8959,  0.8407],\n",
      "        [ 1.2765, -0.3581, -0.3822,  ..., -3.0247,  0.0099,  0.1122]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2955, -0.5454,  0.3783,  ...,  1.9994, -0.1164,  0.9923],\n",
      "        [-0.7634,  0.8460, -0.9795,  ..., -0.0634,  0.5306, -2.2315],\n",
      "        [ 0.8920,  0.2801,  0.3997,  ...,  0.4281,  1.6975,  1.6736],\n",
      "        ...,\n",
      "        [-1.5922, -0.5083,  1.0968,  ..., -2.4758, -1.1462, -0.6276],\n",
      "        [ 1.0609,  0.1264, -0.3931,  ...,  0.3340,  0.5990, -0.5608],\n",
      "        [ 0.4077, -0.2490, -0.9716,  ..., -0.2876, -0.6408,  0.4083]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1440,  1.9766, -0.2102,  ...,  0.6830, -1.1412, -0.6270],\n",
      "        [ 0.2303,  1.9315, -1.4488,  ..., -0.6768, -0.9084,  0.4025],\n",
      "        [ 0.4498, -0.3187, -1.5463,  ...,  0.3429, -2.1157, -0.4424],\n",
      "        ...,\n",
      "        [ 0.6790,  0.6582, -0.1509,  ..., -2.0873, -1.0030,  0.6231],\n",
      "        [-2.1398,  1.7972,  1.7435,  ..., -0.6507, -1.5264,  0.3845],\n",
      "        [ 0.1838, -0.0994,  1.0077,  ..., -1.0764, -0.7709, -0.1608]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5605,  0.6875,  0.1393,  ..., -1.0955, -0.4635,  0.0616],\n",
      "        [-0.7497, -0.0945,  0.6653,  ..., -0.0397,  3.5172,  0.4501],\n",
      "        [-0.2416, -0.2925,  0.8254,  ...,  0.3021,  0.4328, -0.4198],\n",
      "        ...,\n",
      "        [ 0.7187, -0.1079,  0.6860,  ..., -0.3794, -0.4105, -0.1822],\n",
      "        [-1.4663, -0.1444, -0.2758,  ..., -0.3115,  0.7062,  0.5923],\n",
      "        [-0.0246, -0.0447, -1.1430,  ..., -1.3780, -0.3601,  0.1604]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3126,  1.1157, -0.1168,  ...,  1.5085, -1.8722,  0.6227],\n",
      "        [-1.0556,  1.0121, -0.9493,  ..., -0.2048, -1.1899, -0.5201],\n",
      "        [ 1.7209, -2.1393,  0.9169,  ..., -0.0158,  0.6680, -3.2220],\n",
      "        ...,\n",
      "        [-0.5234, -0.2432, -0.6666,  ..., -0.8684, -0.8481, -0.2009],\n",
      "        [ 1.3500,  0.1974,  0.2879,  ..., -1.0284,  1.0607, -1.2364],\n",
      "        [ 1.9849, -0.5693,  0.7948,  ...,  1.5931,  0.2952, -0.0846]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1819, -2.0552, -1.2371,  ..., -1.1957,  1.4300, -0.0042],\n",
      "        [ 1.4372, -2.3744, -1.7077,  ...,  0.2540, -0.1316, -0.3065],\n",
      "        [-0.4068,  0.3383,  0.7801,  ...,  0.0300,  1.0954,  1.0969],\n",
      "        ...,\n",
      "        [-1.1188, -0.0693, -1.1053,  ...,  0.0724,  0.7995,  1.5053],\n",
      "        [-0.8931,  0.7056, -1.0579,  ...,  1.2290,  1.3540,  0.5625],\n",
      "        [ 0.4728, -0.2877,  0.2904,  ..., -0.2810, -0.2761,  0.1992]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4675,  1.2650,  0.7758,  ..., -0.4241,  0.1349, -0.4485],\n",
      "        [-0.5305, -0.6242, -0.2057,  ..., -0.4281, -1.0618, -1.1495],\n",
      "        [ 1.1449,  0.5110,  1.1449,  ..., -0.3261, -0.3202,  0.6499],\n",
      "        ...,\n",
      "        [-1.6344,  0.2610, -0.2790,  ..., -0.3220,  1.2611, -0.4424],\n",
      "        [-0.9262, -1.1029, -0.1797,  ...,  1.3675,  1.5246,  1.2962],\n",
      "        [-0.9915, -0.0039, -0.1262,  ...,  0.6290, -0.2220, -1.2999]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 5.1257e-01, -8.0395e-02, -1.2286e+00,  ..., -3.8617e-01,\n",
      "         -2.7354e-01, -1.3305e+00],\n",
      "        [ 8.2147e-01, -3.6640e-01, -3.2838e-01,  ..., -2.4769e-01,\n",
      "         -1.3774e-01,  6.4269e-01],\n",
      "        [-1.2608e+00, -1.1607e+00, -1.4985e+00,  ...,  1.7741e+00,\n",
      "         -2.8121e-01,  2.5117e-01],\n",
      "        ...,\n",
      "        [-1.5849e+00,  9.9855e-02, -1.5509e+00,  ..., -8.7130e-01,\n",
      "         -2.2122e+00, -1.6574e+00],\n",
      "        [ 1.1369e+00, -6.0877e-01,  4.3805e-05,  ...,  5.3461e-01,\n",
      "          4.0806e+00,  4.4390e-01],\n",
      "        [ 1.0842e+00, -1.6275e-02, -1.8226e+00,  ...,  2.7488e-01,\n",
      "         -6.2766e-02, -4.5918e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.7285, -1.8209,  1.3952,  ..., -1.0217, -1.9883, -0.7275],\n",
      "        [ 0.5709, -0.5605, -2.1055,  ..., -0.0894, -0.2802, -0.2516],\n",
      "        [ 1.2831, -0.5931, -1.5367,  ...,  0.5838,  0.8264,  1.3652],\n",
      "        ...,\n",
      "        [ 1.1488, -0.5047, -1.2412,  ..., -0.5147,  1.3622, -1.0124],\n",
      "        [-0.5846, -0.4534, -0.3465,  ..., -0.5351,  1.8322, -0.2280],\n",
      "        [-0.8494, -0.9640, -0.5405,  ..., -0.7518, -0.4944,  0.4005]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8323,  0.3782,  0.1335,  ..., -0.9793, -0.6117,  0.8072],\n",
      "        [-0.5375,  0.1011, -0.2657,  ..., -0.1373,  0.2870, -0.6600],\n",
      "        [ 1.3227,  0.0381, -0.2241,  ..., -0.3312,  0.8498,  0.2969],\n",
      "        ...,\n",
      "        [-0.1550, -0.3786, -0.8310,  ..., -1.5872,  0.0855,  1.0681],\n",
      "        [ 0.1692, -0.9916, -0.3043,  ...,  0.4597, -0.1973, -0.3344],\n",
      "        [ 0.5940, -0.0417,  1.5367,  ...,  1.6693, -0.2435,  0.4941]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5636,  1.3163,  0.8830,  ...,  0.2900, -2.1635, -0.4484],\n",
      "        [-0.1227,  0.0395, -1.2237,  ...,  0.3694, -0.7724, -1.1173],\n",
      "        [ 1.9092, -2.3864,  0.1853,  ...,  1.2887, -0.2876,  0.3802],\n",
      "        ...,\n",
      "        [ 1.9049, -0.5069,  0.4648,  ..., -0.0795,  0.2750, -3.1963],\n",
      "        [ 1.7029,  0.9388,  0.5566,  ...,  0.2992,  1.3108, -0.1937],\n",
      "        [ 0.2547,  0.3462, -1.2688,  ..., -1.9980, -0.3923, -0.3321]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1278,  1.9171, -0.1048,  ...,  0.7896, -2.6960,  0.3663],\n",
      "        [-1.0198, -0.2168, -0.0330,  ..., -0.3048, -0.6009,  1.2617],\n",
      "        [ 0.5673,  0.9383, -0.5197,  ..., -0.5065, -0.9309, -0.2944],\n",
      "        ...,\n",
      "        [-1.3152,  0.0662, -0.4205,  ...,  1.1230,  0.0261,  0.9660],\n",
      "        [ 0.1933, -1.7357, -1.0092,  ..., -0.2070,  0.0480, -0.5572],\n",
      "        [-0.2617,  1.1734, -0.8964,  ..., -0.8208, -1.1329, -0.5524]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.6165, -0.4263, -0.4989,  ..., -2.1001,  0.7173, -0.2019],\n",
      "        [ 2.0965,  1.4561,  1.3199,  ...,  0.8963, -0.4673, -0.0711],\n",
      "        [ 0.7077, -0.0507,  0.7389,  ..., -2.1959, -1.6592,  0.4042],\n",
      "        ...,\n",
      "        [-0.4981, -0.6519,  1.6581,  ...,  0.7426, -0.3221, -0.1091],\n",
      "        [-0.2357,  1.4142,  0.4364,  ...,  0.2129,  0.6972,  0.3147],\n",
      "        [ 0.0628,  0.1891, -1.1758,  ..., -1.3589,  0.3489,  1.5306]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5225, -1.1506, -0.9899,  ..., -0.0436,  0.5281,  0.0093],\n",
      "        [-1.1272, -0.3249, -0.7312,  ..., -0.6217, -0.5749, -0.2583],\n",
      "        [ 0.3952,  1.4146,  0.2741,  ..., -1.0664, -1.0710, -0.8903],\n",
      "        ...,\n",
      "        [ 0.6420,  0.1403, -0.4397,  ...,  1.8210, -0.5119,  0.6607],\n",
      "        [-0.2098, -0.8154,  0.8783,  ...,  0.9547,  0.2993,  1.4299],\n",
      "        [ 1.2746,  1.0751,  2.3741,  ...,  1.6700, -0.1542,  0.8767]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1958, -0.3609,  0.7681,  ...,  0.2192,  0.4959,  1.0943],\n",
      "        [ 0.8126,  0.0360, -0.4811,  ...,  0.2255, -0.6334, -0.2717],\n",
      "        [-0.8449, -1.4261,  0.0927,  ...,  0.2103,  1.0450, -1.4275],\n",
      "        ...,\n",
      "        [ 0.7720,  1.3787,  0.0432,  ..., -0.2693,  0.4840, -0.7299],\n",
      "        [-1.3261, -0.2419,  1.3997,  ...,  0.2224, -1.6052,  1.0217],\n",
      "        [-0.1599, -0.1784, -2.3054,  ...,  0.9229, -0.1516, -0.0130]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-2.2255, -1.6922,  0.2502,  ..., -0.5589, -0.2174,  1.0727],\n",
      "        [ 0.4041,  1.0614, -0.4319,  ..., -0.1820, -0.3622, -0.5170],\n",
      "        [ 0.2832,  0.1740,  0.7745,  ..., -0.2180, -0.2071,  0.2625],\n",
      "        ...,\n",
      "        [ 0.6538,  1.1359,  0.6468,  ..., -1.0010, -1.0398,  0.6935],\n",
      "        [-1.1387, -0.5765, -1.0443,  ..., -2.6589,  0.2449,  0.1044],\n",
      "        [ 0.3761,  0.2893,  0.0409,  ..., -0.4488, -0.0268, -0.5769]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0706,  2.3983, -1.4914,  ..., -0.5737,  0.3378,  0.3863],\n",
      "        [-0.1432,  0.4004,  0.5303,  ...,  1.0041, -0.2043, -2.4354],\n",
      "        [ 0.0731, -0.9310, -0.2910,  ...,  0.3034, -0.0342,  0.7603],\n",
      "        ...,\n",
      "        [-0.9640,  0.4612, -1.0980,  ...,  1.0975,  1.3242, -0.3087],\n",
      "        [ 0.0406, -1.0671, -0.4366,  ...,  0.6865, -0.5300,  0.6149],\n",
      "        [ 1.2579,  1.4278,  0.5870,  ..., -0.0799, -1.8819,  1.4349]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0401e+00,  8.1685e-01,  1.4676e+00,  ..., -7.8915e-01,\n",
      "         -2.0864e-03,  6.5098e-01],\n",
      "        [-5.2071e-03,  3.0343e-01, -3.2004e-01,  ..., -5.4585e-01,\n",
      "         -1.9435e+00, -1.1891e+00],\n",
      "        [ 1.0568e+00, -2.0496e+00,  7.1576e-01,  ...,  4.6658e-01,\n",
      "         -1.4528e+00,  9.3458e-01],\n",
      "        ...,\n",
      "        [ 1.6136e+00, -9.4922e-01, -1.0846e+00,  ...,  4.3580e-01,\n",
      "         -4.9785e+00,  4.3596e+00],\n",
      "        [ 7.0715e-01,  5.7909e-01,  1.1885e-01,  ...,  1.8591e+00,\n",
      "          1.2918e+00,  5.5553e-01],\n",
      "        [ 1.1045e+00,  7.5943e-01, -3.5218e-01,  ...,  1.0089e+00,\n",
      "          1.9555e-01, -5.9095e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.5531,  0.4900, -0.0960,  ..., -1.4792,  1.4395,  0.4931],\n",
      "        [-0.0804, -1.0806, -0.5252,  ..., -2.7563, -0.0621, -1.3248],\n",
      "        [-1.9088,  0.4809, -0.3919,  ...,  0.9987, -0.8824, -1.0293],\n",
      "        ...,\n",
      "        [ 0.3449, -0.5062,  0.8964,  ...,  0.2889,  1.6532,  0.6019],\n",
      "        [ 0.2266,  0.8007, -0.1745,  ..., -3.0949, -0.2528,  0.5035],\n",
      "        [ 0.5772, -0.5471,  0.7262,  ..., -0.5459, -1.2045, -0.4708]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 8.6829e-01,  1.8415e-01,  2.3246e+00,  ...,  1.9297e+00,\n",
      "          3.2005e-01, -5.0189e-01],\n",
      "        [-1.0335e+00, -1.7658e+00,  1.3314e+00,  ..., -5.6592e-01,\n",
      "          1.5010e-01, -1.4427e+00],\n",
      "        [-2.7323e-01,  1.7327e-01, -1.6332e-01,  ...,  2.3236e-01,\n",
      "          3.1386e-01, -1.1798e+00],\n",
      "        ...,\n",
      "        [-5.5673e-01,  1.4869e+00, -8.2336e-01,  ...,  2.5334e-01,\n",
      "          9.4930e-01,  4.2928e-01],\n",
      "        [-2.6097e-02,  3.1146e-01, -4.9072e-01,  ..., -8.2189e-01,\n",
      "         -4.6506e-01, -1.2583e+00],\n",
      "        [-8.8577e-01,  1.3307e-03,  1.0994e+00,  ..., -1.2372e-01,\n",
      "          1.4932e-01,  2.3152e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2552, -1.8775, -0.4939,  ...,  0.7749, -0.0940,  0.2602],\n",
      "        [ 1.0618, -0.6341,  0.1951,  ...,  1.7406,  0.8399, -0.2342],\n",
      "        [-0.1969,  0.2731,  0.9098,  ...,  0.6445,  0.5334, -0.2124],\n",
      "        ...,\n",
      "        [ 1.4870, -1.2630,  0.0747,  ..., -0.4019, -0.1613, -0.0919],\n",
      "        [ 0.2380,  0.0976,  1.9336,  ...,  0.9721, -1.9403,  0.0980],\n",
      "        [-0.0219, -0.5307, -1.5267,  ..., -0.4793, -0.8431, -0.5971]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0152, -0.0500,  0.5781,  ..., -0.8387, -0.3631, -0.5471],\n",
      "        [ 0.1846, -0.2219,  0.7476,  ...,  1.3153, -1.1289, -0.0130],\n",
      "        [ 1.0021,  1.2914,  2.1101,  ...,  0.4768, -0.8239,  2.8602],\n",
      "        ...,\n",
      "        [ 0.8313, -0.6543,  1.1935,  ..., -1.2946,  0.3256,  0.7979],\n",
      "        [-1.7982,  0.1301, -0.2431,  ..., -1.0521, -0.2652,  0.6250],\n",
      "        [-0.6718,  0.6187, -0.1264,  ..., -0.7362, -0.7193, -2.4728]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.3242,  0.0294, -1.2870,  ..., -2.2197, -0.2313, -1.4314],\n",
      "        [ 1.0427, -0.6365, -0.2379,  ...,  0.9419, -0.3791, -1.2256],\n",
      "        [-2.0723, -0.8005, -1.9436,  ...,  2.6336,  0.3990, -0.5861],\n",
      "        ...,\n",
      "        [-0.6022,  0.0842,  1.0491,  ...,  0.2922,  1.1960, -0.7684],\n",
      "        [ 0.1934, -0.8214,  0.3853,  ..., -0.2963, -0.3152, -0.0913],\n",
      "        [ 0.0332, -0.1971,  0.2309,  ...,  0.7663,  2.0390, -0.0781]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4122,  0.3447, -1.2573,  ..., -0.8347,  0.6361, -1.0603],\n",
      "        [-0.4384,  0.7539, -0.8985,  ..., -0.3070, -2.2011, -0.6532],\n",
      "        [-1.0423, -0.2544, -0.0320,  ...,  2.5087,  0.3425,  0.8054],\n",
      "        ...,\n",
      "        [ 0.9042,  0.5391, -0.8732,  ..., -0.3334,  0.0070,  0.5939],\n",
      "        [ 1.6468,  1.7286,  1.6020,  ...,  0.5022,  0.0787, -0.4115],\n",
      "        [ 0.2564,  0.1576,  0.0380,  ..., -1.1169,  0.0857, -0.3940]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5207,  0.2067, -0.7816,  ..., -0.2222, -1.6158,  0.8794],\n",
      "        [-0.8261, -0.5961,  0.0289,  ...,  0.6217, -0.1361, -0.9393],\n",
      "        [ 0.4796,  0.3796, -2.1324,  ..., -0.3693, -0.1975,  1.5253],\n",
      "        ...,\n",
      "        [-0.5898,  0.1825,  0.7977,  ...,  0.3678,  0.8577,  0.1892],\n",
      "        [-0.8455, -0.2428, -1.0279,  ..., -0.8026, -0.1282,  1.3265],\n",
      "        [ 0.0457,  0.0186, -0.5963,  ..., -0.3080, -0.5978, -0.0649]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.0668,  0.6931, -0.0347,  ...,  0.0299,  0.0964, -0.2253],\n",
      "        [-1.1067, -1.6875,  0.4818,  ..., -0.2394,  1.3259,  0.1402],\n",
      "        [-1.0011, -0.4685, -1.6606,  ...,  0.1546, -0.6012,  1.5857],\n",
      "        ...,\n",
      "        [-0.4273,  0.5972,  0.3907,  ...,  1.4805,  1.2766,  0.7986],\n",
      "        [-0.7768, -0.2376, -0.6040,  ..., -0.8861, -0.0919,  0.7935],\n",
      "        [ 0.7013, -0.1704, -0.8569,  ...,  2.6917,  1.7070,  1.2507]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0756,  0.9725,  0.1317,  ...,  0.1354,  1.0216, -1.5317],\n",
      "        [-0.1129, -1.0381,  1.3620,  ..., -1.0278, -0.7786, -0.1272],\n",
      "        [-1.2465,  0.9692, -0.8966,  ...,  0.4362,  0.4185,  0.7209],\n",
      "        ...,\n",
      "        [ 0.2686, -0.8495, -0.3593,  ..., -0.9665,  0.6365,  0.7124],\n",
      "        [-0.1196,  0.5401,  0.2237,  ...,  1.1493, -0.2046, -0.7755],\n",
      "        [ 0.1127,  0.0949, -0.6216,  ...,  1.4665, -1.3407, -0.7963]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0066, -1.6406,  0.7734,  ..., -0.5551, -0.0407, -2.0788],\n",
      "        [-1.9821, -1.4959,  1.2115,  ..., -0.6358,  0.3404,  0.6847],\n",
      "        [-1.2021,  0.2189,  0.8568,  ..., -0.3609,  0.5264,  0.2287],\n",
      "        ...,\n",
      "        [-0.8859, -0.6154, -1.3175,  ..., -2.1207, -1.1980,  0.1979],\n",
      "        [ 0.0878,  0.4219,  0.5925,  ..., -1.2723, -0.6133,  2.0786],\n",
      "        [-0.2413, -0.2681,  0.2182,  ...,  0.3461, -1.9005,  0.2016]]), 'y': tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.3998, -0.5620,  1.1777,  ...,  0.4292,  0.6283,  1.0954],\n",
      "        [-1.9393,  0.3142, -1.2380,  ..., -0.5228,  1.2768, -0.2028],\n",
      "        [ 0.7771,  1.0750,  2.1957,  ...,  0.3895,  1.7031, -1.9397],\n",
      "        ...,\n",
      "        [-0.6800,  0.1109, -0.7975,  ...,  2.5304,  0.0554,  0.2463],\n",
      "        [-1.1418,  1.6028, -0.5677,  ...,  0.3444, -1.1049,  0.2244],\n",
      "        [-0.3177,  0.6266,  0.7400,  ...,  0.3110,  0.7162, -0.7655]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 5.1636e-01, -2.2301e-02, -2.3827e-01,  ..., -2.3919e-01,\n",
      "          1.8771e+00,  1.0164e+00],\n",
      "        [ 1.9297e+00, -9.1109e-01,  1.7204e+00,  ..., -1.3896e+00,\n",
      "          1.1189e+00, -1.1574e+00],\n",
      "        [-1.2005e+00,  1.6972e-01, -1.0529e+00,  ..., -8.8874e-04,\n",
      "          1.6203e+00,  5.2434e-01],\n",
      "        ...,\n",
      "        [ 6.8897e-01, -1.7849e+00,  5.9224e-01,  ...,  1.3486e+00,\n",
      "          8.3074e-01, -8.1081e-01],\n",
      "        [-1.2404e+00,  1.9156e+00,  7.4400e-01,  ..., -6.9316e-01,\n",
      "         -3.6787e-02,  1.3096e-01],\n",
      "        [ 1.0077e+00,  8.2282e-01, -4.9514e-01,  ..., -4.3287e-01,\n",
      "         -1.8766e+00, -2.2296e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5212,  0.5053,  0.3906,  ..., -1.2011,  0.0611,  1.7287],\n",
      "        [ 0.2039,  0.8642,  0.9738,  ..., -0.4775, -2.3019, -0.6304],\n",
      "        [ 1.0471,  1.7298,  0.1628,  ...,  1.5310, -1.0737,  0.8803],\n",
      "        ...,\n",
      "        [-0.8396, -0.1555, -1.1211,  ...,  0.8413,  1.4397, -1.1336],\n",
      "        [-1.4146,  0.7199, -0.3275,  ..., -0.6265,  0.3858, -1.0191],\n",
      "        [ 0.9463, -0.3488,  0.9396,  ...,  1.7845,  0.4177, -1.2500]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.3506e+00,  3.1472e-01, -1.0185e+00,  ...,  2.1801e+00,\n",
      "          1.2644e+00, -1.8734e+00],\n",
      "        [-1.4893e+00, -2.3394e+00,  1.0305e+00,  ...,  5.3396e-01,\n",
      "         -6.7069e-01,  1.0887e+00],\n",
      "        [ 5.0034e-01, -6.7332e-01,  1.6935e+00,  ...,  6.1740e-01,\n",
      "          5.4555e-01, -3.0384e-01],\n",
      "        ...,\n",
      "        [ 1.0599e+00,  1.5319e+00, -1.9839e+00,  ..., -1.8801e+00,\n",
      "         -3.2686e-01,  1.7130e-01],\n",
      "        [-1.1639e+00, -1.6079e-03, -7.6495e-01,  ...,  7.7784e-01,\n",
      "          9.4549e-01, -6.4687e-02],\n",
      "        [-4.5064e-01,  7.7852e-01, -3.3627e-01,  ...,  1.3532e+00,\n",
      "         -1.4527e+00, -5.2593e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2019, -0.8003,  0.5752,  ..., -0.7537, -0.1185,  0.5378],\n",
      "        [-0.1615,  0.1279,  2.3777,  ...,  0.1382, -0.1166, -0.0830],\n",
      "        [ 0.8317,  0.8536,  2.2395,  ...,  0.3566,  1.9526,  2.3075],\n",
      "        ...,\n",
      "        [-0.1518, -0.4842, -0.4590,  ...,  0.6159,  0.1669,  0.5050],\n",
      "        [-0.0074,  0.7044,  0.4815,  ...,  0.4498,  0.7321,  0.4896],\n",
      "        [ 1.2880,  0.3915,  0.8176,  ..., -0.3183, -2.3605, -4.1243]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2216, -0.6812,  0.6799,  ..., -0.3168, -0.3190,  0.7064],\n",
      "        [-0.9577,  0.6198, -0.4515,  ..., -0.7704, -0.9094, -0.4943],\n",
      "        [-0.1343,  0.2924,  0.3800,  ..., -0.5089,  0.1238, -0.5998],\n",
      "        ...,\n",
      "        [ 0.6721, -1.2228,  0.7035,  ...,  0.8526, -0.6207,  0.8777],\n",
      "        [-0.5698,  1.0469, -0.1935,  ..., -0.1378,  0.0680, -0.7465],\n",
      "        [ 0.2726,  1.5261, -1.1267,  ...,  0.0877, -1.0665, -0.4094]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.8915,  0.0822, -0.0771,  ...,  0.2358,  0.4276, -0.5885],\n",
      "        [ 0.9485,  1.2039,  0.5361,  ...,  0.4044,  0.7971, -1.1871],\n",
      "        [-0.5371, -0.2843,  0.5894,  ..., -0.5983,  2.0338,  0.0669],\n",
      "        ...,\n",
      "        [-2.6995, -1.8993,  1.4852,  ..., -1.6859, -0.6949, -0.1237],\n",
      "        [ 0.6667,  1.3328,  0.0990,  ...,  2.4412, -0.1474, -0.4155],\n",
      "        [ 1.4139, -1.6598,  1.8953,  ..., -1.0588,  0.7756,  0.4858]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1507, -0.8353, -0.7320,  ..., -0.1239,  1.1865,  0.6602],\n",
      "        [ 0.0957, -0.2314, -1.2183,  ...,  0.0166, -0.4442,  0.0287],\n",
      "        [-0.1105,  0.9230, -1.2427,  ...,  1.4147,  0.6934, -0.5213],\n",
      "        ...,\n",
      "        [ 0.4030,  1.2810,  0.3130,  ...,  0.1949,  0.0439, -0.5271],\n",
      "        [ 2.5734, -0.7386,  0.7069,  ...,  1.6592, -0.6170,  0.3309],\n",
      "        [ 1.4530, -0.0990,  1.1390,  ...,  0.4872, -1.1573,  0.5168]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-6.5904e-01, -3.4148e-01,  1.8727e+00,  ...,  2.0024e-02,\n",
      "         -1.7320e+00, -1.2703e+00],\n",
      "        [ 5.3073e-01,  4.2555e-01,  2.1620e-01,  ..., -1.0957e+00,\n",
      "          1.4063e+00,  6.3344e-02],\n",
      "        [-1.2735e+00, -7.0268e-01, -1.4633e-01,  ...,  2.4664e+00,\n",
      "         -7.8381e-01,  1.1576e+00],\n",
      "        ...,\n",
      "        [ 1.1015e+00,  1.6209e+00,  3.2576e-01,  ..., -5.4683e-01,\n",
      "         -2.4618e+00,  1.2000e+00],\n",
      "        [ 2.1044e+00,  1.7358e+00, -3.9334e-02,  ...,  1.6777e+00,\n",
      "          1.6671e-01,  9.5049e-01],\n",
      "        [ 1.6815e-01,  2.4026e-03, -5.7001e-01,  ..., -1.4781e-02,\n",
      "         -4.3111e-01,  1.6174e-02]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6842, -0.8058, -0.9593,  ..., -0.1409, -0.2967, -1.5462],\n",
      "        [-0.4665,  0.4435,  1.1039,  ..., -0.1187, -0.1619,  0.6720],\n",
      "        [-0.3036,  0.3810, -1.3234,  ..., -1.0458,  0.4262, -0.9639],\n",
      "        ...,\n",
      "        [ 0.1238,  0.7552, -0.0981,  ...,  0.8622,  0.3509, -0.0606],\n",
      "        [-0.9225,  2.1017,  0.4048,  ...,  0.3233,  0.4421,  0.9560],\n",
      "        [ 0.4259,  0.6396,  1.1613,  ...,  0.0075, -0.8964, -0.6500]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1867, -0.7327, -0.4270,  ..., -0.8066,  0.0832,  0.8169],\n",
      "        [-0.3744, -0.3384,  2.3447,  ..., -1.0949, -0.0301, -0.1545],\n",
      "        [-0.1919, -0.4666, -1.6029,  ...,  1.3147,  1.1263, -0.1343],\n",
      "        ...,\n",
      "        [ 0.6686,  1.2686, -2.0900,  ..., -1.0396, -0.4901,  0.2010],\n",
      "        [-0.9776, -1.0607,  1.6653,  ..., -1.4326,  0.8005, -0.8739],\n",
      "        [-1.8313,  1.1337, -0.9425,  ..., -0.4630, -2.3429, -0.0690]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1701, -0.1365, -0.6797,  ...,  0.3061,  0.7707,  1.7179],\n",
      "        [ 0.2811,  0.7175, -0.3745,  ...,  0.9580, -1.7895, -1.0670],\n",
      "        [-0.5561, -0.0624,  0.8214,  ...,  0.9018, -0.0347, -1.7424],\n",
      "        ...,\n",
      "        [-0.7586,  1.2908, -1.9419,  ...,  0.4128,  0.4459,  0.4425],\n",
      "        [ 0.6869, -0.2061,  2.4972,  ...,  1.7601,  1.5152,  1.4635],\n",
      "        [ 0.0610,  1.2766,  1.1396,  ..., -0.8757,  2.2720, -0.5400]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5536, -0.3159, -0.2904,  ..., -1.7954,  1.4859, -0.5961],\n",
      "        [-1.5729, -0.1500,  0.9688,  ..., -0.2558,  0.1613,  1.2038],\n",
      "        [ 1.2455,  1.8374,  0.6162,  ..., -1.5960, -0.1718,  0.5383],\n",
      "        ...,\n",
      "        [-0.6552, -0.1635,  0.4369,  ..., -0.0726, -0.8438,  1.6263],\n",
      "        [ 1.0951,  0.2963, -0.4914,  ..., -1.2899,  0.6717, -1.0210],\n",
      "        [-0.3620, -0.4080,  0.9724,  ..., -1.7164,  1.6578,  0.1147]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1782, -0.1722,  0.5796,  ..., -0.0437,  0.0766,  1.0491],\n",
      "        [ 0.2169, -0.6454,  0.1120,  ...,  0.1189, -1.0582, -1.1066],\n",
      "        [ 0.1310, -0.7732,  1.0194,  ...,  0.1478, -0.7865,  1.7121],\n",
      "        ...,\n",
      "        [-1.4691, -1.4566,  0.5336,  ..., -0.3312, -0.2639, -0.4094],\n",
      "        [-0.5180, -0.6791, -0.9016,  ..., -2.3896, -0.8098, -0.0125],\n",
      "        [-0.1733, -1.7913,  0.1642,  ...,  0.0467,  0.7272, -0.6455]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.0893,  0.0780, -0.7160,  ..., -0.8686,  0.3944,  1.1094],\n",
      "        [-1.1888, -0.0772, -0.6995,  ..., -0.0985,  0.1454,  0.9877],\n",
      "        [-0.3657, -1.9777,  0.6926,  ..., -0.5669,  1.5107,  0.9870],\n",
      "        ...,\n",
      "        [-2.3361, -1.2662, -0.4007,  ..., -0.0836, -2.2467,  0.7624],\n",
      "        [ 0.1964,  0.2066,  0.7084,  ..., -1.0229, -1.5461, -1.1635],\n",
      "        [ 0.8809, -0.4728, -0.2750,  ..., -0.1462,  1.1891,  0.0595]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5837,  0.6047, -0.1460,  ..., -1.4398,  0.5049,  0.3598],\n",
      "        [ 0.5573,  0.2501, -0.8168,  ..., -0.6178, -0.0236,  0.0498],\n",
      "        [ 0.7616,  0.2347,  0.9755,  ...,  1.3555,  0.0226,  0.3655],\n",
      "        ...,\n",
      "        [ 1.0210,  1.2093,  0.1136,  ..., -0.1546, -0.4003,  0.2750],\n",
      "        [ 0.3135,  0.5952,  1.5929,  ...,  0.5067, -0.5096, -0.4867],\n",
      "        [ 0.3671,  0.2303,  1.2635,  ...,  1.1022, -0.1090, -0.8110]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.2078,  0.9016,  1.1433,  ...,  0.1200, -0.5536, -1.2532],\n",
      "        [-0.5435, -0.1699,  1.3782,  ..., -0.4277, -1.7423,  1.5535],\n",
      "        [-1.7093,  0.0139, -0.5578,  ...,  1.0724, -0.9707, -0.8428],\n",
      "        ...,\n",
      "        [-0.8496, -0.3565,  1.1682,  ..., -0.7320,  1.3745, -0.6431],\n",
      "        [-0.5171,  0.4894, -0.9623,  ..., -0.5420, -0.5660,  0.6507],\n",
      "        [ 0.2692,  1.4064, -0.3121,  ..., -0.2077,  1.2416,  0.3133]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.4519, -0.1337,  0.2219,  ..., -2.1268, -1.5742, -0.1214],\n",
      "        [-0.0151, -0.3126,  0.0157,  ...,  0.5484, -0.8162,  0.4400],\n",
      "        [-0.8518, -0.8848, -1.7740,  ...,  0.2133,  0.9436, -0.4789],\n",
      "        ...,\n",
      "        [ 1.3759,  0.1354, -0.9192,  ..., -0.2795, -0.7083, -0.8020],\n",
      "        [-0.8019, -0.0891, -1.0628,  ..., -0.1507,  1.7507,  0.8945],\n",
      "        [-0.6164, -0.9819, -0.6007,  ...,  1.8790, -1.3516, -0.1222]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2290,  0.2120, -0.6065,  ...,  0.9855, -0.9772, -1.2880],\n",
      "        [-0.1708,  0.5664,  0.6942,  ..., -0.0980, -0.0661,  0.4131],\n",
      "        [-0.8970, -0.4257,  0.7117,  ...,  1.0788, -0.6535, -0.9105],\n",
      "        ...,\n",
      "        [ 1.3600,  0.7655,  0.7039,  ...,  0.5345,  1.4164, -0.8814],\n",
      "        [ 0.0282, -0.2583, -0.1997,  ..., -2.0287,  0.2207,  0.2156],\n",
      "        [ 0.3246, -0.6853,  0.2493,  ..., -0.6141,  0.1872,  0.3161]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.7420, -2.0479,  0.3326,  ..., -0.6541, -0.0993,  0.3186],\n",
      "        [-2.1252, -0.3864, -1.6433,  ..., -1.9382,  1.5253,  0.9447],\n",
      "        [ 0.2852, -0.1099,  0.2801,  ..., -0.6833, -0.2116,  0.4249],\n",
      "        ...,\n",
      "        [-0.2688,  0.4262, -0.2059,  ..., -0.0621,  1.3542, -0.5432],\n",
      "        [-1.0851, -1.2969, -0.1814,  ...,  0.2012,  1.6304, -0.7425],\n",
      "        [-0.5804, -1.4095, -0.1392,  ..., -0.2962,  1.3800,  0.7930]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8090,  0.0174, -1.8823,  ..., -0.2590, -0.9562, -0.4392],\n",
      "        [-1.6221,  0.4910,  0.5994,  ...,  2.0844,  0.7486, -1.0808],\n",
      "        [-0.7698, -0.2254,  1.0405,  ..., -0.6216,  1.2643, -0.1897],\n",
      "        ...,\n",
      "        [-0.5283, -0.3750, -0.4533,  ...,  0.5147,  0.1173,  0.2288],\n",
      "        [-0.0894,  0.6265, -1.2709,  ...,  1.4164, -1.7814,  0.9084],\n",
      "        [-0.6446, -0.8174,  0.9854,  ...,  0.2514, -0.4818,  0.2816]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5988, -0.1247, -0.1296,  ...,  0.8434, -1.1956,  2.2289],\n",
      "        [ 0.1406,  1.1994, -0.3757,  ..., -0.4314,  0.2542, -0.2236],\n",
      "        [ 0.9570,  0.0884,  0.1802,  ...,  2.1514, -0.8108, -0.9850],\n",
      "        ...,\n",
      "        [-0.4327, -0.7007, -1.9895,  ..., -0.3350, -0.5715, -1.4704],\n",
      "        [ 0.0767,  0.6977,  0.1877,  ...,  0.2776, -0.4619,  0.6622],\n",
      "        [-1.3601, -1.5994,  0.1762,  ...,  1.0541, -0.9733, -0.9969]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7822,  1.0563, -0.9929,  ..., -0.3608,  1.2374, -0.2007],\n",
      "        [ 1.8559,  2.6790,  1.3243,  ...,  1.1356, -0.0648,  0.5810],\n",
      "        [-0.0593,  1.5512, -1.9681,  ...,  0.1565,  0.4657,  0.5991],\n",
      "        ...,\n",
      "        [-0.8246, -0.1776, -0.7585,  ..., -0.5983, -0.0507, -1.8260],\n",
      "        [-0.9207,  0.7554, -1.7967,  ..., -0.0196,  0.7317,  0.2602],\n",
      "        [-1.2576,  0.6503, -0.7942,  ...,  1.4578, -0.7427, -2.9394]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0250,  0.2170,  0.4600,  ..., -0.2160,  1.2939,  0.6926],\n",
      "        [ 0.1463,  0.8941,  1.2185,  ...,  0.1290, -0.5495,  1.4123],\n",
      "        [ 0.6141,  0.5577,  0.9591,  ...,  0.4684,  1.8857,  1.4161],\n",
      "        ...,\n",
      "        [-0.7599, -0.1938, -1.1841,  ..., -1.1239, -0.4880,  0.6430],\n",
      "        [-1.5323, -0.4528, -0.1037,  ...,  0.4039,  0.1720, -0.6056],\n",
      "        [ 1.7392, -0.4609,  0.4342,  ...,  0.6245, -0.9338,  2.4294]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.3145e+00,  4.3273e-01,  9.2225e-01,  ...,  1.5134e+00,\n",
      "          2.9116e+00,  3.2235e-01],\n",
      "        [ 2.0485e-01,  7.2077e-04, -1.3558e-01,  ..., -1.0506e+00,\n",
      "          9.5165e-02,  8.5506e-01],\n",
      "        [ 3.2714e-01,  1.7379e+00, -8.3462e-01,  ..., -9.6306e-01,\n",
      "         -1.1286e+00,  1.5236e+00],\n",
      "        ...,\n",
      "        [-7.7781e-01,  4.7952e-01, -5.5131e-01,  ..., -1.1564e+00,\n",
      "          7.8139e-01, -1.8074e+00],\n",
      "        [ 1.1352e-02,  1.1547e+00,  9.6301e-01,  ..., -2.3785e+00,\n",
      "         -5.7756e-03,  5.4027e-01],\n",
      "        [ 6.5063e-01, -1.0778e+00,  1.3181e+00,  ...,  1.2839e-01,\n",
      "          3.5475e-01,  4.4338e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.3893, -1.3281, -0.1199,  ..., -0.3705, -0.0428,  0.6084],\n",
      "        [ 0.8272,  1.0451, -0.5855,  ...,  0.3057,  0.9723,  0.7475],\n",
      "        [ 0.5003, -1.0070,  0.2340,  ..., -0.4032, -0.8065, -0.4174],\n",
      "        ...,\n",
      "        [-0.4345,  0.3009, -0.7200,  ..., -0.6043, -0.7567, -0.0393],\n",
      "        [ 0.3345,  0.8744,  0.6015,  ..., -0.6753,  0.2134,  0.5739],\n",
      "        [ 0.3566,  0.2325, -0.0526,  ..., -0.7420, -1.7393, -0.4408]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0660, -0.0555, -1.3057,  ...,  0.7415,  0.4161, -0.6337],\n",
      "        [-0.0857, -1.1155, -0.5661,  ...,  1.5656, -0.7719, -1.6055],\n",
      "        [-0.0836, -0.0229,  1.1503,  ..., -1.4568, -1.0350,  0.2709],\n",
      "        ...,\n",
      "        [ 1.1138, -0.1743, -0.4995,  ...,  1.4806,  2.5405, -0.6585],\n",
      "        [-0.9719, -1.5157,  0.3279,  ...,  1.0399, -0.2774, -1.1464],\n",
      "        [ 0.4152,  0.7442, -0.6797,  ...,  0.1653, -0.2730,  0.0168]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.9878,  0.9633, -0.4217,  ...,  0.3130,  0.9925, -0.2549],\n",
      "        [ 0.7250, -0.4621,  0.3276,  ..., -0.3384,  0.8273, -0.4475],\n",
      "        [-1.2420, -1.6698, -1.6837,  ..., -0.4760, -0.5363,  0.1617],\n",
      "        ...,\n",
      "        [ 0.2281,  0.6637,  1.3985,  ..., -1.1539, -0.0053, -0.6021],\n",
      "        [-0.2685,  0.9115, -1.0735,  ..., -1.2211, -0.1803,  0.1134],\n",
      "        [-1.2792, -0.5552,  0.0926,  ..., -0.4423,  1.5368,  2.1323]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1368, -1.2188, -0.3519,  ..., -0.7541,  0.7402,  0.5226],\n",
      "        [ 1.3796,  0.6110,  0.0193,  ...,  1.2439, -0.9157, -0.0035],\n",
      "        [-0.9052,  0.0131, -1.1719,  ...,  0.0905,  0.3851,  0.0670],\n",
      "        ...,\n",
      "        [-0.5531, -0.9204, -1.8574,  ...,  0.5541, -0.6637, -0.7837],\n",
      "        [ 1.8908,  0.2499,  1.6873,  ..., -0.2619,  1.4547, -0.3907],\n",
      "        [-0.2325,  1.2197, -1.7530,  ...,  0.4891,  0.7319, -0.9705]]), 'y': tensor([[0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3988, -0.0877,  1.7473,  ...,  0.5012,  0.3958,  0.4364],\n",
      "        [ 1.3390,  1.1713, -0.8958,  ...,  2.0876,  0.0384, -0.3751],\n",
      "        [ 0.6093, -0.6471, -0.1440,  ..., -0.4257,  1.3806,  0.7462],\n",
      "        ...,\n",
      "        [ 1.2891,  1.7353,  0.0062,  ..., -1.4914, -1.4146, -0.6984],\n",
      "        [ 0.8874,  0.2170,  0.4899,  ...,  0.8629,  0.4472,  1.2306],\n",
      "        [ 0.6423,  0.8437,  0.6594,  ..., -0.7040, -1.1231, -1.6263]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.9388, -1.8142,  0.0158,  ..., -1.0131, -1.4265,  0.5617],\n",
      "        [-2.3679, -1.6582,  0.2369,  ..., -0.0469, -0.7678,  1.1157],\n",
      "        [ 0.7749, -0.4853,  0.7432,  ...,  0.0627, -0.2414,  0.8109],\n",
      "        ...,\n",
      "        [ 0.5650,  0.1910,  0.0819,  ...,  0.4939,  0.8026,  0.0117],\n",
      "        [ 1.1731,  0.6400, -1.4187,  ..., -0.9444, -0.5999, -0.5354],\n",
      "        [ 1.2199,  0.1594,  1.4801,  ...,  0.8500,  0.3430, -0.9474]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8796,  0.4182, -2.3714,  ..., -0.7777,  0.6415, -0.1432],\n",
      "        [ 0.8868, -1.4202, -0.2625,  ...,  0.9818, -0.2972,  0.6466],\n",
      "        [-0.2335, -0.8748, -1.6250,  ..., -0.5575,  0.4352, -1.9318],\n",
      "        ...,\n",
      "        [-0.4001,  0.1258, -1.0762,  ..., -0.7254, -1.4698, -0.9994],\n",
      "        [ 1.7569, -1.3604, -1.3599,  ...,  0.9607,  0.5492, -0.4593],\n",
      "        [ 0.8375, -1.0204,  0.1060,  ..., -0.3662,  0.8130, -0.3544]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-4.3954e-01, -7.0324e-01,  1.2670e+00,  ..., -1.2279e-03,\n",
      "         -4.0397e-01,  4.2006e-01],\n",
      "        [ 1.1558e+00,  1.6718e+00,  1.3176e+00,  ..., -9.5187e-02,\n",
      "         -1.0203e+00, -1.5475e+00],\n",
      "        [ 8.3725e-01, -8.5550e-02, -3.5985e-01,  ..., -9.6070e-01,\n",
      "          5.4268e-02,  2.8576e-01],\n",
      "        ...,\n",
      "        [-1.6873e+00, -2.8194e-01,  1.5282e+00,  ...,  6.2925e-01,\n",
      "          6.9218e-01,  5.1108e-04],\n",
      "        [ 5.6692e-01, -5.0122e-01,  8.5343e-01,  ..., -2.2381e-02,\n",
      "         -4.9925e-01, -1.3634e+00],\n",
      "        [ 3.6681e-01, -1.4335e-01, -1.4044e+00,  ..., -1.4914e+00,\n",
      "          4.2039e-01, -5.3242e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5219,  0.4566,  0.0538,  ...,  2.1306, -0.2475,  0.0978],\n",
      "        [ 0.1926,  0.2662,  0.7709,  ..., -0.4090,  0.6718, -1.3051],\n",
      "        [-1.2462, -0.0913, -2.4065,  ..., -0.0501, -1.3962, -0.1469],\n",
      "        ...,\n",
      "        [ 0.6851,  2.3333, -0.6135,  ...,  0.2883,  0.9923,  2.5650],\n",
      "        [ 0.3513,  1.1369, -0.2018,  ..., -0.7117,  0.8352,  1.3586],\n",
      "        [ 1.9909, -2.4405,  0.8232,  ..., -0.6544, -1.0449,  0.4000]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4752,  2.2505, -1.2391,  ..., -0.0608, -0.5069,  1.7188],\n",
      "        [ 0.1718, -0.1474, -0.7780,  ...,  1.1336,  0.9684, -0.4833],\n",
      "        [ 1.3474,  2.0001, -0.8535,  ..., -1.2100,  0.0261,  0.4177],\n",
      "        ...,\n",
      "        [ 2.1456, -1.1352,  1.1185,  ..., -0.3444,  0.0793, -0.3980],\n",
      "        [-0.5663,  0.7491,  0.9469,  ...,  0.0222, -1.0794,  0.3889],\n",
      "        [ 0.6314, -1.2336, -0.3288,  ...,  0.2116, -1.5223, -2.4641]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0040, -0.9394, -0.2623,  ...,  0.4675, -0.3987, -0.0178],\n",
      "        [ 0.1816,  0.6634, -1.0789,  ..., -1.2809,  1.2750,  0.2107],\n",
      "        [-0.3685, -0.3904,  1.0943,  ..., -0.2985, -0.9164, -1.5021],\n",
      "        ...,\n",
      "        [-1.7223, -0.9057, -0.2081,  ..., -0.9631,  0.4711,  0.0429],\n",
      "        [ 0.5626, -0.4009,  0.6783,  ..., -0.4284, -0.7799,  1.1670],\n",
      "        [ 0.0561, -1.1458, -0.6264,  ...,  1.1205, -0.8831, -1.1297]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.7822, -0.0607,  1.0997,  ...,  0.8904,  0.0809, -1.1082],\n",
      "        [ 0.2997,  0.0316,  0.6309,  ..., -1.0068, -0.1956, -1.1706],\n",
      "        [-0.4324, -0.1133,  1.7083,  ...,  0.3658,  0.4350, -0.6798],\n",
      "        ...,\n",
      "        [-2.1351, -1.9809, -0.8373,  ...,  1.4712, -0.6088,  0.8451],\n",
      "        [ 1.3382, -1.2347,  0.6870,  ..., -0.7579, -1.4694, -1.0303],\n",
      "        [ 0.0309,  0.2071, -0.1188,  ..., -1.1714,  0.8800,  0.8330]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2677, -0.0375, -1.3993,  ..., -0.5470, -0.0213,  1.9768],\n",
      "        [ 0.6915, -0.3108,  0.3552,  ..., -0.1134,  0.1341, -1.4488],\n",
      "        [ 1.0372,  0.8154, -0.5316,  ..., -0.4557,  1.3555, -0.2325],\n",
      "        ...,\n",
      "        [ 1.2240, -0.3865, -0.5112,  ..., -1.0451, -1.3155, -0.3052],\n",
      "        [-0.0514, -2.3650,  1.4314,  ..., -1.5606,  0.7435,  2.0339],\n",
      "        [-1.3445, -1.2467, -1.5490,  ..., -0.4746, -0.0642,  0.0973]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2744,  1.2593, -0.3836,  ..., -1.4237, -0.4269, -0.7993],\n",
      "        [ 1.3766, -0.5952, -0.1746,  ..., -0.0858,  1.5795,  0.4878],\n",
      "        [-0.1484, -1.3887,  1.5605,  ..., -0.9188, -1.0300, -0.9061],\n",
      "        ...,\n",
      "        [ 0.1960, -0.2561,  0.5224,  ..., -0.2595,  0.3755,  1.6480],\n",
      "        [ 0.1360,  0.7707,  0.2178,  ..., -0.2386, -0.3949,  0.0926],\n",
      "        [-1.4774,  0.0377, -0.7528,  ...,  0.4285, -0.4413,  0.5222]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2131,  0.4706, -1.0923,  ...,  1.3850, -0.0542, -1.1097],\n",
      "        [-0.8328, -0.3877, -0.2979,  ...,  1.3897,  2.4941, -1.9773],\n",
      "        [-1.8156,  0.2235,  0.1827,  ..., -1.6277,  1.5565, -0.2853],\n",
      "        ...,\n",
      "        [ 0.0030,  1.1456, -0.6876,  ..., -0.1015,  0.4066, -0.2100],\n",
      "        [-0.7475, -1.1375,  0.5352,  ..., -1.0730, -1.7921,  0.7484],\n",
      "        [ 0.5713,  0.9379, -1.0125,  ...,  0.8059,  1.8004, -0.0753]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1560, -1.6075, -0.1832,  ...,  0.6398, -0.2698,  0.7253],\n",
      "        [ 0.2256,  1.2835, -0.6308,  ...,  0.2894, -0.6983, -0.6794],\n",
      "        [ 0.0561, -0.4292, -0.9453,  ..., -1.3544, -0.0915, -2.0625],\n",
      "        ...,\n",
      "        [ 1.2590,  1.6413, -1.7351,  ..., -0.9987,  0.9012,  0.9509],\n",
      "        [-1.0680, -0.7822, -2.0164,  ..., -1.6426, -0.3839,  2.1064],\n",
      "        [-1.3973, -0.8016, -0.1249,  ...,  0.4274, -0.4179, -0.3738]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9600, -0.0481,  0.9449,  ...,  1.4201,  0.4419, -0.4997],\n",
      "        [-0.5237, -0.8698, -0.9534,  ..., -1.2185, -1.6856, -1.6922],\n",
      "        [-1.6867, -0.6154,  1.1344,  ..., -0.8456, -0.0124, -0.1770],\n",
      "        ...,\n",
      "        [-1.3759,  0.9823, -1.2724,  ..., -0.0405,  1.3786,  0.7915],\n",
      "        [-0.1922, -0.5003, -1.1928,  ...,  0.6359, -0.4422, -2.1805],\n",
      "        [ 0.0391, -0.4948,  1.0148,  ...,  0.3713,  0.9012, -0.0813]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2924,  2.1222, -0.7203,  ...,  4.3719, -0.4598, -0.3703],\n",
      "        [ 1.2396, -0.2951, -1.7020,  ..., -0.5354,  1.2190,  1.2199],\n",
      "        [ 0.5136, -0.0624,  0.6873,  ...,  0.1675, -1.1506, -0.0121],\n",
      "        ...,\n",
      "        [-0.5909, -1.2167,  0.9879,  ..., -0.8695,  0.8744, -0.1566],\n",
      "        [ 0.2671,  0.3294, -0.2724,  ...,  0.1191,  0.3545, -0.4458],\n",
      "        [-0.8029,  0.5004,  0.1309,  ..., -0.1417,  1.9613, -2.4223]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5071,  0.9058, -0.9773,  ...,  2.0295, -0.4877,  0.5506],\n",
      "        [ 2.0190, -0.0874,  2.3403,  ...,  0.0754, -0.5158, -0.8609],\n",
      "        [-0.8225, -0.1622, -0.2456,  ..., -1.4528, -0.2336, -0.8254],\n",
      "        ...,\n",
      "        [ 0.8339,  0.0294,  0.2423,  ..., -0.3634, -2.0806,  1.6780],\n",
      "        [ 0.7052,  0.7963,  0.0560,  ...,  0.6533,  0.2253,  0.0406],\n",
      "        [-0.5507, -1.3424, -0.2437,  ...,  0.2843,  0.4467,  0.3617]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 2.0963, -2.3535,  0.8413,  ...,  1.7409, -0.4931,  0.3136],\n",
      "        [ 1.5265, -2.2395,  0.7863,  ..., -0.9701,  1.3611,  0.7498],\n",
      "        [ 0.4418,  0.5083,  1.1085,  ..., -0.5358, -1.1511,  0.0095],\n",
      "        ...,\n",
      "        [ 1.4951, -0.2561, -0.8236,  ..., -1.4453,  0.3187, -0.5205],\n",
      "        [-2.3333, -0.4137,  1.4800,  ...,  0.3008,  1.4398, -2.0270],\n",
      "        [ 0.0815, -0.5162,  1.1317,  ...,  1.5617,  0.6457, -0.2618]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3764, -0.5981,  0.2221,  ..., -0.7111, -1.5314,  1.1019],\n",
      "        [ 2.0625, -0.0287, -0.5306,  ..., -0.8786,  0.5627,  1.4483],\n",
      "        [-0.2705, -0.8942,  1.4582,  ..., -0.0181,  0.4327, -0.3786],\n",
      "        ...,\n",
      "        [-0.0940,  1.1050,  0.0735,  ...,  0.1449,  0.3186,  1.8539],\n",
      "        [-0.7537,  1.4603, -0.1497,  ...,  0.4715, -0.6061,  1.5717],\n",
      "        [ 0.9876,  0.9348, -0.7615,  ...,  0.8481,  1.5993,  0.8824]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3719, -1.5014,  0.6034,  ..., -0.5439,  1.1063, -0.1814],\n",
      "        [-2.3143,  0.3186,  0.2704,  ...,  1.1136, -1.1656, -1.5140],\n",
      "        [-0.5220,  2.2643,  0.1431,  ...,  0.9569, -0.3111, -1.5677],\n",
      "        ...,\n",
      "        [ 0.8040,  0.0257,  1.9143,  ...,  0.5385, -0.5061,  0.8218],\n",
      "        [-0.4741,  0.2764, -0.7213,  ...,  0.3075,  1.4090, -0.0645],\n",
      "        [ 0.6989,  0.6996, -1.6594,  ...,  1.4271,  1.7807,  0.9179]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6190,  0.8716,  0.2730,  ...,  1.0834,  0.5485,  1.5041],\n",
      "        [ 0.8164, -0.4757, -1.2499,  ..., -1.8358, -0.9433, -0.9204],\n",
      "        [-0.6533,  0.3290,  0.6292,  ...,  0.8851, -0.9999,  0.0034],\n",
      "        ...,\n",
      "        [-0.6982,  0.7957,  0.5527,  ..., -1.3161, -0.1296,  0.3994],\n",
      "        [ 1.1385,  0.1813,  0.1464,  ..., -0.6808, -0.4976,  2.2089],\n",
      "        [ 0.3663,  1.3166,  2.3612,  ..., -0.7857,  0.6955, -0.5849]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3276, -0.4566,  0.2201,  ..., -1.1766, -0.2678,  0.8246],\n",
      "        [ 0.6537, -0.4594,  1.1135,  ...,  1.6309,  0.7703,  0.6281],\n",
      "        [-2.3597,  0.2346,  0.2596,  ...,  1.0020, -0.7368,  1.2586],\n",
      "        ...,\n",
      "        [ 1.1729, -0.1118,  1.2152,  ...,  0.8034, -1.4679, -0.1932],\n",
      "        [ 0.7586, -0.4741,  0.7362,  ..., -0.2317, -1.8676,  1.8647],\n",
      "        [-1.1870,  0.4677,  0.0103,  ...,  0.7733, -1.2838, -1.0036]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.0300,  0.6212, -0.7595,  ..., -0.2691, -0.1171, -0.8856],\n",
      "        [ 0.4148,  0.6933,  0.5631,  ...,  0.7655, -0.1499,  2.6115],\n",
      "        [-0.4901, -0.5918, -0.0912,  ..., -0.8987,  1.2366,  0.6844],\n",
      "        ...,\n",
      "        [-0.5059, -0.8106,  1.6841,  ...,  1.0730, -1.0689,  0.8574],\n",
      "        [-0.3476, -0.6757, -0.3259,  ..., -1.3965,  0.3059, -0.4083],\n",
      "        [-0.8181, -0.4133,  0.4095,  ..., -0.0946,  0.1763, -0.5688]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4113, -0.4861,  0.5205,  ..., -0.4825,  0.5071, -1.4801],\n",
      "        [ 1.2447,  0.8526,  0.1547,  ...,  1.6634,  0.9414,  0.3842],\n",
      "        [-2.3812, -1.4927,  0.6233,  ..., -0.4516, -0.1775, -0.6119],\n",
      "        ...,\n",
      "        [-0.1534,  0.1811,  0.9236,  ...,  0.9195,  1.3598,  0.3723],\n",
      "        [ 0.8876, -0.1218,  0.0962,  ...,  0.7184, -0.0880,  0.0742],\n",
      "        [-0.2948, -0.1045,  0.9940,  ..., -0.7115,  0.8473, -1.7339]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.6475,  1.1887, -0.6443,  ..., -0.7016, -0.0591,  0.7738],\n",
      "        [ 0.3106, -0.7456, -0.6030,  ...,  0.2006, -2.6985,  0.9332],\n",
      "        [-0.9884,  0.7756,  1.2092,  ..., -1.0022,  1.3620, -1.0663],\n",
      "        ...,\n",
      "        [ 0.4444, -0.2824,  1.8617,  ...,  0.7030,  0.1367,  0.5737],\n",
      "        [ 0.1352,  0.1410,  1.0401,  ...,  0.5785,  0.8513, -0.0894],\n",
      "        [ 0.1914, -0.2153, -0.6191,  ...,  0.2551,  0.0532,  0.3441]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0637, -0.2746, -0.3162,  ..., -0.6195, -0.4904, -2.6048],\n",
      "        [-1.2101, -0.9315,  0.8875,  ..., -1.0109, -0.2318, -0.7670],\n",
      "        [-0.0782,  0.4672,  1.4892,  ..., -0.7928, -1.6368, -1.4083],\n",
      "        ...,\n",
      "        [-1.1333,  1.1162, -2.3734,  ..., -0.9308, -0.8078,  0.1016],\n",
      "        [ 0.7470, -1.2377,  0.8167,  ...,  1.1018, -0.5599, -0.5753],\n",
      "        [-1.6301,  2.3433, -1.5720,  ...,  2.4283,  1.9874, -0.4040]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0752, -0.9305,  0.7868,  ...,  0.7176,  1.3537,  0.2095],\n",
      "        [ 1.0156,  1.1412,  0.8424,  ..., -1.1239, -3.7314, -1.5869],\n",
      "        [-0.4935, -0.6833, -0.2899,  ..., -0.9593, -0.5476,  0.6476],\n",
      "        ...,\n",
      "        [-0.6189, -0.4908, -0.3304,  ...,  0.9719, -1.8452,  0.3478],\n",
      "        [-0.4637,  0.8488,  0.9660,  ...,  0.1935,  1.9841,  1.1293],\n",
      "        [-2.3982, -1.4510, -0.3289,  ..., -4.2525, -0.5033, -1.6284]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.6548,  0.2670, -2.3663,  ..., -0.7176, -1.2831,  0.0369],\n",
      "        [-1.1727,  0.4419,  0.1386,  ..., -0.0987,  0.7178,  0.0847],\n",
      "        [-0.1706, -0.8625,  0.0596,  ..., -0.1162,  0.2064,  0.2321],\n",
      "        ...,\n",
      "        [ 0.3376,  0.4009,  2.3226,  ...,  1.4261, -2.5723,  1.0652],\n",
      "        [ 0.4969,  0.8817, -2.4760,  ...,  0.1216,  1.8300,  0.3200],\n",
      "        [ 0.7788,  1.4588, -0.4946,  ...,  0.5051, -1.3910, -0.3559]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 7.8441e-01,  4.2266e-01,  1.7544e+00,  ..., -2.4944e-01,\n",
      "          7.3872e-02, -8.0230e-01],\n",
      "        [-4.5349e-02, -8.2792e-01, -4.3014e-01,  ...,  8.3253e-01,\n",
      "          7.7420e-04,  1.0595e+00],\n",
      "        [ 7.0211e-01, -1.2454e+00, -1.5224e-01,  ...,  3.7509e-01,\n",
      "         -3.0145e-01, -3.9595e-01],\n",
      "        ...,\n",
      "        [ 1.5895e+00, -6.4613e-01,  8.9415e-01,  ...,  8.4710e-01,\n",
      "         -1.5185e+00, -1.4150e+00],\n",
      "        [-5.6507e-01, -7.9158e-01, -1.4498e+00,  ..., -1.1543e+00,\n",
      "         -1.0914e-01, -2.0832e+00],\n",
      "        [ 2.4562e+00, -2.4620e+00,  2.2289e-01,  ...,  8.2483e-01,\n",
      "         -1.3248e+00, -9.3416e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.5621,  1.4913,  1.2756,  ..., -0.4047,  0.1412, -1.3512],\n",
      "        [ 0.5073, -0.6200,  0.0976,  ..., -0.1236,  2.0367,  0.3534],\n",
      "        [-0.8449, -1.0064,  0.2448,  ..., -1.0160,  0.5836,  0.5315],\n",
      "        ...,\n",
      "        [-0.6516, -0.4873, -0.9441,  ..., -0.5525,  0.2189,  0.6543],\n",
      "        [-0.9813, -1.2373, -0.2883,  ...,  1.3000, -0.1356, -1.4017],\n",
      "        [ 0.2897,  1.8782, -1.0284,  ..., -0.0597,  0.3650,  1.6395]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0429, -0.0848,  1.5445,  ..., -1.1199, -0.9992,  0.0991],\n",
      "        [-1.2235, -1.3185, -0.5891,  ...,  0.0394,  0.6312, -1.3850],\n",
      "        [ 0.4183,  0.5003, -0.1391,  ..., -1.1520,  1.0735,  0.9346],\n",
      "        ...,\n",
      "        [ 1.1094, -0.8609, -0.2534,  ...,  0.1480,  0.6560, -1.8128],\n",
      "        [ 1.5597, -0.7315, -0.6583,  ..., -0.2023,  1.3323, -0.1138],\n",
      "        [ 1.1073,  0.3188,  0.6353,  ..., -0.4483, -0.1277,  0.4551]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1735, -0.0338, -0.7467,  ..., -0.3284,  0.5215,  0.5433],\n",
      "        [-1.3615, -0.3750,  0.4168,  ...,  0.8820, -0.5630, -0.0524],\n",
      "        [ 1.6031,  1.0274,  0.8759,  ...,  2.4890,  0.8472,  0.0284],\n",
      "        ...,\n",
      "        [ 0.0699, -0.7729,  0.5040,  ...,  1.1714,  1.3628,  0.6861],\n",
      "        [ 1.6919,  1.7406,  1.1941,  ...,  0.9208, -0.3163, -0.2665],\n",
      "        [-1.4781,  0.3610, -0.9741,  ..., -0.1536,  0.6975, -0.8857]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9055,  0.8227,  0.7601,  ..., -1.0796, -0.8025,  0.3097],\n",
      "        [-2.3466, -0.5560,  1.1042,  ...,  0.1396, -0.7268,  1.0902],\n",
      "        [ 0.0201, -0.3544, -0.8034,  ...,  0.3568,  0.2104, -0.1846],\n",
      "        ...,\n",
      "        [-0.4978,  0.8104, -1.2232,  ..., -0.5922,  1.3541,  0.0798],\n",
      "        [ 0.7421,  0.1949, -1.2753,  ..., -1.1436, -1.0228, -0.2449],\n",
      "        [ 0.3780, -0.1351,  1.4246,  ..., -1.5951, -1.0666,  2.6902]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4660,  0.8671, -0.2224,  ..., -0.8168,  1.1793, -0.4708],\n",
      "        [ 0.2687,  1.1653, -1.1670,  ..., -1.7635, -0.2629,  1.5948],\n",
      "        [-1.5126,  0.0688,  1.1471,  ..., -0.0861, -1.7853,  0.1876],\n",
      "        ...,\n",
      "        [-0.4845, -0.1783, -1.4365,  ..., -0.5450, -0.0978, -0.0165],\n",
      "        [-0.6309,  0.4448,  0.3933,  ..., -0.1682, -1.5744,  1.0715],\n",
      "        [ 0.8129,  1.1233, -0.6109,  ...,  0.0218,  0.7709, -1.5717]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0017e+00,  2.6254e-01, -3.3527e-02,  ..., -5.2322e-01,\n",
      "          6.9678e-01,  5.4094e-01],\n",
      "        [ 2.5378e-01,  1.0023e+00, -9.4640e-01,  ...,  9.3260e-01,\n",
      "          1.5538e+00, -7.0030e-01],\n",
      "        [ 1.0355e+00,  1.6938e+00, -3.8933e-01,  ..., -3.7206e-01,\n",
      "         -1.4849e+00,  4.9363e-01],\n",
      "        ...,\n",
      "        [-1.2046e+00,  6.6654e-02, -1.2740e+00,  ..., -9.4917e-01,\n",
      "         -8.9059e-01, -6.9163e-01],\n",
      "        [ 9.7362e-01, -2.1742e-01,  1.9849e+00,  ..., -1.5799e+00,\n",
      "         -2.0397e-01,  1.2456e+00],\n",
      "        [-1.3887e+00,  7.2077e-04, -8.7565e-01,  ...,  1.7023e-01,\n",
      "          2.6932e-01, -1.7840e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2833e+00, -1.7354e+00,  7.6240e-01,  ..., -2.9144e-01,\n",
      "         -1.2088e+00, -5.7735e-04],\n",
      "        [-7.5123e-01, -3.7161e-01,  3.0868e-01,  ..., -4.2216e-02,\n",
      "         -9.5041e-01, -5.9600e-03],\n",
      "        [ 1.4728e+00,  6.9485e-02,  3.4467e-02,  ...,  5.5503e-01,\n",
      "         -1.7125e+00, -1.2797e+00],\n",
      "        ...,\n",
      "        [-1.4373e+00,  8.0112e-01,  4.4711e-01,  ..., -1.8247e+00,\n",
      "          6.7337e-01, -9.5981e-01],\n",
      "        [ 2.0712e+00,  1.4309e+00,  1.9493e+00,  ..., -9.7268e-01,\n",
      "          6.7132e-01,  1.0165e+00],\n",
      "        [ 7.4431e-01, -3.0666e-01, -6.9158e-01,  ...,  4.7471e-01,\n",
      "          1.0490e+00, -1.1777e+00]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.8665,  1.3173, -0.1015,  ...,  0.7807, -1.5467,  0.2564],\n",
      "        [ 2.6554,  2.2191,  1.5570,  ...,  1.3089, -0.2231,  0.7636],\n",
      "        [ 1.6572,  2.4304,  0.9376,  ..., -0.1160,  0.2341, -2.2461],\n",
      "        ...,\n",
      "        [ 1.0423,  1.5508,  1.1302,  ...,  0.5412, -0.9660, -1.2521],\n",
      "        [-1.6738, -0.4871,  1.2966,  ...,  0.5933, -1.6358, -1.7700],\n",
      "        [-0.3885,  0.3143, -0.9739,  ...,  0.7738,  0.6620, -0.2561]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.9870,  0.2946,  0.0571,  ...,  0.8026, -0.1515,  2.5310],\n",
      "        [ 0.4455, -0.6407, -0.4693,  ...,  0.0849, -0.5898, -1.6979],\n",
      "        [ 0.2171,  0.5169, -0.3864,  ..., -1.5477,  0.0230, -0.7331],\n",
      "        ...,\n",
      "        [ 0.4368, -0.7271,  1.4696,  ...,  1.0311, -1.8678, -0.6516],\n",
      "        [-1.8482,  1.2340,  0.1061,  ..., -2.2702, -0.5260, -0.4970],\n",
      "        [-0.0346, -1.1897, -0.9276,  ...,  1.6530, -0.4194, -0.4405]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5120, -0.4357,  0.3104,  ..., -2.1146, -0.2895,  0.6165],\n",
      "        [-0.4509, -0.0870, -0.1335,  ..., -0.1716, -0.6626, -1.5592],\n",
      "        [ 0.2801, -1.3894, -0.4308,  ...,  0.2934, -0.3527,  0.4827],\n",
      "        ...,\n",
      "        [ 1.3426,  1.9558, -0.3861,  ..., -0.6682,  0.2402,  1.2382],\n",
      "        [-2.5181,  1.7618,  1.0290,  ..., -0.4339,  1.0296,  1.1535],\n",
      "        [-0.5369, -1.4683, -0.3009,  ..., -0.7290,  0.9783, -0.4387]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0770, -1.3755,  1.3026,  ...,  0.7888,  0.0186,  0.6296],\n",
      "        [-1.3561,  0.3946, -0.2081,  ..., -0.6492, -0.9485, -0.5372],\n",
      "        [ 0.1332,  0.7441,  1.5593,  ..., -0.1773, -0.7555,  0.7569],\n",
      "        ...,\n",
      "        [-2.0320, -1.0386,  0.9214,  ...,  0.5724,  0.9484, -0.5319],\n",
      "        [ 0.9041, -0.1440, -0.2935,  ..., -1.0082, -2.2871,  0.1807],\n",
      "        [ 0.9264,  1.1088,  1.0552,  ..., -0.5063,  0.4269,  0.4950]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4083, -1.4870,  1.3778,  ..., -0.5411,  0.8860,  1.0771],\n",
      "        [ 0.8330,  1.8510,  0.1567,  ...,  0.7473, -0.5250,  0.6516],\n",
      "        [-0.6801,  0.1570, -0.0514,  ..., -1.2229, -0.1790, -1.2429],\n",
      "        ...,\n",
      "        [-1.9423, -1.4683,  0.7470,  ..., -0.1777, -0.2513, -1.9108],\n",
      "        [ 0.4373,  0.8842, -0.0045,  ...,  0.0676,  0.6338, -0.2413],\n",
      "        [-0.0890,  0.0804,  1.0092,  ...,  0.7864, -1.4419,  0.5235]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2120, -0.3491,  0.4278,  ..., -0.3791, -0.1898, -0.0428],\n",
      "        [-0.6877,  0.8673,  0.0456,  ..., -0.4336, -1.5166,  0.2360],\n",
      "        [ 0.1052,  0.3513, -0.5811,  ..., -1.9433, -1.0885,  0.2948],\n",
      "        ...,\n",
      "        [ 0.3720,  1.2414,  0.8234,  ...,  1.1538,  1.3116, -0.6475],\n",
      "        [ 2.3370,  1.6257,  0.3500,  ...,  1.5806,  2.5478, -0.7292],\n",
      "        [ 0.1447,  0.8654,  0.6421,  ..., -0.8917, -1.4185, -0.3672]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.6283,  0.7603,  0.0299,  ...,  0.9547, -0.9825, -0.3768],\n",
      "        [-0.6789,  0.3155,  0.1051,  ...,  0.4540,  1.1405, -0.9770],\n",
      "        [-0.7338, -0.1405, -0.9849,  ..., -0.4746,  0.6207, -0.0091],\n",
      "        ...,\n",
      "        [-1.5579,  0.2594, -1.3997,  ...,  0.2886, -0.1387,  0.4993],\n",
      "        [-0.6351, -1.0113, -0.2617,  ...,  0.0891, -0.1397, -0.1412],\n",
      "        [-0.4655,  0.2634,  1.2393,  ...,  0.4801, -2.4573, -1.1900]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1968,  0.3781,  1.6374,  ...,  0.3159,  0.7896, -0.6623],\n",
      "        [ 0.8504,  0.4470, -1.0832,  ...,  0.1149, -0.4406,  0.7927],\n",
      "        [ 0.5386, -0.7538, -0.8372,  ..., -1.8144,  1.0742,  0.1667],\n",
      "        ...,\n",
      "        [ 0.2154, -1.3228,  1.7119,  ..., -0.4864, -1.1707,  0.5196],\n",
      "        [-0.5382,  1.3254,  1.1048,  ..., -0.9286, -1.6286,  0.4730],\n",
      "        [-0.2412,  0.8660, -0.3379,  ..., -1.0308, -0.6533, -1.4095]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7590, -1.3377,  0.9469,  ..., -0.9724, -0.6266,  1.5765],\n",
      "        [-0.2166,  2.0432,  0.8430,  ..., -1.0415, -1.2663, -0.6262],\n",
      "        [ 0.0254, -0.2694, -1.0716,  ..., -0.9684, -0.4286,  0.5718],\n",
      "        ...,\n",
      "        [-0.4050, -0.2381, -0.1734,  ...,  0.3707,  1.1589, -1.2582],\n",
      "        [-0.0658,  0.9187, -2.4170,  ..., -0.7002, -0.8691, -0.7276],\n",
      "        [ 0.0466, -0.2092,  1.1763,  ..., -0.7668, -1.0395,  0.3420]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5796, -1.5642, -0.3984,  ...,  0.4961, -3.9182, -0.6665],\n",
      "        [-0.6767,  0.1985, -0.4602,  ...,  0.4293, -0.6129,  0.7476],\n",
      "        [-0.5535, -1.4804, -0.7808,  ..., -0.3027,  0.9515,  0.9066],\n",
      "        ...,\n",
      "        [-0.9302,  0.4697, -1.8364,  ...,  0.0119, -0.5908, -0.0105],\n",
      "        [-0.3733,  0.5375, -0.1114,  ...,  0.6038, -0.7375,  1.0528],\n",
      "        [ 1.5406, -0.8295, -0.0814,  ..., -0.8783,  1.6042,  0.9996]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.7226, -0.0252, -0.7651,  ..., -0.2124, -0.2232,  0.0970],\n",
      "        [ 1.0999,  1.3580, -1.2269,  ...,  1.3028,  1.1327, -0.3086],\n",
      "        [ 0.7723,  1.3027, -0.2462,  ...,  0.5173, -0.2490,  0.4725],\n",
      "        ...,\n",
      "        [ 0.2159, -2.0105,  1.1035,  ...,  0.6957,  1.1942, -0.1925],\n",
      "        [-0.5181,  1.0105, -2.0640,  ...,  0.2281, -0.4565,  0.9668],\n",
      "        [ 0.2004,  0.0248, -1.8251,  ..., -0.7605,  0.6579, -0.8925]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.1196, -0.6850,  0.2937,  ...,  0.5816, -1.1747,  1.2558],\n",
      "        [-0.2398, -1.5870, -0.7185,  ..., -1.2431, -0.1305,  0.4440],\n",
      "        [ 2.1190, -1.3602,  0.6566,  ..., -0.7016, -1.0597, -0.6146],\n",
      "        ...,\n",
      "        [ 0.9458,  0.6722, -0.8936,  ...,  1.3459, -0.0046,  0.0615],\n",
      "        [ 0.1743,  0.2429,  0.1824,  ..., -0.5916,  0.6461, -0.1722],\n",
      "        [ 0.6105, -0.4542, -0.8394,  ..., -1.7967,  1.2918, -1.1069]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9368, -0.4674,  0.4643,  ...,  1.2387, -1.6015,  0.2338],\n",
      "        [ 0.0327,  0.4125,  1.5653,  ..., -0.9088, -0.1686, -0.3231],\n",
      "        [ 0.1599, -0.6400, -0.4899,  ..., -0.0168, -0.8816, -0.5025],\n",
      "        ...,\n",
      "        [ 0.8146,  0.7975,  1.7609,  ..., -0.6560,  0.7683,  0.6027],\n",
      "        [ 0.4771,  0.7907,  0.9235,  ...,  0.2453,  0.6671,  1.5495],\n",
      "        [-0.9403,  1.1262, -0.8414,  ...,  0.5042,  0.2097, -0.3589]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2878, -1.1829, -1.3064,  ..., -0.7524,  1.4860, -0.3014],\n",
      "        [-0.4490,  0.3160,  0.7728,  ...,  1.3156,  0.2861, -0.5668],\n",
      "        [-0.6170,  0.6615, -0.3174,  ..., -0.1205,  1.3355,  0.1312],\n",
      "        ...,\n",
      "        [-2.2994, -1.1867, -0.4097,  ...,  1.6087, -1.3344, -1.9635],\n",
      "        [-0.1741, -0.9435,  0.4179,  ..., -1.3752,  0.9597,  0.2117],\n",
      "        [-0.7816, -1.0381,  0.9418,  ...,  0.6937,  0.4896,  0.6321]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 2.0195,  0.3606, -0.2227,  ...,  0.9081, -2.1463,  0.0287],\n",
      "        [-0.1473, -1.6129,  0.2605,  ..., -0.3065, -0.2412,  0.9210],\n",
      "        [-1.8533,  2.3432,  1.1629,  ..., -1.9882,  0.2351,  0.9386],\n",
      "        ...,\n",
      "        [-0.4661, -0.3011, -0.2130,  ...,  0.1976,  0.2327, -1.4821],\n",
      "        [ 0.3527, -0.1064, -0.3347,  ..., -0.2326,  0.8766,  0.7959],\n",
      "        [ 1.4362, -1.0781,  0.2551,  ...,  1.9303, -0.4321,  0.0286]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6076,  1.6460,  0.2274,  ..., -0.4508, -0.0811, -1.5765],\n",
      "        [-0.1858,  0.8798, -0.0602,  ...,  0.2788, -0.9721, -0.6738],\n",
      "        [ 0.8428,  1.6424, -0.2699,  ...,  1.4921,  0.0783,  1.0476],\n",
      "        ...,\n",
      "        [ 0.3095,  0.2412,  0.3049,  ...,  0.6587, -0.4453,  0.5787],\n",
      "        [ 0.4538, -1.7307,  0.1269,  ...,  3.1583,  0.3489, -2.4225],\n",
      "        [-0.4073, -0.9545, -0.3192,  ...,  1.6224, -1.9600, -1.2899]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0545,  0.6718,  1.8860,  ..., -1.5128, -0.3715, -0.9717],\n",
      "        [-1.6010,  0.9124,  0.6649,  ..., -1.0479,  0.5914, -0.3270],\n",
      "        [-0.2355,  1.4733,  0.2396,  ..., -0.0638, -0.0864, -0.4150],\n",
      "        ...,\n",
      "        [ 0.4249, -1.0157, -0.1354,  ..., -0.2726, -2.1988,  0.7777],\n",
      "        [ 0.8232, -1.6749, -0.9092,  ..., -0.9734, -1.8837,  2.6225],\n",
      "        [ 1.0682,  0.3217,  1.4246,  ..., -0.8461, -0.2348,  0.6029]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2045,  0.5673, -0.0179,  ..., -1.5558,  0.1591, -0.0536],\n",
      "        [-0.1694,  0.3892, -0.9548,  ..., -0.1761, -0.2477, -0.1423],\n",
      "        [-0.6205, -1.0634,  0.8210,  ...,  0.0403,  0.0369, -0.1460],\n",
      "        ...,\n",
      "        [-0.9245,  0.2588,  1.1057,  ...,  0.0929, -0.5649,  0.2624],\n",
      "        [-0.2592, -0.4823, -0.0315,  ...,  0.1737,  0.6379,  2.1932],\n",
      "        [ 0.0282, -1.0264, -0.5919,  ...,  0.8253,  1.0784,  0.7438]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3899, -0.1511,  0.7846,  ..., -0.0497, -1.6490, -1.5015],\n",
      "        [-0.9816, -0.8755,  0.1303,  ..., -2.2862, -0.4412,  0.9425],\n",
      "        [ 0.7091,  1.1804, -0.0717,  ..., -2.8685,  0.4882, -1.1225],\n",
      "        ...,\n",
      "        [ 0.1636,  0.0998, -0.0407,  ..., -0.3313, -0.2459, -0.5602],\n",
      "        [ 0.5748,  0.5472,  0.3556,  ...,  0.3068,  0.0986, -1.1592],\n",
      "        [-0.0275,  0.7277,  1.2298,  ...,  0.8860, -1.9275,  1.1100]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3994,  0.6640,  0.8315,  ...,  1.3202, -0.8348, -0.2674],\n",
      "        [-2.0060,  0.4388, -1.1604,  ..., -0.4084,  0.7281, -1.0925],\n",
      "        [ 0.0849,  1.4105, -0.6911,  ...,  0.9552, -0.3021, -0.0142],\n",
      "        ...,\n",
      "        [ 1.3987,  0.5590,  0.9802,  ...,  0.8914,  0.3632, -0.5004],\n",
      "        [-0.5663, -0.3992, -0.4119,  ...,  1.8835, -0.7661,  1.1884],\n",
      "        [-1.3056, -0.9102, -0.1184,  ..., -0.9329,  0.2929,  0.6917]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.3081,  0.4960, -0.7138,  ..., -0.3040, -1.7528,  0.2639],\n",
      "        [ 1.7969, -1.8820,  0.7039,  ...,  1.0794, -0.6022,  1.4185],\n",
      "        [-0.2730,  1.6019, -0.0315,  ..., -0.3109, -0.3781,  0.9700],\n",
      "        ...,\n",
      "        [-0.3254,  0.2148,  0.1409,  ...,  0.8194,  0.7203, -0.4364],\n",
      "        [ 1.9030,  2.2779, -0.2579,  ..., -0.7558, -1.4754,  0.7692],\n",
      "        [ 1.2415,  0.3807,  1.0104,  ..., -1.7021,  1.2023, -0.2550]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2169, -0.0246,  0.4937,  ..., -0.6932,  2.3099,  1.8645],\n",
      "        [ 1.7124, -0.8319,  0.5717,  ..., -0.5619, -0.4457, -0.7092],\n",
      "        [-0.4423,  2.5143,  0.6842,  ..., -0.3158, -1.2967,  0.6540],\n",
      "        ...,\n",
      "        [-0.8663,  0.5190,  0.9517,  ..., -0.0439, -0.5998, -2.7752],\n",
      "        [ 0.6567, -2.0909, -0.4053,  ..., -0.3603,  0.1967,  1.3098],\n",
      "        [ 1.3281,  0.4037, -0.9636,  ..., -0.4344, -3.6826,  2.4080]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4066, -1.5844,  0.8954,  ..., -1.4335, -0.0431,  1.3820],\n",
      "        [-1.4112, -0.4399, -1.6114,  ..., -0.2025, -0.8540, -1.0382],\n",
      "        [-1.3249,  0.3795,  0.4397,  ...,  0.7948, -0.6497, -1.0165],\n",
      "        ...,\n",
      "        [ 0.5081, -0.6447, -0.2739,  ...,  1.9027,  0.9118, -0.0332],\n",
      "        [ 0.1649,  1.1371,  0.9997,  ...,  0.0633, -0.6422, -1.2105],\n",
      "        [ 1.3637,  0.7667, -1.2324,  ...,  0.9195,  1.7327, -0.2113]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1596, -1.7024,  0.6421,  ...,  1.3398, -0.7515,  2.3995],\n",
      "        [-0.6947, -1.7994, -0.4670,  ..., -0.3256,  1.5716, -0.3652],\n",
      "        [ 0.9670,  1.4087, -1.5353,  ..., -0.7370, -1.0392, -0.2776],\n",
      "        ...,\n",
      "        [ 1.1785,  0.4792, -0.5161,  ...,  0.6387, -1.2354,  1.1843],\n",
      "        [ 1.1250,  0.0543,  0.4707,  ...,  1.3720, -0.0829,  0.8147],\n",
      "        [ 0.1963, -0.6259, -1.4704,  ...,  0.9343,  0.1174, -0.2536]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4103,  0.0720,  0.0340,  ..., -1.3349,  0.1457, -0.4926],\n",
      "        [ 0.4902,  0.0523,  1.3301,  ..., -0.9005,  0.1930, -0.2064],\n",
      "        [-0.3297,  1.0095, -2.1304,  ..., -0.4089,  0.5749, -1.0400],\n",
      "        ...,\n",
      "        [ 1.7461, -1.6068,  1.7544,  ...,  3.7499, -0.5459,  0.6831],\n",
      "        [-0.1232, -0.4773,  0.3655,  ..., -0.4697,  0.8867,  1.0411],\n",
      "        [ 0.0747,  1.1489,  0.5334,  ..., -0.7868,  2.1542,  2.4948]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.4476, -0.5905, -0.1529,  ...,  1.5605, -0.3585,  1.0043],\n",
      "        [ 1.7810,  0.9722,  1.0467,  ..., -0.2968,  1.0447, -1.1171],\n",
      "        [ 0.7651,  0.7698,  0.4709,  ...,  1.9911, -0.4228,  0.5141],\n",
      "        ...,\n",
      "        [-0.3458,  0.0950,  2.3227,  ...,  0.9047, -0.3327,  1.1474],\n",
      "        [-0.6727, -1.5128, -0.2382,  ..., -0.4831, -1.0140,  1.1294],\n",
      "        [ 0.8679,  1.6577, -0.8101,  ..., -0.3122,  1.1780,  0.7455]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4998,  1.6764,  0.0622,  ..., -0.8283,  1.7918, -0.1702],\n",
      "        [ 0.4710,  0.7824, -0.3286,  ...,  0.0076,  0.2307,  0.0373],\n",
      "        [-2.1317, -1.6070, -1.8996,  ...,  1.2225, -1.5169, -1.3925],\n",
      "        ...,\n",
      "        [ 1.1845, -0.5841, -0.2650,  ..., -0.8747, -0.2460, -0.6509],\n",
      "        [-1.3402,  0.2040, -0.3134,  ...,  0.2040,  0.5555,  0.4518],\n",
      "        [-0.1989, -0.5238,  1.1023,  ...,  0.6237, -0.9412, -1.7487]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.6852, -0.6646, -0.3765,  ..., -0.6007,  1.4906, -0.5368],\n",
      "        [ 0.2638,  0.1835,  0.9388,  ..., -0.3364, -0.7118, -0.4129],\n",
      "        [-0.6283, -0.0023,  0.9364,  ...,  0.5321,  0.2341, -1.1031],\n",
      "        ...,\n",
      "        [-1.2894,  0.4291, -0.7928,  ...,  0.0838,  0.2848, -2.1058],\n",
      "        [ 0.3526, -0.7008, -0.6161,  ...,  1.3398,  0.7923,  0.7881],\n",
      "        [-0.7700,  0.6698, -0.8719,  ...,  0.6870, -0.6270,  0.1867]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9229, -0.5824,  0.8417,  ...,  0.6426, -0.6476, -0.1209],\n",
      "        [-0.8659,  1.0949, -0.6061,  ..., -0.6822, -0.0910, -0.1894],\n",
      "        [ 0.2805, -1.3573, -1.9845,  ..., -0.5687,  1.6961, -0.0633],\n",
      "        ...,\n",
      "        [-1.6778,  1.1795,  0.3812,  ..., -0.0704,  1.2954,  0.7835],\n",
      "        [ 0.2969, -0.4390,  0.7528,  ...,  0.4518,  1.8330, -0.4477],\n",
      "        [ 0.1468,  0.5387,  0.7374,  ...,  1.2498, -1.5029,  1.7493]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0189, -0.3601,  0.0940,  ...,  0.1084,  1.5057, -0.8104],\n",
      "        [-1.0608, -0.5319,  1.1694,  ...,  0.6417,  0.8031, -0.1694],\n",
      "        [-1.3603, -1.4128, -0.1480,  ...,  0.3535,  1.2832, -0.6986],\n",
      "        ...,\n",
      "        [-0.3144, -1.8120, -0.6756,  ...,  0.5136,  0.3853,  1.0991],\n",
      "        [ 0.0424, -0.3564, -0.5751,  ...,  0.9723, -0.0978, -0.4352],\n",
      "        [ 0.2808,  1.6435,  2.2521,  ..., -1.9732, -0.2066, -1.8302]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8911,  0.5436, -0.6813,  ...,  0.1360, -1.0974,  2.5002],\n",
      "        [ 1.9374, -0.1223,  2.3629,  ...,  1.2345,  0.0137, -0.1915],\n",
      "        [-1.1666, -0.9109,  0.4236,  ..., -1.3553, -0.5158, -0.8608],\n",
      "        ...,\n",
      "        [-0.4154,  0.7744, -0.1653,  ..., -0.3129, -1.6380,  0.2111],\n",
      "        [ 1.2506, -0.5949,  0.4432,  ...,  0.5521,  1.2659,  0.4502],\n",
      "        [-1.0323,  0.2813,  0.7497,  ...,  1.8784,  1.5301,  0.0669]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1677, -0.4462,  1.2625,  ...,  0.7625, -1.3637,  1.0515],\n",
      "        [-0.1168, -0.5370,  0.1253,  ...,  1.2775, -0.1717, -1.1440],\n",
      "        [ 0.4638,  1.1240,  0.5755,  ..., -1.4680,  0.3813,  0.8760],\n",
      "        ...,\n",
      "        [ 0.8318, -1.0278,  1.1679,  ...,  0.3442,  0.3205,  0.7957],\n",
      "        [ 0.1725, -0.1347, -0.4646,  ...,  0.8545, -0.8070,  1.1167],\n",
      "        [ 1.0486, -1.0360, -0.6955,  ...,  1.4239,  0.4415,  2.7184]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-2.3698e-01,  2.7731e-01, -5.0819e-01,  ...,  2.9716e-01,\n",
      "          8.0965e-03, -1.2275e+00],\n",
      "        [-6.1695e-04, -2.5503e-02, -6.0897e-01,  ..., -2.7209e-01,\n",
      "          6.3753e-02, -1.2429e+00],\n",
      "        [ 4.4841e-01,  4.8226e-01,  5.6010e-01,  ...,  5.6421e-01,\n",
      "          2.5182e-01,  9.6136e-01],\n",
      "        ...,\n",
      "        [ 1.1071e+00,  3.7373e-01,  6.2989e-01,  ...,  3.1204e-01,\n",
      "          1.0492e-01,  5.6261e-01],\n",
      "        [-1.8418e-01,  1.1015e+00, -3.5451e-01,  ..., -1.5625e+00,\n",
      "         -1.9982e-02, -4.2954e-01],\n",
      "        [ 1.3495e+00, -2.2551e+00, -2.6138e-01,  ..., -4.9064e-01,\n",
      "          1.0533e+00,  1.3479e+00]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4437,  0.8235, -0.9221,  ...,  0.9966,  1.2769, -0.0802],\n",
      "        [-2.3362,  1.9339, -0.3191,  ...,  0.8602, -1.1876,  0.2149],\n",
      "        [ 0.0705,  1.1970, -1.0387,  ...,  1.3575, -1.6993,  1.4686],\n",
      "        ...,\n",
      "        [-0.1650, -1.1038, -0.0250,  ...,  0.6388, -0.7671,  0.3771],\n",
      "        [-1.2044, -0.7055, -1.7477,  ...,  0.9016,  0.2968, -1.7787],\n",
      "        [-0.7488,  0.1459,  0.0671,  ..., -0.0393,  0.1590,  0.2828]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.1826,  1.1886,  0.0883,  ...,  0.9366,  0.1083,  1.1610],\n",
      "        [ 0.7288, -0.5113,  0.1683,  ...,  2.5604, -0.5835,  0.6160],\n",
      "        [-0.9393, -0.1974,  0.4993,  ..., -0.4164, -0.3488, -0.6201],\n",
      "        ...,\n",
      "        [ 0.0515,  1.4201, -0.0245,  ..., -0.9212,  0.4259,  1.3271],\n",
      "        [ 1.1112,  0.1495, -0.9036,  ..., -0.2114, -1.0987,  1.3669],\n",
      "        [ 0.6467, -1.1895,  0.2665,  ..., -0.3864,  0.1301,  1.3830]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-2.2593e-01, -1.0002e+00,  6.8164e-01,  ...,  4.4810e-02,\n",
      "         -1.5573e-01,  1.2357e-01],\n",
      "        [-2.8412e-02, -1.2314e+00, -5.8893e-01,  ..., -1.3189e+00,\n",
      "          4.3002e-01, -2.4909e-01],\n",
      "        [ 7.2482e-01,  6.9971e-01, -9.9728e-01,  ..., -6.6716e-01,\n",
      "         -1.5239e-01,  7.6787e-01],\n",
      "        ...,\n",
      "        [ 2.6100e-02,  5.5444e-05,  2.0201e-01,  ...,  2.4475e+00,\n",
      "         -8.2542e-01,  5.2829e-01],\n",
      "        [ 5.5079e-01, -1.1287e+00,  1.6474e-01,  ...,  1.5280e+00,\n",
      "          1.2338e+00,  2.6074e-01],\n",
      "        [-5.6982e-01,  5.2663e-02,  2.0471e-01,  ..., -3.9158e-01,\n",
      "         -7.2773e-01, -1.4595e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.0786, -1.9958, -0.9766,  ...,  0.4004, -0.2556, -1.3703],\n",
      "        [-0.8386,  0.3895, -0.5602,  ...,  1.5308,  0.8053,  0.7747],\n",
      "        [-2.3440,  1.4966,  0.6286,  ..., -0.9345, -0.0202,  4.0370],\n",
      "        ...,\n",
      "        [-1.6867,  0.6535, -0.4697,  ...,  0.3169, -1.1245, -0.7191],\n",
      "        [ 0.2755, -1.1515, -0.0968,  ..., -0.2424, -0.7551, -0.4903],\n",
      "        [-0.1081,  0.2593, -0.3799,  ..., -0.5550,  0.4238, -0.3415]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2273,  0.5992,  0.1990,  ..., -0.2364,  2.5177,  1.2443],\n",
      "        [-1.4274, -0.9961, -0.7344,  ..., -0.4260, -0.4728,  0.2697],\n",
      "        [-1.0300, -1.0287, -0.3982,  ...,  0.3641, -0.8620,  0.5051],\n",
      "        ...,\n",
      "        [ 1.1817, -0.2765, -0.4782,  ...,  1.1726,  1.8012,  0.2278],\n",
      "        [ 1.2688, -0.6459,  1.2617,  ..., -0.4944, -0.4057,  0.0195],\n",
      "        [-0.0529,  0.1769, -0.6188,  ...,  0.5725,  0.1359, -0.8944]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.5012, -0.6968, -0.2887,  ...,  0.0368, -0.0922,  0.0264],\n",
      "        [-0.3923, -0.1530, -0.2157,  ...,  0.4539,  0.0751,  2.0146],\n",
      "        [-1.4244,  0.2991, -1.5531,  ..., -1.1450, -0.0119, -1.1516],\n",
      "        ...,\n",
      "        [-1.4396, -1.1263, -0.3034,  ...,  0.4297, -1.2201,  1.0024],\n",
      "        [-0.0880,  1.2294,  0.6159,  ...,  0.2275, -1.1274,  0.5193],\n",
      "        [-0.2768, -0.4381, -0.4231,  ..., -1.2382,  1.9894, -1.3808]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0120,  0.0285,  0.8038,  ..., -1.2706,  0.8574, -0.2309],\n",
      "        [ 0.1669,  1.5032,  0.3687,  ...,  0.2911,  1.5626, -1.0058],\n",
      "        [-1.1081, -2.2451, -0.0192,  ..., -1.9283,  1.8439, -0.3710],\n",
      "        ...,\n",
      "        [ 1.3457, -2.7017,  1.6329,  ..., -1.8049,  1.2388,  2.8364],\n",
      "        [ 0.0252, -0.9045, -1.8237,  ..., -0.3513,  0.4065,  0.4465],\n",
      "        [ 0.5893, -1.5839, -0.6351,  ..., -1.2951, -1.8944,  3.1274]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1049,  0.2625, -0.7348,  ..., -2.1255,  0.5698, -1.4445],\n",
      "        [-1.5063, -1.8955, -1.1041,  ..., -0.9043,  0.1552,  0.3452],\n",
      "        [-0.3126, -1.4177, -1.5955,  ...,  0.9621, -0.5828,  0.0426],\n",
      "        ...,\n",
      "        [ 0.8993, -1.0349,  0.4885,  ..., -0.2306, -1.3477,  0.0810],\n",
      "        [ 0.0088, -0.5321,  0.7111,  ..., -0.9273,  1.9153,  0.8348],\n",
      "        [ 0.1521,  1.1802, -0.5303,  ...,  0.9781,  0.4980,  0.0916]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2755,  0.2827,  1.2827,  ...,  1.1346, -0.6673,  0.5213],\n",
      "        [-1.5685,  0.6915,  0.0024,  ...,  0.3357,  0.9062,  0.8600],\n",
      "        [-0.1793, -0.0800, -1.0994,  ...,  0.9541,  2.1538, -0.1075],\n",
      "        ...,\n",
      "        [ 1.0344,  1.2434,  0.2944,  ...,  0.4939, -0.2722,  1.2317],\n",
      "        [-0.4626, -0.9655, -0.3900,  ..., -0.5011,  0.2316,  0.5300],\n",
      "        [ 0.0080,  1.5538, -0.4141,  ...,  1.4211, -0.3317,  0.7556]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9112, -0.1554,  0.7022,  ...,  1.5550, -0.7028, -0.6689],\n",
      "        [ 0.8921, -0.9010,  1.2019,  ...,  1.0911, -1.1095,  0.4686],\n",
      "        [ 0.5596, -0.3148,  1.8431,  ...,  0.2007, -0.4192,  1.1166],\n",
      "        ...,\n",
      "        [ 0.4153, -1.4699, -0.4637,  ...,  2.1715, -0.5118, -2.0820],\n",
      "        [-0.4248,  0.8056, -1.1727,  ..., -1.7837, -1.5838, -0.1463],\n",
      "        [ 0.1282,  0.5143,  1.4630,  ..., -1.3693, -0.2398,  0.1705]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3045, -1.4926, -0.0205,  ..., -1.5757, -1.2038, -0.5301],\n",
      "        [ 0.9280, -0.1949,  0.9829,  ..., -1.2076, -0.9774,  0.4554],\n",
      "        [ 1.2982,  1.6192,  0.2832,  ..., -0.6306,  1.5038,  1.3737],\n",
      "        ...,\n",
      "        [ 0.6422, -0.1524, -0.3844,  ...,  0.3512, -0.1834,  0.2665],\n",
      "        [-0.1393, -0.0281,  1.8809,  ..., -1.0974, -1.5793,  0.4053],\n",
      "        [ 0.1844,  1.5853,  0.4976,  ..., -0.0818,  0.0218,  0.4606]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0935, -0.6277, -0.3278,  ..., -0.1986, -1.0891, -0.3278],\n",
      "        [-0.6738, -1.0524, -1.1627,  ..., -0.4168,  0.0834,  0.9962],\n",
      "        [ 0.9822,  0.0900, -0.2654,  ...,  1.5648,  0.6159,  0.9397],\n",
      "        ...,\n",
      "        [-1.7208, -0.7842,  0.6226,  ...,  1.2960,  0.3263, -0.7026],\n",
      "        [-0.9913,  1.4496, -1.6620,  ..., -0.8092,  4.0550, -0.8470],\n",
      "        [ 0.5843, -0.8124,  0.7946,  ..., -0.3359, -0.3662,  2.2227]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5186, -0.6234,  0.4755,  ...,  0.2383,  0.7433,  0.9344],\n",
      "        [ 0.3292,  0.8186,  0.9895,  ...,  0.4372,  0.2449,  0.1057],\n",
      "        [-1.9150,  0.0974,  0.6014,  ...,  0.0845, -1.1258, -0.9750],\n",
      "        ...,\n",
      "        [-1.1700,  0.3781,  0.3430,  ...,  0.9926,  0.0450,  0.0672],\n",
      "        [-0.9762, -0.2348,  0.7949,  ..., -0.6742,  0.2383,  0.4629],\n",
      "        [ 0.6724,  0.9830,  1.0897,  ...,  0.5899, -0.7212,  0.8498]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.0744e+00, -9.0826e-01, -1.2183e+00,  ..., -7.2593e-01,\n",
      "         -1.6185e+00,  9.2176e-01],\n",
      "        [-2.2698e+00, -8.2864e-01, -9.3038e-01,  ..., -2.0291e+00,\n",
      "         -1.9064e-01, -1.3851e+00],\n",
      "        [-1.3820e+00,  2.0068e-02,  1.5888e+00,  ..., -2.4357e-01,\n",
      "          1.4068e+00,  2.1309e+00],\n",
      "        ...,\n",
      "        [-5.6045e-01, -4.8052e-04, -9.5492e-02,  ...,  9.0242e-01,\n",
      "         -1.1579e+00, -7.9132e-01],\n",
      "        [ 6.9823e-01,  6.4465e-01, -8.5757e-02,  ...,  7.8049e-02,\n",
      "         -1.7511e+00, -9.5575e-01],\n",
      "        [-6.0648e-01,  4.4863e-02, -7.0737e-02,  ..., -2.6152e-01,\n",
      "         -1.3230e-01, -4.3384e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8630, -0.2371,  1.5751,  ...,  3.1157,  0.2190, -0.7451],\n",
      "        [-1.1799,  0.9596, -0.8272,  ..., -0.5312,  0.6379, -1.7155],\n",
      "        [ 0.2132,  1.4314,  1.6567,  ...,  0.4064, -0.4468,  1.0562],\n",
      "        ...,\n",
      "        [-0.8915, -0.6022, -0.2459,  ..., -0.9044,  0.0284, -0.1959],\n",
      "        [-0.8394,  1.4232, -0.5075,  ..., -1.1482, -0.6964, -0.2388],\n",
      "        [ 1.6385, -1.3753,  0.3455,  ...,  1.2399, -1.0334, -0.9822]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.6586,  2.0839,  0.7945,  ...,  0.2076,  0.2726, -1.2051],\n",
      "        [ 0.3868, -0.3674, -1.0361,  ..., -2.4811,  0.2550, -0.5274],\n",
      "        [ 0.2869, -0.7224, -0.0065,  ..., -0.0897,  0.1521, -0.0497],\n",
      "        ...,\n",
      "        [ 0.1568, -1.1737, -2.4029,  ..., -0.5050,  0.1054, -0.2844],\n",
      "        [-1.6086, -0.1747, -0.6987,  ...,  1.8123,  2.0367,  0.2372],\n",
      "        [ 0.8631,  0.1655, -0.4257,  ...,  0.7503,  2.0822, -0.1499]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1446,  0.4093,  0.0852,  ..., -1.9728, -1.8645, -1.1181],\n",
      "        [ 1.1527,  0.7991,  0.9502,  ..., -0.5124, -0.2443, -0.2684],\n",
      "        [ 1.4904, -2.4164, -1.7248,  ..., -0.3953,  0.9630, -0.2117],\n",
      "        ...,\n",
      "        [-0.2916, -0.0274, -0.7097,  ..., -0.6119,  0.7742, -0.5131],\n",
      "        [ 0.5439,  0.4999, -0.4597,  ..., -0.4843,  1.1413, -0.1239],\n",
      "        [-0.5042, -2.1581,  0.6213,  ..., -0.2442, -1.3594,  0.5581]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2371, -0.9355,  0.1477,  ..., -1.0461,  1.1767,  0.2705],\n",
      "        [-0.1511,  1.2293, -0.7071,  ..., -0.4279,  0.4715,  1.6000],\n",
      "        [-0.3505,  0.0588,  1.1640,  ..., -0.1715, -0.2512, -0.9393],\n",
      "        ...,\n",
      "        [ 0.2081,  1.6534,  1.2730,  ..., -0.3951, -0.0515,  0.7479],\n",
      "        [ 0.6234,  0.1311,  0.5842,  ..., -0.0887, -0.2507, -0.5718],\n",
      "        [-0.5949,  1.0289,  2.0313,  ..., -0.0128, -0.5523,  0.5607]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([60, 256, 16])\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = Model(\n",
    "            num_features=num_features,\n",
    "            num_targets=num_targets,\n",
    "            hidden_size=hidden_size,\n",
    "        )\n",
    "# previous method they averaged each prediction result or something from the fold in k-fold\n",
    "# what we're gonna do here is try testing a dummy model first, then maybe implement that\n",
    "# by loading all state model, and do data augmentation on all of that, or if no time we just report result \n",
    "# with one model, and how it improves ? \n",
    "seed = 15\n",
    "fold = 4\n",
    "mod_name = f'FOLD_mod11_{seed}_{fold}_.pth'\n",
    "model.load_state_dict(torch.load(mod_name))\n",
    "\n",
    "# summary(model, )\n",
    "# print(model)\n",
    "\n",
    "# output the extracted feature (image based for 1D-CNN)\n",
    "# 1. prepare training data (use full training data)\n",
    "train_df = train.reset_index(drop=True).copy()\n",
    "\n",
    "# split into X and y train\n",
    "x_train, y_train, y_train_ns = train_df[feature_cols], train_df[target_cols].values,train_df[target_nonsc_cols2].values\n",
    "# x_valid, y_valid, y_valid_ns  = valid_df[feature_cols], valid_df[target_cols].values,valid_df[target_nonsc_cols2].values\n",
    "\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "# preprocess x_train\n",
    "x_train, _, _ = preprocessData(x_train, None, None)\n",
    "train_dataset = TrainDataset(x_train, y_train)\n",
    "\n",
    "# valid_dataset = TrainDataset(x_valid, y_valid)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(trainloader)\n",
    "\n",
    "# 2. Extract features\n",
    "extracted_feats = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:   \n",
    "        X_data = data['x'].to(DEVICE)\n",
    "        y_data = data['y'].to(DEVICE)\n",
    "        print(data)\n",
    "        model.to(DEVICE)\n",
    "        extracted_feat = model.extractImageFeat(X_data)\n",
    "        print(extracted_feat.shape)\n",
    "\n",
    "        # # shape will be (batch_size, 256, hidden_size (4096) / 256 = 16)\n",
    "        # extracted_feats.append(extracted_feat) \n",
    "\n",
    "# store extracted_feats as \n",
    "\n",
    "\n",
    "# 3. apply data augmentation\n",
    "# generate augmented data + original data and save it to disk \n",
    "\n",
    "\n",
    "\n",
    "# make it into the same format as train_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
