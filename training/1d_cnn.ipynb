{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "# later when inputting kaggle change this to /kaggle/input\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('../kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/audreych/Documents/code/machine_learning/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterative-stratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import copy\n",
    "from copy import deepcopy as dp\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def norm_fit(df_1,saveM = True, sc_name = 'zsco'):   \n",
    "    from sklearn.preprocessing import StandardScaler,MinMaxScaler,MaxAbsScaler,RobustScaler,Normalizer,QuantileTransformer,PowerTransformer\n",
    "    ss_1_dic = {'zsco':StandardScaler(),\n",
    "                'mima':MinMaxScaler(),\n",
    "                'maxb':MaxAbsScaler(), \n",
    "                'robu':RobustScaler(),\n",
    "                'norm':Normalizer(), \n",
    "                'quan':QuantileTransformer(n_quantiles=100,random_state=0, output_distribution=\"normal\"),\n",
    "                'powe':PowerTransformer()}\n",
    "    ss_1 = ss_1_dic[sc_name]\n",
    "    df_2 = pd.DataFrame(ss_1.fit_transform(df_1),index = df_1.index,columns = df_1.columns)\n",
    "    if saveM == False:\n",
    "        return(df_2)\n",
    "    else:\n",
    "        return(df_2,ss_1)\n",
    "\n",
    "def norm_tra(df_1,ss_x):\n",
    "    df_2 = pd.DataFrame(ss_x.transform(df_1),index = df_1.index,columns = df_1.columns)\n",
    "    return(df_2)\n",
    "\n",
    "def g_table(list1):\n",
    "    table_dic = {}\n",
    "    for i in list1:\n",
    "        if i not in table_dic.keys():\n",
    "            table_dic[i] = 1\n",
    "        else:\n",
    "            table_dic[i] += 1\n",
    "    return(table_dic)\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "gene 772\n",
      "cell 100\n",
      "872\n"
     ]
    }
   ],
   "source": [
    "SEED = [0, 1, 2, 3 ,4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "input_dir = '../input/lish-moa/'\n",
    "\n",
    "sc_dic = {}\n",
    "feat_dic = {}\n",
    "train_features = pd.read_csv(input_dir+'train_features.csv')\n",
    "train_targets_scored = pd.read_csv(input_dir+'train_targets_scored.csv')\n",
    "train_targets_nonscored = pd.read_csv(input_dir+'train_targets_nonscored.csv')\n",
    "test_features = pd.read_csv(input_dir+'test_features.csv')\n",
    "sample_submission = pd.read_csv(input_dir+'sample_submission.csv')\n",
    "train_drug = pd.read_csv(input_dir+'train_drug.csv')\n",
    "\n",
    "target_cols = train_targets_scored.drop('sig_id', axis=1).columns.values.tolist()\n",
    "target_nonsc_cols = train_targets_nonscored.drop('sig_id', axis=1).columns.values.tolist()\n",
    "\n",
    "######## non-score ########\n",
    "nonctr_id = train_features.loc[train_features['cp_type']!='ctl_vehicle','sig_id'].tolist()\n",
    "tmp_con1 = [i in nonctr_id for i in train_targets_scored['sig_id']]\n",
    "mat_cor = pd.DataFrame(np.corrcoef(train_targets_scored.drop('sig_id',axis = 1)[tmp_con1].T,\n",
    "                      train_targets_nonscored.drop('sig_id',axis = 1)[tmp_con1].T))\n",
    "mat_cor2 = mat_cor.iloc[(train_targets_scored.shape[1]-1):,0:train_targets_scored.shape[1]-1]\n",
    "mat_cor2.index = target_nonsc_cols\n",
    "mat_cor2.columns = target_cols\n",
    "mat_cor2 = mat_cor2.dropna()\n",
    "mat_cor2_max = mat_cor2.abs().max(axis = 1)\n",
    "\n",
    "q_n_cut = 0.9\n",
    "target_nonsc_cols2 = mat_cor2_max[mat_cor2_max > np.quantile(mat_cor2_max,q_n_cut)].index.tolist()\n",
    "print(len(target_nonsc_cols2))\n",
    "\n",
    "GENES = [col for col in train_features.columns if col.startswith('g-')]\n",
    "CELLS = [col for col in train_features.columns if col.startswith('c-')]\n",
    "feat_dic['gene'] = GENES\n",
    "feat_dic['cell'] = CELLS\n",
    "\n",
    "# sample norm \n",
    "q2 = train_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.25).copy()\n",
    "q7 = train_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.75).copy()\n",
    "qmean = (q2+q7)/2\n",
    "train_features[feat_dic['gene']] = (train_features[feat_dic['gene']].T - qmean.values).T\n",
    "q2 = test_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.25).copy()\n",
    "q7 = test_features[feat_dic['gene']].apply(np.quantile,axis = 1,q = 0.75).copy()\n",
    "qmean = (q2+q7)/2\n",
    "test_features[feat_dic['gene']] = (test_features[feat_dic['gene']].T - qmean.values).T\n",
    "\n",
    "q2 = train_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.25).copy()\n",
    "q7 = train_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.72).copy()\n",
    "qmean = (q2+q7)/2\n",
    "train_features[feat_dic['cell']] = (train_features[feat_dic['cell']].T - qmean.values).T\n",
    "qmean2 = train_features[feat_dic['cell']].abs().apply(np.quantile,axis = 1,q = 0.75).copy()+4\n",
    "train_features[feat_dic['cell']] = (train_features[feat_dic['cell']].T / qmean2.values).T.copy()\n",
    "\n",
    "q2 = test_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.25).copy()\n",
    "q7 = test_features[feat_dic['cell']].apply(np.quantile,axis = 1,q = 0.72).copy()\n",
    "qmean = (q2+q7)/2\n",
    "test_features[feat_dic['cell']] = (test_features[feat_dic['cell']].T - qmean.values).T\n",
    "qmean2 = test_features[feat_dic['cell']].abs().apply(np.quantile,axis = 1,q = 0.75).copy()+4\n",
    "test_features[feat_dic['cell']] = (test_features[feat_dic['cell']].T / qmean2.values).T.copy()\n",
    "\n",
    "# remove ctl\n",
    "train = train_features.merge(train_targets_scored, on='sig_id')\n",
    "train = train.merge(train_targets_nonscored[['sig_id']+target_nonsc_cols2], on='sig_id')\n",
    "\n",
    "train = train[train['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "test = test_features[test_features['cp_type']!='ctl_vehicle'].reset_index(drop=True)\n",
    "\n",
    "target = train[['sig_id']+target_cols]\n",
    "target_ns = train[['sig_id']+target_nonsc_cols2]\n",
    "\n",
    "train0 = train.drop('cp_type', axis=1)\n",
    "test = test.drop('cp_type', axis=1)\n",
    "\n",
    "target_cols = target.drop('sig_id', axis=1).columns.values.tolist()\n",
    "\n",
    "# drug ids\n",
    "tar_sig = target['sig_id'].tolist()\n",
    "train_drug = train_drug.loc[[i in tar_sig for i in train_drug['sig_id']]]\n",
    "target = target.merge(train_drug, on='sig_id', how='left') \n",
    "\n",
    "# LOCATE DRUGS\n",
    "vc = train_drug.drug_id.value_counts()\n",
    "vc1 = vc.loc[vc <= 19].index\n",
    "vc2 = vc.loc[vc > 19].index\n",
    "\n",
    "feature_cols = []\n",
    "for key_i in feat_dic.keys():\n",
    "    value_i = feat_dic[key_i]\n",
    "    print(key_i,len(value_i))\n",
    "    feature_cols += value_i\n",
    "    \n",
    "print(len(feature_cols))\n",
    "feature_cols0 = dp(feature_cols)\n",
    "    \n",
    "oof = np.zeros((len(train), len(target_cols)))\n",
    "predictions = np.zeros((len(test), len(target_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperParameters\n",
    "DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "EPOCHS = 25\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "NFOLDS = 5\n",
    "EARLY_STOPPING_STEPS = 10\n",
    "EARLY_STOP = False\n",
    "\n",
    "# global features\n",
    "n_comp1 = 50\n",
    "n_comp2 = 15\n",
    "hidden_size = 4096\n",
    "\n",
    "num_features=len(feature_cols) + n_comp1 + n_comp2\n",
    "num_targets=len(target_cols)\n",
    "num_targets_0=len(target_nonsc_cols2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0, pos_weight=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "        self.pos_weight = pos_weight\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "        assert 0 <= smoothing < 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "            self.smoothing)\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight,\n",
    "                                                    pos_weight = self.pos_weight)\n",
    "\n",
    "        if  self.reduction == 'sum':\n",
    "            loss = loss.sum()\n",
    "        elif  self.reduction == 'mean':\n",
    "            loss = loss.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "class TrainDataset:\n",
    "    def __init__(self, features, targets):\n",
    "        print(features)\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float),\n",
    "            'y' : torch.tensor(self.targets[idx, :], dtype=torch.float)            \n",
    "        }\n",
    "        return dct\n",
    "\n",
    "class TestDataset:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.features.shape[0])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        dct = {\n",
    "            'x' : torch.tensor(self.features[idx, :], dtype=torch.float)\n",
    "        }\n",
    "        return dct\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, num_features, num_targets, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        cha_1 = 256\n",
    "        cha_2 = 512\n",
    "        cha_3 = 512\n",
    "\n",
    "        cha_1_reshape = int(hidden_size/cha_1)\n",
    "        cha_po_1 = int(hidden_size/cha_1/2)\n",
    "        cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "        self.cha_1 = cha_1\n",
    "        self.cha_2 = cha_2\n",
    "        self.cha_3 = cha_3\n",
    "        self.cha_1_reshape = cha_1_reshape\n",
    "        self.cha_po_1 = cha_po_1\n",
    "        self.cha_po_2 = cha_po_2\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "        self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "        self.dropout_c1 = nn.Dropout(0.1)\n",
    "        self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "        self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "        self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2 = nn.Dropout(0.1)\n",
    "        self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "        self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2_1 = nn.Dropout(0.3)\n",
    "        self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "        self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "        self.dropout_c2_2 = nn.Dropout(0.2)\n",
    "        self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "        self.flt = nn.Flatten()\n",
    "\n",
    "        self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "        self.dropout3 = nn.Dropout(0.2)\n",
    "        self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, num_targets))\n",
    "\n",
    "    def extractImageFeat(self, x):\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.celu(self.dense1(x), alpha=0.06)\n",
    "        x = x.reshape(x.shape[0],self.cha_1,\n",
    "                        self.cha_1_reshape)\n",
    "        \n",
    "        return x \n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "        x = x.reshape(x.shape[0],self.cha_1,\n",
    "                        self.cha_1_reshape)\n",
    "\n",
    "        x = self.batch_norm_c1(x)\n",
    "        x = self.dropout_c1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = self.ave_po_c1(x)\n",
    "\n",
    "        x = self.batch_norm_c2(x)\n",
    "        x = self.dropout_c2(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x_s = x\n",
    "\n",
    "        x = self.batch_norm_c2_1(x)\n",
    "        x = self.dropout_c2_1(x)\n",
    "        x = F.relu(self.conv2_1(x))\n",
    "\n",
    "        x = self.batch_norm_c2_2(x)\n",
    "        x = self.dropout_c2_2(x)\n",
    "        x = F.relu(self.conv2_2(x))\n",
    "        x =  x * x_s\n",
    "\n",
    "        x = self.max_po_c2(x)\n",
    "\n",
    "        x = self.flt(x)\n",
    "\n",
    "        x = self.batch_norm3(x)\n",
    "        x = self.dropout3(x)\n",
    "        x = self.dense3(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "def train_fn(model, optimizer, scheduler, loss_fn, dataloader, device):\n",
    "    model.train()\n",
    "    final_loss = 0\n",
    "\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        final_loss += loss.item()\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "\n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def valid_fn(model, loss_fn, dataloader, device):\n",
    "    model.eval()\n",
    "    final_loss = 0\n",
    "    valid_preds = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        inputs, targets = data['x'].to(device), data['y'].to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        final_loss += loss.item()\n",
    "        valid_preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    final_loss /= len(dataloader)\n",
    "    valid_preds = np.concatenate(valid_preds)\n",
    "\n",
    "    return final_loss, valid_preds\n",
    "\n",
    "def inference_fn(model, dataloader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "\n",
    "    for data in dataloader:\n",
    "        inputs = data['x'].to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "\n",
    "        preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(fold, seed, train, test, pos_weight):\n",
    "    seed_everything(seed)\n",
    "\n",
    "    trn_idx = train[train['kfold'] != fold].index\n",
    "    val_idx = train[train['kfold'] == fold].index\n",
    "\n",
    "    train_df = train[train['kfold'] != fold].reset_index(drop=True).copy()\n",
    "    valid_df = train[train['kfold'] == fold].reset_index(drop=True).copy()\n",
    "\n",
    "    x_train, y_train,y_train_ns = train_df[feature_cols], train_df[target_cols].values,train_df[target_nonsc_cols2].values\n",
    "    x_valid, y_valid,y_valid_ns  = valid_df[feature_cols], valid_df[target_cols].values,valid_df[target_nonsc_cols2].values\n",
    "    x_test = test[feature_cols]\n",
    "\n",
    "    #------------ norm --------------\n",
    "    col_num = list(set(feat_dic['gene'] + feat_dic['cell']) & set(feature_cols))\n",
    "    col_num.sort()\n",
    "    x_train[col_num],ss = norm_fit(x_train[col_num],True,'quan')\n",
    "    x_valid[col_num]    = norm_tra(x_valid[col_num],ss)\n",
    "    x_test[col_num]     = norm_tra(x_test[col_num],ss)\n",
    "\n",
    "    #------------ pca --------------\n",
    "    def pca_pre(tr,va,te,\n",
    "                n_comp,feat_raw,feat_new):\n",
    "        pca = PCA(n_components=n_comp, random_state=42)\n",
    "        tr2 = pd.DataFrame(pca.fit_transform(tr[feat_raw]),columns=feat_new)\n",
    "        va2 = pd.DataFrame(pca.transform(va[feat_raw]),columns=feat_new)\n",
    "        te2 = pd.DataFrame(pca.transform(te[feat_raw]),columns=feat_new)\n",
    "        return(tr2,va2,te2)\n",
    "\n",
    "\n",
    "    pca_feat_g = [f'pca_G-{i}' for i in range(n_comp1)]\n",
    "    feat_dic['pca_g'] = pca_feat_g\n",
    "    x_tr_g_pca,x_va_g_pca,x_te_g_pca = pca_pre(x_train,x_valid,x_test,\n",
    "                                                n_comp1,feat_dic['gene'],pca_feat_g)\n",
    "    x_train = pd.concat([x_train,x_tr_g_pca],axis = 1)\n",
    "    x_valid = pd.concat([x_valid,x_va_g_pca],axis = 1)\n",
    "    x_test  = pd.concat([x_test,x_te_g_pca],axis = 1)\n",
    "\n",
    "    pca_feat_g = [f'pca_C-{i}' for i in range(n_comp2)]\n",
    "    feat_dic['pca_c'] = pca_feat_g\n",
    "    x_tr_c_pca,x_va_c_pca,x_te_c_pca = pca_pre(x_train,x_valid,x_test,\n",
    "                                                n_comp2,feat_dic['cell'],pca_feat_g)\n",
    "    x_train = pd.concat([x_train,x_tr_c_pca],axis = 1)\n",
    "    x_valid = pd.concat([x_valid,x_va_c_pca],axis = 1)\n",
    "    x_test  = pd.concat([x_test,x_te_c_pca], axis = 1)\n",
    "\n",
    "    x_train,x_valid,x_test = x_train.values,x_valid.values,x_test.values\n",
    "    print(x_train.shape)\n",
    "\n",
    "    train_dataset = TrainDataset(x_train, y_train_ns)\n",
    "    valid_dataset = TrainDataset(x_valid, y_valid_ns)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets_0,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=0.0001)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e5, \n",
    "                                                max_lr=0.0001, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "\n",
    "    loss_tr = nn.BCEWithLogitsLoss()   #SmoothBCEwLogits(smoothing = 0.001)\n",
    "    loss_va = nn.BCEWithLogitsLoss()    \n",
    "\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "    \n",
    "    # train warmup with non scored \n",
    "    for epoch in range(1):\n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n",
    "        print(f\"FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n",
    "\n",
    "    model.dense3 = nn.utils.weight_norm(nn.Linear(model.cha_po_2, num_targets))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    train_dataset = TrainDataset(x_train, y_train)\n",
    "    valid_dataset = TrainDataset(x_valid, y_valid)\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "                                                max_lr=1e-2, epochs=EPOCHS, steps_per_epoch=len(trainloader))\n",
    "\n",
    "    loss_tr = SmoothBCEwLogits(smoothing = 0.001, pos_weight=pos_weight)\n",
    "    loss_va = nn.BCEWithLogitsLoss()    \n",
    "\n",
    "    early_stopping_steps = EARLY_STOPPING_STEPS\n",
    "    early_step = 0\n",
    "\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    best_loss = np.inf\n",
    "\n",
    "    mod_name = f\"FOLD_mod11_{seed}_{fold}_.pth\"\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        train_loss = train_fn(model, optimizer,scheduler, loss_tr, trainloader, DEVICE)\n",
    "        valid_loss, valid_preds = valid_fn(model, loss_va, validloader, DEVICE)\n",
    "        print(f\"SEED: {seed}, FOLD: {fold}, EPOCH: {epoch},train_loss: {train_loss}, valid_loss: {valid_loss}\")\n",
    "\n",
    "        if valid_loss < best_loss:\n",
    "\n",
    "            best_loss = valid_loss\n",
    "            oof[val_idx] = valid_preds\n",
    "            torch.save(model.state_dict(), mod_name)\n",
    "\n",
    "        elif(EARLY_STOP == True):\n",
    "\n",
    "            early_step += 1\n",
    "            if (early_step >= early_stopping_steps):\n",
    "                break\n",
    "\n",
    "    #--------------------- PREDICTION---------------------\n",
    "    testdataset = TestDataset(x_test)\n",
    "    testloader = torch.utils.data.DataLoader(testdataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = Model(\n",
    "        num_features=num_features,\n",
    "        num_targets=num_targets,\n",
    "        hidden_size=hidden_size,\n",
    "    )\n",
    "\n",
    "    model.load_state_dict(torch.load(mod_name))\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "    predictions = inference_fn(model, testloader, DEVICE)\n",
    "    return oof, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k_fold(NFOLDS, seed, train, test, pos_weight):\n",
    "    oof = np.zeros((len(train), len(target_cols)))\n",
    "    predictions = np.zeros((len(test), len(target_cols)))\n",
    "\n",
    "    for fold in range(NFOLDS):\n",
    "        oof_, pred_ = run_training(fold, seed, train, test, pos_weight)\n",
    "\n",
    "        predictions += pred_ / NFOLDS\n",
    "        oof += oof_\n",
    "\n",
    "    return oof, predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17556, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.736779404723126, valid_loss: 0.7167257717677525\n",
      "SEED: 0, FOLD: 0, EPOCH: 0,train_loss: 0.46687912573848944, valid_loss: 0.024165539762803487\n",
      "SEED: 0, FOLD: 0, EPOCH: 1,train_loss: 0.02069511819306923, valid_loss: 0.02094758376479149\n",
      "SEED: 0, FOLD: 0, EPOCH: 2,train_loss: 0.01883962676199018, valid_loss: 0.01805939469486475\n",
      "SEED: 0, FOLD: 0, EPOCH: 3,train_loss: 0.018191139821125114, valid_loss: 0.0190495602786541\n",
      "SEED: 0, FOLD: 0, EPOCH: 4,train_loss: 0.01803769728006876, valid_loss: 0.017824575092111314\n",
      "SEED: 0, FOLD: 0, EPOCH: 5,train_loss: 0.017784679726953957, valid_loss: 0.018006538067545208\n",
      "SEED: 0, FOLD: 0, EPOCH: 6,train_loss: 0.01783845548018597, valid_loss: 0.0177716533520392\n",
      "SEED: 0, FOLD: 0, EPOCH: 7,train_loss: 0.01785273516577655, valid_loss: 0.017828260468585152\n",
      "SEED: 0, FOLD: 0, EPOCH: 8,train_loss: 0.01782443625447543, valid_loss: 0.0177497642913035\n",
      "SEED: 0, FOLD: 0, EPOCH: 9,train_loss: 0.017907184393455584, valid_loss: 0.017747293785214426\n",
      "SEED: 0, FOLD: 0, EPOCH: 10,train_loss: 0.017727041488810293, valid_loss: 0.01813558784446546\n",
      "SEED: 0, FOLD: 0, EPOCH: 11,train_loss: 0.017719027343327583, valid_loss: 0.01760802229068109\n",
      "SEED: 0, FOLD: 0, EPOCH: 12,train_loss: 0.017617132872397055, valid_loss: 0.01774146288101162\n",
      "SEED: 0, FOLD: 0, EPOCH: 13,train_loss: 0.017583761883872576, valid_loss: 0.017686453381819383\n",
      "SEED: 0, FOLD: 0, EPOCH: 14,train_loss: 0.01737688148421222, valid_loss: 0.01765666234173945\n",
      "SEED: 0, FOLD: 0, EPOCH: 15,train_loss: 0.01734560088969875, valid_loss: 0.017438216081687382\n",
      "SEED: 0, FOLD: 0, EPOCH: 16,train_loss: 0.017095487382586882, valid_loss: 0.017315071129373142\n",
      "SEED: 0, FOLD: 0, EPOCH: 17,train_loss: 0.016896651106198198, valid_loss: 0.01741635517350265\n",
      "SEED: 0, FOLD: 0, EPOCH: 18,train_loss: 0.01656422450247666, valid_loss: 0.01730406643556697\n",
      "SEED: 0, FOLD: 0, EPOCH: 19,train_loss: 0.016186165387161833, valid_loss: 0.01737468796116965\n",
      "SEED: 0, FOLD: 0, EPOCH: 20,train_loss: 0.015736542547634548, valid_loss: 0.017198788188397884\n",
      "SEED: 0, FOLD: 0, EPOCH: 21,train_loss: 0.015264103924720615, valid_loss: 0.017388165688940457\n",
      "SEED: 0, FOLD: 0, EPOCH: 22,train_loss: 0.014728958057104677, valid_loss: 0.01719696330172675\n",
      "SEED: 0, FOLD: 0, EPOCH: 23,train_loss: 0.014324238847779192, valid_loss: 0.017194777354598047\n",
      "SEED: 0, FOLD: 0, EPOCH: 24,train_loss: 0.014046000121026367, valid_loss: 0.017178002638476235\n",
      "(17486, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7369105428674795, valid_loss: 0.7166308420045036\n",
      "SEED: 0, FOLD: 1, EPOCH: 0,train_loss: 0.4686234544310039, valid_loss: 0.025349475656236922\n",
      "SEED: 0, FOLD: 1, EPOCH: 1,train_loss: 0.020821763528850828, valid_loss: 0.01939063583101545\n",
      "SEED: 0, FOLD: 1, EPOCH: 2,train_loss: 0.018772624602989993, valid_loss: 0.019090036675333977\n",
      "SEED: 0, FOLD: 1, EPOCH: 3,train_loss: 0.01815733983161023, valid_loss: 0.01813375662480082\n",
      "SEED: 0, FOLD: 1, EPOCH: 4,train_loss: 0.01782549382697274, valid_loss: 0.01811238295797791\n",
      "SEED: 0, FOLD: 1, EPOCH: 5,train_loss: 0.01776871974342061, valid_loss: 0.019113618774073464\n",
      "SEED: 0, FOLD: 1, EPOCH: 6,train_loss: 0.017789289001783316, valid_loss: 0.01831435052944081\n",
      "SEED: 0, FOLD: 1, EPOCH: 7,train_loss: 0.017846850719112548, valid_loss: 0.018651188910007478\n",
      "SEED: 0, FOLD: 1, EPOCH: 8,train_loss: 0.017838541343536254, valid_loss: 0.018295314535498618\n",
      "SEED: 0, FOLD: 1, EPOCH: 9,train_loss: 0.017805981470176774, valid_loss: 0.018256023366536412\n",
      "SEED: 0, FOLD: 1, EPOCH: 10,train_loss: 0.01777832069345852, valid_loss: 0.01841504363609212\n",
      "SEED: 0, FOLD: 1, EPOCH: 11,train_loss: 0.017704545595023755, valid_loss: 0.018115038238465785\n",
      "SEED: 0, FOLD: 1, EPOCH: 12,train_loss: 0.01761150107222752, valid_loss: 0.01800167376973799\n",
      "SEED: 0, FOLD: 1, EPOCH: 13,train_loss: 0.017531410600636562, valid_loss: 0.018042496857898577\n",
      "SEED: 0, FOLD: 1, EPOCH: 14,train_loss: 0.017421920464312943, valid_loss: 0.018097378632852008\n",
      "SEED: 0, FOLD: 1, EPOCH: 15,train_loss: 0.017291406516230453, valid_loss: 0.018013693578541278\n",
      "SEED: 0, FOLD: 1, EPOCH: 16,train_loss: 0.017101213539930157, valid_loss: 0.01779878833996398\n",
      "SEED: 0, FOLD: 1, EPOCH: 17,train_loss: 0.016873595787443383, valid_loss: 0.017961435552154268\n",
      "SEED: 0, FOLD: 1, EPOCH: 18,train_loss: 0.01659414970254811, valid_loss: 0.017848544088857516\n",
      "SEED: 0, FOLD: 1, EPOCH: 19,train_loss: 0.01621467219733626, valid_loss: 0.017672006014202324\n",
      "SEED: 0, FOLD: 1, EPOCH: 20,train_loss: 0.01582849789818708, valid_loss: 0.0176281335364495\n",
      "SEED: 0, FOLD: 1, EPOCH: 21,train_loss: 0.015400224657606905, valid_loss: 0.01752312776765653\n",
      "SEED: 0, FOLD: 1, EPOCH: 22,train_loss: 0.014896387846147927, valid_loss: 0.017529181231345448\n",
      "SEED: 0, FOLD: 1, EPOCH: 23,train_loss: 0.014464557612736295, valid_loss: 0.017497572302818298\n",
      "SEED: 0, FOLD: 1, EPOCH: 24,train_loss: 0.014253160195683475, valid_loss: 0.017516121507755347\n",
      "(17606, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7369800542575725, valid_loss: 0.7167699652559617\n",
      "SEED: 0, FOLD: 2, EPOCH: 0,train_loss: 0.46787485836640647, valid_loss: 0.02309854476548293\n",
      "SEED: 0, FOLD: 2, EPOCH: 1,train_loss: 0.0206148029183564, valid_loss: 0.01862164307385683\n",
      "SEED: 0, FOLD: 2, EPOCH: 2,train_loss: 0.01898299532847992, valid_loss: 0.017901024425073582\n",
      "SEED: 0, FOLD: 2, EPOCH: 3,train_loss: 0.01815031220515569, valid_loss: 0.01768739168148707\n",
      "SEED: 0, FOLD: 2, EPOCH: 4,train_loss: 0.017943815726354933, valid_loss: 0.01814123977194814\n",
      "SEED: 0, FOLD: 2, EPOCH: 5,train_loss: 0.017916431151114513, valid_loss: 0.017968354198862526\n",
      "SEED: 0, FOLD: 2, EPOCH: 6,train_loss: 0.01793949999779031, valid_loss: 0.01794705627595677\n",
      "SEED: 0, FOLD: 2, EPOCH: 7,train_loss: 0.01790823184115731, valid_loss: 0.017697028103558457\n",
      "SEED: 0, FOLD: 2, EPOCH: 8,train_loss: 0.01795276450128227, valid_loss: 0.01792938125264995\n",
      "SEED: 0, FOLD: 2, EPOCH: 9,train_loss: 0.01788834904226056, valid_loss: 0.017776549985522732\n",
      "SEED: 0, FOLD: 2, EPOCH: 10,train_loss: 0.0178402170026, valid_loss: 0.01774567288949209\n",
      "SEED: 0, FOLD: 2, EPOCH: 11,train_loss: 0.01782382075148432, valid_loss: 0.01763933549142059\n",
      "SEED: 0, FOLD: 2, EPOCH: 12,train_loss: 0.017770162763316995, valid_loss: 0.01747473838793881\n",
      "SEED: 0, FOLD: 2, EPOCH: 13,train_loss: 0.017662642550641212, valid_loss: 0.01745632238795652\n",
      "SEED: 0, FOLD: 2, EPOCH: 14,train_loss: 0.01757333013296559, valid_loss: 0.017254368402063847\n",
      "SEED: 0, FOLD: 2, EPOCH: 15,train_loss: 0.017330551546984825, valid_loss: 0.017357949496192092\n",
      "SEED: 0, FOLD: 2, EPOCH: 16,train_loss: 0.017220286389245935, valid_loss: 0.017211006132557112\n",
      "SEED: 0, FOLD: 2, EPOCH: 17,train_loss: 0.016935886268544455, valid_loss: 0.017298970891929725\n",
      "SEED: 0, FOLD: 2, EPOCH: 18,train_loss: 0.0166901219231279, valid_loss: 0.01714892841546851\n",
      "SEED: 0, FOLD: 2, EPOCH: 19,train_loss: 0.016323819108631298, valid_loss: 0.017012246309176964\n",
      "SEED: 0, FOLD: 2, EPOCH: 20,train_loss: 0.015934302458080692, valid_loss: 0.016961338518954375\n",
      "SEED: 0, FOLD: 2, EPOCH: 21,train_loss: 0.015467604433280834, valid_loss: 0.0169421305112979\n",
      "SEED: 0, FOLD: 2, EPOCH: 22,train_loss: 0.014912921442663755, valid_loss: 0.016948446357513174\n",
      "SEED: 0, FOLD: 2, EPOCH: 23,train_loss: 0.014500830416986044, valid_loss: 0.01693356943809811\n",
      "SEED: 0, FOLD: 2, EPOCH: 24,train_loss: 0.014275409186771814, valid_loss: 0.016948256285532433\n",
      "(17580, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7371836334898851, valid_loss: 0.7167486837932042\n",
      "SEED: 0, FOLD: 3, EPOCH: 0,train_loss: 0.46728218549295614, valid_loss: 0.02484885065683297\n",
      "SEED: 0, FOLD: 3, EPOCH: 1,train_loss: 0.020799749463364697, valid_loss: 0.01872267286692347\n",
      "SEED: 0, FOLD: 3, EPOCH: 2,train_loss: 0.01902853578761004, valid_loss: 0.018435187052403178\n",
      "SEED: 0, FOLD: 3, EPOCH: 3,train_loss: 0.01834362414598033, valid_loss: 0.018047325951712472\n",
      "SEED: 0, FOLD: 3, EPOCH: 4,train_loss: 0.017843004403824823, valid_loss: 0.018138662885342327\n",
      "SEED: 0, FOLD: 3, EPOCH: 5,train_loss: 0.017899483165609232, valid_loss: 0.01814723861004625\n",
      "SEED: 0, FOLD: 3, EPOCH: 6,train_loss: 0.017841208955623966, valid_loss: 0.01806061387594257\n",
      "SEED: 0, FOLD: 3, EPOCH: 7,train_loss: 0.017827174477819084, valid_loss: 0.017865103935556754\n",
      "SEED: 0, FOLD: 3, EPOCH: 8,train_loss: 0.01788247498832103, valid_loss: 0.01783851185547454\n",
      "SEED: 0, FOLD: 3, EPOCH: 9,train_loss: 0.017846526132653587, valid_loss: 0.017865273728966714\n",
      "SEED: 0, FOLD: 3, EPOCH: 10,train_loss: 0.01780066475191194, valid_loss: 0.01790800549622093\n",
      "SEED: 0, FOLD: 3, EPOCH: 11,train_loss: 0.017765457411229178, valid_loss: 0.017682172491082122\n",
      "SEED: 0, FOLD: 3, EPOCH: 12,train_loss: 0.01771991180283004, valid_loss: 0.01765221410564014\n",
      "SEED: 0, FOLD: 3, EPOCH: 13,train_loss: 0.01764515445203237, valid_loss: 0.017918379099241325\n",
      "SEED: 0, FOLD: 3, EPOCH: 14,train_loss: 0.017486340798221638, valid_loss: 0.0174926581127303\n",
      "SEED: 0, FOLD: 3, EPOCH: 15,train_loss: 0.01730220667693926, valid_loss: 0.01746761572680303\n",
      "SEED: 0, FOLD: 3, EPOCH: 16,train_loss: 0.01716647552245337, valid_loss: 0.017498142618153776\n",
      "SEED: 0, FOLD: 3, EPOCH: 17,train_loss: 0.016920423270135685, valid_loss: 0.017213367351463862\n",
      "SEED: 0, FOLD: 3, EPOCH: 18,train_loss: 0.01668073588550307, valid_loss: 0.01746445707976818\n",
      "SEED: 0, FOLD: 3, EPOCH: 19,train_loss: 0.016372144431469664, valid_loss: 0.017258154574249472\n",
      "SEED: 0, FOLD: 3, EPOCH: 20,train_loss: 0.015915770758537277, valid_loss: 0.017201561480760574\n",
      "SEED: 0, FOLD: 3, EPOCH: 21,train_loss: 0.015410585092731577, valid_loss: 0.017224889461483275\n",
      "SEED: 0, FOLD: 3, EPOCH: 22,train_loss: 0.014901830963250519, valid_loss: 0.017158204157437597\n",
      "SEED: 0, FOLD: 3, EPOCH: 23,train_loss: 0.014444842995346888, valid_loss: 0.017208670558673995\n",
      "SEED: 0, FOLD: 3, EPOCH: 24,train_loss: 0.014231044407664001, valid_loss: 0.017205800568418844\n",
      "(17564, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7369988603868346, valid_loss: 0.7160299829074315\n",
      "SEED: 0, FOLD: 4, EPOCH: 0,train_loss: 0.4671587167388719, valid_loss: 0.027453665541751045\n",
      "SEED: 0, FOLD: 4, EPOCH: 1,train_loss: 0.02159413326855587, valid_loss: 0.01943387607378619\n",
      "SEED: 0, FOLD: 4, EPOCH: 2,train_loss: 0.019247061330015244, valid_loss: 0.018428117409348486\n",
      "SEED: 0, FOLD: 4, EPOCH: 3,train_loss: 0.018563034404339134, valid_loss: 0.01887824721634388\n",
      "SEED: 0, FOLD: 4, EPOCH: 4,train_loss: 0.018197217510770195, valid_loss: 0.018248139055711883\n",
      "SEED: 0, FOLD: 4, EPOCH: 5,train_loss: 0.017936844884863367, valid_loss: 0.01832232086786202\n",
      "SEED: 0, FOLD: 4, EPOCH: 6,train_loss: 0.01782961533256415, valid_loss: 0.018041715611304555\n",
      "SEED: 0, FOLD: 4, EPOCH: 7,train_loss: 0.017863480758893747, valid_loss: 0.018105156027844974\n",
      "SEED: 0, FOLD: 4, EPOCH: 8,train_loss: 0.01775542701985957, valid_loss: 0.01810409788574491\n",
      "SEED: 0, FOLD: 4, EPOCH: 9,train_loss: 0.017801000082028517, valid_loss: 0.018019274941512516\n",
      "SEED: 0, FOLD: 4, EPOCH: 10,train_loss: 0.01778210124567799, valid_loss: 0.018236398909773147\n",
      "SEED: 0, FOLD: 4, EPOCH: 11,train_loss: 0.017769932794128206, valid_loss: 0.017900061128394946\n",
      "SEED: 0, FOLD: 4, EPOCH: 12,train_loss: 0.017707310468498348, valid_loss: 0.017749702877232005\n",
      "SEED: 0, FOLD: 4, EPOCH: 13,train_loss: 0.017559977552003187, valid_loss: 0.01787297214780535\n",
      "SEED: 0, FOLD: 4, EPOCH: 14,train_loss: 0.01747471763603929, valid_loss: 0.01780384337263448\n",
      "SEED: 0, FOLD: 4, EPOCH: 15,train_loss: 0.0172911812753781, valid_loss: 0.017699033713766507\n",
      "SEED: 0, FOLD: 4, EPOCH: 16,train_loss: 0.017087638459127884, valid_loss: 0.01768570350749152\n",
      "SEED: 0, FOLD: 4, EPOCH: 17,train_loss: 0.016802765422271215, valid_loss: 0.017513922761593546\n",
      "SEED: 0, FOLD: 4, EPOCH: 18,train_loss: 0.016556708979001945, valid_loss: 0.017305257304438524\n",
      "SEED: 0, FOLD: 4, EPOCH: 19,train_loss: 0.01617282722145319, valid_loss: 0.017337128333747388\n",
      "SEED: 0, FOLD: 4, EPOCH: 20,train_loss: 0.015771142787475517, valid_loss: 0.017283346982938902\n",
      "SEED: 0, FOLD: 4, EPOCH: 21,train_loss: 0.015302970829973186, valid_loss: 0.017255763762763568\n",
      "SEED: 0, FOLD: 4, EPOCH: 22,train_loss: 0.01473727465296785, valid_loss: 0.017270480495478427\n",
      "SEED: 0, FOLD: 4, EPOCH: 23,train_loss: 0.014283842609628387, valid_loss: 0.017251470418913024\n",
      "SEED: 0, FOLD: 4, EPOCH: 24,train_loss: 0.014056652959814106, valid_loss: 0.017244287500424043\n",
      "(17577, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7343175355075062, valid_loss: 0.6997978414808\n",
      "SEED: 1, FOLD: 0, EPOCH: 0,train_loss: 0.4675089741746585, valid_loss: 0.023369410846914563\n",
      "SEED: 1, FOLD: 0, EPOCH: 1,train_loss: 0.020936691431679588, valid_loss: 0.019524203985929488\n",
      "SEED: 1, FOLD: 0, EPOCH: 2,train_loss: 0.019388981055522312, valid_loss: 0.0179280033867274\n",
      "SEED: 1, FOLD: 0, EPOCH: 3,train_loss: 0.01820250857702416, valid_loss: 0.017418710754386016\n",
      "SEED: 1, FOLD: 0, EPOCH: 4,train_loss: 0.01782371728019654, valid_loss: 0.01737290868269546\n",
      "SEED: 1, FOLD: 0, EPOCH: 5,train_loss: 0.01779305316048904, valid_loss: 0.01759505013802222\n",
      "SEED: 1, FOLD: 0, EPOCH: 6,train_loss: 0.01784762425645106, valid_loss: 0.01740198577088969\n",
      "SEED: 1, FOLD: 0, EPOCH: 7,train_loss: 0.01785014758048498, valid_loss: 0.01749285738915205\n",
      "SEED: 1, FOLD: 0, EPOCH: 8,train_loss: 0.017819309316953455, valid_loss: 0.017356384465737004\n",
      "SEED: 1, FOLD: 0, EPOCH: 9,train_loss: 0.017849957361223474, valid_loss: 0.017544084734150343\n",
      "SEED: 1, FOLD: 0, EPOCH: 10,train_loss: 0.017797179533627586, valid_loss: 0.017424757752035346\n",
      "SEED: 1, FOLD: 0, EPOCH: 11,train_loss: 0.017736071889437197, valid_loss: 0.017448068303721292\n",
      "SEED: 1, FOLD: 0, EPOCH: 12,train_loss: 0.01769438664685341, valid_loss: 0.01727187702698367\n",
      "SEED: 1, FOLD: 0, EPOCH: 13,train_loss: 0.01757840756866811, valid_loss: 0.017078572112534728\n",
      "SEED: 1, FOLD: 0, EPOCH: 14,train_loss: 0.017417135115280962, valid_loss: 0.017004916524248462\n",
      "SEED: 1, FOLD: 0, EPOCH: 15,train_loss: 0.01723404647782445, valid_loss: 0.017019972897001676\n",
      "SEED: 1, FOLD: 0, EPOCH: 16,train_loss: 0.01709788986414239, valid_loss: 0.016869201058787957\n",
      "SEED: 1, FOLD: 0, EPOCH: 17,train_loss: 0.016841579343367746, valid_loss: 0.016875155961939267\n",
      "SEED: 1, FOLD: 0, EPOCH: 18,train_loss: 0.01652669859375211, valid_loss: 0.01678958742746285\n",
      "SEED: 1, FOLD: 0, EPOCH: 19,train_loss: 0.01617655091230636, valid_loss: 0.016829553831900868\n",
      "SEED: 1, FOLD: 0, EPOCH: 20,train_loss: 0.015726694358053846, valid_loss: 0.016851116503987993\n",
      "SEED: 1, FOLD: 0, EPOCH: 21,train_loss: 0.015240114857105242, valid_loss: 0.01663775130042008\n",
      "SEED: 1, FOLD: 0, EPOCH: 22,train_loss: 0.014716805923946094, valid_loss: 0.016667804547718594\n",
      "SEED: 1, FOLD: 0, EPOCH: 23,train_loss: 0.014243627243769773, valid_loss: 0.016664158659321922\n",
      "SEED: 1, FOLD: 0, EPOCH: 24,train_loss: 0.013987318659876135, valid_loss: 0.016672574249761447\n",
      "(17532, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7347548486542528, valid_loss: 0.6960970384734018\n",
      "SEED: 1, FOLD: 1, EPOCH: 0,train_loss: 0.4680755430302263, valid_loss: 0.023574466737253327\n",
      "SEED: 1, FOLD: 1, EPOCH: 1,train_loss: 0.020991936203663367, valid_loss: 0.019067825164113726\n",
      "SEED: 1, FOLD: 1, EPOCH: 2,train_loss: 0.018982793877485894, valid_loss: 0.01839332724256175\n",
      "SEED: 1, FOLD: 1, EPOCH: 3,train_loss: 0.01819739880271419, valid_loss: 0.0179347712546587\n",
      "SEED: 1, FOLD: 1, EPOCH: 4,train_loss: 0.017918945657238908, valid_loss: 0.01784897819161415\n",
      "SEED: 1, FOLD: 1, EPOCH: 5,train_loss: 0.017868135518727513, valid_loss: 0.017899574818355697\n",
      "SEED: 1, FOLD: 1, EPOCH: 6,train_loss: 0.017985358045701564, valid_loss: 0.01787633023091725\n",
      "SEED: 1, FOLD: 1, EPOCH: 7,train_loss: 0.01789901397415321, valid_loss: 0.01800593345292977\n",
      "SEED: 1, FOLD: 1, EPOCH: 8,train_loss: 0.017916661231730975, valid_loss: 0.017724727732794626\n",
      "SEED: 1, FOLD: 1, EPOCH: 9,train_loss: 0.017850624934437065, valid_loss: 0.01774554375026907\n",
      "SEED: 1, FOLD: 1, EPOCH: 10,train_loss: 0.017825279153720307, valid_loss: 0.017633075213858058\n",
      "SEED: 1, FOLD: 1, EPOCH: 11,train_loss: 0.017806278766017324, valid_loss: 0.01771907303482294\n",
      "SEED: 1, FOLD: 1, EPOCH: 12,train_loss: 0.01765766557659546, valid_loss: 0.017526932672730516\n",
      "SEED: 1, FOLD: 1, EPOCH: 13,train_loss: 0.017586247709980848, valid_loss: 0.018247582603778158\n",
      "SEED: 1, FOLD: 1, EPOCH: 14,train_loss: 0.017497988526512236, valid_loss: 0.017590473379407612\n",
      "SEED: 1, FOLD: 1, EPOCH: 15,train_loss: 0.01736886934615182, valid_loss: 0.017251144642276423\n",
      "SEED: 1, FOLD: 1, EPOCH: 16,train_loss: 0.01714752065901556, valid_loss: 0.017338783772928374\n",
      "SEED: 1, FOLD: 1, EPOCH: 17,train_loss: 0.016927604257625385, valid_loss: 0.01730947427983795\n",
      "SEED: 1, FOLD: 1, EPOCH: 18,train_loss: 0.0166288714407243, valid_loss: 0.017177958014820305\n",
      "SEED: 1, FOLD: 1, EPOCH: 19,train_loss: 0.01633016760359063, valid_loss: 0.017219082000000135\n",
      "SEED: 1, FOLD: 1, EPOCH: 20,train_loss: 0.015869808104569023, valid_loss: 0.017018999638301984\n",
      "SEED: 1, FOLD: 1, EPOCH: 21,train_loss: 0.01537142463545077, valid_loss: 0.01708928437105247\n",
      "SEED: 1, FOLD: 1, EPOCH: 22,train_loss: 0.0148944526869994, valid_loss: 0.01707886058304991\n",
      "SEED: 1, FOLD: 1, EPOCH: 23,train_loss: 0.014435463809292682, valid_loss: 0.017086617196244852\n",
      "SEED: 1, FOLD: 1, EPOCH: 24,train_loss: 0.014212652748573, valid_loss: 0.01707524231501988\n",
      "(17585, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7343341168286144, valid_loss: 0.6962700247764587\n",
      "SEED: 1, FOLD: 2, EPOCH: 0,train_loss: 0.46678444706713373, valid_loss: 0.02776231137769563\n",
      "SEED: 1, FOLD: 2, EPOCH: 1,train_loss: 0.021115083517371746, valid_loss: 0.01923627315887383\n",
      "SEED: 1, FOLD: 2, EPOCH: 2,train_loss: 0.01902355758500272, valid_loss: 0.018008571304380893\n",
      "SEED: 1, FOLD: 2, EPOCH: 3,train_loss: 0.018103396466028862, valid_loss: 0.017880888735609394\n",
      "SEED: 1, FOLD: 2, EPOCH: 4,train_loss: 0.01778941465190787, valid_loss: 0.017719634595726216\n",
      "SEED: 1, FOLD: 2, EPOCH: 5,train_loss: 0.017709917989491984, valid_loss: 0.017612244002521038\n",
      "SEED: 1, FOLD: 2, EPOCH: 6,train_loss: 0.01776344959448645, valid_loss: 0.017852546381098882\n",
      "SEED: 1, FOLD: 2, EPOCH: 7,train_loss: 0.017805069954930874, valid_loss: 0.01787837456379618\n",
      "SEED: 1, FOLD: 2, EPOCH: 8,train_loss: 0.01780332145753546, valid_loss: 0.01782841073083026\n",
      "SEED: 1, FOLD: 2, EPOCH: 9,train_loss: 0.017819301542434572, valid_loss: 0.018563518513526236\n",
      "SEED: 1, FOLD: 2, EPOCH: 10,train_loss: 0.017745555783419506, valid_loss: 0.017779215265597614\n",
      "SEED: 1, FOLD: 2, EPOCH: 11,train_loss: 0.017668491411630228, valid_loss: 0.017604059034160204\n",
      "SEED: 1, FOLD: 2, EPOCH: 12,train_loss: 0.017639669225267742, valid_loss: 0.017630304529198577\n",
      "SEED: 1, FOLD: 2, EPOCH: 13,train_loss: 0.017530127759159044, valid_loss: 0.01770278715661594\n",
      "SEED: 1, FOLD: 2, EPOCH: 14,train_loss: 0.017465391675469236, valid_loss: 0.0175380514934659\n",
      "SEED: 1, FOLD: 2, EPOCH: 15,train_loss: 0.01730513082061341, valid_loss: 0.01731290939663138\n",
      "SEED: 1, FOLD: 2, EPOCH: 16,train_loss: 0.017127729554161215, valid_loss: 0.017350034655204842\n",
      "SEED: 1, FOLD: 2, EPOCH: 17,train_loss: 0.01687023461377923, valid_loss: 0.01723368423325675\n",
      "SEED: 1, FOLD: 2, EPOCH: 18,train_loss: 0.016562168560652197, valid_loss: 0.0172472941290055\n",
      "SEED: 1, FOLD: 2, EPOCH: 19,train_loss: 0.016268817491937374, valid_loss: 0.01706999923501696\n",
      "SEED: 1, FOLD: 2, EPOCH: 20,train_loss: 0.015725396863738264, valid_loss: 0.01719317747546094\n",
      "SEED: 1, FOLD: 2, EPOCH: 21,train_loss: 0.015243825192252794, valid_loss: 0.01716147820864405\n",
      "SEED: 1, FOLD: 2, EPOCH: 22,train_loss: 0.014698464342433474, valid_loss: 0.01715906241110393\n",
      "SEED: 1, FOLD: 2, EPOCH: 23,train_loss: 0.014249020067138084, valid_loss: 0.017129764493022646\n",
      "SEED: 1, FOLD: 2, EPOCH: 24,train_loss: 0.01397094451079982, valid_loss: 0.017122575055275646\n",
      "(17593, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7345684861791306, valid_loss: 0.6971183163779122\n",
      "SEED: 1, FOLD: 3, EPOCH: 0,train_loss: 0.4683806936432054, valid_loss: 0.024321717023849488\n",
      "SEED: 1, FOLD: 3, EPOCH: 1,train_loss: 0.020946218294725902, valid_loss: 0.019461645452039582\n",
      "SEED: 1, FOLD: 3, EPOCH: 2,train_loss: 0.018871326228954655, valid_loss: 0.018713766815406936\n",
      "SEED: 1, FOLD: 3, EPOCH: 3,train_loss: 0.01809849030594679, valid_loss: 0.018472569489053316\n",
      "SEED: 1, FOLD: 3, EPOCH: 4,train_loss: 0.017879825058406677, valid_loss: 0.018314032842006\n",
      "SEED: 1, FOLD: 3, EPOCH: 5,train_loss: 0.017797133574883144, valid_loss: 0.018486282495515687\n",
      "SEED: 1, FOLD: 3, EPOCH: 6,train_loss: 0.017719772205674562, valid_loss: 0.018294070128883635\n",
      "SEED: 1, FOLD: 3, EPOCH: 7,train_loss: 0.017770222928105057, valid_loss: 0.01832563022949866\n",
      "SEED: 1, FOLD: 3, EPOCH: 8,train_loss: 0.017750895116478205, valid_loss: 0.01858476187501635\n",
      "SEED: 1, FOLD: 3, EPOCH: 9,train_loss: 0.017788085809814325, valid_loss: 0.018394978610532624\n",
      "SEED: 1, FOLD: 3, EPOCH: 10,train_loss: 0.017723421437962763, valid_loss: 0.01831605884113482\n",
      "SEED: 1, FOLD: 3, EPOCH: 11,train_loss: 0.017708264412763325, valid_loss: 0.018390878183501106\n",
      "SEED: 1, FOLD: 3, EPOCH: 12,train_loss: 0.01758909840946612, valid_loss: 0.018149340179349695\n",
      "SEED: 1, FOLD: 3, EPOCH: 13,train_loss: 0.017509338101777044, valid_loss: 0.018339123763144016\n",
      "SEED: 1, FOLD: 3, EPOCH: 14,train_loss: 0.017389383571951286, valid_loss: 0.018077858723700047\n",
      "SEED: 1, FOLD: 3, EPOCH: 15,train_loss: 0.01718466418484847, valid_loss: 0.018131616339087487\n",
      "SEED: 1, FOLD: 3, EPOCH: 16,train_loss: 0.017042458185629137, valid_loss: 0.017890550488872187\n",
      "SEED: 1, FOLD: 3, EPOCH: 17,train_loss: 0.016794202376858913, valid_loss: 0.01789151629699128\n",
      "SEED: 1, FOLD: 3, EPOCH: 18,train_loss: 0.016622447725925325, valid_loss: 0.017903464766485352\n",
      "SEED: 1, FOLD: 3, EPOCH: 19,train_loss: 0.01616275056089828, valid_loss: 0.017871386078851564\n",
      "SEED: 1, FOLD: 3, EPOCH: 20,train_loss: 0.015742763276279405, valid_loss: 0.01788113053355898\n",
      "SEED: 1, FOLD: 3, EPOCH: 21,train_loss: 0.015259949827863686, valid_loss: 0.017749623847859247\n",
      "SEED: 1, FOLD: 3, EPOCH: 22,train_loss: 0.014748250498719837, valid_loss: 0.01775160027401788\n",
      "SEED: 1, FOLD: 3, EPOCH: 23,train_loss: 0.014282053228521692, valid_loss: 0.017774486195828235\n",
      "SEED: 1, FOLD: 3, EPOCH: 24,train_loss: 0.01405034638752324, valid_loss: 0.017751586250960828\n",
      "(17505, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.734495011559368, valid_loss: 0.6975872635841369\n",
      "SEED: 1, FOLD: 4, EPOCH: 0,train_loss: 0.46910980517846823, valid_loss: 0.02537475318780967\n",
      "SEED: 1, FOLD: 4, EPOCH: 1,train_loss: 0.020924853555259915, valid_loss: 0.019582399725914003\n",
      "SEED: 1, FOLD: 4, EPOCH: 2,train_loss: 0.019236238340228577, valid_loss: 0.018562723589794976\n",
      "SEED: 1, FOLD: 4, EPOCH: 3,train_loss: 0.01817060282358723, valid_loss: 0.01847739044044699\n",
      "SEED: 1, FOLD: 4, EPOCH: 4,train_loss: 0.017895035228154957, valid_loss: 0.018235306069254876\n",
      "SEED: 1, FOLD: 4, EPOCH: 5,train_loss: 0.017833876763436483, valid_loss: 0.018294956375445637\n",
      "SEED: 1, FOLD: 4, EPOCH: 6,train_loss: 0.017750516153165023, valid_loss: 0.01830607745796442\n",
      "SEED: 1, FOLD: 4, EPOCH: 7,train_loss: 0.017790786072231123, valid_loss: 0.018298335213746342\n",
      "SEED: 1, FOLD: 4, EPOCH: 8,train_loss: 0.017840111662164655, valid_loss: 0.018653008395007678\n",
      "SEED: 1, FOLD: 4, EPOCH: 9,train_loss: 0.01782336413017372, valid_loss: 0.01872547705258642\n",
      "SEED: 1, FOLD: 4, EPOCH: 10,train_loss: 0.01772270093325281, valid_loss: 0.018380294234624932\n",
      "SEED: 1, FOLD: 4, EPOCH: 11,train_loss: 0.017730314774017264, valid_loss: 0.01805935369006225\n",
      "SEED: 1, FOLD: 4, EPOCH: 12,train_loss: 0.0176879005968897, valid_loss: 0.01819381650005068\n",
      "SEED: 1, FOLD: 4, EPOCH: 13,train_loss: 0.017562400182559543, valid_loss: 0.017932607047259807\n",
      "SEED: 1, FOLD: 4, EPOCH: 14,train_loss: 0.01741086802424958, valid_loss: 0.018154873086937837\n",
      "SEED: 1, FOLD: 4, EPOCH: 15,train_loss: 0.017270198268611935, valid_loss: 0.017833658174744676\n",
      "SEED: 1, FOLD: 4, EPOCH: 16,train_loss: 0.017097044219500826, valid_loss: 0.01789132910115378\n",
      "SEED: 1, FOLD: 4, EPOCH: 17,train_loss: 0.016885021110031293, valid_loss: 0.017992102727293968\n",
      "SEED: 1, FOLD: 4, EPOCH: 18,train_loss: 0.01660954912811735, valid_loss: 0.01780526643352849\n",
      "SEED: 1, FOLD: 4, EPOCH: 19,train_loss: 0.016230031902337596, valid_loss: 0.017743022606841154\n",
      "SEED: 1, FOLD: 4, EPOCH: 20,train_loss: 0.0158346276730299, valid_loss: 0.017703553369002683\n",
      "SEED: 1, FOLD: 4, EPOCH: 21,train_loss: 0.01537717699351972, valid_loss: 0.017688303121498654\n",
      "SEED: 1, FOLD: 4, EPOCH: 22,train_loss: 0.014870009854109618, valid_loss: 0.01767020547496421\n",
      "SEED: 1, FOLD: 4, EPOCH: 23,train_loss: 0.014433360087556125, valid_loss: 0.017625835883830276\n",
      "SEED: 1, FOLD: 4, EPOCH: 24,train_loss: 0.014197510701135127, valid_loss: 0.01762048096529075\n",
      "(17579, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7376675195452096, valid_loss: 0.703517780985151\n",
      "SEED: 2, FOLD: 0, EPOCH: 0,train_loss: 0.4645664579626443, valid_loss: 0.02501989315663065\n",
      "SEED: 2, FOLD: 0, EPOCH: 1,train_loss: 0.021284343539804653, valid_loss: 0.019195250581417765\n",
      "SEED: 2, FOLD: 0, EPOCH: 2,train_loss: 0.019191668895275696, valid_loss: 0.018546509396817002\n",
      "SEED: 2, FOLD: 0, EPOCH: 3,train_loss: 0.018380517160277002, valid_loss: 0.017463121909115996\n",
      "SEED: 2, FOLD: 0, EPOCH: 4,train_loss: 0.017986490310210247, valid_loss: 0.018322157327617918\n",
      "SEED: 2, FOLD: 0, EPOCH: 5,train_loss: 0.01804875501472017, valid_loss: 0.017911937965878418\n",
      "SEED: 2, FOLD: 0, EPOCH: 6,train_loss: 0.01805423899297265, valid_loss: 0.017410297745040486\n",
      "SEED: 2, FOLD: 0, EPOCH: 7,train_loss: 0.017983938540345516, valid_loss: 0.017809842926050937\n",
      "SEED: 2, FOLD: 0, EPOCH: 8,train_loss: 0.017969804923927437, valid_loss: 0.01798191557505301\n",
      "SEED: 2, FOLD: 0, EPOCH: 9,train_loss: 0.017928830044263083, valid_loss: 0.01754824412720544\n",
      "SEED: 2, FOLD: 0, EPOCH: 10,train_loss: 0.017887426627988832, valid_loss: 0.017563401109405925\n",
      "SEED: 2, FOLD: 0, EPOCH: 11,train_loss: 0.01787017271651522, valid_loss: 0.017473068993006435\n",
      "SEED: 2, FOLD: 0, EPOCH: 12,train_loss: 0.017754941969516054, valid_loss: 0.017265888516392026\n",
      "SEED: 2, FOLD: 0, EPOCH: 13,train_loss: 0.017726878365636734, valid_loss: 0.01902777903846332\n",
      "SEED: 2, FOLD: 0, EPOCH: 14,train_loss: 0.017602436845123335, valid_loss: 0.016952018572815825\n",
      "SEED: 2, FOLD: 0, EPOCH: 15,train_loss: 0.017354707010900198, valid_loss: 0.01717286857643298\n",
      "SEED: 2, FOLD: 0, EPOCH: 16,train_loss: 0.01718713752790422, valid_loss: 0.017014189729733127\n",
      "SEED: 2, FOLD: 0, EPOCH: 17,train_loss: 0.016969185491240976, valid_loss: 0.016975846700370313\n",
      "SEED: 2, FOLD: 0, EPOCH: 18,train_loss: 0.0166993067410869, valid_loss: 0.016802790920649256\n",
      "SEED: 2, FOLD: 0, EPOCH: 19,train_loss: 0.016355046354558155, valid_loss: 0.016802911327353547\n",
      "SEED: 2, FOLD: 0, EPOCH: 20,train_loss: 0.015969286733509405, valid_loss: 0.016797254766736713\n",
      "SEED: 2, FOLD: 0, EPOCH: 21,train_loss: 0.015462950060980907, valid_loss: 0.01669745541044644\n",
      "SEED: 2, FOLD: 0, EPOCH: 22,train_loss: 0.014934580239966728, valid_loss: 0.016640895871179444\n",
      "SEED: 2, FOLD: 0, EPOCH: 23,train_loss: 0.0145205388965922, valid_loss: 0.016648013623697416\n",
      "SEED: 2, FOLD: 0, EPOCH: 24,train_loss: 0.014267868895515583, valid_loss: 0.01661794630012342\n",
      "(17572, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7380742547304734, valid_loss: 0.705209459577288\n",
      "SEED: 2, FOLD: 1, EPOCH: 0,train_loss: 0.46821850501810724, valid_loss: 0.024182651937007905\n",
      "SEED: 2, FOLD: 1, EPOCH: 1,train_loss: 0.021326126274315342, valid_loss: 0.01925636237221105\n",
      "SEED: 2, FOLD: 1, EPOCH: 2,train_loss: 0.019045563698138878, valid_loss: 0.017962081570710456\n",
      "SEED: 2, FOLD: 1, EPOCH: 3,train_loss: 0.018281925456139488, valid_loss: 0.017809630717550005\n",
      "SEED: 2, FOLD: 1, EPOCH: 4,train_loss: 0.018097296370652275, valid_loss: 0.01756614249731813\n",
      "SEED: 2, FOLD: 1, EPOCH: 5,train_loss: 0.017956302750963663, valid_loss: 0.01777110823563167\n",
      "SEED: 2, FOLD: 1, EPOCH: 6,train_loss: 0.017981967753798202, valid_loss: 0.017443788317697387\n",
      "SEED: 2, FOLD: 1, EPOCH: 7,train_loss: 0.01798298338806068, valid_loss: 0.017435119301080704\n",
      "SEED: 2, FOLD: 1, EPOCH: 8,train_loss: 0.017973382349895393, valid_loss: 0.017802718920367104\n",
      "SEED: 2, FOLD: 1, EPOCH: 9,train_loss: 0.01797380033151611, valid_loss: 0.017543054026152406\n",
      "SEED: 2, FOLD: 1, EPOCH: 10,train_loss: 0.017950551523624556, valid_loss: 0.017546614525573594\n",
      "SEED: 2, FOLD: 1, EPOCH: 11,train_loss: 0.017868985104766012, valid_loss: 0.017669624595769814\n",
      "SEED: 2, FOLD: 1, EPOCH: 12,train_loss: 0.017787919298786183, valid_loss: 0.017433213575610094\n",
      "SEED: 2, FOLD: 1, EPOCH: 13,train_loss: 0.017715155329231336, valid_loss: 0.017298941340829644\n",
      "SEED: 2, FOLD: 1, EPOCH: 14,train_loss: 0.017560758432238432, valid_loss: 0.017244331778160163\n",
      "SEED: 2, FOLD: 1, EPOCH: 15,train_loss: 0.017394706242434357, valid_loss: 0.017171558045915195\n",
      "SEED: 2, FOLD: 1, EPOCH: 16,train_loss: 0.017256448767485395, valid_loss: 0.017111200386924402\n",
      "SEED: 2, FOLD: 1, EPOCH: 17,train_loss: 0.016958721731182024, valid_loss: 0.016907386774463313\n",
      "SEED: 2, FOLD: 1, EPOCH: 18,train_loss: 0.01672554322504911, valid_loss: 0.016968036948570183\n",
      "SEED: 2, FOLD: 1, EPOCH: 19,train_loss: 0.01636136900228651, valid_loss: 0.01685728228517941\n",
      "SEED: 2, FOLD: 1, EPOCH: 20,train_loss: 0.0159324470947942, valid_loss: 0.016749046902571407\n",
      "SEED: 2, FOLD: 1, EPOCH: 21,train_loss: 0.01546332272498504, valid_loss: 0.01680394863443715\n",
      "SEED: 2, FOLD: 1, EPOCH: 22,train_loss: 0.014928264273465544, valid_loss: 0.01667415869555303\n",
      "SEED: 2, FOLD: 1, EPOCH: 23,train_loss: 0.014517438280787588, valid_loss: 0.016688722212399754\n",
      "SEED: 2, FOLD: 1, EPOCH: 24,train_loss: 0.01426157914776949, valid_loss: 0.016693754520799433\n",
      "(17584, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7376708854799685, valid_loss: 0.7041055287633623\n",
      "SEED: 2, FOLD: 2, EPOCH: 0,train_loss: 0.46666766264462384, valid_loss: 0.024030172984514916\n",
      "SEED: 2, FOLD: 2, EPOCH: 1,train_loss: 0.020811865085978872, valid_loss: 0.018670768663287162\n",
      "SEED: 2, FOLD: 2, EPOCH: 2,train_loss: 0.01895308043078884, valid_loss: 0.018106615410319396\n",
      "SEED: 2, FOLD: 2, EPOCH: 3,train_loss: 0.018260171461472477, valid_loss: 0.018143952531473977\n",
      "SEED: 2, FOLD: 2, EPOCH: 4,train_loss: 0.018014923709890118, valid_loss: 0.018073129946632044\n",
      "SEED: 2, FOLD: 2, EPOCH: 5,train_loss: 0.01782210884561789, valid_loss: 0.017934735624917916\n",
      "SEED: 2, FOLD: 2, EPOCH: 6,train_loss: 0.017900025195347658, valid_loss: 0.01803150089191539\n",
      "SEED: 2, FOLD: 2, EPOCH: 7,train_loss: 0.017853426639044632, valid_loss: 0.01803522032818624\n",
      "SEED: 2, FOLD: 2, EPOCH: 8,train_loss: 0.0177960861204327, valid_loss: 0.01830473371914455\n",
      "SEED: 2, FOLD: 2, EPOCH: 9,train_loss: 0.017795157929261524, valid_loss: 0.018146421760320663\n",
      "SEED: 2, FOLD: 2, EPOCH: 10,train_loss: 0.01775498026172104, valid_loss: 0.01811933754278081\n",
      "SEED: 2, FOLD: 2, EPOCH: 11,train_loss: 0.017678251759945484, valid_loss: 0.01790441181510687\n",
      "SEED: 2, FOLD: 2, EPOCH: 12,train_loss: 0.017661755978791178, valid_loss: 0.017641896594847953\n",
      "SEED: 2, FOLD: 2, EPOCH: 13,train_loss: 0.01757973253025093, valid_loss: 0.017611228089247432\n",
      "SEED: 2, FOLD: 2, EPOCH: 14,train_loss: 0.017390576953851225, valid_loss: 0.017649143455283983\n",
      "SEED: 2, FOLD: 2, EPOCH: 15,train_loss: 0.017232986814949825, valid_loss: 0.017549104349953788\n",
      "SEED: 2, FOLD: 2, EPOCH: 16,train_loss: 0.017054931004194245, valid_loss: 0.017556228089545454\n",
      "SEED: 2, FOLD: 2, EPOCH: 17,train_loss: 0.01682525939321604, valid_loss: 0.017563378012606077\n",
      "SEED: 2, FOLD: 2, EPOCH: 18,train_loss: 0.016550458616752556, valid_loss: 0.0174175904531564\n",
      "SEED: 2, FOLD: 2, EPOCH: 19,train_loss: 0.016172052948209253, valid_loss: 0.017476718606693403\n",
      "SEED: 2, FOLD: 2, EPOCH: 20,train_loss: 0.01574641630134505, valid_loss: 0.017435292819780963\n",
      "SEED: 2, FOLD: 2, EPOCH: 21,train_loss: 0.015267117650828499, valid_loss: 0.01743038794291871\n",
      "SEED: 2, FOLD: 2, EPOCH: 22,train_loss: 0.014744316362708376, valid_loss: 0.017428426444530486\n",
      "SEED: 2, FOLD: 2, EPOCH: 23,train_loss: 0.01432589319386128, valid_loss: 0.017441715353301593\n",
      "SEED: 2, FOLD: 2, EPOCH: 24,train_loss: 0.014069146645403858, valid_loss: 0.017445421644619534\n",
      "(17468, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7377382495107442, valid_loss: 0.7073004245758057\n",
      "SEED: 2, FOLD: 3, EPOCH: 0,train_loss: 0.467584020410576, valid_loss: 0.02386944256722927\n",
      "SEED: 2, FOLD: 3, EPOCH: 1,train_loss: 0.02060776619906843, valid_loss: 0.01877283017550196\n",
      "SEED: 2, FOLD: 3, EPOCH: 2,train_loss: 0.019017873359096313, valid_loss: 0.018505061524254934\n",
      "SEED: 2, FOLD: 3, EPOCH: 3,train_loss: 0.018274106030916646, valid_loss: 0.01809269857725927\n",
      "SEED: 2, FOLD: 3, EPOCH: 4,train_loss: 0.018159017429082065, valid_loss: 0.018112047814897128\n",
      "SEED: 2, FOLD: 3, EPOCH: 5,train_loss: 0.01787112943528995, valid_loss: 0.018019574587898594\n",
      "SEED: 2, FOLD: 3, EPOCH: 6,train_loss: 0.017833067355745465, valid_loss: 0.018280114127056938\n",
      "SEED: 2, FOLD: 3, EPOCH: 7,train_loss: 0.017808186230215715, valid_loss: 0.01824305685503142\n",
      "SEED: 2, FOLD: 3, EPOCH: 8,train_loss: 0.017818453381803347, valid_loss: 0.017850228079727717\n",
      "SEED: 2, FOLD: 3, EPOCH: 9,train_loss: 0.01775660477306721, valid_loss: 0.018060520477592944\n",
      "SEED: 2, FOLD: 3, EPOCH: 10,train_loss: 0.017718793246487195, valid_loss: 0.01810166101370539\n",
      "SEED: 2, FOLD: 3, EPOCH: 11,train_loss: 0.017622010911522556, valid_loss: 0.01807480212301016\n",
      "SEED: 2, FOLD: 3, EPOCH: 12,train_loss: 0.01763830287042108, valid_loss: 0.018223172266568458\n",
      "SEED: 2, FOLD: 3, EPOCH: 13,train_loss: 0.01757995256080027, valid_loss: 0.017715790016310556\n",
      "SEED: 2, FOLD: 3, EPOCH: 14,train_loss: 0.017400642047996503, valid_loss: 0.017826811277440617\n",
      "SEED: 2, FOLD: 3, EPOCH: 15,train_loss: 0.01729326350546449, valid_loss: 0.017866408904748304\n",
      "SEED: 2, FOLD: 3, EPOCH: 16,train_loss: 0.01706170965747459, valid_loss: 0.017630552048129695\n",
      "SEED: 2, FOLD: 3, EPOCH: 17,train_loss: 0.016900345621916064, valid_loss: 0.017616798356175422\n",
      "SEED: 2, FOLD: 3, EPOCH: 18,train_loss: 0.016574688595685647, valid_loss: 0.017404989738549505\n",
      "SEED: 2, FOLD: 3, EPOCH: 19,train_loss: 0.016276300979954916, valid_loss: 0.017321475994374072\n",
      "SEED: 2, FOLD: 3, EPOCH: 20,train_loss: 0.01587269452475283, valid_loss: 0.01736695556236165\n",
      "SEED: 2, FOLD: 3, EPOCH: 21,train_loss: 0.015337857689681279, valid_loss: 0.017381312352206024\n",
      "SEED: 2, FOLD: 3, EPOCH: 22,train_loss: 0.014867065848279609, valid_loss: 0.01731157765856811\n",
      "SEED: 2, FOLD: 3, EPOCH: 23,train_loss: 0.014410167069167552, valid_loss: 0.01731313176985298\n",
      "SEED: 2, FOLD: 3, EPOCH: 24,train_loss: 0.014214009243695841, valid_loss: 0.0173100583255291\n",
      "(17589, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7378755669662918, valid_loss: 0.7079552071435111\n",
      "SEED: 2, FOLD: 4, EPOCH: 0,train_loss: 0.46737065459129173, valid_loss: 0.025833638172064508\n",
      "SEED: 2, FOLD: 4, EPOCH: 1,train_loss: 0.02089663362805394, valid_loss: 0.020107740163803102\n",
      "SEED: 2, FOLD: 4, EPOCH: 2,train_loss: 0.019133408135478047, valid_loss: 0.01901278809777328\n",
      "SEED: 2, FOLD: 4, EPOCH: 3,train_loss: 0.01834648800338956, valid_loss: 0.019174419449908393\n",
      "SEED: 2, FOLD: 4, EPOCH: 4,train_loss: 0.017998143436684124, valid_loss: 0.018720730606998717\n",
      "SEED: 2, FOLD: 4, EPOCH: 5,train_loss: 0.017706071741986965, valid_loss: 0.018547821789979935\n",
      "SEED: 2, FOLD: 4, EPOCH: 6,train_loss: 0.017734339764422697, valid_loss: 0.018581019368554864\n",
      "SEED: 2, FOLD: 4, EPOCH: 7,train_loss: 0.0176328069705894, valid_loss: 0.018376571285937515\n",
      "SEED: 2, FOLD: 4, EPOCH: 8,train_loss: 0.017601347055988037, valid_loss: 0.019335749905024256\n",
      "SEED: 2, FOLD: 4, EPOCH: 9,train_loss: 0.01756416329358151, valid_loss: 0.01864714263273137\n",
      "SEED: 2, FOLD: 4, EPOCH: 10,train_loss: 0.017490840361764032, valid_loss: 0.018428649620286057\n",
      "SEED: 2, FOLD: 4, EPOCH: 11,train_loss: 0.017436110421313322, valid_loss: 0.018586975069982664\n",
      "SEED: 2, FOLD: 4, EPOCH: 12,train_loss: 0.017387691945971354, valid_loss: 0.01841046983110053\n",
      "SEED: 2, FOLD: 4, EPOCH: 13,train_loss: 0.017224317598764017, valid_loss: 0.018133822216519286\n",
      "SEED: 2, FOLD: 4, EPOCH: 14,train_loss: 0.017050550231521112, valid_loss: 0.018169788111533438\n",
      "SEED: 2, FOLD: 4, EPOCH: 15,train_loss: 0.016920983960069177, valid_loss: 0.018197330965527465\n",
      "SEED: 2, FOLD: 4, EPOCH: 16,train_loss: 0.01666189060020058, valid_loss: 0.018131135404109953\n",
      "SEED: 2, FOLD: 4, EPOCH: 17,train_loss: 0.016472004968133093, valid_loss: 0.01824084044034992\n",
      "SEED: 2, FOLD: 4, EPOCH: 18,train_loss: 0.01615677590387455, valid_loss: 0.017967822030186653\n",
      "SEED: 2, FOLD: 4, EPOCH: 19,train_loss: 0.01569480965912774, valid_loss: 0.01802265638751643\n",
      "SEED: 2, FOLD: 4, EPOCH: 20,train_loss: 0.015219159869720106, valid_loss: 0.018015176696436746\n",
      "SEED: 2, FOLD: 4, EPOCH: 21,train_loss: 0.014743355399780516, valid_loss: 0.018087047897279263\n",
      "SEED: 2, FOLD: 4, EPOCH: 22,train_loss: 0.01418639344257721, valid_loss: 0.018107281305960246\n",
      "SEED: 2, FOLD: 4, EPOCH: 23,train_loss: 0.013681787194387205, valid_loss: 0.018039994074829986\n",
      "SEED: 2, FOLD: 4, EPOCH: 24,train_loss: 0.013419297523796558, valid_loss: 0.018049467700932707\n",
      "(17591, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7345065003719883, valid_loss: 0.6981497696467809\n",
      "SEED: 3, FOLD: 0, EPOCH: 0,train_loss: 0.46689722603321937, valid_loss: 0.02328245203409876\n",
      "SEED: 3, FOLD: 0, EPOCH: 1,train_loss: 0.020773719496809055, valid_loss: 0.018408745041649258\n",
      "SEED: 3, FOLD: 0, EPOCH: 2,train_loss: 0.01966549998716168, valid_loss: 0.01839225839025208\n",
      "SEED: 3, FOLD: 0, EPOCH: 3,train_loss: 0.01829636339908061, valid_loss: 0.01789775994340224\n",
      "SEED: 3, FOLD: 0, EPOCH: 4,train_loss: 0.01787707010500025, valid_loss: 0.018019183878121632\n",
      "SEED: 3, FOLD: 0, EPOCH: 5,train_loss: 0.017712920890662117, valid_loss: 0.017707520151244743\n",
      "SEED: 3, FOLD: 0, EPOCH: 6,train_loss: 0.017780414330300646, valid_loss: 0.017765541461163332\n",
      "SEED: 3, FOLD: 0, EPOCH: 7,train_loss: 0.01776098057060786, valid_loss: 0.01752715509917055\n",
      "SEED: 3, FOLD: 0, EPOCH: 8,train_loss: 0.017778758857183267, valid_loss: 0.017666646931320428\n",
      "SEED: 3, FOLD: 0, EPOCH: 9,train_loss: 0.017702940480270678, valid_loss: 0.017526364136886383\n",
      "SEED: 3, FOLD: 0, EPOCH: 10,train_loss: 0.017775250160121832, valid_loss: 0.017746160186028908\n",
      "SEED: 3, FOLD: 0, EPOCH: 11,train_loss: 0.017652424322306248, valid_loss: 0.017869629611128143\n",
      "SEED: 3, FOLD: 0, EPOCH: 12,train_loss: 0.017657446222838716, valid_loss: 0.017664362503481763\n",
      "SEED: 3, FOLD: 0, EPOCH: 13,train_loss: 0.017488290899959597, valid_loss: 0.017590422801939506\n",
      "SEED: 3, FOLD: 0, EPOCH: 14,train_loss: 0.01741589156343885, valid_loss: 0.017342291579448752\n",
      "SEED: 3, FOLD: 0, EPOCH: 15,train_loss: 0.017280994826738817, valid_loss: 0.01740482480464769\n",
      "SEED: 3, FOLD: 0, EPOCH: 16,train_loss: 0.01707320347212363, valid_loss: 0.017357227991202047\n",
      "SEED: 3, FOLD: 0, EPOCH: 17,train_loss: 0.01681731378092714, valid_loss: 0.017180162139369973\n",
      "SEED: 3, FOLD: 0, EPOCH: 18,train_loss: 0.016548925875753597, valid_loss: 0.017063455104029606\n",
      "SEED: 3, FOLD: 0, EPOCH: 19,train_loss: 0.016175416460179764, valid_loss: 0.017107590510776\n",
      "SEED: 3, FOLD: 0, EPOCH: 20,train_loss: 0.01578290235467147, valid_loss: 0.017161673477052577\n",
      "SEED: 3, FOLD: 0, EPOCH: 21,train_loss: 0.01531163369561883, valid_loss: 0.016992112804603363\n",
      "SEED: 3, FOLD: 0, EPOCH: 22,train_loss: 0.014813747405465962, valid_loss: 0.017112120580194252\n",
      "SEED: 3, FOLD: 0, EPOCH: 23,train_loss: 0.014420944535969824, valid_loss: 0.017035836054544364\n",
      "SEED: 3, FOLD: 0, EPOCH: 24,train_loss: 0.0141552175341201, valid_loss: 0.017065129918046297\n",
      "(17572, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7347343805907429, valid_loss: 0.6954673750059945\n",
      "SEED: 3, FOLD: 1, EPOCH: 0,train_loss: 0.465605361967523, valid_loss: 0.023631288430520467\n",
      "SEED: 3, FOLD: 1, EPOCH: 1,train_loss: 0.020956821645191616, valid_loss: 0.019062584851469312\n",
      "SEED: 3, FOLD: 1, EPOCH: 2,train_loss: 0.019152177065826843, valid_loss: 0.017961683071085383\n",
      "SEED: 3, FOLD: 1, EPOCH: 3,train_loss: 0.01824228348804341, valid_loss: 0.01790678740612098\n",
      "SEED: 3, FOLD: 1, EPOCH: 4,train_loss: 0.017888656864617613, valid_loss: 0.017915785578744754\n",
      "SEED: 3, FOLD: 1, EPOCH: 5,train_loss: 0.017979784598709015, valid_loss: 0.01796813506100859\n",
      "SEED: 3, FOLD: 1, EPOCH: 6,train_loss: 0.017950626454599525, valid_loss: 0.0183409185814006\n",
      "SEED: 3, FOLD: 1, EPOCH: 7,train_loss: 0.017893233478231275, valid_loss: 0.017783145393644062\n",
      "SEED: 3, FOLD: 1, EPOCH: 8,train_loss: 0.017891516774028973, valid_loss: 0.017857636431498188\n",
      "SEED: 3, FOLD: 1, EPOCH: 9,train_loss: 0.017894912774310164, valid_loss: 0.017766389144318443\n",
      "SEED: 3, FOLD: 1, EPOCH: 10,train_loss: 0.017834111474508394, valid_loss: 0.017719576507806777\n",
      "SEED: 3, FOLD: 1, EPOCH: 11,train_loss: 0.017780253042777378, valid_loss: 0.017820389116449016\n",
      "SEED: 3, FOLD: 1, EPOCH: 12,train_loss: 0.01770759114752645, valid_loss: 0.01776063625833818\n",
      "SEED: 3, FOLD: 1, EPOCH: 13,train_loss: 0.017633601024314976, valid_loss: 0.017475493757852487\n",
      "SEED: 3, FOLD: 1, EPOCH: 14,train_loss: 0.017499563554166885, valid_loss: 0.017602199928036757\n",
      "SEED: 3, FOLD: 1, EPOCH: 15,train_loss: 0.017350728454851153, valid_loss: 0.017661579538668905\n",
      "SEED: 3, FOLD: 1, EPOCH: 16,train_loss: 0.01719277760391866, valid_loss: 0.017418793934796537\n",
      "SEED: 3, FOLD: 1, EPOCH: 17,train_loss: 0.016937808383364176, valid_loss: 0.017219713809234757\n",
      "SEED: 3, FOLD: 1, EPOCH: 18,train_loss: 0.016642149119381455, valid_loss: 0.01728591075433152\n",
      "SEED: 3, FOLD: 1, EPOCH: 19,train_loss: 0.016348535944100306, valid_loss: 0.017137677701456206\n",
      "SEED: 3, FOLD: 1, EPOCH: 20,train_loss: 0.015939526563591284, valid_loss: 0.017208667392177242\n",
      "SEED: 3, FOLD: 1, EPOCH: 21,train_loss: 0.015461678603205128, valid_loss: 0.017191023193299772\n",
      "SEED: 3, FOLD: 1, EPOCH: 22,train_loss: 0.01493595643778858, valid_loss: 0.01717908475548029\n",
      "SEED: 3, FOLD: 1, EPOCH: 23,train_loss: 0.014510288578120695, valid_loss: 0.017120787714208874\n",
      "SEED: 3, FOLD: 1, EPOCH: 24,train_loss: 0.014253613444558088, valid_loss: 0.017120347038975785\n",
      "(17520, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7344431237582743, valid_loss: 0.6929103561810085\n",
      "SEED: 3, FOLD: 2, EPOCH: 0,train_loss: 0.46690518116700824, valid_loss: 0.02411137143416064\n",
      "SEED: 3, FOLD: 2, EPOCH: 1,train_loss: 0.021009410235242252, valid_loss: 0.019535962332572255\n",
      "SEED: 3, FOLD: 2, EPOCH: 2,train_loss: 0.019225075772970262, valid_loss: 0.018946529286248345\n",
      "SEED: 3, FOLD: 2, EPOCH: 3,train_loss: 0.018290652030140814, valid_loss: 0.01858159527182579\n",
      "SEED: 3, FOLD: 2, EPOCH: 4,train_loss: 0.018017885676265635, valid_loss: 0.018317481156970773\n",
      "SEED: 3, FOLD: 2, EPOCH: 5,train_loss: 0.017878826836763072, valid_loss: 0.018229247576424055\n",
      "SEED: 3, FOLD: 2, EPOCH: 6,train_loss: 0.017887096906447932, valid_loss: 0.018157773864056384\n",
      "SEED: 3, FOLD: 2, EPOCH: 7,train_loss: 0.017824489779661605, valid_loss: 0.018110680181000913\n",
      "SEED: 3, FOLD: 2, EPOCH: 8,train_loss: 0.01784047730484583, valid_loss: 0.01786496878734657\n",
      "SEED: 3, FOLD: 2, EPOCH: 9,train_loss: 0.017834554120463177, valid_loss: 0.017963667107479913\n",
      "SEED: 3, FOLD: 2, EPOCH: 10,train_loss: 0.017784514226508837, valid_loss: 0.018006308908973423\n",
      "SEED: 3, FOLD: 2, EPOCH: 11,train_loss: 0.01768113467434462, valid_loss: 0.0181694452517799\n",
      "SEED: 3, FOLD: 2, EPOCH: 12,train_loss: 0.017619432147293196, valid_loss: 0.01790717699165855\n",
      "SEED: 3, FOLD: 2, EPOCH: 13,train_loss: 0.017537247484726626, valid_loss: 0.017717015104634422\n",
      "SEED: 3, FOLD: 2, EPOCH: 14,train_loss: 0.017379359484915317, valid_loss: 0.017863353049116477\n",
      "SEED: 3, FOLD: 2, EPOCH: 15,train_loss: 0.017279979099866248, valid_loss: 0.017730976694396564\n",
      "SEED: 3, FOLD: 2, EPOCH: 16,train_loss: 0.01707627147735253, valid_loss: 0.0178220343376909\n",
      "SEED: 3, FOLD: 2, EPOCH: 17,train_loss: 0.016820982812366783, valid_loss: 0.01771095868732248\n",
      "SEED: 3, FOLD: 2, EPOCH: 18,train_loss: 0.01656225318238683, valid_loss: 0.017528349480458668\n",
      "SEED: 3, FOLD: 2, EPOCH: 19,train_loss: 0.016209687915270346, valid_loss: 0.017499729698257787\n",
      "SEED: 3, FOLD: 2, EPOCH: 20,train_loss: 0.015767825488680904, valid_loss: 0.01735232472419739\n",
      "SEED: 3, FOLD: 2, EPOCH: 21,train_loss: 0.015267866058615001, valid_loss: 0.01748545752572162\n",
      "SEED: 3, FOLD: 2, EPOCH: 22,train_loss: 0.014730455211098612, valid_loss: 0.01737505274691752\n",
      "SEED: 3, FOLD: 2, EPOCH: 23,train_loss: 0.01429168421122497, valid_loss: 0.01735854380364929\n",
      "SEED: 3, FOLD: 2, EPOCH: 24,train_loss: 0.014046088085394271, valid_loss: 0.01737881654075214\n",
      "(17578, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7343765847060991, valid_loss: 0.6910368919372558\n",
      "SEED: 3, FOLD: 3, EPOCH: 0,train_loss: 0.46597632278512785, valid_loss: 0.02357594221830368\n",
      "SEED: 3, FOLD: 3, EPOCH: 1,train_loss: 0.020838911591124706, valid_loss: 0.018869758317513124\n",
      "SEED: 3, FOLD: 3, EPOCH: 2,train_loss: 0.018961527175607458, valid_loss: 0.018251106914665017\n",
      "SEED: 3, FOLD: 3, EPOCH: 3,train_loss: 0.01827711151048973, valid_loss: 0.017918701895645688\n",
      "SEED: 3, FOLD: 3, EPOCH: 4,train_loss: 0.01792906743703761, valid_loss: 0.018373287921505315\n",
      "SEED: 3, FOLD: 3, EPOCH: 5,train_loss: 0.017982605939218098, valid_loss: 0.017994784217860018\n",
      "SEED: 3, FOLD: 3, EPOCH: 6,train_loss: 0.017911410526089046, valid_loss: 0.018901393163417067\n",
      "SEED: 3, FOLD: 3, EPOCH: 7,train_loss: 0.017917209277874317, valid_loss: 0.018123246117361953\n",
      "SEED: 3, FOLD: 3, EPOCH: 8,train_loss: 0.017954525294835152, valid_loss: 0.017847532725759913\n",
      "SEED: 3, FOLD: 3, EPOCH: 9,train_loss: 0.01793674878317161, valid_loss: 0.018027636674898012\n",
      "SEED: 3, FOLD: 3, EPOCH: 10,train_loss: 0.017831258914446917, valid_loss: 0.017925584582345826\n",
      "SEED: 3, FOLD: 3, EPOCH: 11,train_loss: 0.017770473069200914, valid_loss: 0.017743537628224917\n",
      "SEED: 3, FOLD: 3, EPOCH: 12,train_loss: 0.01770257540182143, valid_loss: 0.017808289719479425\n",
      "SEED: 3, FOLD: 3, EPOCH: 13,train_loss: 0.017602872677093397, valid_loss: 0.01790310809654849\n",
      "SEED: 3, FOLD: 3, EPOCH: 14,train_loss: 0.017472274156044357, valid_loss: 0.017669569754174778\n",
      "SEED: 3, FOLD: 3, EPOCH: 15,train_loss: 0.01729305188401022, valid_loss: 0.017702687584928104\n",
      "SEED: 3, FOLD: 3, EPOCH: 16,train_loss: 0.017192814870319074, valid_loss: 0.017574470836137022\n",
      "SEED: 3, FOLD: 3, EPOCH: 17,train_loss: 0.01692645147820746, valid_loss: 0.017446257626371725\n",
      "SEED: 3, FOLD: 3, EPOCH: 18,train_loss: 0.01659570177477123, valid_loss: 0.017163268982299737\n",
      "SEED: 3, FOLD: 3, EPOCH: 19,train_loss: 0.016226755556367014, valid_loss: 0.01717072475169386\n",
      "SEED: 3, FOLD: 3, EPOCH: 20,train_loss: 0.015840028304660667, valid_loss: 0.01712042045380388\n",
      "SEED: 3, FOLD: 3, EPOCH: 21,train_loss: 0.01534473361528438, valid_loss: 0.017133252934685775\n",
      "SEED: 3, FOLD: 3, EPOCH: 22,train_loss: 0.014796943079842173, valid_loss: 0.01715102389987026\n",
      "SEED: 3, FOLD: 3, EPOCH: 23,train_loss: 0.014309771325223255, valid_loss: 0.017171292565762997\n",
      "SEED: 3, FOLD: 3, EPOCH: 24,train_loss: 0.014083497347715109, valid_loss: 0.01718914391739028\n",
      "(17531, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7345513409941736, valid_loss: 0.6935538223811558\n",
      "SEED: 3, FOLD: 4, EPOCH: 0,train_loss: 0.46801952037443645, valid_loss: 0.02365109734237194\n",
      "SEED: 3, FOLD: 4, EPOCH: 1,train_loss: 0.02089518890546186, valid_loss: 0.018456356919237544\n",
      "SEED: 3, FOLD: 4, EPOCH: 2,train_loss: 0.01895182729311233, valid_loss: 0.017639400224600518\n",
      "SEED: 3, FOLD: 4, EPOCH: 3,train_loss: 0.018282426351232686, valid_loss: 0.017700537693287645\n",
      "SEED: 3, FOLD: 4, EPOCH: 4,train_loss: 0.017988919933075016, valid_loss: 0.018029033445886203\n",
      "SEED: 3, FOLD: 4, EPOCH: 5,train_loss: 0.01790337809735406, valid_loss: 0.017422795588416713\n",
      "SEED: 3, FOLD: 4, EPOCH: 6,train_loss: 0.017916520540840433, valid_loss: 0.017733227115656648\n",
      "SEED: 3, FOLD: 4, EPOCH: 7,train_loss: 0.017899805272038837, valid_loss: 0.01757240133093936\n",
      "SEED: 3, FOLD: 4, EPOCH: 8,train_loss: 0.01788671876229074, valid_loss: 0.01724646022277219\n",
      "SEED: 3, FOLD: 4, EPOCH: 9,train_loss: 0.017860209188648384, valid_loss: 0.01768921392836741\n",
      "SEED: 3, FOLD: 4, EPOCH: 10,train_loss: 0.01785675288062461, valid_loss: 0.0177825177354472\n",
      "SEED: 3, FOLD: 4, EPOCH: 11,train_loss: 0.017803299159192255, valid_loss: 0.017365765811077186\n",
      "SEED: 3, FOLD: 4, EPOCH: 12,train_loss: 0.017760114859871185, valid_loss: 0.01740898375532457\n",
      "SEED: 3, FOLD: 4, EPOCH: 13,train_loss: 0.017644489761849826, valid_loss: 0.017284709215164184\n",
      "SEED: 3, FOLD: 4, EPOCH: 14,train_loss: 0.01746740429424239, valid_loss: 0.017067402521414417\n",
      "SEED: 3, FOLD: 4, EPOCH: 15,train_loss: 0.017326205547382362, valid_loss: 0.017182572984269687\n",
      "SEED: 3, FOLD: 4, EPOCH: 16,train_loss: 0.017167771235108376, valid_loss: 0.017126947268843652\n",
      "SEED: 3, FOLD: 4, EPOCH: 17,train_loss: 0.016946589961702372, valid_loss: 0.016992417377020633\n",
      "SEED: 3, FOLD: 4, EPOCH: 18,train_loss: 0.01664081670642987, valid_loss: 0.01700586029993636\n",
      "SEED: 3, FOLD: 4, EPOCH: 19,train_loss: 0.016263098027693094, valid_loss: 0.017025470254676683\n",
      "SEED: 3, FOLD: 4, EPOCH: 20,train_loss: 0.01582802691408535, valid_loss: 0.016876701744539396\n",
      "SEED: 3, FOLD: 4, EPOCH: 21,train_loss: 0.015317814852906404, valid_loss: 0.016893212922981807\n",
      "SEED: 3, FOLD: 4, EPOCH: 22,train_loss: 0.01480186066461088, valid_loss: 0.01692999063857964\n",
      "SEED: 3, FOLD: 4, EPOCH: 23,train_loss: 0.014283398519793567, valid_loss: 0.01695199047348329\n",
      "SEED: 3, FOLD: 4, EPOCH: 24,train_loss: 0.014052324411697197, valid_loss: 0.016955853386649063\n",
      "(17588, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7340588345043901, valid_loss: 0.7063287224088396\n",
      "SEED: 4, FOLD: 0, EPOCH: 0,train_loss: 0.4676025369461032, valid_loss: 0.02383009275155408\n",
      "SEED: 4, FOLD: 0, EPOCH: 1,train_loss: 0.02080494793050963, valid_loss: 0.019053980442030088\n",
      "SEED: 4, FOLD: 0, EPOCH: 2,train_loss: 0.01897573203145378, valid_loss: 0.019044032533253943\n",
      "SEED: 4, FOLD: 0, EPOCH: 3,train_loss: 0.018321859663811283, valid_loss: 0.017759469364370617\n",
      "SEED: 4, FOLD: 0, EPOCH: 4,train_loss: 0.018039639499308407, valid_loss: 0.01791533747954028\n",
      "SEED: 4, FOLD: 0, EPOCH: 5,train_loss: 0.01789063369801295, valid_loss: 0.018528186210564204\n",
      "SEED: 4, FOLD: 0, EPOCH: 6,train_loss: 0.01796232016109254, valid_loss: 0.018105613812804223\n",
      "SEED: 4, FOLD: 0, EPOCH: 7,train_loss: 0.01788329511232998, valid_loss: 0.018742762452789715\n",
      "SEED: 4, FOLD: 0, EPOCH: 8,train_loss: 0.017889442279988874, valid_loss: 0.01799683485712324\n",
      "SEED: 4, FOLD: 0, EPOCH: 9,train_loss: 0.017854723465237497, valid_loss: 0.018074124945061547\n",
      "SEED: 4, FOLD: 0, EPOCH: 10,train_loss: 0.01783010204309139, valid_loss: 0.01771422563386815\n",
      "SEED: 4, FOLD: 0, EPOCH: 11,train_loss: 0.017775232809177345, valid_loss: 0.017910232448152135\n",
      "SEED: 4, FOLD: 0, EPOCH: 12,train_loss: 0.01772330715523466, valid_loss: 0.017856704949268273\n",
      "SEED: 4, FOLD: 0, EPOCH: 13,train_loss: 0.017567688889423574, valid_loss: 0.01776022599743945\n",
      "SEED: 4, FOLD: 0, EPOCH: 14,train_loss: 0.017471363288822813, valid_loss: 0.017536049096712043\n",
      "SEED: 4, FOLD: 0, EPOCH: 15,train_loss: 0.017305352428145168, valid_loss: 0.01767647082784346\n",
      "SEED: 4, FOLD: 0, EPOCH: 16,train_loss: 0.01713453825779151, valid_loss: 0.01747000270656177\n",
      "SEED: 4, FOLD: 0, EPOCH: 17,train_loss: 0.016917257515740566, valid_loss: 0.017294900598270553\n",
      "SEED: 4, FOLD: 0, EPOCH: 18,train_loss: 0.016620182411988146, valid_loss: 0.01744852443890912\n",
      "SEED: 4, FOLD: 0, EPOCH: 19,train_loss: 0.016315998563515968, valid_loss: 0.017330042831599713\n",
      "SEED: 4, FOLD: 0, EPOCH: 20,train_loss: 0.015864401650817497, valid_loss: 0.017259112346385205\n",
      "SEED: 4, FOLD: 0, EPOCH: 21,train_loss: 0.01538928734489541, valid_loss: 0.017244783576045718\n",
      "SEED: 4, FOLD: 0, EPOCH: 22,train_loss: 0.01487819847745308, valid_loss: 0.01716503652610949\n",
      "SEED: 4, FOLD: 0, EPOCH: 23,train_loss: 0.014435298659879229, valid_loss: 0.017139393171029433\n",
      "SEED: 4, FOLD: 0, EPOCH: 24,train_loss: 0.014192131725882275, valid_loss: 0.017167453574282784\n",
      "(17601, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.734112490778384, valid_loss: 0.7054686669041129\n",
      "SEED: 4, FOLD: 1, EPOCH: 0,train_loss: 0.46862252755765466, valid_loss: 0.023376391871887094\n",
      "SEED: 4, FOLD: 1, EPOCH: 1,train_loss: 0.020822377834954987, valid_loss: 0.018733395811389473\n",
      "SEED: 4, FOLD: 1, EPOCH: 2,train_loss: 0.01903616330599871, valid_loss: 0.018544585142722902\n",
      "SEED: 4, FOLD: 1, EPOCH: 3,train_loss: 0.01821059701235398, valid_loss: 0.018297183601295248\n",
      "SEED: 4, FOLD: 1, EPOCH: 4,train_loss: 0.01789023611775559, valid_loss: 0.018322469666600227\n",
      "SEED: 4, FOLD: 1, EPOCH: 5,train_loss: 0.01782054811095198, valid_loss: 0.018150750985916925\n",
      "SEED: 4, FOLD: 1, EPOCH: 6,train_loss: 0.017817940367250772, valid_loss: 0.018090198720421863\n",
      "SEED: 4, FOLD: 1, EPOCH: 7,train_loss: 0.017824663348711918, valid_loss: 0.018380911116871762\n",
      "SEED: 4, FOLD: 1, EPOCH: 8,train_loss: 0.01784287496348438, valid_loss: 0.018010828342727003\n",
      "SEED: 4, FOLD: 1, EPOCH: 9,train_loss: 0.01782001042738557, valid_loss: 0.017989589038359767\n",
      "SEED: 4, FOLD: 1, EPOCH: 10,train_loss: 0.017771345340525328, valid_loss: 0.01823813024470035\n",
      "SEED: 4, FOLD: 1, EPOCH: 11,train_loss: 0.01773766476822936, valid_loss: 0.01799743326709551\n",
      "SEED: 4, FOLD: 1, EPOCH: 12,train_loss: 0.017666939180344343, valid_loss: 0.01864852479604237\n",
      "SEED: 4, FOLD: 1, EPOCH: 13,train_loss: 0.01756940478378016, valid_loss: 0.01774639025440111\n",
      "SEED: 4, FOLD: 1, EPOCH: 14,train_loss: 0.017441865535911875, valid_loss: 0.01782441380269387\n",
      "SEED: 4, FOLD: 1, EPOCH: 15,train_loss: 0.01727927268307278, valid_loss: 0.018252412158557597\n",
      "SEED: 4, FOLD: 1, EPOCH: 16,train_loss: 0.017138703631750053, valid_loss: 0.01752315234283314\n",
      "SEED: 4, FOLD: 1, EPOCH: 17,train_loss: 0.01686454889620992, valid_loss: 0.0176318436039283\n",
      "SEED: 4, FOLD: 1, EPOCH: 18,train_loss: 0.016636499365710693, valid_loss: 0.01748152422335218\n",
      "SEED: 4, FOLD: 1, EPOCH: 19,train_loss: 0.016271428130837023, valid_loss: 0.01746903880334952\n",
      "SEED: 4, FOLD: 1, EPOCH: 20,train_loss: 0.01585500698833578, valid_loss: 0.017510915503782386\n",
      "SEED: 4, FOLD: 1, EPOCH: 21,train_loss: 0.015413891800773748, valid_loss: 0.017508569173514843\n",
      "SEED: 4, FOLD: 1, EPOCH: 22,train_loss: 0.014921931144983872, valid_loss: 0.017450263449812636\n",
      "SEED: 4, FOLD: 1, EPOCH: 23,train_loss: 0.01447167211090741, valid_loss: 0.01738374266663895\n",
      "SEED: 4, FOLD: 1, EPOCH: 24,train_loss: 0.014261518537566282, valid_loss: 0.01741577512310708\n",
      "(17580, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7341920081256093, valid_loss: 0.70968325648989\n",
      "SEED: 4, FOLD: 2, EPOCH: 0,train_loss: 0.46690142504277005, valid_loss: 0.02534401219870363\n",
      "SEED: 4, FOLD: 2, EPOCH: 1,train_loss: 0.020935193406067032, valid_loss: 0.018374697278652874\n",
      "SEED: 4, FOLD: 2, EPOCH: 2,train_loss: 0.019245609614080277, valid_loss: 0.018387637792953423\n",
      "SEED: 4, FOLD: 2, EPOCH: 3,train_loss: 0.018366507618971493, valid_loss: 0.017614691850862334\n",
      "SEED: 4, FOLD: 2, EPOCH: 4,train_loss: 0.018004389688966498, valid_loss: 0.017718725372105837\n",
      "SEED: 4, FOLD: 2, EPOCH: 5,train_loss: 0.01796594573913709, valid_loss: 0.017819626855530908\n",
      "SEED: 4, FOLD: 2, EPOCH: 6,train_loss: 0.017941536408835564, valid_loss: 0.01746572713766779\n",
      "SEED: 4, FOLD: 2, EPOCH: 7,train_loss: 0.017946869789528242, valid_loss: 0.017531250909503016\n",
      "SEED: 4, FOLD: 2, EPOCH: 8,train_loss: 0.017944945656842945, valid_loss: 0.01744111676567367\n",
      "SEED: 4, FOLD: 2, EPOCH: 9,train_loss: 0.01792114985215923, valid_loss: 0.017772867078227655\n",
      "SEED: 4, FOLD: 2, EPOCH: 10,train_loss: 0.017954043942787077, valid_loss: 0.01862535189305033\n",
      "SEED: 4, FOLD: 2, EPOCH: 11,train_loss: 0.017839147398869198, valid_loss: 0.01737108559214643\n",
      "SEED: 4, FOLD: 2, EPOCH: 12,train_loss: 0.017800521166266306, valid_loss: 0.017048426438122988\n",
      "SEED: 4, FOLD: 2, EPOCH: 13,train_loss: 0.017712052209653717, valid_loss: 0.01716643518635205\n",
      "SEED: 4, FOLD: 2, EPOCH: 14,train_loss: 0.01755879896328501, valid_loss: 0.017218382629965032\n",
      "SEED: 4, FOLD: 2, EPOCH: 15,train_loss: 0.017459297073546095, valid_loss: 0.01701997865789703\n",
      "SEED: 4, FOLD: 2, EPOCH: 16,train_loss: 0.017275800651776186, valid_loss: 0.016920877460922513\n",
      "SEED: 4, FOLD: 2, EPOCH: 17,train_loss: 0.01699345081747658, valid_loss: 0.01685639818065933\n",
      "SEED: 4, FOLD: 2, EPOCH: 18,train_loss: 0.01669665181712396, valid_loss: 0.016940909344702958\n",
      "SEED: 4, FOLD: 2, EPOCH: 19,train_loss: 0.01638623296647616, valid_loss: 0.016763214394450186\n",
      "SEED: 4, FOLD: 2, EPOCH: 20,train_loss: 0.01600620545365888, valid_loss: 0.01665890079789928\n",
      "SEED: 4, FOLD: 2, EPOCH: 21,train_loss: 0.015512908835881863, valid_loss: 0.01661833259942276\n",
      "SEED: 4, FOLD: 2, EPOCH: 22,train_loss: 0.01504031696991212, valid_loss: 0.01669199937688453\n",
      "SEED: 4, FOLD: 2, EPOCH: 23,train_loss: 0.014575581194535978, valid_loss: 0.016654282967959132\n",
      "SEED: 4, FOLD: 2, EPOCH: 24,train_loss: 0.014367160664034494, valid_loss: 0.016634034498461656\n",
      "(17538, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7345617914545364, valid_loss: 0.7038540431431362\n",
      "SEED: 4, FOLD: 3, EPOCH: 0,train_loss: 0.46821645515012567, valid_loss: 0.026648135270391192\n",
      "SEED: 4, FOLD: 3, EPOCH: 1,train_loss: 0.021336930291052315, valid_loss: 0.032465765039835656\n",
      "SEED: 4, FOLD: 3, EPOCH: 2,train_loss: 0.020664557153224083, valid_loss: 0.026624699415905135\n",
      "SEED: 4, FOLD: 3, EPOCH: 3,train_loss: 0.019243543387215206, valid_loss: 0.01842582928282874\n",
      "SEED: 4, FOLD: 3, EPOCH: 4,train_loss: 0.01852173322096359, valid_loss: 0.018213540581720217\n",
      "SEED: 4, FOLD: 3, EPOCH: 5,train_loss: 0.018400372174716947, valid_loss: 0.018483798950910568\n",
      "SEED: 4, FOLD: 3, EPOCH: 6,train_loss: 0.018520011789286913, valid_loss: 0.018546183087996073\n",
      "SEED: 4, FOLD: 3, EPOCH: 7,train_loss: 0.01826914754844662, valid_loss: 0.0181608147919178\n",
      "SEED: 4, FOLD: 3, EPOCH: 8,train_loss: 0.01812463477793811, valid_loss: 0.024131000893456597\n",
      "SEED: 4, FOLD: 3, EPOCH: 9,train_loss: 0.01832370686115346, valid_loss: 0.01765460590166705\n",
      "SEED: 4, FOLD: 3, EPOCH: 10,train_loss: 0.018112076594885708, valid_loss: 0.01833768667919295\n",
      "SEED: 4, FOLD: 3, EPOCH: 11,train_loss: 0.017990551963178576, valid_loss: 0.01808693991707904\n",
      "SEED: 4, FOLD: 3, EPOCH: 12,train_loss: 0.01775597079076629, valid_loss: 0.017646836037082333\n",
      "SEED: 4, FOLD: 3, EPOCH: 13,train_loss: 0.01787309546995422, valid_loss: 0.017657501596425262\n",
      "SEED: 4, FOLD: 3, EPOCH: 14,train_loss: 0.017818620037017525, valid_loss: 0.017440908082893915\n",
      "SEED: 4, FOLD: 3, EPOCH: 15,train_loss: 0.017594914559436882, valid_loss: 0.017326215840876104\n",
      "SEED: 4, FOLD: 3, EPOCH: 16,train_loss: 0.01739439962134845, valid_loss: 0.017367933903421673\n",
      "SEED: 4, FOLD: 3, EPOCH: 17,train_loss: 0.017321637008285175, valid_loss: 0.01726427690259048\n",
      "SEED: 4, FOLD: 3, EPOCH: 18,train_loss: 0.01705870867126446, valid_loss: 0.017053243704140186\n",
      "SEED: 4, FOLD: 3, EPOCH: 19,train_loss: 0.016715874800971454, valid_loss: 0.01685855540313891\n",
      "SEED: 4, FOLD: 3, EPOCH: 20,train_loss: 0.01631079878712046, valid_loss: 0.017073193644838672\n",
      "SEED: 4, FOLD: 3, EPOCH: 21,train_loss: 0.015961043691883486, valid_loss: 0.01686563388045345\n",
      "SEED: 4, FOLD: 3, EPOCH: 22,train_loss: 0.015433373975742987, valid_loss: 0.016942242107221058\n",
      "SEED: 4, FOLD: 3, EPOCH: 23,train_loss: 0.01515481085853948, valid_loss: 0.016930983614708697\n",
      "SEED: 4, FOLD: 3, EPOCH: 24,train_loss: 0.014943710251616827, valid_loss: 0.016869548947683402\n",
      "(17485, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7337405990510091, valid_loss: 0.7045751401356288\n",
      "SEED: 4, FOLD: 4, EPOCH: 0,train_loss: 0.46835863282972007, valid_loss: 0.02500745148531028\n",
      "SEED: 4, FOLD: 4, EPOCH: 1,train_loss: 0.020936407937403142, valid_loss: 0.019119464393172945\n",
      "SEED: 4, FOLD: 4, EPOCH: 2,train_loss: 0.0189318645976647, valid_loss: 0.018280430670295444\n",
      "SEED: 4, FOLD: 4, EPOCH: 3,train_loss: 0.018018481715915413, valid_loss: 0.018283364629106864\n",
      "SEED: 4, FOLD: 4, EPOCH: 4,train_loss: 0.017857791488840632, valid_loss: 0.018026271595486573\n",
      "SEED: 4, FOLD: 4, EPOCH: 5,train_loss: 0.017840044756494734, valid_loss: 0.018123190850019455\n",
      "SEED: 4, FOLD: 4, EPOCH: 6,train_loss: 0.017722173804675577, valid_loss: 0.018129911007625715\n",
      "SEED: 4, FOLD: 4, EPOCH: 7,train_loss: 0.017736006439765438, valid_loss: 0.018173769861459733\n",
      "SEED: 4, FOLD: 4, EPOCH: 8,train_loss: 0.017755769084404856, valid_loss: 0.017932343004005296\n",
      "SEED: 4, FOLD: 4, EPOCH: 9,train_loss: 0.01771639517243326, valid_loss: 0.018287344835698605\n",
      "SEED: 4, FOLD: 4, EPOCH: 10,train_loss: 0.01775995777226495, valid_loss: 0.018108641542494298\n",
      "SEED: 4, FOLD: 4, EPOCH: 11,train_loss: 0.017677992799856365, valid_loss: 0.018085727760834353\n",
      "SEED: 4, FOLD: 4, EPOCH: 12,train_loss: 0.017670240966997444, valid_loss: 0.01776857235069786\n",
      "SEED: 4, FOLD: 4, EPOCH: 13,train_loss: 0.017540010147775613, valid_loss: 0.017826124600001745\n",
      "SEED: 4, FOLD: 4, EPOCH: 14,train_loss: 0.017416574516381227, valid_loss: 0.018060334346124102\n",
      "SEED: 4, FOLD: 4, EPOCH: 15,train_loss: 0.017291392695947285, valid_loss: 0.017956294332231795\n",
      "SEED: 4, FOLD: 4, EPOCH: 16,train_loss: 0.017078777571229168, valid_loss: 0.01755899124379669\n",
      "SEED: 4, FOLD: 4, EPOCH: 17,train_loss: 0.016856019718259792, valid_loss: 0.01774841280920165\n",
      "SEED: 4, FOLD: 4, EPOCH: 18,train_loss: 0.016570881450970243, valid_loss: 0.01756978375571115\n",
      "SEED: 4, FOLD: 4, EPOCH: 19,train_loss: 0.016240934113951496, valid_loss: 0.01745394633284637\n",
      "SEED: 4, FOLD: 4, EPOCH: 20,train_loss: 0.015807497790967025, valid_loss: 0.01742909893925701\n",
      "SEED: 4, FOLD: 4, EPOCH: 21,train_loss: 0.015357966500803502, valid_loss: 0.01744192202708551\n",
      "SEED: 4, FOLD: 4, EPOCH: 22,train_loss: 0.014822088481083403, valid_loss: 0.01741748335106032\n",
      "SEED: 4, FOLD: 4, EPOCH: 23,train_loss: 0.014364118184758363, valid_loss: 0.01743021926709584\n",
      "SEED: 4, FOLD: 4, EPOCH: 24,train_loss: 0.014130086875962514, valid_loss: 0.01745301234935011\n",
      "(17564, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7360968727996384, valid_loss: 0.7028307284627642\n",
      "SEED: 5, FOLD: 0, EPOCH: 0,train_loss: 0.46593162109670433, valid_loss: 0.02354907366846289\n",
      "SEED: 5, FOLD: 0, EPOCH: 1,train_loss: 0.020737596099143444, valid_loss: 0.02089801180575575\n",
      "SEED: 5, FOLD: 0, EPOCH: 2,train_loss: 0.018883530752382416, valid_loss: 0.01858135730560337\n",
      "SEED: 5, FOLD: 0, EPOCH: 3,train_loss: 0.018173739739248285, valid_loss: 0.018106084955590112\n",
      "SEED: 5, FOLD: 0, EPOCH: 4,train_loss: 0.017869367311452177, valid_loss: 0.018467907873647552\n",
      "SEED: 5, FOLD: 0, EPOCH: 5,train_loss: 0.017909244404754776, valid_loss: 0.018582871024097714\n",
      "SEED: 5, FOLD: 0, EPOCH: 6,train_loss: 0.0178766878105808, valid_loss: 0.018213371373713018\n",
      "SEED: 5, FOLD: 0, EPOCH: 7,train_loss: 0.017875538140103436, valid_loss: 0.01888399693582739\n",
      "SEED: 5, FOLD: 0, EPOCH: 8,train_loss: 0.017914326780516167, valid_loss: 0.017965825647115706\n",
      "SEED: 5, FOLD: 0, EPOCH: 9,train_loss: 0.017852979057562956, valid_loss: 0.018094144628516266\n",
      "SEED: 5, FOLD: 0, EPOCH: 10,train_loss: 0.017849922531108925, valid_loss: 0.018543929766331402\n",
      "SEED: 5, FOLD: 0, EPOCH: 11,train_loss: 0.017804515757260546, valid_loss: 0.01794630762721811\n",
      "SEED: 5, FOLD: 0, EPOCH: 12,train_loss: 0.01766302668745967, valid_loss: 0.017882834295076984\n",
      "SEED: 5, FOLD: 0, EPOCH: 13,train_loss: 0.017644353676587343, valid_loss: 0.017902547121047975\n",
      "SEED: 5, FOLD: 0, EPOCH: 14,train_loss: 0.017448737758441246, valid_loss: 0.018130380447421754\n",
      "SEED: 5, FOLD: 0, EPOCH: 15,train_loss: 0.017375289799942486, valid_loss: 0.017744366052959648\n",
      "SEED: 5, FOLD: 0, EPOCH: 16,train_loss: 0.01709206036521473, valid_loss: 0.01767944677599839\n",
      "SEED: 5, FOLD: 0, EPOCH: 17,train_loss: 0.016914870967899544, valid_loss: 0.01763492412865162\n",
      "SEED: 5, FOLD: 0, EPOCH: 18,train_loss: 0.016664701696161344, valid_loss: 0.017485962408993926\n",
      "SEED: 5, FOLD: 0, EPOCH: 19,train_loss: 0.016338549075189276, valid_loss: 0.017400321470839638\n",
      "SEED: 5, FOLD: 0, EPOCH: 20,train_loss: 0.015918310812633972, valid_loss: 0.017320486690316883\n",
      "SEED: 5, FOLD: 0, EPOCH: 21,train_loss: 0.01547294404303682, valid_loss: 0.017237779631146363\n",
      "SEED: 5, FOLD: 0, EPOCH: 22,train_loss: 0.01498051929841007, valid_loss: 0.017256199941039087\n",
      "SEED: 5, FOLD: 0, EPOCH: 23,train_loss: 0.01460366476111222, valid_loss: 0.017272218423230307\n",
      "SEED: 5, FOLD: 0, EPOCH: 24,train_loss: 0.014376419461399748, valid_loss: 0.017281598704201834\n",
      "(17535, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7367819295312367, valid_loss: 0.7027316519192287\n",
      "SEED: 5, FOLD: 1, EPOCH: 0,train_loss: 0.4680083334364378, valid_loss: 0.02329029573925904\n",
      "SEED: 5, FOLD: 1, EPOCH: 1,train_loss: 0.021076366672441907, valid_loss: 0.019082533781017576\n",
      "SEED: 5, FOLD: 1, EPOCH: 2,train_loss: 0.01915864748404409, valid_loss: 0.017964887166661874\n",
      "SEED: 5, FOLD: 1, EPOCH: 3,train_loss: 0.01831965121257044, valid_loss: 0.01776640811668975\n",
      "SEED: 5, FOLD: 1, EPOCH: 4,train_loss: 0.018053119064029986, valid_loss: 0.018440046134803975\n",
      "SEED: 5, FOLD: 1, EPOCH: 5,train_loss: 0.017946708383188195, valid_loss: 0.017639888689986297\n",
      "SEED: 5, FOLD: 1, EPOCH: 6,train_loss: 0.017938756091642555, valid_loss: 0.017720323428511618\n",
      "SEED: 5, FOLD: 1, EPOCH: 7,train_loss: 0.017988173012370174, valid_loss: 0.017724802158772944\n",
      "SEED: 5, FOLD: 1, EPOCH: 8,train_loss: 0.017950679080384058, valid_loss: 0.017673500441014768\n",
      "SEED: 5, FOLD: 1, EPOCH: 9,train_loss: 0.01792329117438219, valid_loss: 0.017553206692848888\n",
      "SEED: 5, FOLD: 1, EPOCH: 10,train_loss: 0.01788219097104386, valid_loss: 0.01905980317720345\n",
      "SEED: 5, FOLD: 1, EPOCH: 11,train_loss: 0.017889585685882257, valid_loss: 0.017582757265440056\n",
      "SEED: 5, FOLD: 1, EPOCH: 12,train_loss: 0.01777898147702217, valid_loss: 0.017615858438823906\n",
      "SEED: 5, FOLD: 1, EPOCH: 13,train_loss: 0.017663516770422893, valid_loss: 0.017461054851966244\n",
      "SEED: 5, FOLD: 1, EPOCH: 14,train_loss: 0.017535185461768705, valid_loss: 0.017443519192082542\n",
      "SEED: 5, FOLD: 1, EPOCH: 15,train_loss: 0.017389574081358248, valid_loss: 0.01724206225148269\n",
      "SEED: 5, FOLD: 1, EPOCH: 16,train_loss: 0.017197449453664523, valid_loss: 0.01724408785147326\n",
      "SEED: 5, FOLD: 1, EPOCH: 17,train_loss: 0.016952250839421784, valid_loss: 0.017128602521760124\n",
      "SEED: 5, FOLD: 1, EPOCH: 18,train_loss: 0.016688930666087752, valid_loss: 0.01730484917227711\n",
      "SEED: 5, FOLD: 1, EPOCH: 19,train_loss: 0.016351025503971717, valid_loss: 0.017193089904529706\n",
      "SEED: 5, FOLD: 1, EPOCH: 20,train_loss: 0.015898869270934677, valid_loss: 0.017012065116848264\n",
      "SEED: 5, FOLD: 1, EPOCH: 21,train_loss: 0.015480143582298808, valid_loss: 0.016984250529536178\n",
      "SEED: 5, FOLD: 1, EPOCH: 22,train_loss: 0.014973163210453779, valid_loss: 0.01702351775020361\n",
      "SEED: 5, FOLD: 1, EPOCH: 23,train_loss: 0.014547152193195193, valid_loss: 0.017003215397042887\n",
      "SEED: 5, FOLD: 1, EPOCH: 24,train_loss: 0.014308030621903221, valid_loss: 0.017002662218042783\n",
      "(17572, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.736134406881056, valid_loss: 0.7013909016336713\n",
      "SEED: 5, FOLD: 2, EPOCH: 0,train_loss: 0.4659917995036728, valid_loss: 0.02311089608286108\n",
      "SEED: 5, FOLD: 2, EPOCH: 1,train_loss: 0.02111056999073944, valid_loss: 0.018210599571466445\n",
      "SEED: 5, FOLD: 2, EPOCH: 2,train_loss: 0.01892017415198295, valid_loss: 0.017519778039838587\n",
      "SEED: 5, FOLD: 2, EPOCH: 3,train_loss: 0.018325961127445316, valid_loss: 0.017958282466445652\n",
      "SEED: 5, FOLD: 2, EPOCH: 4,train_loss: 0.0181047804383696, valid_loss: 0.017476632605705943\n",
      "SEED: 5, FOLD: 2, EPOCH: 5,train_loss: 0.01799828406639289, valid_loss: 0.017759043749954018\n",
      "SEED: 5, FOLD: 2, EPOCH: 6,train_loss: 0.017945485000593075, valid_loss: 0.017479600730751242\n",
      "SEED: 5, FOLD: 2, EPOCH: 7,train_loss: 0.01807154038840014, valid_loss: 0.01727755538054875\n",
      "SEED: 5, FOLD: 2, EPOCH: 8,train_loss: 0.017948399196662333, valid_loss: 0.017136908349181926\n",
      "SEED: 5, FOLD: 2, EPOCH: 9,train_loss: 0.018006060933829216, valid_loss: 0.017606579352702413\n",
      "SEED: 5, FOLD: 2, EPOCH: 10,train_loss: 0.017887074216876343, valid_loss: 0.01743600174252476\n",
      "SEED: 5, FOLD: 2, EPOCH: 11,train_loss: 0.017835317247047806, valid_loss: 0.017594967463186808\n",
      "SEED: 5, FOLD: 2, EPOCH: 12,train_loss: 0.01786489806988317, valid_loss: 0.01732369802360024\n",
      "SEED: 5, FOLD: 2, EPOCH: 13,train_loss: 0.01766313698844633, valid_loss: 0.017554058799786228\n",
      "SEED: 5, FOLD: 2, EPOCH: 14,train_loss: 0.017592422711406496, valid_loss: 0.017277305253914424\n",
      "SEED: 5, FOLD: 2, EPOCH: 15,train_loss: 0.017409087442185566, valid_loss: 0.017180963259722504\n",
      "SEED: 5, FOLD: 2, EPOCH: 16,train_loss: 0.0172563962759855, valid_loss: 0.017017560452222823\n",
      "SEED: 5, FOLD: 2, EPOCH: 17,train_loss: 0.01705781607956126, valid_loss: 0.017111066515956605\n",
      "SEED: 5, FOLD: 2, EPOCH: 18,train_loss: 0.016745075063806944, valid_loss: 0.016932663188448976\n",
      "SEED: 5, FOLD: 2, EPOCH: 19,train_loss: 0.016458970987224493, valid_loss: 0.016746417299977372\n",
      "SEED: 5, FOLD: 2, EPOCH: 20,train_loss: 0.01607033301927689, valid_loss: 0.016769618248300894\n",
      "SEED: 5, FOLD: 2, EPOCH: 21,train_loss: 0.015563473989512178, valid_loss: 0.016685438475438526\n",
      "SEED: 5, FOLD: 2, EPOCH: 22,train_loss: 0.015074403430132763, valid_loss: 0.016656830427902086\n",
      "SEED: 5, FOLD: 2, EPOCH: 23,train_loss: 0.014663245900115673, valid_loss: 0.01665879919060639\n",
      "SEED: 5, FOLD: 2, EPOCH: 24,train_loss: 0.01445204834116326, valid_loss: 0.01666744742542505\n",
      "(17516, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7361484491912118, valid_loss: 0.7032452940940856\n",
      "SEED: 5, FOLD: 3, EPOCH: 0,train_loss: 0.46766281877066535, valid_loss: 0.024296330341270992\n",
      "SEED: 5, FOLD: 3, EPOCH: 1,train_loss: 0.02086739349484879, valid_loss: 0.02001945168844291\n",
      "SEED: 5, FOLD: 3, EPOCH: 2,train_loss: 0.018896927866731247, valid_loss: 0.018494209806833948\n",
      "SEED: 5, FOLD: 3, EPOCH: 3,train_loss: 0.018305835416064644, valid_loss: 0.018415662832558154\n",
      "SEED: 5, FOLD: 3, EPOCH: 4,train_loss: 0.017951119487194248, valid_loss: 0.018077328694718224\n",
      "SEED: 5, FOLD: 3, EPOCH: 5,train_loss: 0.017908126693626826, valid_loss: 0.01834673115185329\n",
      "SEED: 5, FOLD: 3, EPOCH: 6,train_loss: 0.017825222397427055, valid_loss: 0.018223994837275572\n",
      "SEED: 5, FOLD: 3, EPOCH: 7,train_loss: 0.017847009329465185, valid_loss: 0.018170088556196007\n",
      "SEED: 5, FOLD: 3, EPOCH: 8,train_loss: 0.017829154074246432, valid_loss: 0.018050989295755115\n",
      "SEED: 5, FOLD: 3, EPOCH: 9,train_loss: 0.017839228000192747, valid_loss: 0.018337234748261315\n",
      "SEED: 5, FOLD: 3, EPOCH: 10,train_loss: 0.017805639545630365, valid_loss: 0.0181830923472132\n",
      "SEED: 5, FOLD: 3, EPOCH: 11,train_loss: 0.0177210217246609, valid_loss: 0.018040285658623492\n",
      "SEED: 5, FOLD: 3, EPOCH: 12,train_loss: 0.01764931753413738, valid_loss: 0.01776044507111822\n",
      "SEED: 5, FOLD: 3, EPOCH: 13,train_loss: 0.017530723563293472, valid_loss: 0.018333843749548707\n",
      "SEED: 5, FOLD: 3, EPOCH: 14,train_loss: 0.017457585401126068, valid_loss: 0.01795998580221619\n",
      "SEED: 5, FOLD: 3, EPOCH: 15,train_loss: 0.017272410628786924, valid_loss: 0.01784894210951669\n",
      "SEED: 5, FOLD: 3, EPOCH: 16,train_loss: 0.017057815546265048, valid_loss: 0.01772820164582559\n",
      "SEED: 5, FOLD: 3, EPOCH: 17,train_loss: 0.016891971046961572, valid_loss: 0.017763038245694977\n",
      "SEED: 5, FOLD: 3, EPOCH: 18,train_loss: 0.016580970169310153, valid_loss: 0.017573979204254492\n",
      "SEED: 5, FOLD: 3, EPOCH: 19,train_loss: 0.016219067040586125, valid_loss: 0.01746217760124377\n",
      "SEED: 5, FOLD: 3, EPOCH: 20,train_loss: 0.01579056861028619, valid_loss: 0.017394340996231352\n",
      "SEED: 5, FOLD: 3, EPOCH: 21,train_loss: 0.015335853130006008, valid_loss: 0.017396349566323417\n",
      "SEED: 5, FOLD: 3, EPOCH: 22,train_loss: 0.014789915799985837, valid_loss: 0.017340010005448547\n",
      "SEED: 5, FOLD: 3, EPOCH: 23,train_loss: 0.014349590878199488, valid_loss: 0.017312082116092954\n",
      "SEED: 5, FOLD: 3, EPOCH: 24,train_loss: 0.014110142412683824, valid_loss: 0.01731904149055481\n",
      "(17605, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7362750125104103, valid_loss: 0.7021718077799853\n",
      "SEED: 5, FOLD: 4, EPOCH: 0,train_loss: 0.46570800734764856, valid_loss: 0.0246675371137612\n",
      "SEED: 5, FOLD: 4, EPOCH: 1,train_loss: 0.02095330015256785, valid_loss: 0.019772838034174022\n",
      "SEED: 5, FOLD: 4, EPOCH: 2,train_loss: 0.0189892570555642, valid_loss: 0.01848288346081972\n",
      "SEED: 5, FOLD: 4, EPOCH: 3,train_loss: 0.018309560293952625, valid_loss: 0.018566266030949706\n",
      "SEED: 5, FOLD: 4, EPOCH: 4,train_loss: 0.017975943925642016, valid_loss: 0.01857912025469191\n",
      "SEED: 5, FOLD: 4, EPOCH: 5,train_loss: 0.017900185673025207, valid_loss: 0.01844315236324773\n",
      "SEED: 5, FOLD: 4, EPOCH: 6,train_loss: 0.01788578874202094, valid_loss: 0.01828332097433946\n",
      "SEED: 5, FOLD: 4, EPOCH: 7,train_loss: 0.017861046301929848, valid_loss: 0.01837838430176763\n",
      "SEED: 5, FOLD: 4, EPOCH: 8,train_loss: 0.017791356709178374, valid_loss: 0.018021454240250236\n",
      "SEED: 5, FOLD: 4, EPOCH: 9,train_loss: 0.017850894798133253, valid_loss: 0.018234219073372727\n",
      "SEED: 5, FOLD: 4, EPOCH: 10,train_loss: 0.01781337947814145, valid_loss: 0.01799667122609475\n",
      "SEED: 5, FOLD: 4, EPOCH: 11,train_loss: 0.017709945591733507, valid_loss: 0.01816374885247034\n",
      "SEED: 5, FOLD: 4, EPOCH: 12,train_loss: 0.017636263257135517, valid_loss: 0.017981517238213736\n",
      "SEED: 5, FOLD: 4, EPOCH: 13,train_loss: 0.017625847851614588, valid_loss: 0.017957688802305388\n",
      "SEED: 5, FOLD: 4, EPOCH: 14,train_loss: 0.01748122166896212, valid_loss: 0.017712770112077978\n",
      "SEED: 5, FOLD: 4, EPOCH: 15,train_loss: 0.01732504785573785, valid_loss: 0.018231512814321938\n",
      "SEED: 5, FOLD: 4, EPOCH: 16,train_loss: 0.01713869774012246, valid_loss: 0.01762181315023233\n",
      "SEED: 5, FOLD: 4, EPOCH: 17,train_loss: 0.01692121580540054, valid_loss: 0.01756748746094458\n",
      "SEED: 5, FOLD: 4, EPOCH: 18,train_loss: 0.016669476141586252, valid_loss: 0.017606833292280927\n",
      "SEED: 5, FOLD: 4, EPOCH: 19,train_loss: 0.016312197606632675, valid_loss: 0.017547849237042314\n",
      "SEED: 5, FOLD: 4, EPOCH: 20,train_loss: 0.015920987541692844, valid_loss: 0.01764434217201436\n",
      "SEED: 5, FOLD: 4, EPOCH: 21,train_loss: 0.015497809451451336, valid_loss: 0.017533319591380218\n",
      "SEED: 5, FOLD: 4, EPOCH: 22,train_loss: 0.014976036728130302, valid_loss: 0.017498330487047926\n",
      "SEED: 5, FOLD: 4, EPOCH: 23,train_loss: 0.014562552281911823, valid_loss: 0.01747189714189838\n",
      "SEED: 5, FOLD: 4, EPOCH: 24,train_loss: 0.01436909215281839, valid_loss: 0.017475630923667374\n",
      "(17517, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7342957893427271, valid_loss: 0.6831454191889081\n",
      "SEED: 6, FOLD: 0, EPOCH: 0,train_loss: 0.4690769885931789, valid_loss: 0.024121794317449843\n",
      "SEED: 6, FOLD: 0, EPOCH: 1,train_loss: 0.02099986876068759, valid_loss: 0.019298134398247513\n",
      "SEED: 6, FOLD: 0, EPOCH: 2,train_loss: 0.018804122863786063, valid_loss: 0.01835115849971771\n",
      "SEED: 6, FOLD: 0, EPOCH: 3,train_loss: 0.018116391916507785, valid_loss: 0.018196026076163566\n",
      "SEED: 6, FOLD: 0, EPOCH: 4,train_loss: 0.01778396332541304, valid_loss: 0.018002807322357383\n",
      "SEED: 6, FOLD: 0, EPOCH: 5,train_loss: 0.017761800451761615, valid_loss: 0.018337760253676345\n",
      "SEED: 6, FOLD: 0, EPOCH: 6,train_loss: 0.01782102078661649, valid_loss: 0.01786242135401283\n",
      "SEED: 6, FOLD: 0, EPOCH: 7,train_loss: 0.017812117682701915, valid_loss: 0.018397055193781854\n",
      "SEED: 6, FOLD: 0, EPOCH: 8,train_loss: 0.0178145785768428, valid_loss: 0.018099604892943585\n",
      "SEED: 6, FOLD: 0, EPOCH: 9,train_loss: 0.017759597969044298, valid_loss: 0.017795612051018646\n",
      "SEED: 6, FOLD: 0, EPOCH: 10,train_loss: 0.017764532693872487, valid_loss: 0.01814547444560698\n",
      "SEED: 6, FOLD: 0, EPOCH: 11,train_loss: 0.01774425720320131, valid_loss: 0.01768064152981554\n",
      "SEED: 6, FOLD: 0, EPOCH: 12,train_loss: 0.01763511101042267, valid_loss: 0.01769839408142226\n",
      "SEED: 6, FOLD: 0, EPOCH: 13,train_loss: 0.017540331984305903, valid_loss: 0.017796774288373333\n",
      "SEED: 6, FOLD: 0, EPOCH: 14,train_loss: 0.017444069497287273, valid_loss: 0.01757474954106978\n",
      "SEED: 6, FOLD: 0, EPOCH: 15,train_loss: 0.017268764378543754, valid_loss: 0.017699104653937477\n",
      "SEED: 6, FOLD: 0, EPOCH: 16,train_loss: 0.017112165322377734, valid_loss: 0.01761114128998348\n",
      "SEED: 6, FOLD: 0, EPOCH: 17,train_loss: 0.01690953247330702, valid_loss: 0.01746766319764512\n",
      "SEED: 6, FOLD: 0, EPOCH: 18,train_loss: 0.01656006571639628, valid_loss: 0.017426020918147905\n",
      "SEED: 6, FOLD: 0, EPOCH: 19,train_loss: 0.01627287757413013, valid_loss: 0.017493808402546815\n",
      "SEED: 6, FOLD: 0, EPOCH: 20,train_loss: 0.015839041455438102, valid_loss: 0.01745254953524896\n",
      "SEED: 6, FOLD: 0, EPOCH: 21,train_loss: 0.015365694160063337, valid_loss: 0.01741822042635509\n",
      "SEED: 6, FOLD: 0, EPOCH: 22,train_loss: 0.014825795763546097, valid_loss: 0.017446139880589077\n",
      "SEED: 6, FOLD: 0, EPOCH: 23,train_loss: 0.014394808043963718, valid_loss: 0.017421990766056945\n",
      "SEED: 6, FOLD: 0, EPOCH: 24,train_loss: 0.014157860220348747, valid_loss: 0.017427388791527068\n",
      "(17539, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7339991758699003, valid_loss: 0.6857712694576809\n",
      "SEED: 6, FOLD: 1, EPOCH: 0,train_loss: 0.46571034272673767, valid_loss: 0.023493796533771923\n",
      "SEED: 6, FOLD: 1, EPOCH: 1,train_loss: 0.021041154901942482, valid_loss: 0.02377023638359138\n",
      "SEED: 6, FOLD: 1, EPOCH: 2,train_loss: 0.019620496833669968, valid_loss: 0.019994233974388667\n",
      "SEED: 6, FOLD: 1, EPOCH: 3,train_loss: 0.018842213530687317, valid_loss: 0.020425146552068847\n",
      "SEED: 6, FOLD: 1, EPOCH: 4,train_loss: 0.018402155677693478, valid_loss: 0.020641508006623812\n",
      "SEED: 6, FOLD: 1, EPOCH: 5,train_loss: 0.018274966762333675, valid_loss: 0.018212952970394065\n",
      "SEED: 6, FOLD: 1, EPOCH: 6,train_loss: 0.018077560558753168, valid_loss: 0.018548105391008513\n",
      "SEED: 6, FOLD: 1, EPOCH: 7,train_loss: 0.018067905611857987, valid_loss: 0.018632976604359492\n",
      "SEED: 6, FOLD: 1, EPOCH: 8,train_loss: 0.018048637317142624, valid_loss: 0.01824652062995093\n",
      "SEED: 6, FOLD: 1, EPOCH: 9,train_loss: 0.01802281425267026, valid_loss: 0.01830591426364013\n",
      "SEED: 6, FOLD: 1, EPOCH: 10,train_loss: 0.018052249566476414, valid_loss: 0.01783871751810823\n",
      "SEED: 6, FOLD: 1, EPOCH: 11,train_loss: 0.01794133420385744, valid_loss: 0.018054563232830594\n",
      "SEED: 6, FOLD: 1, EPOCH: 12,train_loss: 0.017897122755538727, valid_loss: 0.017932519928685258\n",
      "SEED: 6, FOLD: 1, EPOCH: 13,train_loss: 0.017764484138646418, valid_loss: 0.01799767767744405\n",
      "SEED: 6, FOLD: 1, EPOCH: 14,train_loss: 0.01775505459880915, valid_loss: 0.017620261226381575\n",
      "SEED: 6, FOLD: 1, EPOCH: 15,train_loss: 0.017484813503435125, valid_loss: 0.017762458963053566\n",
      "SEED: 6, FOLD: 1, EPOCH: 16,train_loss: 0.01747631741201748, valid_loss: 0.017557051458529063\n",
      "SEED: 6, FOLD: 1, EPOCH: 17,train_loss: 0.01720431793238158, valid_loss: 0.017535095954579968\n",
      "SEED: 6, FOLD: 1, EPOCH: 18,train_loss: 0.016890063490448654, valid_loss: 0.01732158607670239\n",
      "SEED: 6, FOLD: 1, EPOCH: 19,train_loss: 0.01657120443786076, valid_loss: 0.017203993456704276\n",
      "SEED: 6, FOLD: 1, EPOCH: 20,train_loss: 0.016131491022373455, valid_loss: 0.017141192938600266\n",
      "SEED: 6, FOLD: 1, EPOCH: 21,train_loss: 0.015865415314455397, valid_loss: 0.017165306982185158\n",
      "SEED: 6, FOLD: 1, EPOCH: 22,train_loss: 0.015416428352287714, valid_loss: 0.0171916645818523\n",
      "SEED: 6, FOLD: 1, EPOCH: 23,train_loss: 0.015082026224421419, valid_loss: 0.017105574666389397\n",
      "SEED: 6, FOLD: 1, EPOCH: 24,train_loss: 0.014911072936071001, valid_loss: 0.01712728485997234\n",
      "(17535, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7340316972593321, valid_loss: 0.6865424956594195\n",
      "SEED: 6, FOLD: 2, EPOCH: 0,train_loss: 0.46668697168955403, valid_loss: 0.02507516954626356\n",
      "SEED: 6, FOLD: 2, EPOCH: 1,train_loss: 0.021204398061237195, valid_loss: 0.018906079179474285\n",
      "SEED: 6, FOLD: 2, EPOCH: 2,train_loss: 0.018928683899941234, valid_loss: 0.01824159286916256\n",
      "SEED: 6, FOLD: 2, EPOCH: 3,train_loss: 0.01813812075305159, valid_loss: 0.018239697574504783\n",
      "SEED: 6, FOLD: 2, EPOCH: 4,train_loss: 0.01790202207808947, valid_loss: 0.01827000786683389\n",
      "SEED: 6, FOLD: 2, EPOCH: 5,train_loss: 0.01792412523832852, valid_loss: 0.017695584387651512\n",
      "SEED: 6, FOLD: 2, EPOCH: 6,train_loss: 0.017813780909254603, valid_loss: 0.017966329998203686\n",
      "SEED: 6, FOLD: 2, EPOCH: 7,train_loss: 0.01788967422270862, valid_loss: 0.01782422736287117\n",
      "SEED: 6, FOLD: 2, EPOCH: 8,train_loss: 0.017859693167962296, valid_loss: 0.017759539719138826\n",
      "SEED: 6, FOLD: 2, EPOCH: 9,train_loss: 0.017838287813058736, valid_loss: 0.018134249853236334\n",
      "SEED: 6, FOLD: 2, EPOCH: 10,train_loss: 0.01782479551178913, valid_loss: 0.017930350958236627\n",
      "SEED: 6, FOLD: 2, EPOCH: 11,train_loss: 0.0176868101609123, valid_loss: 0.017831060104072094\n",
      "SEED: 6, FOLD: 2, EPOCH: 12,train_loss: 0.017658162331820406, valid_loss: 0.01783323966498886\n",
      "SEED: 6, FOLD: 2, EPOCH: 13,train_loss: 0.017599123951564304, valid_loss: 0.018095063205276218\n",
      "SEED: 6, FOLD: 2, EPOCH: 14,train_loss: 0.017465202464130674, valid_loss: 0.017470870752419744\n",
      "SEED: 6, FOLD: 2, EPOCH: 15,train_loss: 0.017307760309509552, valid_loss: 0.017143864557147025\n",
      "SEED: 6, FOLD: 2, EPOCH: 16,train_loss: 0.01714400996719181, valid_loss: 0.017332285775669982\n",
      "SEED: 6, FOLD: 2, EPOCH: 17,train_loss: 0.01689144073693204, valid_loss: 0.01738202598478113\n",
      "SEED: 6, FOLD: 2, EPOCH: 18,train_loss: 0.016656985723950565, valid_loss: 0.017263003731412548\n",
      "SEED: 6, FOLD: 2, EPOCH: 19,train_loss: 0.01622365251944883, valid_loss: 0.01716099227113383\n",
      "SEED: 6, FOLD: 2, EPOCH: 20,train_loss: 0.015808423226495293, valid_loss: 0.017090465633996896\n",
      "SEED: 6, FOLD: 2, EPOCH: 21,train_loss: 0.015321752294408578, valid_loss: 0.017081670596131256\n",
      "SEED: 6, FOLD: 2, EPOCH: 22,train_loss: 0.014771302543362997, valid_loss: 0.01704714551035847\n",
      "SEED: 6, FOLD: 2, EPOCH: 23,train_loss: 0.01431088853137989, valid_loss: 0.01704216862895659\n",
      "SEED: 6, FOLD: 2, EPOCH: 24,train_loss: 0.014047935407907858, valid_loss: 0.017058788798749447\n",
      "(17586, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7343091623506685, valid_loss: 0.680975832257952\n",
      "SEED: 6, FOLD: 3, EPOCH: 0,train_loss: 0.46699426985899173, valid_loss: 0.02404744273849896\n",
      "SEED: 6, FOLD: 3, EPOCH: 1,train_loss: 0.0212202166625555, valid_loss: 0.018743827805987427\n",
      "SEED: 6, FOLD: 3, EPOCH: 2,train_loss: 0.01904528391668978, valid_loss: 0.018090746604970523\n",
      "SEED: 6, FOLD: 3, EPOCH: 3,train_loss: 0.018195847710729508, valid_loss: 0.018365430778690746\n",
      "SEED: 6, FOLD: 3, EPOCH: 4,train_loss: 0.017837939979643492, valid_loss: 0.017753217768456255\n",
      "SEED: 6, FOLD: 3, EPOCH: 5,train_loss: 0.017879504298764295, valid_loss: 0.01816209490810122\n",
      "SEED: 6, FOLD: 3, EPOCH: 6,train_loss: 0.017920000141189583, valid_loss: 0.017780073971620628\n",
      "SEED: 6, FOLD: 3, EPOCH: 7,train_loss: 0.017863278277218342, valid_loss: 0.018091139969016824\n",
      "SEED: 6, FOLD: 3, EPOCH: 8,train_loss: 0.01789237198460361, valid_loss: 0.01792573465832642\n",
      "SEED: 6, FOLD: 3, EPOCH: 9,train_loss: 0.017813991782241974, valid_loss: 0.017648697830736637\n",
      "SEED: 6, FOLD: 3, EPOCH: 10,train_loss: 0.01777452895876722, valid_loss: 0.017635575868189333\n",
      "SEED: 6, FOLD: 3, EPOCH: 11,train_loss: 0.01775931159331315, valid_loss: 0.01758356560021639\n",
      "SEED: 6, FOLD: 3, EPOCH: 12,train_loss: 0.01767006944325091, valid_loss: 0.017549627859677588\n",
      "SEED: 6, FOLD: 3, EPOCH: 13,train_loss: 0.017561589279954416, valid_loss: 0.01755435602473361\n",
      "SEED: 6, FOLD: 3, EPOCH: 14,train_loss: 0.01750815956029987, valid_loss: 0.01755711218076093\n",
      "SEED: 6, FOLD: 3, EPOCH: 15,train_loss: 0.017253678285287344, valid_loss: 0.017340905671673162\n",
      "SEED: 6, FOLD: 3, EPOCH: 16,train_loss: 0.017183006464409224, valid_loss: 0.01733626944145986\n",
      "SEED: 6, FOLD: 3, EPOCH: 17,train_loss: 0.01692372343192498, valid_loss: 0.01729995629617146\n",
      "SEED: 6, FOLD: 3, EPOCH: 18,train_loss: 0.016534006223082542, valid_loss: 0.017195910082331727\n",
      "SEED: 6, FOLD: 3, EPOCH: 19,train_loss: 0.016255295140317816, valid_loss: 0.017074383635606084\n",
      "SEED: 6, FOLD: 3, EPOCH: 20,train_loss: 0.01584981711230416, valid_loss: 0.01706499851175717\n",
      "SEED: 6, FOLD: 3, EPOCH: 21,train_loss: 0.01533608311328335, valid_loss: 0.017037030069955758\n",
      "SEED: 6, FOLD: 3, EPOCH: 22,train_loss: 0.014833057818907326, valid_loss: 0.01705382780304977\n",
      "SEED: 6, FOLD: 3, EPOCH: 23,train_loss: 0.014354218465640493, valid_loss: 0.01705127592597689\n",
      "SEED: 6, FOLD: 3, EPOCH: 24,train_loss: 0.014116178448919369, valid_loss: 0.01704814588384969\n",
      "(17615, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.734051596859227, valid_loss: 0.6818730427938349\n",
      "SEED: 6, FOLD: 4, EPOCH: 0,train_loss: 0.4662704980135828, valid_loss: 0.02396498993039131\n",
      "SEED: 6, FOLD: 4, EPOCH: 1,train_loss: 0.020831909462593605, valid_loss: 0.018820387420847136\n",
      "SEED: 6, FOLD: 4, EPOCH: 2,train_loss: 0.01921340569421865, valid_loss: 0.018509432098225635\n",
      "SEED: 6, FOLD: 4, EPOCH: 3,train_loss: 0.018349413287596428, valid_loss: 0.017800370477797353\n",
      "SEED: 6, FOLD: 4, EPOCH: 4,train_loss: 0.017931876521881506, valid_loss: 0.017925660728531724\n",
      "SEED: 6, FOLD: 4, EPOCH: 5,train_loss: 0.01788603418601164, valid_loss: 0.017969153355807066\n",
      "SEED: 6, FOLD: 4, EPOCH: 6,train_loss: 0.017871636276443798, valid_loss: 0.018148738836102626\n",
      "SEED: 6, FOLD: 4, EPOCH: 7,train_loss: 0.01789408795994477, valid_loss: 0.017719018382622916\n",
      "SEED: 6, FOLD: 4, EPOCH: 8,train_loss: 0.01784596994411254, valid_loss: 0.017944009235019192\n",
      "SEED: 6, FOLD: 4, EPOCH: 9,train_loss: 0.017835678930893755, valid_loss: 0.017665813156567952\n",
      "SEED: 6, FOLD: 4, EPOCH: 10,train_loss: 0.017840007731717997, valid_loss: 0.017844142967506367\n",
      "SEED: 6, FOLD: 4, EPOCH: 11,train_loss: 0.017788651939211548, valid_loss: 0.01766654523089528\n",
      "SEED: 6, FOLD: 4, EPOCH: 12,train_loss: 0.017704023750147957, valid_loss: 0.017738078666083953\n",
      "SEED: 6, FOLD: 4, EPOCH: 13,train_loss: 0.017638542351947315, valid_loss: 0.017636292367516196\n",
      "SEED: 6, FOLD: 4, EPOCH: 14,train_loss: 0.017468636308837195, valid_loss: 0.017280626220299918\n",
      "SEED: 6, FOLD: 4, EPOCH: 15,train_loss: 0.017365563647362633, valid_loss: 0.017430448877241683\n",
      "SEED: 6, FOLD: 4, EPOCH: 16,train_loss: 0.01716320259847503, valid_loss: 0.017330249387990024\n",
      "SEED: 6, FOLD: 4, EPOCH: 17,train_loss: 0.01697497367453964, valid_loss: 0.017125435721348312\n",
      "SEED: 6, FOLD: 4, EPOCH: 18,train_loss: 0.016642520555119583, valid_loss: 0.017251808661967516\n",
      "SEED: 6, FOLD: 4, EPOCH: 19,train_loss: 0.016318826079098642, valid_loss: 0.017179750179981485\n",
      "SEED: 6, FOLD: 4, EPOCH: 20,train_loss: 0.01588778469738537, valid_loss: 0.017127679250038722\n",
      "SEED: 6, FOLD: 4, EPOCH: 21,train_loss: 0.015398439762277016, valid_loss: 0.01706341643105535\n",
      "SEED: 6, FOLD: 4, EPOCH: 22,train_loss: 0.014921924990156422, valid_loss: 0.017078627037870532\n",
      "SEED: 6, FOLD: 4, EPOCH: 23,train_loss: 0.014478737562624872, valid_loss: 0.017028203973656193\n",
      "SEED: 6, FOLD: 4, EPOCH: 24,train_loss: 0.014248320697874262, valid_loss: 0.01702936738729477\n",
      "(17569, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7356484540994617, valid_loss: 0.6903154168810163\n",
      "SEED: 7, FOLD: 0, EPOCH: 0,train_loss: 0.4655978061339777, valid_loss: 0.023940065928867885\n",
      "SEED: 7, FOLD: 0, EPOCH: 1,train_loss: 0.021085544097898663, valid_loss: 0.02107993300471987\n",
      "SEED: 7, FOLD: 0, EPOCH: 2,train_loss: 0.018979544440905254, valid_loss: 0.01807837464979717\n",
      "SEED: 7, FOLD: 0, EPOCH: 3,train_loss: 0.01835024833301271, valid_loss: 0.01776001365589244\n",
      "SEED: 7, FOLD: 0, EPOCH: 4,train_loss: 0.017998367757199034, valid_loss: 0.01771104982388871\n",
      "SEED: 7, FOLD: 0, EPOCH: 5,train_loss: 0.0179083951195513, valid_loss: 0.01748919737126146\n",
      "SEED: 7, FOLD: 0, EPOCH: 6,train_loss: 0.017893369849501312, valid_loss: 0.017599567132336753\n",
      "SEED: 7, FOLD: 0, EPOCH: 7,train_loss: 0.018012129067294838, valid_loss: 0.017543165146240165\n",
      "SEED: 7, FOLD: 0, EPOCH: 8,train_loss: 0.01798366820709645, valid_loss: 0.017511999819959913\n",
      "SEED: 7, FOLD: 0, EPOCH: 9,train_loss: 0.01791387112757218, valid_loss: 0.017662291281989644\n",
      "SEED: 7, FOLD: 0, EPOCH: 10,train_loss: 0.017868823574289032, valid_loss: 0.017431097770375863\n",
      "SEED: 7, FOLD: 0, EPOCH: 11,train_loss: 0.017800814863564312, valid_loss: 0.017390320769378118\n",
      "SEED: 7, FOLD: 0, EPOCH: 12,train_loss: 0.017743846927971943, valid_loss: 0.01733309669154031\n",
      "SEED: 7, FOLD: 0, EPOCH: 13,train_loss: 0.017657843992060076, valid_loss: 0.01724721970302718\n",
      "SEED: 7, FOLD: 0, EPOCH: 14,train_loss: 0.017593862900537424, valid_loss: 0.017127065493592195\n",
      "SEED: 7, FOLD: 0, EPOCH: 15,train_loss: 0.01742991317819426, valid_loss: 0.01702926073755537\n",
      "SEED: 7, FOLD: 0, EPOCH: 16,train_loss: 0.017268510299154383, valid_loss: 0.016944186948239803\n",
      "SEED: 7, FOLD: 0, EPOCH: 17,train_loss: 0.017007301770744547, valid_loss: 0.01687107676906245\n",
      "SEED: 7, FOLD: 0, EPOCH: 18,train_loss: 0.016714268795929958, valid_loss: 0.01707714820014579\n",
      "SEED: 7, FOLD: 0, EPOCH: 19,train_loss: 0.016410221109517675, valid_loss: 0.01686917809503419\n",
      "SEED: 7, FOLD: 0, EPOCH: 20,train_loss: 0.015988510257254045, valid_loss: 0.01695729637784617\n",
      "SEED: 7, FOLD: 0, EPOCH: 21,train_loss: 0.015504139887195999, valid_loss: 0.016822708610977444\n",
      "SEED: 7, FOLD: 0, EPOCH: 22,train_loss: 0.01499031641372088, valid_loss: 0.016681258832769736\n",
      "SEED: 7, FOLD: 0, EPOCH: 23,train_loss: 0.014592317823806534, valid_loss: 0.01674474110560758\n",
      "SEED: 7, FOLD: 0, EPOCH: 24,train_loss: 0.01433958766469057, valid_loss: 0.016761581865804537\n",
      "(17564, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7355124103850212, valid_loss: 0.691426248209817\n",
      "SEED: 7, FOLD: 1, EPOCH: 0,train_loss: 0.46691169970385404, valid_loss: 0.023983944047774586\n",
      "SEED: 7, FOLD: 1, EPOCH: 1,train_loss: 0.02067873354299345, valid_loss: 0.018916328544063228\n",
      "SEED: 7, FOLD: 1, EPOCH: 2,train_loss: 0.018949150364252106, valid_loss: 0.018268315680325033\n",
      "SEED: 7, FOLD: 1, EPOCH: 3,train_loss: 0.018313035335175802, valid_loss: 0.018226372211107185\n",
      "SEED: 7, FOLD: 1, EPOCH: 4,train_loss: 0.017923840065149292, valid_loss: 0.018573419962610516\n",
      "SEED: 7, FOLD: 1, EPOCH: 5,train_loss: 0.017818343164264294, valid_loss: 0.018488776231450694\n",
      "SEED: 7, FOLD: 1, EPOCH: 6,train_loss: 0.018001242311320442, valid_loss: 0.018914800988776344\n",
      "SEED: 7, FOLD: 1, EPOCH: 7,train_loss: 0.017941221007672342, valid_loss: 0.017964930193764824\n",
      "SEED: 7, FOLD: 1, EPOCH: 8,train_loss: 0.017873841277121202, valid_loss: 0.018497667301978382\n",
      "SEED: 7, FOLD: 1, EPOCH: 9,train_loss: 0.017969866188755935, valid_loss: 0.018365715736789363\n",
      "SEED: 7, FOLD: 1, EPOCH: 10,train_loss: 0.01785710096305263, valid_loss: 0.0179307669667261\n",
      "SEED: 7, FOLD: 1, EPOCH: 11,train_loss: 0.017798814693114895, valid_loss: 0.0180174142654453\n",
      "SEED: 7, FOLD: 1, EPOCH: 12,train_loss: 0.017698332768581484, valid_loss: 0.017805660276540687\n",
      "SEED: 7, FOLD: 1, EPOCH: 13,train_loss: 0.017619684466795214, valid_loss: 0.017815803204263958\n",
      "SEED: 7, FOLD: 1, EPOCH: 14,train_loss: 0.017486841843018065, valid_loss: 0.018097603294466223\n",
      "SEED: 7, FOLD: 1, EPOCH: 15,train_loss: 0.017364190668677507, valid_loss: 0.01777273722525154\n",
      "SEED: 7, FOLD: 1, EPOCH: 16,train_loss: 0.017226125761542633, valid_loss: 0.017682947245027336\n",
      "SEED: 7, FOLD: 1, EPOCH: 17,train_loss: 0.01692640383903315, valid_loss: 0.01766859010926315\n",
      "SEED: 7, FOLD: 1, EPOCH: 18,train_loss: 0.016668531645521307, valid_loss: 0.01780008351696389\n",
      "SEED: 7, FOLD: 1, EPOCH: 19,train_loss: 0.016387850181132122, valid_loss: 0.01758911976856845\n",
      "SEED: 7, FOLD: 1, EPOCH: 20,train_loss: 0.016013966515606295, valid_loss: 0.017398364788719586\n",
      "SEED: 7, FOLD: 1, EPOCH: 21,train_loss: 0.015504864091728476, valid_loss: 0.017395275990877833\n",
      "SEED: 7, FOLD: 1, EPOCH: 22,train_loss: 0.01501468046689811, valid_loss: 0.0174510497333748\n",
      "SEED: 7, FOLD: 1, EPOCH: 23,train_loss: 0.014625727786156147, valid_loss: 0.017375115784151213\n",
      "SEED: 7, FOLD: 1, EPOCH: 24,train_loss: 0.014421932514001062, valid_loss: 0.017402543367019723\n",
      "(17556, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7356690941513448, valid_loss: 0.6896167056901115\n",
      "SEED: 7, FOLD: 2, EPOCH: 0,train_loss: 0.46708906756417046, valid_loss: 0.023272869203771862\n",
      "SEED: 7, FOLD: 2, EPOCH: 1,train_loss: 0.02100090461148732, valid_loss: 0.01870318544762475\n",
      "SEED: 7, FOLD: 2, EPOCH: 2,train_loss: 0.01924671513446863, valid_loss: 0.017911349050700666\n",
      "SEED: 7, FOLD: 2, EPOCH: 3,train_loss: 0.018269471938897303, valid_loss: 0.017719867053840842\n",
      "SEED: 7, FOLD: 2, EPOCH: 4,train_loss: 0.018063581305677475, valid_loss: 0.017852558727775303\n",
      "SEED: 7, FOLD: 2, EPOCH: 5,train_loss: 0.018057431998676148, valid_loss: 0.01776840915637357\n",
      "SEED: 7, FOLD: 2, EPOCH: 6,train_loss: 0.01794225105718858, valid_loss: 0.017656319801296505\n",
      "SEED: 7, FOLD: 2, EPOCH: 7,train_loss: 0.017957834695614336, valid_loss: 0.017615291316594395\n",
      "SEED: 7, FOLD: 2, EPOCH: 8,train_loss: 0.017891627844369064, valid_loss: 0.01765230537525245\n",
      "SEED: 7, FOLD: 2, EPOCH: 9,train_loss: 0.017946082248311977, valid_loss: 0.017933367911194053\n",
      "SEED: 7, FOLD: 2, EPOCH: 10,train_loss: 0.017853539484296587, valid_loss: 0.017472870328596662\n",
      "SEED: 7, FOLD: 2, EPOCH: 11,train_loss: 0.017805747411119333, valid_loss: 0.01752311283988612\n",
      "SEED: 7, FOLD: 2, EPOCH: 12,train_loss: 0.017707751719686, valid_loss: 0.01739745448742594\n",
      "SEED: 7, FOLD: 2, EPOCH: 13,train_loss: 0.017593773581303547, valid_loss: 0.017253295837768485\n",
      "SEED: 7, FOLD: 2, EPOCH: 14,train_loss: 0.01751175467464803, valid_loss: 0.017463861299412593\n",
      "SEED: 7, FOLD: 2, EPOCH: 15,train_loss: 0.017380455292869305, valid_loss: 0.017123316654137202\n",
      "SEED: 7, FOLD: 2, EPOCH: 16,train_loss: 0.017166621632118156, valid_loss: 0.017022239815975938\n",
      "SEED: 7, FOLD: 2, EPOCH: 17,train_loss: 0.01690862597087803, valid_loss: 0.017011264099606446\n",
      "SEED: 7, FOLD: 2, EPOCH: 18,train_loss: 0.016654601205896208, valid_loss: 0.01730035524815321\n",
      "SEED: 7, FOLD: 2, EPOCH: 19,train_loss: 0.016264807176438793, valid_loss: 0.01697892344423703\n",
      "SEED: 7, FOLD: 2, EPOCH: 20,train_loss: 0.015889393597625305, valid_loss: 0.016796608828008174\n",
      "SEED: 7, FOLD: 2, EPOCH: 21,train_loss: 0.015419863940527042, valid_loss: 0.016783476780567852\n",
      "SEED: 7, FOLD: 2, EPOCH: 22,train_loss: 0.014869261141596497, valid_loss: 0.01683919903423105\n",
      "SEED: 7, FOLD: 2, EPOCH: 23,train_loss: 0.01446054563385205, valid_loss: 0.016796494222113063\n",
      "SEED: 7, FOLD: 2, EPOCH: 24,train_loss: 0.014201868440200022, valid_loss: 0.016819114690380436\n",
      "(17532, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7359926565720217, valid_loss: 0.6914134417261396\n",
      "SEED: 7, FOLD: 3, EPOCH: 0,train_loss: 0.4682114162638675, valid_loss: 0.024697168011750495\n",
      "SEED: 7, FOLD: 3, EPOCH: 1,train_loss: 0.020623939356555904, valid_loss: 0.01919226220675877\n",
      "SEED: 7, FOLD: 3, EPOCH: 2,train_loss: 0.01902101874813764, valid_loss: 0.01851475943944284\n",
      "SEED: 7, FOLD: 3, EPOCH: 3,train_loss: 0.017993155159871942, valid_loss: 0.018310476573450224\n",
      "SEED: 7, FOLD: 3, EPOCH: 4,train_loss: 0.01774764709500936, valid_loss: 0.01847165506333113\n",
      "SEED: 7, FOLD: 3, EPOCH: 5,train_loss: 0.017652718812553553, valid_loss: 0.018321640683071953\n",
      "SEED: 7, FOLD: 3, EPOCH: 6,train_loss: 0.017679834391677033, valid_loss: 0.018612945984516824\n",
      "SEED: 7, FOLD: 3, EPOCH: 7,train_loss: 0.017746813472931403, valid_loss: 0.01830469737095492\n",
      "SEED: 7, FOLD: 3, EPOCH: 8,train_loss: 0.017701244926637542, valid_loss: 0.01814796474895307\n",
      "SEED: 7, FOLD: 3, EPOCH: 9,train_loss: 0.017682190223114333, valid_loss: 0.018329823203384877\n",
      "SEED: 7, FOLD: 3, EPOCH: 10,train_loss: 0.017668132411900662, valid_loss: 0.018184051316763674\n",
      "SEED: 7, FOLD: 3, EPOCH: 11,train_loss: 0.01756682406675859, valid_loss: 0.018239412776061465\n",
      "SEED: 7, FOLD: 3, EPOCH: 12,train_loss: 0.017540299381217817, valid_loss: 0.018106872428740775\n",
      "SEED: 7, FOLD: 3, EPOCH: 13,train_loss: 0.017353165928736654, valid_loss: 0.018862018680998256\n",
      "SEED: 7, FOLD: 3, EPOCH: 14,train_loss: 0.017292801617053304, valid_loss: 0.018127704677837236\n",
      "SEED: 7, FOLD: 3, EPOCH: 15,train_loss: 0.017133315161795077, valid_loss: 0.017813411168754102\n",
      "SEED: 7, FOLD: 3, EPOCH: 16,train_loss: 0.016908507243505795, valid_loss: 0.017897343103374753\n",
      "SEED: 7, FOLD: 3, EPOCH: 17,train_loss: 0.016708623074049498, valid_loss: 0.017897287969078336\n",
      "SEED: 7, FOLD: 3, EPOCH: 18,train_loss: 0.016378791363787476, valid_loss: 0.017782882946942535\n",
      "SEED: 7, FOLD: 3, EPOCH: 19,train_loss: 0.016039157408649904, valid_loss: 0.01779667048582009\n",
      "SEED: 7, FOLD: 3, EPOCH: 20,train_loss: 0.015653043992164797, valid_loss: 0.017745272628962992\n",
      "SEED: 7, FOLD: 3, EPOCH: 21,train_loss: 0.01508327674827654, valid_loss: 0.01769399395478623\n",
      "SEED: 7, FOLD: 3, EPOCH: 22,train_loss: 0.014530683643300167, valid_loss: 0.01768727164183344\n",
      "SEED: 7, FOLD: 3, EPOCH: 23,train_loss: 0.014060985276570721, valid_loss: 0.017632694409361906\n",
      "SEED: 7, FOLD: 3, EPOCH: 24,train_loss: 0.013817347205468337, valid_loss: 0.017660789457815036\n",
      "(17571, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.736025295395782, valid_loss: 0.692817371232169\n",
      "SEED: 7, FOLD: 4, EPOCH: 0,train_loss: 0.4665057763484293, valid_loss: 0.023998425794499262\n",
      "SEED: 7, FOLD: 4, EPOCH: 1,train_loss: 0.02099323955674966, valid_loss: 0.018916285570178715\n",
      "SEED: 7, FOLD: 4, EPOCH: 2,train_loss: 0.01893239745033392, valid_loss: 0.018176396270947796\n",
      "SEED: 7, FOLD: 4, EPOCH: 3,train_loss: 0.018345190252622833, valid_loss: 0.017841323811028684\n",
      "SEED: 7, FOLD: 4, EPOCH: 4,train_loss: 0.018028592191420605, valid_loss: 0.018418471754661627\n",
      "SEED: 7, FOLD: 4, EPOCH: 5,train_loss: 0.01786982318710374, valid_loss: 0.018185732779758317\n",
      "SEED: 7, FOLD: 4, EPOCH: 6,train_loss: 0.01782884542573837, valid_loss: 0.018073539888220174\n",
      "SEED: 7, FOLD: 4, EPOCH: 7,train_loss: 0.017815924175353586, valid_loss: 0.018309575292680944\n",
      "SEED: 7, FOLD: 4, EPOCH: 8,train_loss: 0.01781008928420319, valid_loss: 0.01779153517314366\n",
      "SEED: 7, FOLD: 4, EPOCH: 9,train_loss: 0.0177503220156591, valid_loss: 0.01794557651238782\n",
      "SEED: 7, FOLD: 4, EPOCH: 10,train_loss: 0.01773149451996753, valid_loss: 0.01776842602661678\n",
      "SEED: 7, FOLD: 4, EPOCH: 11,train_loss: 0.01774525738901634, valid_loss: 0.017768171136932714\n",
      "SEED: 7, FOLD: 4, EPOCH: 12,train_loss: 0.017663451404297266, valid_loss: 0.017902629050825323\n",
      "SEED: 7, FOLD: 4, EPOCH: 13,train_loss: 0.017535024626261515, valid_loss: 0.017691987460213048\n",
      "SEED: 7, FOLD: 4, EPOCH: 14,train_loss: 0.01744483185230174, valid_loss: 0.017568626760372092\n",
      "SEED: 7, FOLD: 4, EPOCH: 15,train_loss: 0.017312765681603247, valid_loss: 0.01760994110788618\n",
      "SEED: 7, FOLD: 4, EPOCH: 16,train_loss: 0.017089156251724646, valid_loss: 0.01745966523885727\n",
      "SEED: 7, FOLD: 4, EPOCH: 17,train_loss: 0.016913859679809084, valid_loss: 0.0174959520144122\n",
      "SEED: 7, FOLD: 4, EPOCH: 18,train_loss: 0.01653662409660393, valid_loss: 0.017425789630838802\n",
      "SEED: 7, FOLD: 4, EPOCH: 19,train_loss: 0.016257643713143425, valid_loss: 0.017350813666624682\n",
      "SEED: 7, FOLD: 4, EPOCH: 20,train_loss: 0.01588569403342579, valid_loss: 0.017286336847714016\n",
      "SEED: 7, FOLD: 4, EPOCH: 21,train_loss: 0.015361513355341942, valid_loss: 0.017254038740481648\n",
      "SEED: 7, FOLD: 4, EPOCH: 22,train_loss: 0.014899260755898296, valid_loss: 0.01729004955185311\n",
      "SEED: 7, FOLD: 4, EPOCH: 23,train_loss: 0.014457333778989489, valid_loss: 0.01728595971528973\n",
      "SEED: 7, FOLD: 4, EPOCH: 24,train_loss: 0.014243476086066685, valid_loss: 0.017301956032003674\n",
      "(17505, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7353917377708602, valid_loss: 0.7018885101590838\n",
      "SEED: 8, FOLD: 0, EPOCH: 0,train_loss: 0.467685771140739, valid_loss: 0.024627419135400227\n",
      "SEED: 8, FOLD: 0, EPOCH: 1,train_loss: 0.020978495981680216, valid_loss: 0.019200796367866653\n",
      "SEED: 8, FOLD: 0, EPOCH: 2,train_loss: 0.01896797777255521, valid_loss: 0.018576370711837497\n",
      "SEED: 8, FOLD: 0, EPOCH: 3,train_loss: 0.01827777473487123, valid_loss: 0.017915823150958333\n",
      "SEED: 8, FOLD: 0, EPOCH: 4,train_loss: 0.017889953333966053, valid_loss: 0.01793603003025055\n",
      "SEED: 8, FOLD: 0, EPOCH: 5,train_loss: 0.017888857065326107, valid_loss: 0.01804802151662963\n",
      "SEED: 8, FOLD: 0, EPOCH: 6,train_loss: 0.01788462147143853, valid_loss: 0.01842304973730019\n",
      "SEED: 8, FOLD: 0, EPOCH: 7,train_loss: 0.017872120450883017, valid_loss: 0.017935786183391297\n",
      "SEED: 8, FOLD: 0, EPOCH: 8,train_loss: 0.01787102704419054, valid_loss: 0.018006118041064056\n",
      "SEED: 8, FOLD: 0, EPOCH: 9,train_loss: 0.017830289560404135, valid_loss: 0.018228455978844847\n",
      "SEED: 8, FOLD: 0, EPOCH: 10,train_loss: 0.017867505326051348, valid_loss: 0.018145181691007956\n",
      "SEED: 8, FOLD: 0, EPOCH: 11,train_loss: 0.01769457178285522, valid_loss: 0.017815754482788698\n",
      "SEED: 8, FOLD: 0, EPOCH: 12,train_loss: 0.017649596794950265, valid_loss: 0.01775865283395563\n",
      "SEED: 8, FOLD: 0, EPOCH: 13,train_loss: 0.017571949563159123, valid_loss: 0.017703797987529208\n",
      "SEED: 8, FOLD: 0, EPOCH: 14,train_loss: 0.017383921279633133, valid_loss: 0.017794455508036273\n",
      "SEED: 8, FOLD: 0, EPOCH: 15,train_loss: 0.017282511060037753, valid_loss: 0.017541671384658133\n",
      "SEED: 8, FOLD: 0, EPOCH: 16,train_loss: 0.01707074562101251, valid_loss: 0.0175674953098808\n",
      "SEED: 8, FOLD: 0, EPOCH: 17,train_loss: 0.01684037420599565, valid_loss: 0.017658047564327716\n",
      "SEED: 8, FOLD: 0, EPOCH: 18,train_loss: 0.016541419503190657, valid_loss: 0.017548152564891745\n",
      "SEED: 8, FOLD: 0, EPOCH: 19,train_loss: 0.01619498849758049, valid_loss: 0.017560905830136368\n",
      "SEED: 8, FOLD: 0, EPOCH: 20,train_loss: 0.015762487521571833, valid_loss: 0.017402401646333082\n",
      "SEED: 8, FOLD: 0, EPOCH: 21,train_loss: 0.01533002224172989, valid_loss: 0.01738371428634439\n",
      "SEED: 8, FOLD: 0, EPOCH: 22,train_loss: 0.014757967764770027, valid_loss: 0.017477788110928875\n",
      "SEED: 8, FOLD: 0, EPOCH: 23,train_loss: 0.014323621104559758, valid_loss: 0.01746715363115072\n",
      "SEED: 8, FOLD: 0, EPOCH: 24,train_loss: 0.014096487823357113, valid_loss: 0.01746270555470671\n",
      "(17567, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7351628114347872, valid_loss: 0.6992931927953447\n",
      "SEED: 8, FOLD: 1, EPOCH: 0,train_loss: 0.46578611368718353, valid_loss: 0.023767418733664922\n",
      "SEED: 8, FOLD: 1, EPOCH: 1,train_loss: 0.020627486708479515, valid_loss: 0.018707799831671375\n",
      "SEED: 8, FOLD: 1, EPOCH: 2,train_loss: 0.018888712617690148, valid_loss: 0.018264692995165074\n",
      "SEED: 8, FOLD: 1, EPOCH: 3,train_loss: 0.01821650085511847, valid_loss: 0.0192191747416343\n",
      "SEED: 8, FOLD: 1, EPOCH: 4,train_loss: 0.017927596898938435, valid_loss: 0.01790598761290312\n",
      "SEED: 8, FOLD: 1, EPOCH: 5,train_loss: 0.017918454476402723, valid_loss: 0.01846618881183011\n",
      "SEED: 8, FOLD: 1, EPOCH: 6,train_loss: 0.01792192643346346, valid_loss: 0.017769588796155793\n",
      "SEED: 8, FOLD: 1, EPOCH: 7,train_loss: 0.017781197977508757, valid_loss: 0.017899252846837042\n",
      "SEED: 8, FOLD: 1, EPOCH: 8,train_loss: 0.017857214800365593, valid_loss: 0.018158860690891742\n",
      "SEED: 8, FOLD: 1, EPOCH: 9,train_loss: 0.017875910169728424, valid_loss: 0.017993639303105217\n",
      "SEED: 8, FOLD: 1, EPOCH: 10,train_loss: 0.017766315631730402, valid_loss: 0.018100771786911145\n",
      "SEED: 8, FOLD: 1, EPOCH: 11,train_loss: 0.01774322616773239, valid_loss: 0.01803001926413604\n",
      "SEED: 8, FOLD: 1, EPOCH: 12,train_loss: 0.017715429576734703, valid_loss: 0.017920076474547388\n",
      "SEED: 8, FOLD: 1, EPOCH: 13,train_loss: 0.017605128650809976, valid_loss: 0.017743857337960176\n",
      "SEED: 8, FOLD: 1, EPOCH: 14,train_loss: 0.017490534867713417, valid_loss: 0.017751732308949743\n",
      "SEED: 8, FOLD: 1, EPOCH: 15,train_loss: 0.017365583704541557, valid_loss: 0.017575181727962835\n",
      "SEED: 8, FOLD: 1, EPOCH: 16,train_loss: 0.01707862923596648, valid_loss: 0.017430424370935987\n",
      "SEED: 8, FOLD: 1, EPOCH: 17,train_loss: 0.016913598875744618, valid_loss: 0.017541044391691685\n",
      "SEED: 8, FOLD: 1, EPOCH: 18,train_loss: 0.016661506254171978, valid_loss: 0.01736804015402283\n",
      "SEED: 8, FOLD: 1, EPOCH: 19,train_loss: 0.016285033295929865, valid_loss: 0.017374605499207975\n",
      "SEED: 8, FOLD: 1, EPOCH: 20,train_loss: 0.015888814692911896, valid_loss: 0.01733525070760931\n",
      "SEED: 8, FOLD: 1, EPOCH: 21,train_loss: 0.015391257780509583, valid_loss: 0.017288764220263278\n",
      "SEED: 8, FOLD: 1, EPOCH: 22,train_loss: 0.01490572133384969, valid_loss: 0.017328469109322342\n",
      "SEED: 8, FOLD: 1, EPOCH: 23,train_loss: 0.014479329640828613, valid_loss: 0.017300439120403358\n",
      "SEED: 8, FOLD: 1, EPOCH: 24,train_loss: 0.014237984542505465, valid_loss: 0.017310173250734806\n",
      "(17582, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7356032081272291, valid_loss: 0.7007815224783761\n",
      "SEED: 8, FOLD: 2, EPOCH: 0,train_loss: 0.4663175412359229, valid_loss: 0.024017969518899916\n",
      "SEED: 8, FOLD: 2, EPOCH: 1,train_loss: 0.020778584793425987, valid_loss: 0.018948741416846004\n",
      "SEED: 8, FOLD: 2, EPOCH: 2,train_loss: 0.018851948240636917, valid_loss: 0.018017211662871496\n",
      "SEED: 8, FOLD: 2, EPOCH: 3,train_loss: 0.01815480436535849, valid_loss: 0.01795209946909121\n",
      "SEED: 8, FOLD: 2, EPOCH: 4,train_loss: 0.017952712380961664, valid_loss: 0.018256948914911066\n",
      "SEED: 8, FOLD: 2, EPOCH: 5,train_loss: 0.017936173327051212, valid_loss: 0.01794616425676005\n",
      "SEED: 8, FOLD: 2, EPOCH: 6,train_loss: 0.017944266486481047, valid_loss: 0.01801925775195871\n",
      "SEED: 8, FOLD: 2, EPOCH: 7,train_loss: 0.01793053574131235, valid_loss: 0.01787957264376538\n",
      "SEED: 8, FOLD: 2, EPOCH: 8,train_loss: 0.017972575041694916, valid_loss: 0.01791693836982761\n",
      "SEED: 8, FOLD: 2, EPOCH: 9,train_loss: 0.017871642896932535, valid_loss: 0.018178028879421097\n",
      "SEED: 8, FOLD: 2, EPOCH: 10,train_loss: 0.017851182036911665, valid_loss: 0.017740995117596216\n",
      "SEED: 8, FOLD: 2, EPOCH: 11,train_loss: 0.017786570844928854, valid_loss: 0.017852400163454667\n",
      "SEED: 8, FOLD: 2, EPOCH: 12,train_loss: 0.01769388049328025, valid_loss: 0.017989031012569157\n",
      "SEED: 8, FOLD: 2, EPOCH: 13,train_loss: 0.01755679078211171, valid_loss: 0.017907430843583174\n",
      "SEED: 8, FOLD: 2, EPOCH: 14,train_loss: 0.017533576352170843, valid_loss: 0.01771668004138129\n",
      "SEED: 8, FOLD: 2, EPOCH: 15,train_loss: 0.01736344619775596, valid_loss: 0.017669686701680933\n",
      "SEED: 8, FOLD: 2, EPOCH: 16,train_loss: 0.017192322112943813, valid_loss: 0.017415521666407585\n",
      "SEED: 8, FOLD: 2, EPOCH: 17,train_loss: 0.01700336558987265, valid_loss: 0.017387560568749905\n",
      "SEED: 8, FOLD: 2, EPOCH: 18,train_loss: 0.01664081285370217, valid_loss: 0.017363617436162063\n",
      "SEED: 8, FOLD: 2, EPOCH: 19,train_loss: 0.016356542301566704, valid_loss: 0.0174248834539737\n",
      "SEED: 8, FOLD: 2, EPOCH: 20,train_loss: 0.015931465021887983, valid_loss: 0.017318113387695382\n",
      "SEED: 8, FOLD: 2, EPOCH: 21,train_loss: 0.01545317484524803, valid_loss: 0.01718874139977353\n",
      "SEED: 8, FOLD: 2, EPOCH: 22,train_loss: 0.014950136431371388, valid_loss: 0.017236962621765477\n",
      "SEED: 8, FOLD: 2, EPOCH: 23,train_loss: 0.014557115591900505, valid_loss: 0.017246802869652\n",
      "SEED: 8, FOLD: 2, EPOCH: 24,train_loss: 0.014299734981487627, valid_loss: 0.017236034918044294\n",
      "(17583, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7356360377608866, valid_loss: 0.6996472307613918\n",
      "SEED: 8, FOLD: 3, EPOCH: 0,train_loss: 0.46725158066745254, valid_loss: 0.02330995015799999\n",
      "SEED: 8, FOLD: 3, EPOCH: 1,train_loss: 0.020855690636064694, valid_loss: 0.018381368448691707\n",
      "SEED: 8, FOLD: 3, EPOCH: 2,train_loss: 0.018856027797944305, valid_loss: 0.01809526024652379\n",
      "SEED: 8, FOLD: 3, EPOCH: 3,train_loss: 0.01825851637978053, valid_loss: 0.01766819299331733\n",
      "SEED: 8, FOLD: 3, EPOCH: 4,train_loss: 0.018028084944555725, valid_loss: 0.017780628321426257\n",
      "SEED: 8, FOLD: 3, EPOCH: 5,train_loss: 0.017889987893294598, valid_loss: 0.017800017313233444\n",
      "SEED: 8, FOLD: 3, EPOCH: 6,train_loss: 0.01786696955399669, valid_loss: 0.01795067566313914\n",
      "SEED: 8, FOLD: 3, EPOCH: 7,train_loss: 0.01791024556302506, valid_loss: 0.018410475951220306\n",
      "SEED: 8, FOLD: 3, EPOCH: 8,train_loss: 0.01794938921280529, valid_loss: 0.017546465008386542\n",
      "SEED: 8, FOLD: 3, EPOCH: 9,train_loss: 0.017836686041530058, valid_loss: 0.017968308074133736\n",
      "SEED: 8, FOLD: 3, EPOCH: 10,train_loss: 0.017839141149559746, valid_loss: 0.01771074751658099\n",
      "SEED: 8, FOLD: 3, EPOCH: 11,train_loss: 0.017799525568936613, valid_loss: 0.01768006019826446\n",
      "SEED: 8, FOLD: 3, EPOCH: 12,train_loss: 0.01770773384909051, valid_loss: 0.017656901106238364\n",
      "SEED: 8, FOLD: 3, EPOCH: 13,train_loss: 0.017580205689359835, valid_loss: 0.01750827178891216\n",
      "SEED: 8, FOLD: 3, EPOCH: 14,train_loss: 0.01751462121129684, valid_loss: 0.017385727193738734\n",
      "SEED: 8, FOLD: 3, EPOCH: 15,train_loss: 0.017312541988718767, valid_loss: 0.017227712406643798\n",
      "SEED: 8, FOLD: 3, EPOCH: 16,train_loss: 0.01710978172638494, valid_loss: 0.0174521894593324\n",
      "SEED: 8, FOLD: 3, EPOCH: 17,train_loss: 0.01696007609691309, valid_loss: 0.017353716545871326\n",
      "SEED: 8, FOLD: 3, EPOCH: 18,train_loss: 0.01663219173560324, valid_loss: 0.017216939638767925\n",
      "SEED: 8, FOLD: 3, EPOCH: 19,train_loss: 0.016269856213551502, valid_loss: 0.017026919073292186\n",
      "SEED: 8, FOLD: 3, EPOCH: 20,train_loss: 0.01589813821044737, valid_loss: 0.016924854341362205\n",
      "SEED: 8, FOLD: 3, EPOCH: 21,train_loss: 0.01538219957517973, valid_loss: 0.01707436873444489\n",
      "SEED: 8, FOLD: 3, EPOCH: 22,train_loss: 0.014877681485444738, valid_loss: 0.017047622986137868\n",
      "SEED: 8, FOLD: 3, EPOCH: 23,train_loss: 0.014465466695095318, valid_loss: 0.017029156269771712\n",
      "SEED: 8, FOLD: 3, EPOCH: 24,train_loss: 0.014205726599185795, valid_loss: 0.017030074766704015\n",
      "(17555, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7357634785382644, valid_loss: 0.7039131351879665\n",
      "SEED: 8, FOLD: 4, EPOCH: 0,train_loss: 0.4660309439767962, valid_loss: 0.02324518992432526\n",
      "SEED: 8, FOLD: 4, EPOCH: 1,train_loss: 0.021039436841248604, valid_loss: 0.01994041446596384\n",
      "SEED: 8, FOLD: 4, EPOCH: 2,train_loss: 0.019337720534615757, valid_loss: 0.018055248180670398\n",
      "SEED: 8, FOLD: 4, EPOCH: 3,train_loss: 0.01837238412944303, valid_loss: 0.017883467647646156\n",
      "SEED: 8, FOLD: 4, EPOCH: 4,train_loss: 0.018034805294018293, valid_loss: 0.017941503865378242\n",
      "SEED: 8, FOLD: 4, EPOCH: 5,train_loss: 0.01796139025574793, valid_loss: 0.017861987384302277\n",
      "SEED: 8, FOLD: 4, EPOCH: 6,train_loss: 0.0180762296785479, valid_loss: 0.017862196559352533\n",
      "SEED: 8, FOLD: 4, EPOCH: 7,train_loss: 0.018058360790482897, valid_loss: 0.017820363199072226\n",
      "SEED: 8, FOLD: 4, EPOCH: 8,train_loss: 0.018002199582701574, valid_loss: 0.01783540884831122\n",
      "SEED: 8, FOLD: 4, EPOCH: 9,train_loss: 0.01789948219379437, valid_loss: 0.017885245781924044\n",
      "SEED: 8, FOLD: 4, EPOCH: 10,train_loss: 0.018029495047918266, valid_loss: 0.01782379922057901\n",
      "SEED: 8, FOLD: 4, EPOCH: 11,train_loss: 0.017911157071374466, valid_loss: 0.01753832453063556\n",
      "SEED: 8, FOLD: 4, EPOCH: 12,train_loss: 0.017799385182181562, valid_loss: 0.017654463489140782\n",
      "SEED: 8, FOLD: 4, EPOCH: 13,train_loss: 0.017681669659804607, valid_loss: 0.017631233323897634\n",
      "SEED: 8, FOLD: 4, EPOCH: 14,train_loss: 0.017625462918447844, valid_loss: 0.017375018554074424\n",
      "SEED: 8, FOLD: 4, EPOCH: 15,train_loss: 0.01745267060544828, valid_loss: 0.01707608505551304\n",
      "SEED: 8, FOLD: 4, EPOCH: 16,train_loss: 0.017276658649569836, valid_loss: 0.017335108534565994\n",
      "SEED: 8, FOLD: 4, EPOCH: 17,train_loss: 0.017049824184589626, valid_loss: 0.017147060270820344\n",
      "SEED: 8, FOLD: 4, EPOCH: 18,train_loss: 0.016795353721017422, valid_loss: 0.017142905720642636\n",
      "SEED: 8, FOLD: 4, EPOCH: 19,train_loss: 0.016449788821510214, valid_loss: 0.01705941797367164\n",
      "SEED: 8, FOLD: 4, EPOCH: 20,train_loss: 0.016091154085175283, valid_loss: 0.016924839307154927\n",
      "SEED: 8, FOLD: 4, EPOCH: 21,train_loss: 0.01562603318091968, valid_loss: 0.016937505533652645\n",
      "SEED: 8, FOLD: 4, EPOCH: 22,train_loss: 0.015155249842159126, valid_loss: 0.016959599458745547\n",
      "SEED: 8, FOLD: 4, EPOCH: 23,train_loss: 0.014724929101657177, valid_loss: 0.016933146198945388\n",
      "SEED: 8, FOLD: 4, EPOCH: 24,train_loss: 0.01454626635202895, valid_loss: 0.01693106120718377\n",
      "(17576, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7358415921529134, valid_loss: 0.7080209936414447\n",
      "SEED: 9, FOLD: 0, EPOCH: 0,train_loss: 0.4666329572868088, valid_loss: 0.024028376223785536\n",
      "SEED: 9, FOLD: 0, EPOCH: 1,train_loss: 0.021114281081743, valid_loss: 0.01909351274371147\n",
      "SEED: 9, FOLD: 0, EPOCH: 2,train_loss: 0.019159242011390736, valid_loss: 0.018115269738648618\n",
      "SEED: 9, FOLD: 0, EPOCH: 3,train_loss: 0.018466797286131674, valid_loss: 0.017844368011823722\n",
      "SEED: 9, FOLD: 0, EPOCH: 4,train_loss: 0.018034635732571285, valid_loss: 0.017753835208714007\n",
      "SEED: 9, FOLD: 0, EPOCH: 5,train_loss: 0.017885492271001356, valid_loss: 0.017699944068278586\n",
      "SEED: 9, FOLD: 0, EPOCH: 6,train_loss: 0.01791863014543618, valid_loss: 0.017717418766447477\n",
      "SEED: 9, FOLD: 0, EPOCH: 7,train_loss: 0.017977177138453808, valid_loss: 0.017870407471699375\n",
      "SEED: 9, FOLD: 0, EPOCH: 8,train_loss: 0.017891418384523062, valid_loss: 0.017741745923246656\n",
      "SEED: 9, FOLD: 0, EPOCH: 9,train_loss: 0.017883031912471935, valid_loss: 0.01767448740346091\n",
      "SEED: 9, FOLD: 0, EPOCH: 10,train_loss: 0.01784084796014687, valid_loss: 0.01764935428010566\n",
      "SEED: 9, FOLD: 0, EPOCH: 11,train_loss: 0.017802727273732857, valid_loss: 0.017465200913803918\n",
      "SEED: 9, FOLD: 0, EPOCH: 12,train_loss: 0.01768185043086608, valid_loss: 0.017651980157409396\n",
      "SEED: 9, FOLD: 0, EPOCH: 13,train_loss: 0.017670095790231575, valid_loss: 0.017563178203999996\n",
      "SEED: 9, FOLD: 0, EPOCH: 14,train_loss: 0.01754368010206499, valid_loss: 0.01767435749726636\n",
      "SEED: 9, FOLD: 0, EPOCH: 15,train_loss: 0.017412191985741905, valid_loss: 0.017563996064875808\n",
      "SEED: 9, FOLD: 0, EPOCH: 16,train_loss: 0.017248101977874405, valid_loss: 0.0174115746148995\n",
      "SEED: 9, FOLD: 0, EPOCH: 17,train_loss: 0.017051780974303467, valid_loss: 0.01728862931153604\n",
      "SEED: 9, FOLD: 0, EPOCH: 18,train_loss: 0.016709987985213167, valid_loss: 0.01717847205166306\n",
      "SEED: 9, FOLD: 0, EPOCH: 19,train_loss: 0.016386613108055746, valid_loss: 0.017211220200572697\n",
      "SEED: 9, FOLD: 0, EPOCH: 20,train_loss: 0.01601965280006761, valid_loss: 0.01718473093850272\n",
      "SEED: 9, FOLD: 0, EPOCH: 21,train_loss: 0.015538167869807154, valid_loss: 0.017222302061106476\n",
      "SEED: 9, FOLD: 0, EPOCH: 22,train_loss: 0.015065693944368673, valid_loss: 0.01719688908862216\n",
      "SEED: 9, FOLD: 0, EPOCH: 23,train_loss: 0.014652044188393198, valid_loss: 0.017156599940998215\n",
      "SEED: 9, FOLD: 0, EPOCH: 24,train_loss: 0.014404105825646631, valid_loss: 0.017143639203693186\n",
      "(17531, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7358161332833506, valid_loss: 0.7041864378111703\n",
      "SEED: 9, FOLD: 1, EPOCH: 0,train_loss: 0.46666324108730267, valid_loss: 0.02390936245875699\n",
      "SEED: 9, FOLD: 1, EPOCH: 1,train_loss: 0.020680852003232407, valid_loss: 0.01888182642204421\n",
      "SEED: 9, FOLD: 1, EPOCH: 2,train_loss: 0.018939955499920533, valid_loss: 0.018063177620725974\n",
      "SEED: 9, FOLD: 1, EPOCH: 3,train_loss: 0.018369645430930774, valid_loss: 0.01812087031347411\n",
      "SEED: 9, FOLD: 1, EPOCH: 4,train_loss: 0.018046927964654718, valid_loss: 0.017875710103128637\n",
      "SEED: 9, FOLD: 1, EPOCH: 5,train_loss: 0.01788362771626154, valid_loss: 0.017829584915723118\n",
      "SEED: 9, FOLD: 1, EPOCH: 6,train_loss: 0.017889537433855726, valid_loss: 0.01777718870767525\n",
      "SEED: 9, FOLD: 1, EPOCH: 7,train_loss: 0.01791137293742521, valid_loss: 0.018491411954164504\n",
      "SEED: 9, FOLD: 1, EPOCH: 8,train_loss: 0.01789367638773074, valid_loss: 0.018143810225384575\n",
      "SEED: 9, FOLD: 1, EPOCH: 9,train_loss: 0.01787387173160584, valid_loss: 0.017810327745974065\n",
      "SEED: 9, FOLD: 1, EPOCH: 10,train_loss: 0.017844006256030425, valid_loss: 0.017756125197878905\n",
      "SEED: 9, FOLD: 1, EPOCH: 11,train_loss: 0.017789296126061113, valid_loss: 0.017708386959774152\n",
      "SEED: 9, FOLD: 1, EPOCH: 12,train_loss: 0.017767883776041278, valid_loss: 0.01761197466403246\n",
      "SEED: 9, FOLD: 1, EPOCH: 13,train_loss: 0.017602799242756664, valid_loss: 0.017585049755871295\n",
      "SEED: 9, FOLD: 1, EPOCH: 14,train_loss: 0.017479766126259837, valid_loss: 0.017822032900793212\n",
      "SEED: 9, FOLD: 1, EPOCH: 15,train_loss: 0.017402689264964882, valid_loss: 0.017430506540196282\n",
      "SEED: 9, FOLD: 1, EPOCH: 16,train_loss: 0.017154494728757082, valid_loss: 0.017508678909923348\n",
      "SEED: 9, FOLD: 1, EPOCH: 17,train_loss: 0.01693765524720406, valid_loss: 0.017287692507462843\n",
      "SEED: 9, FOLD: 1, EPOCH: 18,train_loss: 0.016628825343655843, valid_loss: 0.0174291979521513\n",
      "SEED: 9, FOLD: 1, EPOCH: 19,train_loss: 0.016310683009724547, valid_loss: 0.017212382145226003\n",
      "SEED: 9, FOLD: 1, EPOCH: 20,train_loss: 0.015879121880951155, valid_loss: 0.017397860464240824\n",
      "SEED: 9, FOLD: 1, EPOCH: 21,train_loss: 0.015396644177771833, valid_loss: 0.017305397668055125\n",
      "SEED: 9, FOLD: 1, EPOCH: 22,train_loss: 0.01490296740220846, valid_loss: 0.017285222959305558\n",
      "SEED: 9, FOLD: 1, EPOCH: 23,train_loss: 0.014411132123294102, valid_loss: 0.017256429844668932\n",
      "SEED: 9, FOLD: 1, EPOCH: 24,train_loss: 0.01418920791959458, valid_loss: 0.017249776422977446\n",
      "(17558, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7356605935787809, valid_loss: 0.7054235458374023\n",
      "SEED: 9, FOLD: 2, EPOCH: 0,train_loss: 0.46604358412973257, valid_loss: 0.023776520629014287\n",
      "SEED: 9, FOLD: 2, EPOCH: 1,train_loss: 0.020923459834918594, valid_loss: 0.01952389505292688\n",
      "SEED: 9, FOLD: 2, EPOCH: 2,train_loss: 0.019016744487959404, valid_loss: 0.01827780774661473\n",
      "SEED: 9, FOLD: 2, EPOCH: 3,train_loss: 0.018176455745824438, valid_loss: 0.018288642061608178\n",
      "SEED: 9, FOLD: 2, EPOCH: 4,train_loss: 0.018064778230652428, valid_loss: 0.0186493594199419\n",
      "SEED: 9, FOLD: 2, EPOCH: 5,train_loss: 0.018058701053909634, valid_loss: 0.01823888724403722\n",
      "SEED: 9, FOLD: 2, EPOCH: 6,train_loss: 0.017968800580264, valid_loss: 0.018131016993096896\n",
      "SEED: 9, FOLD: 2, EPOCH: 7,train_loss: 0.017947564144497333, valid_loss: 0.01810046788305044\n",
      "SEED: 9, FOLD: 2, EPOCH: 8,train_loss: 0.01794922723016445, valid_loss: 0.018090213648974895\n",
      "SEED: 9, FOLD: 2, EPOCH: 9,train_loss: 0.017877869442969128, valid_loss: 0.01788218306111438\n",
      "SEED: 9, FOLD: 2, EPOCH: 10,train_loss: 0.017908007844580687, valid_loss: 0.01798448748886585\n",
      "SEED: 9, FOLD: 2, EPOCH: 11,train_loss: 0.01784710905285201, valid_loss: 0.01825215169893844\n",
      "SEED: 9, FOLD: 2, EPOCH: 12,train_loss: 0.017815641006049904, valid_loss: 0.017674119850354535\n",
      "SEED: 9, FOLD: 2, EPOCH: 13,train_loss: 0.01765360162201999, valid_loss: 0.01775617870901312\n",
      "SEED: 9, FOLD: 2, EPOCH: 14,train_loss: 0.01759215523286358, valid_loss: 0.01738637246723686\n",
      "SEED: 9, FOLD: 2, EPOCH: 15,train_loss: 0.017393890214894993, valid_loss: 0.017403570243290492\n",
      "SEED: 9, FOLD: 2, EPOCH: 16,train_loss: 0.01723751646426061, valid_loss: 0.017471587684537684\n",
      "SEED: 9, FOLD: 2, EPOCH: 17,train_loss: 0.016993256920165775, valid_loss: 0.017455653686608587\n",
      "SEED: 9, FOLD: 2, EPOCH: 18,train_loss: 0.016793022141454443, valid_loss: 0.01741010948483433\n",
      "SEED: 9, FOLD: 2, EPOCH: 19,train_loss: 0.01646154193693529, valid_loss: 0.017230966500937937\n",
      "SEED: 9, FOLD: 2, EPOCH: 20,train_loss: 0.01603043875724509, valid_loss: 0.01731662516083036\n",
      "SEED: 9, FOLD: 2, EPOCH: 21,train_loss: 0.01560607808979525, valid_loss: 0.01706944757274219\n",
      "SEED: 9, FOLD: 2, EPOCH: 22,train_loss: 0.015143916820702345, valid_loss: 0.01708602782871042\n",
      "SEED: 9, FOLD: 2, EPOCH: 23,train_loss: 0.014796733377042456, valid_loss: 0.01709021119666951\n",
      "SEED: 9, FOLD: 2, EPOCH: 24,train_loss: 0.014580165434196808, valid_loss: 0.017098793014883994\n",
      "(17600, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7355350182540175, valid_loss: 0.7054894215920392\n",
      "SEED: 9, FOLD: 3, EPOCH: 0,train_loss: 0.46700347731888725, valid_loss: 0.023902732440653968\n",
      "SEED: 9, FOLD: 3, EPOCH: 1,train_loss: 0.02074639894662128, valid_loss: 0.020104784354129258\n",
      "SEED: 9, FOLD: 3, EPOCH: 2,train_loss: 0.01892892575647304, valid_loss: 0.018407285651739907\n",
      "SEED: 9, FOLD: 3, EPOCH: 3,train_loss: 0.01815362915099747, valid_loss: 0.01875769253820181\n",
      "SEED: 9, FOLD: 3, EPOCH: 4,train_loss: 0.01791221408875308, valid_loss: 0.018091350574703777\n",
      "SEED: 9, FOLD: 3, EPOCH: 5,train_loss: 0.017814873366792133, valid_loss: 0.01815268145326306\n",
      "SEED: 9, FOLD: 3, EPOCH: 6,train_loss: 0.01781581960402537, valid_loss: 0.01849272014463649\n",
      "SEED: 9, FOLD: 3, EPOCH: 7,train_loss: 0.01786263435539128, valid_loss: 0.01818380658240879\n",
      "SEED: 9, FOLD: 3, EPOCH: 8,train_loss: 0.01788620940962995, valid_loss: 0.01859221640316879\n",
      "SEED: 9, FOLD: 3, EPOCH: 9,train_loss: 0.01786451629511472, valid_loss: 0.018370521473972237\n",
      "SEED: 9, FOLD: 3, EPOCH: 10,train_loss: 0.01778704815449706, valid_loss: 0.01827460971167859\n",
      "SEED: 9, FOLD: 3, EPOCH: 11,train_loss: 0.017731770198198334, valid_loss: 0.018022037001655382\n",
      "SEED: 9, FOLD: 3, EPOCH: 12,train_loss: 0.01763854987676377, valid_loss: 0.017978598719791454\n",
      "SEED: 9, FOLD: 3, EPOCH: 13,train_loss: 0.017599352966130213, valid_loss: 0.01812955895986627\n",
      "SEED: 9, FOLD: 3, EPOCH: 14,train_loss: 0.017506248418889616, valid_loss: 0.018058714758166495\n",
      "SEED: 9, FOLD: 3, EPOCH: 15,train_loss: 0.017323795010916132, valid_loss: 0.017713537028826335\n",
      "SEED: 9, FOLD: 3, EPOCH: 16,train_loss: 0.01718047834203943, valid_loss: 0.01781874108950005\n",
      "SEED: 9, FOLD: 3, EPOCH: 17,train_loss: 0.016943439402604017, valid_loss: 0.017575970303048107\n",
      "SEED: 9, FOLD: 3, EPOCH: 18,train_loss: 0.0166978409068416, valid_loss: 0.017712223946171647\n",
      "SEED: 9, FOLD: 3, EPOCH: 19,train_loss: 0.01637177606639655, valid_loss: 0.017503749305272803\n",
      "SEED: 9, FOLD: 3, EPOCH: 20,train_loss: 0.015955751471599375, valid_loss: 0.01742281825007761\n",
      "SEED: 9, FOLD: 3, EPOCH: 21,train_loss: 0.015515814805268377, valid_loss: 0.017435187419109485\n",
      "SEED: 9, FOLD: 3, EPOCH: 22,train_loss: 0.015057030100159454, valid_loss: 0.017412638866945225\n",
      "SEED: 9, FOLD: 3, EPOCH: 23,train_loss: 0.014674988042131283, valid_loss: 0.017377526828033084\n",
      "SEED: 9, FOLD: 3, EPOCH: 24,train_loss: 0.014479389360201532, valid_loss: 0.017374808133086738\n",
      "(17527, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7359882567050683, valid_loss: 0.7038859571729388\n",
      "SEED: 9, FOLD: 4, EPOCH: 0,train_loss: 0.46754662165023986, valid_loss: 0.02387246558708804\n",
      "SEED: 9, FOLD: 4, EPOCH: 1,train_loss: 0.02089734775197767, valid_loss: 0.01861545933144433\n",
      "SEED: 9, FOLD: 4, EPOCH: 2,train_loss: 0.019001664675391505, valid_loss: 0.017912537711007256\n",
      "SEED: 9, FOLD: 4, EPOCH: 3,train_loss: 0.018173194979827334, valid_loss: 0.018061645116124833\n",
      "SEED: 9, FOLD: 4, EPOCH: 4,train_loss: 0.01793284895727887, valid_loss: 0.017745101398655348\n",
      "SEED: 9, FOLD: 4, EPOCH: 5,train_loss: 0.018004157097779052, valid_loss: 0.018434607290795872\n",
      "SEED: 9, FOLD: 4, EPOCH: 6,train_loss: 0.017931406236641162, valid_loss: 0.017809598413961274\n",
      "SEED: 9, FOLD: 4, EPOCH: 7,train_loss: 0.017948531348557367, valid_loss: 0.017772748959915978\n",
      "SEED: 9, FOLD: 4, EPOCH: 8,train_loss: 0.017987700573501797, valid_loss: 0.017549627859677588\n",
      "SEED: 9, FOLD: 4, EPOCH: 9,train_loss: 0.017893982527736763, valid_loss: 0.017852790227958135\n",
      "SEED: 9, FOLD: 4, EPOCH: 10,train_loss: 0.01788204080377617, valid_loss: 0.017874670906790666\n",
      "SEED: 9, FOLD: 4, EPOCH: 11,train_loss: 0.017784635624746338, valid_loss: 0.01772693661706788\n",
      "SEED: 9, FOLD: 4, EPOCH: 12,train_loss: 0.017743310027749, valid_loss: 0.017611489125660486\n",
      "SEED: 9, FOLD: 4, EPOCH: 13,train_loss: 0.017622032454305322, valid_loss: 0.01738511584699154\n",
      "SEED: 9, FOLD: 4, EPOCH: 14,train_loss: 0.017560706671028242, valid_loss: 0.017356291679399356\n",
      "SEED: 9, FOLD: 4, EPOCH: 15,train_loss: 0.017355081543707063, valid_loss: 0.017283136557255472\n",
      "SEED: 9, FOLD: 4, EPOCH: 16,train_loss: 0.017168307826466805, valid_loss: 0.017494946691606728\n",
      "SEED: 9, FOLD: 4, EPOCH: 17,train_loss: 0.016930574027780632, valid_loss: 0.01724289876541921\n",
      "SEED: 9, FOLD: 4, EPOCH: 18,train_loss: 0.01670024399203758, valid_loss: 0.017406129597553183\n",
      "SEED: 9, FOLD: 4, EPOCH: 19,train_loss: 0.016346810154453682, valid_loss: 0.01714829688093492\n",
      "SEED: 9, FOLD: 4, EPOCH: 20,train_loss: 0.01592348401781416, valid_loss: 0.017077711038291456\n",
      "SEED: 9, FOLD: 4, EPOCH: 21,train_loss: 0.01547427854779428, valid_loss: 0.017070113867521285\n",
      "SEED: 9, FOLD: 4, EPOCH: 22,train_loss: 0.014972459857970693, valid_loss: 0.01699481223310743\n",
      "SEED: 9, FOLD: 4, EPOCH: 23,train_loss: 0.014540166342563002, valid_loss: 0.01699764858931303\n",
      "SEED: 9, FOLD: 4, EPOCH: 24,train_loss: 0.014312040910505466, valid_loss: 0.016988281799214227\n",
      "(17607, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7343962123428566, valid_loss: 0.705938491751166\n",
      "SEED: 10, FOLD: 0, EPOCH: 0,train_loss: 0.46561857505930937, valid_loss: 0.024167122812393832\n",
      "SEED: 10, FOLD: 0, EPOCH: 1,train_loss: 0.020874872736200905, valid_loss: 0.01905787139035323\n",
      "SEED: 10, FOLD: 0, EPOCH: 2,train_loss: 0.01881040385721818, valid_loss: 0.018581659889177364\n",
      "SEED: 10, FOLD: 0, EPOCH: 3,train_loss: 0.018553014979630276, valid_loss: 0.018349851865102264\n",
      "SEED: 10, FOLD: 0, EPOCH: 4,train_loss: 0.018002453786523445, valid_loss: 0.018218425650368717\n",
      "SEED: 10, FOLD: 0, EPOCH: 5,train_loss: 0.0179491447136346, valid_loss: 0.018255991039468962\n",
      "SEED: 10, FOLD: 0, EPOCH: 6,train_loss: 0.01789237672894977, valid_loss: 0.018288152073236072\n",
      "SEED: 10, FOLD: 0, EPOCH: 7,train_loss: 0.01788820071901748, valid_loss: 0.018406403908396467\n",
      "SEED: 10, FOLD: 0, EPOCH: 8,train_loss: 0.017840817422214626, valid_loss: 0.018169349388164634\n",
      "SEED: 10, FOLD: 0, EPOCH: 9,train_loss: 0.017821915852634804, valid_loss: 0.018246626727940404\n",
      "SEED: 10, FOLD: 0, EPOCH: 10,train_loss: 0.017783468865883955, valid_loss: 0.01843576308558969\n",
      "SEED: 10, FOLD: 0, EPOCH: 11,train_loss: 0.017752264660067747, valid_loss: 0.018031350117834175\n",
      "SEED: 10, FOLD: 0, EPOCH: 12,train_loss: 0.017655650693653286, valid_loss: 0.017883459188263204\n",
      "SEED: 10, FOLD: 0, EPOCH: 13,train_loss: 0.017562957534539528, valid_loss: 0.017937647507471198\n",
      "SEED: 10, FOLD: 0, EPOCH: 14,train_loss: 0.017384805325148762, valid_loss: 0.018145238542381453\n",
      "SEED: 10, FOLD: 0, EPOCH: 15,train_loss: 0.01730097664952062, valid_loss: 0.017719850108465728\n",
      "SEED: 10, FOLD: 0, EPOCH: 16,train_loss: 0.017069379367150257, valid_loss: 0.01777305029442205\n",
      "SEED: 10, FOLD: 0, EPOCH: 17,train_loss: 0.016855178441366424, valid_loss: 0.017706402550067973\n",
      "SEED: 10, FOLD: 0, EPOCH: 18,train_loss: 0.0165763383636764, valid_loss: 0.017616293228724423\n",
      "SEED: 10, FOLD: 0, EPOCH: 19,train_loss: 0.0161865651405052, valid_loss: 0.017555299625896355\n",
      "SEED: 10, FOLD: 0, EPOCH: 20,train_loss: 0.015780891635981592, valid_loss: 0.017489724299486947\n",
      "SEED: 10, FOLD: 0, EPOCH: 21,train_loss: 0.015320291546969742, valid_loss: 0.017551915966631734\n",
      "SEED: 10, FOLD: 0, EPOCH: 22,train_loss: 0.014818399287490309, valid_loss: 0.01759882364422083\n",
      "SEED: 10, FOLD: 0, EPOCH: 23,train_loss: 0.014388981106542591, valid_loss: 0.01755522643489873\n",
      "SEED: 10, FOLD: 0, EPOCH: 24,train_loss: 0.014135892853896687, valid_loss: 0.017546562669689163\n",
      "(17453, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7344255699728527, valid_loss: 0.7015954454739889\n",
      "SEED: 10, FOLD: 1, EPOCH: 0,train_loss: 0.4674730705110914, valid_loss: 0.023810804821550846\n",
      "SEED: 10, FOLD: 1, EPOCH: 1,train_loss: 0.020838306958440446, valid_loss: 0.02111424955849846\n",
      "SEED: 10, FOLD: 1, EPOCH: 2,train_loss: 0.019126932197896233, valid_loss: 0.0182395633827481\n",
      "SEED: 10, FOLD: 1, EPOCH: 3,train_loss: 0.018308958562131782, valid_loss: 0.017955297474852867\n",
      "SEED: 10, FOLD: 1, EPOCH: 4,train_loss: 0.017975982693261908, valid_loss: 0.01813911080049972\n",
      "SEED: 10, FOLD: 1, EPOCH: 5,train_loss: 0.017924884415782282, valid_loss: 0.017849756870418787\n",
      "SEED: 10, FOLD: 1, EPOCH: 6,train_loss: 0.017953766652648032, valid_loss: 0.018132564844563603\n",
      "SEED: 10, FOLD: 1, EPOCH: 7,train_loss: 0.01792772693464356, valid_loss: 0.017715589712477393\n",
      "SEED: 10, FOLD: 1, EPOCH: 8,train_loss: 0.01793656087596051, valid_loss: 0.01763644356591006\n",
      "SEED: 10, FOLD: 1, EPOCH: 9,train_loss: 0.017906042842371184, valid_loss: 0.017867775866761804\n",
      "SEED: 10, FOLD: 1, EPOCH: 10,train_loss: 0.01783097181197283, valid_loss: 0.017631194114478096\n",
      "SEED: 10, FOLD: 1, EPOCH: 11,train_loss: 0.017823747583549387, valid_loss: 0.017928957525226805\n",
      "SEED: 10, FOLD: 1, EPOCH: 12,train_loss: 0.01776835258479101, valid_loss: 0.01772526736992101\n",
      "SEED: 10, FOLD: 1, EPOCH: 13,train_loss: 0.017641000442859465, valid_loss: 0.017639809106994007\n",
      "SEED: 10, FOLD: 1, EPOCH: 14,train_loss: 0.01753807681728236, valid_loss: 0.017716727012561426\n",
      "SEED: 10, FOLD: 1, EPOCH: 15,train_loss: 0.01740114751142742, valid_loss: 0.017705282946634624\n",
      "SEED: 10, FOLD: 1, EPOCH: 16,train_loss: 0.017225753223645862, valid_loss: 0.01732810917827818\n",
      "SEED: 10, FOLD: 1, EPOCH: 17,train_loss: 0.016980474665217155, valid_loss: 0.01728245194277002\n",
      "SEED: 10, FOLD: 1, EPOCH: 18,train_loss: 0.01674833095013878, valid_loss: 0.01719891968079739\n",
      "SEED: 10, FOLD: 1, EPOCH: 19,train_loss: 0.01633586545549605, valid_loss: 0.017156554696460564\n",
      "SEED: 10, FOLD: 1, EPOCH: 20,train_loss: 0.015936893145859676, valid_loss: 0.01709645003494289\n",
      "SEED: 10, FOLD: 1, EPOCH: 21,train_loss: 0.015522425566004576, valid_loss: 0.017027908651572134\n",
      "SEED: 10, FOLD: 1, EPOCH: 22,train_loss: 0.014998182477633449, valid_loss: 0.01702615199610591\n",
      "SEED: 10, FOLD: 1, EPOCH: 23,train_loss: 0.014584087521979844, valid_loss: 0.017062773669345513\n",
      "SEED: 10, FOLD: 1, EPOCH: 24,train_loss: 0.014360890125543096, valid_loss: 0.01704395277839568\n",
      "(17567, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.73437733710676, valid_loss: 0.7034176536968776\n",
      "SEED: 10, FOLD: 2, EPOCH: 0,train_loss: 0.4670697548089252, valid_loss: 0.0234522887638637\n",
      "SEED: 10, FOLD: 2, EPOCH: 1,train_loss: 0.020741295636348103, valid_loss: 0.019961985040988242\n",
      "SEED: 10, FOLD: 2, EPOCH: 2,train_loss: 0.01916452931861083, valid_loss: 0.018214564930115428\n",
      "SEED: 10, FOLD: 2, EPOCH: 3,train_loss: 0.018399888798054577, valid_loss: 0.01831855486546244\n",
      "SEED: 10, FOLD: 2, EPOCH: 4,train_loss: 0.017998572783139738, valid_loss: 0.01824144183525017\n",
      "SEED: 10, FOLD: 2, EPOCH: 5,train_loss: 0.017967535581007815, valid_loss: 0.018484942242503168\n",
      "SEED: 10, FOLD: 2, EPOCH: 6,train_loss: 0.01787610841995996, valid_loss: 0.017967564719063894\n",
      "SEED: 10, FOLD: 2, EPOCH: 7,train_loss: 0.017926689952719902, valid_loss: 0.017995349424225943\n",
      "SEED: 10, FOLD: 2, EPOCH: 8,train_loss: 0.01787588297240976, valid_loss: 0.018643431471926826\n",
      "SEED: 10, FOLD: 2, EPOCH: 9,train_loss: 0.017966085154077282, valid_loss: 0.01776360065809318\n",
      "SEED: 10, FOLD: 2, EPOCH: 10,train_loss: 0.017791267767872498, valid_loss: 0.018011668590562684\n",
      "SEED: 10, FOLD: 2, EPOCH: 11,train_loss: 0.01774002587341744, valid_loss: 0.017988731286355426\n",
      "SEED: 10, FOLD: 2, EPOCH: 12,train_loss: 0.0177206720792405, valid_loss: 0.017815785722008773\n",
      "SEED: 10, FOLD: 2, EPOCH: 13,train_loss: 0.017616165457698313, valid_loss: 0.017606535527322973\n",
      "SEED: 10, FOLD: 2, EPOCH: 14,train_loss: 0.01749045657587872, valid_loss: 0.017745077264096056\n",
      "SEED: 10, FOLD: 2, EPOCH: 15,train_loss: 0.017329284421883633, valid_loss: 0.01756968429046018\n",
      "SEED: 10, FOLD: 2, EPOCH: 16,train_loss: 0.01715597812005359, valid_loss: 0.017515976806836468\n",
      "SEED: 10, FOLD: 2, EPOCH: 17,train_loss: 0.016889242165168558, valid_loss: 0.017353561813277858\n",
      "SEED: 10, FOLD: 2, EPOCH: 18,train_loss: 0.016593470076180023, valid_loss: 0.01742045788892678\n",
      "SEED: 10, FOLD: 2, EPOCH: 19,train_loss: 0.016252296214140413, valid_loss: 0.01731821508812053\n",
      "SEED: 10, FOLD: 2, EPOCH: 20,train_loss: 0.01582454016054238, valid_loss: 0.017442273215523788\n",
      "SEED: 10, FOLD: 2, EPOCH: 21,train_loss: 0.015331716944827982, valid_loss: 0.01733723022043705\n",
      "SEED: 10, FOLD: 2, EPOCH: 22,train_loss: 0.01485631762045449, valid_loss: 0.017374337118651186\n",
      "SEED: 10, FOLD: 2, EPOCH: 23,train_loss: 0.014385636619197718, valid_loss: 0.01740743906370231\n",
      "SEED: 10, FOLD: 2, EPOCH: 24,train_loss: 0.01415738868324653, valid_loss: 0.01737748472286122\n",
      "(17588, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7345363152199897, valid_loss: 0.7004985553877694\n",
      "SEED: 10, FOLD: 3, EPOCH: 0,train_loss: 0.46632910120314447, valid_loss: 0.02421454308288438\n",
      "SEED: 10, FOLD: 3, EPOCH: 1,train_loss: 0.020867939808986324, valid_loss: 0.01868953529213156\n",
      "SEED: 10, FOLD: 3, EPOCH: 2,train_loss: 0.019108820585129055, valid_loss: 0.018585966527462007\n",
      "SEED: 10, FOLD: 3, EPOCH: 3,train_loss: 0.018390138134144356, valid_loss: 0.017878062331250735\n",
      "SEED: 10, FOLD: 3, EPOCH: 4,train_loss: 0.018111677563654772, valid_loss: 0.017981142976454326\n",
      "SEED: 10, FOLD: 3, EPOCH: 5,train_loss: 0.017908974597905424, valid_loss: 0.017771655933133193\n",
      "SEED: 10, FOLD: 3, EPOCH: 6,train_loss: 0.017888812179528715, valid_loss: 0.017873358513627733\n",
      "SEED: 10, FOLD: 3, EPOCH: 7,train_loss: 0.017969616560562365, valid_loss: 0.018557784812791005\n",
      "SEED: 10, FOLD: 3, EPOCH: 8,train_loss: 0.017945950088239668, valid_loss: 0.017792613857558797\n",
      "SEED: 10, FOLD: 3, EPOCH: 9,train_loss: 0.017917726620815803, valid_loss: 0.018225814082792828\n",
      "SEED: 10, FOLD: 3, EPOCH: 10,train_loss: 0.01784488334711911, valid_loss: 0.01776094420679978\n",
      "SEED: 10, FOLD: 3, EPOCH: 11,train_loss: 0.017781088290655094, valid_loss: 0.017827547980206353\n",
      "SEED: 10, FOLD: 3, EPOCH: 12,train_loss: 0.017789821572385837, valid_loss: 0.017853973912341253\n",
      "SEED: 10, FOLD: 3, EPOCH: 13,train_loss: 0.017651831731200218, valid_loss: 0.01754309202411345\n",
      "SEED: 10, FOLD: 3, EPOCH: 14,train_loss: 0.017514538215608267, valid_loss: 0.01761544926890305\n",
      "SEED: 10, FOLD: 3, EPOCH: 15,train_loss: 0.017418481598513714, valid_loss: 0.017574138593460832\n",
      "SEED: 10, FOLD: 3, EPOCH: 16,train_loss: 0.017169497853171997, valid_loss: 0.017411745366241252\n",
      "SEED: 10, FOLD: 3, EPOCH: 17,train_loss: 0.01696602766658517, valid_loss: 0.017367916660649435\n",
      "SEED: 10, FOLD: 3, EPOCH: 18,train_loss: 0.01674507590064752, valid_loss: 0.017161839694849083\n",
      "SEED: 10, FOLD: 3, EPOCH: 19,train_loss: 0.016352487835979115, valid_loss: 0.017138472864670413\n",
      "SEED: 10, FOLD: 3, EPOCH: 20,train_loss: 0.015935265243161415, valid_loss: 0.017006834942315308\n",
      "SEED: 10, FOLD: 3, EPOCH: 21,train_loss: 0.01548062734629797, valid_loss: 0.017028621690613883\n",
      "SEED: 10, FOLD: 3, EPOCH: 22,train_loss: 0.014976106415354256, valid_loss: 0.017097033879586627\n",
      "SEED: 10, FOLD: 3, EPOCH: 23,train_loss: 0.014494191544751326, valid_loss: 0.017016745012785706\n",
      "SEED: 10, FOLD: 3, EPOCH: 24,train_loss: 0.0142787531139734, valid_loss: 0.017039889230259828\n",
      "(17577, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7347601989041204, valid_loss: 0.7042381746428353\n",
      "SEED: 10, FOLD: 4, EPOCH: 0,train_loss: 0.4667854841420616, valid_loss: 0.025331680849194526\n",
      "SEED: 10, FOLD: 4, EPOCH: 1,train_loss: 0.02087095844140951, valid_loss: 0.019119051125432763\n",
      "SEED: 10, FOLD: 4, EPOCH: 2,train_loss: 0.018943929788319096, valid_loss: 0.018319265517805303\n",
      "SEED: 10, FOLD: 4, EPOCH: 3,train_loss: 0.018294516363707575, valid_loss: 0.01805455431874309\n",
      "SEED: 10, FOLD: 4, EPOCH: 4,train_loss: 0.01792522403749003, valid_loss: 0.018530812726489137\n",
      "SEED: 10, FOLD: 4, EPOCH: 5,train_loss: 0.017909180528173845, valid_loss: 0.01828645920114858\n",
      "SEED: 10, FOLD: 4, EPOCH: 6,train_loss: 0.01795441460242306, valid_loss: 0.01772728149912187\n",
      "SEED: 10, FOLD: 4, EPOCH: 7,train_loss: 0.01793698601397699, valid_loss: 0.017873064721269268\n",
      "SEED: 10, FOLD: 4, EPOCH: 8,train_loss: 0.017955026521846867, valid_loss: 0.018284798174032144\n",
      "SEED: 10, FOLD: 4, EPOCH: 9,train_loss: 0.017888097052016983, valid_loss: 0.01820527889898845\n",
      "SEED: 10, FOLD: 4, EPOCH: 10,train_loss: 0.01785398469697954, valid_loss: 0.017859198738421712\n",
      "SEED: 10, FOLD: 4, EPOCH: 11,train_loss: 0.017828214508683785, valid_loss: 0.0178724683289017\n",
      "SEED: 10, FOLD: 4, EPOCH: 12,train_loss: 0.01778074992361708, valid_loss: 0.01807829202818019\n",
      "SEED: 10, FOLD: 4, EPOCH: 13,train_loss: 0.017705745205445135, valid_loss: 0.017688467566456114\n",
      "SEED: 10, FOLD: 4, EPOCH: 14,train_loss: 0.017498140155837155, valid_loss: 0.017582347137587412\n",
      "SEED: 10, FOLD: 4, EPOCH: 15,train_loss: 0.017345987712505503, valid_loss: 0.017777148447930814\n",
      "SEED: 10, FOLD: 4, EPOCH: 16,train_loss: 0.017223567850347878, valid_loss: 0.017301657689469202\n",
      "SEED: 10, FOLD: 4, EPOCH: 17,train_loss: 0.016942275499088177, valid_loss: 0.017203001039368764\n",
      "SEED: 10, FOLD: 4, EPOCH: 18,train_loss: 0.01665959093530757, valid_loss: 0.0173445960772889\n",
      "SEED: 10, FOLD: 4, EPOCH: 19,train_loss: 0.016372745013053434, valid_loss: 0.017199270932802133\n",
      "SEED: 10, FOLD: 4, EPOCH: 20,train_loss: 0.015971686238881903, valid_loss: 0.017105151606457574\n",
      "SEED: 10, FOLD: 4, EPOCH: 21,train_loss: 0.01548301967103844, valid_loss: 0.01706530044653586\n",
      "SEED: 10, FOLD: 4, EPOCH: 22,train_loss: 0.015001429292116907, valid_loss: 0.017015422933868\n",
      "SEED: 10, FOLD: 4, EPOCH: 23,train_loss: 0.014562630236310803, valid_loss: 0.016969973540731837\n",
      "SEED: 10, FOLD: 4, EPOCH: 24,train_loss: 0.014332506056551052, valid_loss: 0.01696960013359785\n",
      "(17543, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7343289260415063, valid_loss: 0.6933776804379055\n",
      "SEED: 11, FOLD: 0, EPOCH: 0,train_loss: 0.46676036500898394, valid_loss: 0.0239938137786729\n",
      "SEED: 11, FOLD: 0, EPOCH: 1,train_loss: 0.020820588791284008, valid_loss: 0.022776083914296967\n",
      "SEED: 11, FOLD: 0, EPOCH: 2,train_loss: 0.019245001662900482, valid_loss: 0.018120573753757137\n",
      "SEED: 11, FOLD: 0, EPOCH: 3,train_loss: 0.018233077418383047, valid_loss: 0.018096898150231158\n",
      "SEED: 11, FOLD: 0, EPOCH: 4,train_loss: 0.017991258897751137, valid_loss: 0.018595739640295504\n",
      "SEED: 11, FOLD: 0, EPOCH: 5,train_loss: 0.017972362963347765, valid_loss: 0.017878428660333158\n",
      "SEED: 11, FOLD: 0, EPOCH: 6,train_loss: 0.017927076519075512, valid_loss: 0.01800433567592076\n",
      "SEED: 11, FOLD: 0, EPOCH: 7,train_loss: 0.017976808213237404, valid_loss: 0.018112278303929738\n",
      "SEED: 11, FOLD: 0, EPOCH: 8,train_loss: 0.0179853822927976, valid_loss: 0.018099751483116832\n",
      "SEED: 11, FOLD: 0, EPOCH: 9,train_loss: 0.0179310564181187, valid_loss: 0.017838003592831747\n",
      "SEED: 11, FOLD: 0, EPOCH: 10,train_loss: 0.01788662631145638, valid_loss: 0.017704918049275875\n",
      "SEED: 11, FOLD: 0, EPOCH: 11,train_loss: 0.017917964472502903, valid_loss: 0.017980701715818472\n",
      "SEED: 11, FOLD: 0, EPOCH: 12,train_loss: 0.017774607345083918, valid_loss: 0.01760112103074789\n",
      "SEED: 11, FOLD: 0, EPOCH: 13,train_loss: 0.017680385764148356, valid_loss: 0.01760336554476193\n",
      "SEED: 11, FOLD: 0, EPOCH: 14,train_loss: 0.01750468396568212, valid_loss: 0.017626791261136532\n",
      "SEED: 11, FOLD: 0, EPOCH: 15,train_loss: 0.01743590106944675, valid_loss: 0.0173904345237783\n",
      "SEED: 11, FOLD: 0, EPOCH: 16,train_loss: 0.017352269537261, valid_loss: 0.017502697663647787\n",
      "SEED: 11, FOLD: 0, EPOCH: 17,train_loss: 0.01705524438749189, valid_loss: 0.0172817913549287\n",
      "SEED: 11, FOLD: 0, EPOCH: 18,train_loss: 0.016689347177473963, valid_loss: 0.017633941849427563\n",
      "SEED: 11, FOLD: 0, EPOCH: 19,train_loss: 0.01653976537341225, valid_loss: 0.01722805808697428\n",
      "SEED: 11, FOLD: 0, EPOCH: 20,train_loss: 0.016136769104101088, valid_loss: 0.01712978431688888\n",
      "SEED: 11, FOLD: 0, EPOCH: 21,train_loss: 0.015649108715571354, valid_loss: 0.01706727743148804\n",
      "SEED: 11, FOLD: 0, EPOCH: 22,train_loss: 0.015206052685507399, valid_loss: 0.01703771472509418\n",
      "SEED: 11, FOLD: 0, EPOCH: 23,train_loss: 0.014793090583027704, valid_loss: 0.0170858162854399\n",
      "SEED: 11, FOLD: 0, EPOCH: 24,train_loss: 0.014617158342962679, valid_loss: 0.01704616772809199\n",
      "(17543, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7342153433440388, valid_loss: 0.6936715466635568\n",
      "SEED: 11, FOLD: 1, EPOCH: 0,train_loss: 0.46779149766687467, valid_loss: 0.024061765734638488\n",
      "SEED: 11, FOLD: 1, EPOCH: 1,train_loss: 0.02096874153484469, valid_loss: 0.018666162182177815\n",
      "SEED: 11, FOLD: 1, EPOCH: 2,train_loss: 0.018926264812656933, valid_loss: 0.025278903916478156\n",
      "SEED: 11, FOLD: 1, EPOCH: 3,train_loss: 0.018780301331771887, valid_loss: 0.018540335366768496\n",
      "SEED: 11, FOLD: 1, EPOCH: 4,train_loss: 0.01809875281068726, valid_loss: 0.017748089507222176\n",
      "SEED: 11, FOLD: 1, EPOCH: 5,train_loss: 0.01798224901996445, valid_loss: 0.01833789904734918\n",
      "SEED: 11, FOLD: 1, EPOCH: 6,train_loss: 0.018009511072296595, valid_loss: 0.01823570853365319\n",
      "SEED: 11, FOLD: 1, EPOCH: 7,train_loss: 0.01797998077708526, valid_loss: 0.01856042343590941\n",
      "SEED: 11, FOLD: 1, EPOCH: 8,train_loss: 0.017942077945917845, valid_loss: 0.01785203559058053\n",
      "SEED: 11, FOLD: 1, EPOCH: 9,train_loss: 0.018038895284838003, valid_loss: 0.0178790399272527\n",
      "SEED: 11, FOLD: 1, EPOCH: 10,train_loss: 0.017935418658822342, valid_loss: 0.01795775916959558\n",
      "SEED: 11, FOLD: 1, EPOCH: 11,train_loss: 0.01792699815300496, valid_loss: 0.017859728341656073\n",
      "SEED: 11, FOLD: 1, EPOCH: 12,train_loss: 0.01780477062245642, valid_loss: 0.017712697785879885\n",
      "SEED: 11, FOLD: 1, EPOCH: 13,train_loss: 0.017702127287191324, valid_loss: 0.01774080722991909\n",
      "SEED: 11, FOLD: 1, EPOCH: 14,train_loss: 0.017547669496549213, valid_loss: 0.01732983174068587\n",
      "SEED: 11, FOLD: 1, EPOCH: 15,train_loss: 0.01748574814637718, valid_loss: 0.017270339759332794\n",
      "SEED: 11, FOLD: 1, EPOCH: 16,train_loss: 0.017312769231426973, valid_loss: 0.017135548192475522\n",
      "SEED: 11, FOLD: 1, EPOCH: 17,train_loss: 0.01708051436783179, valid_loss: 0.01735226432127612\n",
      "SEED: 11, FOLD: 1, EPOCH: 18,train_loss: 0.016801323093797848, valid_loss: 0.01714708541652986\n",
      "SEED: 11, FOLD: 1, EPOCH: 19,train_loss: 0.016435526365387268, valid_loss: 0.01723360044083425\n",
      "SEED: 11, FOLD: 1, EPOCH: 20,train_loss: 0.016169999186219513, valid_loss: 0.017062495994780744\n",
      "SEED: 11, FOLD: 1, EPOCH: 21,train_loss: 0.015624666627010574, valid_loss: 0.0170209103929145\n",
      "SEED: 11, FOLD: 1, EPOCH: 22,train_loss: 0.015176113411460234, valid_loss: 0.017012694158724376\n",
      "SEED: 11, FOLD: 1, EPOCH: 23,train_loss: 0.014818736385770035, valid_loss: 0.01697720776179007\n",
      "SEED: 11, FOLD: 1, EPOCH: 24,train_loss: 0.014597541632373695, valid_loss: 0.016968016299818242\n",
      "(17611, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7338531237581501, valid_loss: 0.6947739352198208\n",
      "SEED: 11, FOLD: 2, EPOCH: 0,train_loss: 0.4663727025541922, valid_loss: 0.024052037638338172\n",
      "SEED: 11, FOLD: 2, EPOCH: 1,train_loss: 0.020768929245895233, valid_loss: 0.01916742533007089\n",
      "SEED: 11, FOLD: 2, EPOCH: 2,train_loss: 0.018851256375943405, valid_loss: 0.01833405438810587\n",
      "SEED: 11, FOLD: 2, EPOCH: 3,train_loss: 0.018226380709666704, valid_loss: 0.018573320744668737\n",
      "SEED: 11, FOLD: 2, EPOCH: 4,train_loss: 0.01793521492863479, valid_loss: 0.018708979272667098\n",
      "SEED: 11, FOLD: 2, EPOCH: 5,train_loss: 0.01791060160494585, valid_loss: 0.018245022990466916\n",
      "SEED: 11, FOLD: 2, EPOCH: 6,train_loss: 0.01794457842555383, valid_loss: 0.018471172435537857\n",
      "SEED: 11, FOLD: 2, EPOCH: 7,train_loss: 0.01795444952701961, valid_loss: 0.018148450947859707\n",
      "SEED: 11, FOLD: 2, EPOCH: 8,train_loss: 0.017916478378617245, valid_loss: 0.01841244665796266\n",
      "SEED: 11, FOLD: 2, EPOCH: 9,train_loss: 0.017898072711313547, valid_loss: 0.01808178553576855\n",
      "SEED: 11, FOLD: 2, EPOCH: 10,train_loss: 0.0178317046602783, valid_loss: 0.01814079421627171\n",
      "SEED: 11, FOLD: 2, EPOCH: 11,train_loss: 0.017749432211174913, valid_loss: 0.0179454740958617\n",
      "SEED: 11, FOLD: 2, EPOCH: 12,train_loss: 0.01772038525213366, valid_loss: 0.017862528644721296\n",
      "SEED: 11, FOLD: 2, EPOCH: 13,train_loss: 0.01764546674878701, valid_loss: 0.017842705498504287\n",
      "SEED: 11, FOLD: 2, EPOCH: 14,train_loss: 0.01751248044488223, valid_loss: 0.017732249545481277\n",
      "SEED: 11, FOLD: 2, EPOCH: 15,train_loss: 0.017386750243874132, valid_loss: 0.01771412244724\n",
      "SEED: 11, FOLD: 2, EPOCH: 16,train_loss: 0.017191807348011196, valid_loss: 0.017713618190849528\n",
      "SEED: 11, FOLD: 2, EPOCH: 17,train_loss: 0.01697238527940235, valid_loss: 0.017660066951066256\n",
      "SEED: 11, FOLD: 2, EPOCH: 18,train_loss: 0.0167193284150267, valid_loss: 0.017485140877611497\n",
      "SEED: 11, FOLD: 2, EPOCH: 19,train_loss: 0.016387951992236187, valid_loss: 0.017555032007615354\n",
      "SEED: 11, FOLD: 2, EPOCH: 20,train_loss: 0.016035341650949442, valid_loss: 0.017546081449836493\n",
      "SEED: 11, FOLD: 2, EPOCH: 21,train_loss: 0.015567127190044393, valid_loss: 0.017390008851447526\n",
      "SEED: 11, FOLD: 2, EPOCH: 22,train_loss: 0.015121588044786367, valid_loss: 0.01746735940961277\n",
      "SEED: 11, FOLD: 2, EPOCH: 23,train_loss: 0.014687908570403639, valid_loss: 0.017439059036619523\n",
      "SEED: 11, FOLD: 2, EPOCH: 24,train_loss: 0.014478681183865538, valid_loss: 0.017423613106503207\n",
      "(17565, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7341769851636195, valid_loss: 0.6964738590376718\n",
      "SEED: 11, FOLD: 3, EPOCH: 0,train_loss: 0.46748852457149304, valid_loss: 0.023791104980877466\n",
      "SEED: 11, FOLD: 3, EPOCH: 1,train_loss: 0.021294648016708485, valid_loss: 0.018988312727638654\n",
      "SEED: 11, FOLD: 3, EPOCH: 2,train_loss: 0.019009339069758636, valid_loss: 0.01855043705020632\n",
      "SEED: 11, FOLD: 3, EPOCH: 3,train_loss: 0.018446496485368065, valid_loss: 0.01855366283229419\n",
      "SEED: 11, FOLD: 3, EPOCH: 4,train_loss: 0.01786184862283045, valid_loss: 0.018654954699533325\n",
      "SEED: 11, FOLD: 3, EPOCH: 5,train_loss: 0.0179374602596289, valid_loss: 0.017971661500632764\n",
      "SEED: 11, FOLD: 3, EPOCH: 6,train_loss: 0.017797367620295372, valid_loss: 0.01780688940946545\n",
      "SEED: 11, FOLD: 3, EPOCH: 7,train_loss: 0.017853714356981756, valid_loss: 0.017740082927048206\n",
      "SEED: 11, FOLD: 3, EPOCH: 8,train_loss: 0.01783317644014091, valid_loss: 0.017735027761331627\n",
      "SEED: 11, FOLD: 3, EPOCH: 9,train_loss: 0.017830172303956057, valid_loss: 0.01772545145026275\n",
      "SEED: 11, FOLD: 3, EPOCH: 10,train_loss: 0.01774328733133017, valid_loss: 0.017680445765810352\n",
      "SEED: 11, FOLD: 3, EPOCH: 11,train_loss: 0.01769703281098518, valid_loss: 0.01755930097507579\n",
      "SEED: 11, FOLD: 3, EPOCH: 12,train_loss: 0.017693492887622637, valid_loss: 0.017650013736316136\n",
      "SEED: 11, FOLD: 3, EPOCH: 13,train_loss: 0.0176114277050331, valid_loss: 0.017679619656077453\n",
      "SEED: 11, FOLD: 3, EPOCH: 14,train_loss: 0.01741909712175096, valid_loss: 0.017669567625437463\n",
      "SEED: 11, FOLD: 3, EPOCH: 15,train_loss: 0.017231484537647255, valid_loss: 0.017579362887356963\n",
      "SEED: 11, FOLD: 3, EPOCH: 16,train_loss: 0.01706973667782934, valid_loss: 0.017484554728227002\n",
      "SEED: 11, FOLD: 3, EPOCH: 17,train_loss: 0.016863368390856878, valid_loss: 0.01734791046806744\n",
      "SEED: 11, FOLD: 3, EPOCH: 18,train_loss: 0.016614051886658737, valid_loss: 0.017469496013862745\n",
      "SEED: 11, FOLD: 3, EPOCH: 19,train_loss: 0.016212414909640083, valid_loss: 0.017202231075082508\n",
      "SEED: 11, FOLD: 3, EPOCH: 20,train_loss: 0.01578266200596008, valid_loss: 0.017353060096502303\n",
      "SEED: 11, FOLD: 3, EPOCH: 21,train_loss: 0.015301175982407902, valid_loss: 0.017273702738540512\n",
      "SEED: 11, FOLD: 3, EPOCH: 22,train_loss: 0.014752556623864, valid_loss: 0.017263913420694214\n",
      "SEED: 11, FOLD: 3, EPOCH: 23,train_loss: 0.014346178708786982, valid_loss: 0.017242459314210073\n",
      "SEED: 11, FOLD: 3, EPOCH: 24,train_loss: 0.014107931533531435, valid_loss: 0.017268298539732184\n",
      "(17530, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.73386922108866, valid_loss: 0.6960305060659137\n",
      "SEED: 11, FOLD: 4, EPOCH: 0,train_loss: 0.46851927716366565, valid_loss: 0.02391481745455946\n",
      "SEED: 11, FOLD: 4, EPOCH: 1,train_loss: 0.02120790045953145, valid_loss: 0.018985618171947344\n",
      "SEED: 11, FOLD: 4, EPOCH: 2,train_loss: 0.019147541917806123, valid_loss: 0.01809305985059057\n",
      "SEED: 11, FOLD: 4, EPOCH: 3,train_loss: 0.01828561364978987, valid_loss: 0.01861605995467731\n",
      "SEED: 11, FOLD: 4, EPOCH: 4,train_loss: 0.01809186083230659, valid_loss: 0.01809893697500229\n",
      "SEED: 11, FOLD: 4, EPOCH: 5,train_loss: 0.01803306840278589, valid_loss: 0.017773852231247084\n",
      "SEED: 11, FOLD: 4, EPOCH: 6,train_loss: 0.017986151518939186, valid_loss: 0.017911123910120556\n",
      "SEED: 11, FOLD: 4, EPOCH: 7,train_loss: 0.017916879433132436, valid_loss: 0.01785860066967351\n",
      "SEED: 11, FOLD: 4, EPOCH: 8,train_loss: 0.018023658088360824, valid_loss: 0.017824234973107065\n",
      "SEED: 11, FOLD: 4, EPOCH: 9,train_loss: 0.017923146282343098, valid_loss: 0.017793510747807367\n",
      "SEED: 11, FOLD: 4, EPOCH: 10,train_loss: 0.017893468655210777, valid_loss: 0.017611596680113247\n",
      "SEED: 11, FOLD: 4, EPOCH: 11,train_loss: 0.01785276366574486, valid_loss: 0.01830977994416441\n",
      "SEED: 11, FOLD: 4, EPOCH: 12,train_loss: 0.017755424168749447, valid_loss: 0.017713684615279945\n",
      "SEED: 11, FOLD: 4, EPOCH: 13,train_loss: 0.017708675942662424, valid_loss: 0.017517062090337276\n",
      "SEED: 11, FOLD: 4, EPOCH: 14,train_loss: 0.01759535601077071, valid_loss: 0.01741221472620964\n",
      "SEED: 11, FOLD: 4, EPOCH: 15,train_loss: 0.017382464969843407, valid_loss: 0.0178242418382849\n",
      "SEED: 11, FOLD: 4, EPOCH: 16,train_loss: 0.01729917524885522, valid_loss: 0.017380759492516516\n",
      "SEED: 11, FOLD: 4, EPOCH: 17,train_loss: 0.01703526809077411, valid_loss: 0.017250165210238526\n",
      "SEED: 11, FOLD: 4, EPOCH: 18,train_loss: 0.01673422129756778, valid_loss: 0.017179384002728122\n",
      "SEED: 11, FOLD: 4, EPOCH: 19,train_loss: 0.01641079192695609, valid_loss: 0.01720571057604892\n",
      "SEED: 11, FOLD: 4, EPOCH: 20,train_loss: 0.0161031674607283, valid_loss: 0.017146062638078417\n",
      "SEED: 11, FOLD: 4, EPOCH: 21,train_loss: 0.015560387980437627, valid_loss: 0.01702999650899853\n",
      "SEED: 11, FOLD: 4, EPOCH: 22,train_loss: 0.015083090925629991, valid_loss: 0.017053176036902835\n",
      "SEED: 11, FOLD: 4, EPOCH: 23,train_loss: 0.01468367915410195, valid_loss: 0.016997820724334034\n",
      "SEED: 11, FOLD: 4, EPOCH: 24,train_loss: 0.014448494799978976, valid_loss: 0.017012876085937025\n",
      "(17574, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7350559882495714, valid_loss: 0.6995994874409267\n",
      "SEED: 12, FOLD: 0, EPOCH: 0,train_loss: 0.4672917964044904, valid_loss: 0.026075306907296182\n",
      "SEED: 12, FOLD: 0, EPOCH: 1,train_loss: 0.021040616853945496, valid_loss: 0.0191392363182136\n",
      "SEED: 12, FOLD: 0, EPOCH: 2,train_loss: 0.019017198703427246, valid_loss: 0.01934913301042148\n",
      "SEED: 12, FOLD: 0, EPOCH: 3,train_loss: 0.01826875303885427, valid_loss: 0.01819314608084304\n",
      "SEED: 12, FOLD: 0, EPOCH: 4,train_loss: 0.017924937514075333, valid_loss: 0.018312721513211727\n",
      "SEED: 12, FOLD: 0, EPOCH: 5,train_loss: 0.017766800715817488, valid_loss: 0.01836333658014025\n",
      "SEED: 12, FOLD: 0, EPOCH: 6,train_loss: 0.017806202321704746, valid_loss: 0.01858494986913034\n",
      "SEED: 12, FOLD: 0, EPOCH: 7,train_loss: 0.01787046716292051, valid_loss: 0.018569543505353586\n",
      "SEED: 12, FOLD: 0, EPOCH: 8,train_loss: 0.01783704547130543, valid_loss: 0.01834309705133949\n",
      "SEED: 12, FOLD: 0, EPOCH: 9,train_loss: 0.017803121675345777, valid_loss: 0.01805063323783023\n",
      "SEED: 12, FOLD: 0, EPOCH: 10,train_loss: 0.017747125892049593, valid_loss: 0.018281972674386842\n",
      "SEED: 12, FOLD: 0, EPOCH: 11,train_loss: 0.017690337269796408, valid_loss: 0.018092020308332783\n",
      "SEED: 12, FOLD: 0, EPOCH: 12,train_loss: 0.0175925120913788, valid_loss: 0.017824457372937884\n",
      "SEED: 12, FOLD: 0, EPOCH: 13,train_loss: 0.01753278021984126, valid_loss: 0.017976249647991997\n",
      "SEED: 12, FOLD: 0, EPOCH: 14,train_loss: 0.017386620270385258, valid_loss: 0.018068372883966993\n",
      "SEED: 12, FOLD: 0, EPOCH: 15,train_loss: 0.017278885664553312, valid_loss: 0.018185108793633324\n",
      "SEED: 12, FOLD: 0, EPOCH: 16,train_loss: 0.017115092154700254, valid_loss: 0.017915197435234273\n",
      "SEED: 12, FOLD: 0, EPOCH: 17,train_loss: 0.016790200321786644, valid_loss: 0.017683695150273186\n",
      "SEED: 12, FOLD: 0, EPOCH: 18,train_loss: 0.016576238455709772, valid_loss: 0.017821843789092132\n",
      "SEED: 12, FOLD: 0, EPOCH: 19,train_loss: 0.016190178631602423, valid_loss: 0.0176690101357443\n",
      "SEED: 12, FOLD: 0, EPOCH: 20,train_loss: 0.015850544718188652, valid_loss: 0.01755536249173539\n",
      "SEED: 12, FOLD: 0, EPOCH: 21,train_loss: 0.015332525960453178, valid_loss: 0.017457776277193002\n",
      "SEED: 12, FOLD: 0, EPOCH: 22,train_loss: 0.0147774671609311, valid_loss: 0.017471791990101338\n",
      "SEED: 12, FOLD: 0, EPOCH: 23,train_loss: 0.014323273295725601, valid_loss: 0.01751964172082288\n",
      "SEED: 12, FOLD: 0, EPOCH: 24,train_loss: 0.014068325603569763, valid_loss: 0.01750481171267373\n",
      "(17599, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7352862159411112, valid_loss: 0.7022675801725948\n",
      "SEED: 12, FOLD: 1, EPOCH: 0,train_loss: 0.4657542237984961, valid_loss: 0.02542767657295746\n",
      "SEED: 12, FOLD: 1, EPOCH: 1,train_loss: 0.021120665689417416, valid_loss: 0.01911711791420684\n",
      "SEED: 12, FOLD: 1, EPOCH: 2,train_loss: 0.019053029841271, valid_loss: 0.018373684683705076\n",
      "SEED: 12, FOLD: 1, EPOCH: 3,train_loss: 0.01836117473093496, valid_loss: 0.01805430941064568\n",
      "SEED: 12, FOLD: 1, EPOCH: 4,train_loss: 0.01798191219838201, valid_loss: 0.01810424528358614\n",
      "SEED: 12, FOLD: 1, EPOCH: 5,train_loss: 0.017909411793115778, valid_loss: 0.017999217188095346\n",
      "SEED: 12, FOLD: 1, EPOCH: 6,train_loss: 0.017846835291256077, valid_loss: 0.018005118650548598\n",
      "SEED: 12, FOLD: 1, EPOCH: 7,train_loss: 0.01782304192285823, valid_loss: 0.018033970859559142\n",
      "SEED: 12, FOLD: 1, EPOCH: 8,train_loss: 0.01789609325941706, valid_loss: 0.018043984878150857\n",
      "SEED: 12, FOLD: 1, EPOCH: 9,train_loss: 0.01779647351688017, valid_loss: 0.017971637275289085\n",
      "SEED: 12, FOLD: 1, EPOCH: 10,train_loss: 0.017791143605026646, valid_loss: 0.01817108383950065\n",
      "SEED: 12, FOLD: 1, EPOCH: 11,train_loss: 0.017751125463594992, valid_loss: 0.01757425025982015\n",
      "SEED: 12, FOLD: 1, EPOCH: 12,train_loss: 0.017649036501466795, valid_loss: 0.01785817605388515\n",
      "SEED: 12, FOLD: 1, EPOCH: 13,train_loss: 0.017556549394098314, valid_loss: 0.017614342628375572\n",
      "SEED: 12, FOLD: 1, EPOCH: 14,train_loss: 0.017482996283881905, valid_loss: 0.017628194517729914\n",
      "SEED: 12, FOLD: 1, EPOCH: 15,train_loss: 0.017340485350755247, valid_loss: 0.017656113459345174\n",
      "SEED: 12, FOLD: 1, EPOCH: 16,train_loss: 0.017171993696441252, valid_loss: 0.017640334362273708\n",
      "SEED: 12, FOLD: 1, EPOCH: 17,train_loss: 0.01693054462067675, valid_loss: 0.017324125750319046\n",
      "SEED: 12, FOLD: 1, EPOCH: 18,train_loss: 0.016633939362414505, valid_loss: 0.017223872463492787\n",
      "SEED: 12, FOLD: 1, EPOCH: 19,train_loss: 0.016253471900911434, valid_loss: 0.017185204032370272\n",
      "SEED: 12, FOLD: 1, EPOCH: 20,train_loss: 0.0158206801119166, valid_loss: 0.017173616297762182\n",
      "SEED: 12, FOLD: 1, EPOCH: 21,train_loss: 0.015332917743564947, valid_loss: 0.01713805218391559\n",
      "SEED: 12, FOLD: 1, EPOCH: 22,train_loss: 0.014819208478582079, valid_loss: 0.017116201986723086\n",
      "SEED: 12, FOLD: 1, EPOCH: 23,train_loss: 0.014341484026416489, valid_loss: 0.017114271190674865\n",
      "SEED: 12, FOLD: 1, EPOCH: 24,train_loss: 0.014101986975773521, valid_loss: 0.017108875135069385\n",
      "(17500, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7351109842314337, valid_loss: 0.6981082762990679\n",
      "SEED: 12, FOLD: 2, EPOCH: 0,train_loss: 0.4688339334416346, valid_loss: 0.02438227885535785\n",
      "SEED: 12, FOLD: 2, EPOCH: 1,train_loss: 0.020691142492268208, valid_loss: 0.018887130011405264\n",
      "SEED: 12, FOLD: 2, EPOCH: 2,train_loss: 0.019188230340606974, valid_loss: 0.01820799761584827\n",
      "SEED: 12, FOLD: 2, EPOCH: 3,train_loss: 0.018354185666535457, valid_loss: 0.018453684928161757\n",
      "SEED: 12, FOLD: 2, EPOCH: 4,train_loss: 0.017967935080510856, valid_loss: 0.018036446826798575\n",
      "SEED: 12, FOLD: 2, EPOCH: 5,train_loss: 0.017944449055803953, valid_loss: 0.01822656760258334\n",
      "SEED: 12, FOLD: 2, EPOCH: 6,train_loss: 0.01783712165443784, valid_loss: 0.017744346761277743\n",
      "SEED: 12, FOLD: 2, EPOCH: 7,train_loss: 0.017841453888337976, valid_loss: 0.018197689790810857\n",
      "SEED: 12, FOLD: 2, EPOCH: 8,train_loss: 0.017856463484031006, valid_loss: 0.018000484417591778\n",
      "SEED: 12, FOLD: 2, EPOCH: 9,train_loss: 0.017823309406474995, valid_loss: 0.017574558619941984\n",
      "SEED: 12, FOLD: 2, EPOCH: 10,train_loss: 0.017802269245586255, valid_loss: 0.018446857961160797\n",
      "SEED: 12, FOLD: 2, EPOCH: 11,train_loss: 0.017762498590197875, valid_loss: 0.01762009771274669\n",
      "SEED: 12, FOLD: 2, EPOCH: 12,train_loss: 0.01769247027046054, valid_loss: 0.01750405590449061\n",
      "SEED: 12, FOLD: 2, EPOCH: 13,train_loss: 0.017563110815673848, valid_loss: 0.017764710182590144\n",
      "SEED: 12, FOLD: 2, EPOCH: 14,train_loss: 0.017424695438494647, valid_loss: 0.017407482942300184\n",
      "SEED: 12, FOLD: 2, EPOCH: 15,train_loss: 0.017361142162750236, valid_loss: 0.017474924826196263\n",
      "SEED: 12, FOLD: 2, EPOCH: 16,train_loss: 0.017167662052831947, valid_loss: 0.017261605763009617\n",
      "SEED: 12, FOLD: 2, EPOCH: 17,train_loss: 0.0169069177002041, valid_loss: 0.01737880488591535\n",
      "SEED: 12, FOLD: 2, EPOCH: 18,train_loss: 0.01663361457822314, valid_loss: 0.017213146761059762\n",
      "SEED: 12, FOLD: 2, EPOCH: 19,train_loss: 0.016237888709526426, valid_loss: 0.017314426308231694\n",
      "SEED: 12, FOLD: 2, EPOCH: 20,train_loss: 0.015795262877142776, valid_loss: 0.017017091624438763\n",
      "SEED: 12, FOLD: 2, EPOCH: 21,train_loss: 0.01531944681557208, valid_loss: 0.017034977568047387\n",
      "SEED: 12, FOLD: 2, EPOCH: 22,train_loss: 0.014742599473926274, valid_loss: 0.01712030175008944\n",
      "SEED: 12, FOLD: 2, EPOCH: 23,train_loss: 0.014268955005074505, valid_loss: 0.01709559511925493\n",
      "SEED: 12, FOLD: 2, EPOCH: 24,train_loss: 0.0139964892304618, valid_loss: 0.017091825285128186\n",
      "(17623, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7355296918447467, valid_loss: 0.6988349644576802\n",
      "SEED: 12, FOLD: 3, EPOCH: 0,train_loss: 0.4670228035175714, valid_loss: 0.022832876728738054\n",
      "SEED: 12, FOLD: 3, EPOCH: 1,train_loss: 0.021100457433773125, valid_loss: 0.018603107125005302\n",
      "SEED: 12, FOLD: 3, EPOCH: 2,train_loss: 0.01897260461650465, valid_loss: 0.017697860897683045\n",
      "SEED: 12, FOLD: 3, EPOCH: 3,train_loss: 0.018215693668394848, valid_loss: 0.017498108037911794\n",
      "SEED: 12, FOLD: 3, EPOCH: 4,train_loss: 0.01795304594291509, valid_loss: 0.017998327227199778\n",
      "SEED: 12, FOLD: 3, EPOCH: 5,train_loss: 0.017955770824050556, valid_loss: 0.017768032684483948\n",
      "SEED: 12, FOLD: 3, EPOCH: 6,train_loss: 0.017865092952506267, valid_loss: 0.01803359394783483\n",
      "SEED: 12, FOLD: 3, EPOCH: 7,train_loss: 0.01794680224839544, valid_loss: 0.017589316648595473\n",
      "SEED: 12, FOLD: 3, EPOCH: 8,train_loss: 0.01790454346632612, valid_loss: 0.01746854049098842\n",
      "SEED: 12, FOLD: 3, EPOCH: 9,train_loss: 0.017846003687684086, valid_loss: 0.01776697812601924\n",
      "SEED: 12, FOLD: 3, EPOCH: 10,train_loss: 0.01789973445398652, valid_loss: 0.017495100057738668\n",
      "SEED: 12, FOLD: 3, EPOCH: 11,train_loss: 0.017813270229954218, valid_loss: 0.017491731683121008\n",
      "SEED: 12, FOLD: 3, EPOCH: 12,train_loss: 0.017698449264887884, valid_loss: 0.017327459446866724\n",
      "SEED: 12, FOLD: 3, EPOCH: 13,train_loss: 0.017595509600326204, valid_loss: 0.017349495086818933\n",
      "SEED: 12, FOLD: 3, EPOCH: 14,train_loss: 0.017515571234558804, valid_loss: 0.017351508277523166\n",
      "SEED: 12, FOLD: 3, EPOCH: 15,train_loss: 0.017380371298371017, valid_loss: 0.017230370328487718\n",
      "SEED: 12, FOLD: 3, EPOCH: 16,train_loss: 0.017144836046719465, valid_loss: 0.017057230778257635\n",
      "SEED: 12, FOLD: 3, EPOCH: 17,train_loss: 0.0169264173972002, valid_loss: 0.017100744935519555\n",
      "SEED: 12, FOLD: 3, EPOCH: 18,train_loss: 0.01660211669092161, valid_loss: 0.017284181982497957\n",
      "SEED: 12, FOLD: 3, EPOCH: 19,train_loss: 0.016286656085023846, valid_loss: 0.01694600804544547\n",
      "SEED: 12, FOLD: 3, EPOCH: 20,train_loss: 0.015866245035136093, valid_loss: 0.016931380200035432\n",
      "SEED: 12, FOLD: 3, EPOCH: 21,train_loss: 0.015387012947188772, valid_loss: 0.016907737069927594\n",
      "SEED: 12, FOLD: 3, EPOCH: 22,train_loss: 0.014867748322802177, valid_loss: 0.016924538540051264\n",
      "SEED: 12, FOLD: 3, EPOCH: 23,train_loss: 0.014403347384886465, valid_loss: 0.016935578492634436\n",
      "SEED: 12, FOLD: 3, EPOCH: 24,train_loss: 0.01414955849421845, valid_loss: 0.016971467528492212\n",
      "(17496, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7351700694021517, valid_loss: 0.6992262942450387\n",
      "SEED: 12, FOLD: 4, EPOCH: 0,train_loss: 0.46858178375519977, valid_loss: 0.024698717040675028\n",
      "SEED: 12, FOLD: 4, EPOCH: 1,train_loss: 0.020912018924081413, valid_loss: 0.01903305250619139\n",
      "SEED: 12, FOLD: 4, EPOCH: 2,train_loss: 0.019042915882148445, valid_loss: 0.018389269124184336\n",
      "SEED: 12, FOLD: 4, EPOCH: 3,train_loss: 0.01811341919603139, valid_loss: 0.01823161473231656\n",
      "SEED: 12, FOLD: 4, EPOCH: 4,train_loss: 0.017913204393465155, valid_loss: 0.01823737741048847\n",
      "SEED: 12, FOLD: 4, EPOCH: 5,train_loss: 0.01776684701007648, valid_loss: 0.018153419478663377\n",
      "SEED: 12, FOLD: 4, EPOCH: 6,train_loss: 0.017876484907184638, valid_loss: 0.018739178031682967\n",
      "SEED: 12, FOLD: 4, EPOCH: 7,train_loss: 0.017824053472030338, valid_loss: 0.018154108258230345\n",
      "SEED: 12, FOLD: 4, EPOCH: 8,train_loss: 0.017844572384590213, valid_loss: 0.018554098584822248\n",
      "SEED: 12, FOLD: 4, EPOCH: 9,train_loss: 0.017767520546641227, valid_loss: 0.01845593662666423\n",
      "SEED: 12, FOLD: 4, EPOCH: 10,train_loss: 0.017769700840768152, valid_loss: 0.018090546051306385\n",
      "SEED: 12, FOLD: 4, EPOCH: 11,train_loss: 0.017634478384071457, valid_loss: 0.018046635362718787\n",
      "SEED: 12, FOLD: 4, EPOCH: 12,train_loss: 0.017644960297285205, valid_loss: 0.018153364504022256\n",
      "SEED: 12, FOLD: 4, EPOCH: 13,train_loss: 0.017527033867192093, valid_loss: 0.018098907438772065\n",
      "SEED: 12, FOLD: 4, EPOCH: 14,train_loss: 0.017426799214615003, valid_loss: 0.017968025564083032\n",
      "SEED: 12, FOLD: 4, EPOCH: 15,train_loss: 0.01724192085437966, valid_loss: 0.017957876303366253\n",
      "SEED: 12, FOLD: 4, EPOCH: 16,train_loss: 0.017115661704464116, valid_loss: 0.01755438196871962\n",
      "SEED: 12, FOLD: 4, EPOCH: 17,train_loss: 0.016803588079166237, valid_loss: 0.01769623870828322\n",
      "SEED: 12, FOLD: 4, EPOCH: 18,train_loss: 0.016548928077312283, valid_loss: 0.017416514296616826\n",
      "SEED: 12, FOLD: 4, EPOCH: 19,train_loss: 0.01618663057766474, valid_loss: 0.01754717222814049\n",
      "SEED: 12, FOLD: 4, EPOCH: 20,train_loss: 0.015753127668515172, valid_loss: 0.017424375031675612\n",
      "SEED: 12, FOLD: 4, EPOCH: 21,train_loss: 0.015242292328200636, valid_loss: 0.017375902166324002\n",
      "SEED: 12, FOLD: 4, EPOCH: 22,train_loss: 0.014773803423192814, valid_loss: 0.017363849787839822\n",
      "SEED: 12, FOLD: 4, EPOCH: 23,train_loss: 0.01433486035977402, valid_loss: 0.01740384064614773\n",
      "SEED: 12, FOLD: 4, EPOCH: 24,train_loss: 0.014081411328792136, valid_loss: 0.0173823797543134\n",
      "(17543, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7364648191825204, valid_loss: 0.6978754128728594\n",
      "SEED: 13, FOLD: 0, EPOCH: 0,train_loss: 0.4674841022739808, valid_loss: 0.02449004916208131\n",
      "SEED: 13, FOLD: 0, EPOCH: 1,train_loss: 0.021236271786409012, valid_loss: 0.018546102116150515\n",
      "SEED: 13, FOLD: 0, EPOCH: 2,train_loss: 0.019145490547669106, valid_loss: 0.056928360089659694\n",
      "SEED: 13, FOLD: 0, EPOCH: 3,train_loss: 0.018404647168042004, valid_loss: 0.018395363459629673\n",
      "SEED: 13, FOLD: 0, EPOCH: 4,train_loss: 0.01813405788625064, valid_loss: 0.01900726942611592\n",
      "SEED: 13, FOLD: 0, EPOCH: 5,train_loss: 0.018112616701240557, valid_loss: 0.01765414880854743\n",
      "SEED: 13, FOLD: 0, EPOCH: 6,train_loss: 0.0180041480647481, valid_loss: 0.01783503235450813\n",
      "SEED: 13, FOLD: 0, EPOCH: 7,train_loss: 0.017970572954610638, valid_loss: 0.017727910886917796\n",
      "SEED: 13, FOLD: 0, EPOCH: 8,train_loss: 0.017951309532467007, valid_loss: 0.017852449576769555\n",
      "SEED: 13, FOLD: 0, EPOCH: 9,train_loss: 0.018082799511435238, valid_loss: 0.01771261425954955\n",
      "SEED: 13, FOLD: 0, EPOCH: 10,train_loss: 0.017993599507093862, valid_loss: 0.017742521502077578\n",
      "SEED: 13, FOLD: 0, EPOCH: 11,train_loss: 0.018028253385716158, valid_loss: 0.0176319917930024\n",
      "SEED: 13, FOLD: 0, EPOCH: 12,train_loss: 0.017883937441460464, valid_loss: 0.01762939358928374\n",
      "SEED: 13, FOLD: 0, EPOCH: 13,train_loss: 0.017788568687071835, valid_loss: 0.018289219534822872\n",
      "SEED: 13, FOLD: 0, EPOCH: 14,train_loss: 0.017858327744339687, valid_loss: 0.017383116111159325\n",
      "SEED: 13, FOLD: 0, EPOCH: 15,train_loss: 0.017595029085118702, valid_loss: 0.017509211786091328\n",
      "SEED: 13, FOLD: 0, EPOCH: 16,train_loss: 0.01730788719124984, valid_loss: 0.017221956247729913\n",
      "SEED: 13, FOLD: 0, EPOCH: 17,train_loss: 0.017083121875327997, valid_loss: 0.017224557511508466\n",
      "SEED: 13, FOLD: 0, EPOCH: 18,train_loss: 0.016859802768390247, valid_loss: 0.01718171358640705\n",
      "SEED: 13, FOLD: 0, EPOCH: 19,train_loss: 0.01659180526284204, valid_loss: 0.01708134434052876\n",
      "SEED: 13, FOLD: 0, EPOCH: 20,train_loss: 0.01612225123613641, valid_loss: 0.017106352719877448\n",
      "SEED: 13, FOLD: 0, EPOCH: 21,train_loss: 0.01577003261047429, valid_loss: 0.017042179671781402\n",
      "SEED: 13, FOLD: 0, EPOCH: 22,train_loss: 0.015306834435171408, valid_loss: 0.017102747516972678\n",
      "SEED: 13, FOLD: 0, EPOCH: 23,train_loss: 0.015029979100369888, valid_loss: 0.01699071555797543\n",
      "SEED: 13, FOLD: 0, EPOCH: 24,train_loss: 0.014735440257936716, valid_loss: 0.017008783934371812\n",
      "(17653, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7358235652032106, valid_loss: 0.6974033765933093\n",
      "SEED: 13, FOLD: 1, EPOCH: 0,train_loss: 0.46774935770941817, valid_loss: 0.02388072178206023\n",
      "SEED: 13, FOLD: 1, EPOCH: 1,train_loss: 0.02072223188166601, valid_loss: 0.01905012738836162\n",
      "SEED: 13, FOLD: 1, EPOCH: 2,train_loss: 0.018882547653671623, valid_loss: 0.0181306047255502\n",
      "SEED: 13, FOLD: 1, EPOCH: 3,train_loss: 0.018191316860147577, valid_loss: 0.01841474280637853\n",
      "SEED: 13, FOLD: 1, EPOCH: 4,train_loss: 0.017922701961968258, valid_loss: 0.018542795825530502\n",
      "SEED: 13, FOLD: 1, EPOCH: 5,train_loss: 0.017893028938198004, valid_loss: 0.018579426769386318\n",
      "SEED: 13, FOLD: 1, EPOCH: 6,train_loss: 0.017851923801598772, valid_loss: 0.017900722046547076\n",
      "SEED: 13, FOLD: 1, EPOCH: 7,train_loss: 0.01785351493922265, valid_loss: 0.018038985209868234\n",
      "SEED: 13, FOLD: 1, EPOCH: 8,train_loss: 0.017847029526002596, valid_loss: 0.017902517033850446\n",
      "SEED: 13, FOLD: 1, EPOCH: 9,train_loss: 0.017802047684950674, valid_loss: 0.01826484884847613\n",
      "SEED: 13, FOLD: 1, EPOCH: 10,train_loss: 0.017816557447709467, valid_loss: 0.01784146105980172\n",
      "SEED: 13, FOLD: 1, EPOCH: 11,train_loss: 0.017761859111487865, valid_loss: 0.01788127005976789\n",
      "SEED: 13, FOLD: 1, EPOCH: 12,train_loss: 0.017702281454820997, valid_loss: 0.01799082668388591\n",
      "SEED: 13, FOLD: 1, EPOCH: 13,train_loss: 0.01752810024291925, valid_loss: 0.01782453219022821\n",
      "SEED: 13, FOLD: 1, EPOCH: 14,train_loss: 0.017449939650469933, valid_loss: 0.017548473853179637\n",
      "SEED: 13, FOLD: 1, EPOCH: 15,train_loss: 0.017347040727896536, valid_loss: 0.017577400266685906\n",
      "SEED: 13, FOLD: 1, EPOCH: 16,train_loss: 0.017074953373251617, valid_loss: 0.01751302040236838\n",
      "SEED: 13, FOLD: 1, EPOCH: 17,train_loss: 0.016914704517609833, valid_loss: 0.01770414543502471\n",
      "SEED: 13, FOLD: 1, EPOCH: 18,train_loss: 0.016653624984125297, valid_loss: 0.017426333280608934\n",
      "SEED: 13, FOLD: 1, EPOCH: 19,train_loss: 0.01623449038606191, valid_loss: 0.01758143776918159\n",
      "SEED: 13, FOLD: 1, EPOCH: 20,train_loss: 0.015848378738577383, valid_loss: 0.017433620989322662\n",
      "SEED: 13, FOLD: 1, EPOCH: 21,train_loss: 0.015384151850003695, valid_loss: 0.017386068754336414\n",
      "SEED: 13, FOLD: 1, EPOCH: 22,train_loss: 0.014877010440534872, valid_loss: 0.017351473572061342\n",
      "SEED: 13, FOLD: 1, EPOCH: 23,train_loss: 0.014416783454193585, valid_loss: 0.01740802309530623\n",
      "SEED: 13, FOLD: 1, EPOCH: 24,train_loss: 0.014167334411995134, valid_loss: 0.01740371813888059\n",
      "(17591, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7359492338222006, valid_loss: 0.6975084151540484\n",
      "SEED: 13, FOLD: 2, EPOCH: 0,train_loss: 0.46746181796534336, valid_loss: 0.024024161909307753\n",
      "SEED: 13, FOLD: 2, EPOCH: 1,train_loss: 0.02080136653629766, valid_loss: 0.019061290472745896\n",
      "SEED: 13, FOLD: 2, EPOCH: 2,train_loss: 0.018982791260856648, valid_loss: 0.018473830659474645\n",
      "SEED: 13, FOLD: 2, EPOCH: 3,train_loss: 0.018264388955751623, valid_loss: 0.018038896577698842\n",
      "SEED: 13, FOLD: 2, EPOCH: 4,train_loss: 0.017922329216979553, valid_loss: 0.01818849497607776\n",
      "SEED: 13, FOLD: 2, EPOCH: 5,train_loss: 0.017960785024300003, valid_loss: 0.018478501534887722\n",
      "SEED: 13, FOLD: 2, EPOCH: 6,train_loss: 0.01790205608594461, valid_loss: 0.01809656989893743\n",
      "SEED: 13, FOLD: 2, EPOCH: 7,train_loss: 0.017929876013996378, valid_loss: 0.017982165728296553\n",
      "SEED: 13, FOLD: 2, EPOCH: 8,train_loss: 0.017942103010642786, valid_loss: 0.01768521469618593\n",
      "SEED: 13, FOLD: 2, EPOCH: 9,train_loss: 0.01785151731978724, valid_loss: 0.018285241004611763\n",
      "SEED: 13, FOLD: 2, EPOCH: 10,train_loss: 0.017814077963323696, valid_loss: 0.01782850929136787\n",
      "SEED: 13, FOLD: 2, EPOCH: 11,train_loss: 0.017824618982664055, valid_loss: 0.018008304493767873\n",
      "SEED: 13, FOLD: 2, EPOCH: 12,train_loss: 0.017681909603593143, valid_loss: 0.017427111523491995\n",
      "SEED: 13, FOLD: 2, EPOCH: 13,train_loss: 0.017558069143822227, valid_loss: 0.017595571013433592\n",
      "SEED: 13, FOLD: 2, EPOCH: 14,train_loss: 0.017560508871532005, valid_loss: 0.01720627091292824\n",
      "SEED: 13, FOLD: 2, EPOCH: 15,train_loss: 0.017335283063838015, valid_loss: 0.017331182051982197\n",
      "SEED: 13, FOLD: 2, EPOCH: 16,train_loss: 0.017200842202789543, valid_loss: 0.017241172545722553\n",
      "SEED: 13, FOLD: 2, EPOCH: 17,train_loss: 0.016979196189862232, valid_loss: 0.017131856722491127\n",
      "SEED: 13, FOLD: 2, EPOCH: 18,train_loss: 0.016678741782147816, valid_loss: 0.01706537857119526\n",
      "SEED: 13, FOLD: 2, EPOCH: 19,train_loss: 0.01626364625585468, valid_loss: 0.016991022921034268\n",
      "SEED: 13, FOLD: 2, EPOCH: 20,train_loss: 0.015948983307495928, valid_loss: 0.017006416246294974\n",
      "SEED: 13, FOLD: 2, EPOCH: 21,train_loss: 0.015401527805226868, valid_loss: 0.016965691718672002\n",
      "SEED: 13, FOLD: 2, EPOCH: 22,train_loss: 0.01492107237783679, valid_loss: 0.01698088880096163\n",
      "SEED: 13, FOLD: 2, EPOCH: 23,train_loss: 0.014485803830936768, valid_loss: 0.016977101005613802\n",
      "SEED: 13, FOLD: 2, EPOCH: 24,train_loss: 0.014245655212173428, valid_loss: 0.016942762689931053\n",
      "(17494, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.736212934020662, valid_loss: 0.6970513326781137\n",
      "SEED: 13, FOLD: 3, EPOCH: 0,train_loss: 0.4703148950407975, valid_loss: 0.02394937298127583\n",
      "SEED: 13, FOLD: 3, EPOCH: 1,train_loss: 0.021040385507427862, valid_loss: 0.019090290154729572\n",
      "SEED: 13, FOLD: 3, EPOCH: 2,train_loss: 0.01903125768133106, valid_loss: 0.01765241487217801\n",
      "SEED: 13, FOLD: 3, EPOCH: 3,train_loss: 0.01834087778073158, valid_loss: 0.017668471006410464\n",
      "SEED: 13, FOLD: 3, EPOCH: 4,train_loss: 0.018004823557651827, valid_loss: 0.017765344546309538\n",
      "SEED: 13, FOLD: 3, EPOCH: 5,train_loss: 0.017933863255936298, valid_loss: 0.017538660019636155\n",
      "SEED: 13, FOLD: 3, EPOCH: 6,train_loss: 0.017949729199337697, valid_loss: 0.017569547119949545\n",
      "SEED: 13, FOLD: 3, EPOCH: 7,train_loss: 0.017968127911869625, valid_loss: 0.017349048597472053\n",
      "SEED: 13, FOLD: 3, EPOCH: 8,train_loss: 0.01789227683423427, valid_loss: 0.01745319648512772\n",
      "SEED: 13, FOLD: 3, EPOCH: 9,train_loss: 0.017912567110501067, valid_loss: 0.017683342950684685\n",
      "SEED: 13, FOLD: 3, EPOCH: 10,train_loss: 0.017883549600730846, valid_loss: 0.017382415171180454\n",
      "SEED: 13, FOLD: 3, EPOCH: 11,train_loss: 0.01782363086911666, valid_loss: 0.01735000011644193\n",
      "SEED: 13, FOLD: 3, EPOCH: 12,train_loss: 0.017764038338332715, valid_loss: 0.01726105104067496\n",
      "SEED: 13, FOLD: 3, EPOCH: 13,train_loss: 0.01767861560313371, valid_loss: 0.017281767672726087\n",
      "SEED: 13, FOLD: 3, EPOCH: 14,train_loss: 0.017519019911215253, valid_loss: 0.01715058439544269\n",
      "SEED: 13, FOLD: 3, EPOCH: 15,train_loss: 0.017409437607946623, valid_loss: 0.01731827687472105\n",
      "SEED: 13, FOLD: 3, EPOCH: 16,train_loss: 0.017260917204085492, valid_loss: 0.017107304212238106\n",
      "SEED: 13, FOLD: 3, EPOCH: 17,train_loss: 0.01699498334532454, valid_loss: 0.017054412088223867\n",
      "SEED: 13, FOLD: 3, EPOCH: 18,train_loss: 0.016688235471174664, valid_loss: 0.017017753661743233\n",
      "SEED: 13, FOLD: 3, EPOCH: 19,train_loss: 0.01643733829123913, valid_loss: 0.016889670571046216\n",
      "SEED: 13, FOLD: 3, EPOCH: 20,train_loss: 0.015979656575750695, valid_loss: 0.016897887284202235\n",
      "SEED: 13, FOLD: 3, EPOCH: 21,train_loss: 0.01549773649006647, valid_loss: 0.016935217274086815\n",
      "SEED: 13, FOLD: 3, EPOCH: 22,train_loss: 0.015023401632469936, valid_loss: 0.01684893010450261\n",
      "SEED: 13, FOLD: 3, EPOCH: 23,train_loss: 0.014603794735931132, valid_loss: 0.016826071989323413\n",
      "SEED: 13, FOLD: 3, EPOCH: 24,train_loss: 0.01437478325581246, valid_loss: 0.016834534358765398\n",
      "(17511, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7358215525202507, valid_loss: 0.6976013234683446\n",
      "SEED: 13, FOLD: 4, EPOCH: 0,train_loss: 0.4691552374865452, valid_loss: 0.024304111089025224\n",
      "SEED: 13, FOLD: 4, EPOCH: 1,train_loss: 0.020595010560359398, valid_loss: 0.019409815381680216\n",
      "SEED: 13, FOLD: 4, EPOCH: 2,train_loss: 0.018841451883696726, valid_loss: 0.018839501323444502\n",
      "SEED: 13, FOLD: 4, EPOCH: 3,train_loss: 0.017964420969305683, valid_loss: 0.01856754645705223\n",
      "SEED: 13, FOLD: 4, EPOCH: 4,train_loss: 0.017732734105339015, valid_loss: 0.018632861280015536\n",
      "SEED: 13, FOLD: 4, EPOCH: 5,train_loss: 0.01771615924191301, valid_loss: 0.01886039599776268\n",
      "SEED: 13, FOLD: 4, EPOCH: 6,train_loss: 0.017735754914690545, valid_loss: 0.018604919420821327\n",
      "SEED: 13, FOLD: 4, EPOCH: 7,train_loss: 0.01768072464768469, valid_loss: 0.01836125637803759\n",
      "SEED: 13, FOLD: 4, EPOCH: 8,train_loss: 0.01772945735902682, valid_loss: 0.019256470991032466\n",
      "SEED: 13, FOLD: 4, EPOCH: 9,train_loss: 0.017691388522295185, valid_loss: 0.018588343688419887\n",
      "SEED: 13, FOLD: 4, EPOCH: 10,train_loss: 0.01767097532504449, valid_loss: 0.01848376930824348\n",
      "SEED: 13, FOLD: 4, EPOCH: 11,train_loss: 0.017613056319745354, valid_loss: 0.018406269326806068\n",
      "SEED: 13, FOLD: 4, EPOCH: 12,train_loss: 0.01752277218267648, valid_loss: 0.018556832681809153\n",
      "SEED: 13, FOLD: 4, EPOCH: 13,train_loss: 0.017492177753444135, valid_loss: 0.01850999849183219\n",
      "SEED: 13, FOLD: 4, EPOCH: 14,train_loss: 0.017322807538792166, valid_loss: 0.018127390582646643\n",
      "SEED: 13, FOLD: 4, EPOCH: 15,train_loss: 0.017202183502270794, valid_loss: 0.01802962709750448\n",
      "SEED: 13, FOLD: 4, EPOCH: 16,train_loss: 0.01700946825291336, valid_loss: 0.01805622529770647\n",
      "SEED: 13, FOLD: 4, EPOCH: 17,train_loss: 0.01676964415849125, valid_loss: 0.018056852317282133\n",
      "SEED: 13, FOLD: 4, EPOCH: 18,train_loss: 0.01654660360493364, valid_loss: 0.017789253033697605\n",
      "SEED: 13, FOLD: 4, EPOCH: 19,train_loss: 0.016177474602676222, valid_loss: 0.017761665343173912\n",
      "SEED: 13, FOLD: 4, EPOCH: 20,train_loss: 0.015706276412319094, valid_loss: 0.017775914658393177\n",
      "SEED: 13, FOLD: 4, EPOCH: 21,train_loss: 0.015268666628938521, valid_loss: 0.017773014599723476\n",
      "SEED: 13, FOLD: 4, EPOCH: 22,train_loss: 0.014718032265285941, valid_loss: 0.017828034795820714\n",
      "SEED: 13, FOLD: 4, EPOCH: 23,train_loss: 0.014268109778853228, valid_loss: 0.017821243511778967\n",
      "SEED: 13, FOLD: 4, EPOCH: 24,train_loss: 0.01402504114692446, valid_loss: 0.01784620311643396\n",
      "(17631, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7358559568723043, valid_loss: 0.704323444296332\n",
      "SEED: 14, FOLD: 0, EPOCH: 0,train_loss: 0.4672077343245779, valid_loss: 0.02490228244706112\n",
      "SEED: 14, FOLD: 0, EPOCH: 1,train_loss: 0.020730461439360744, valid_loss: 0.01978683630552362\n",
      "SEED: 14, FOLD: 0, EPOCH: 2,train_loss: 0.019232897965264492, valid_loss: 0.01868369145428433\n",
      "SEED: 14, FOLD: 0, EPOCH: 3,train_loss: 0.018356167819296967, valid_loss: 0.018202595056637245\n",
      "SEED: 14, FOLD: 0, EPOCH: 4,train_loss: 0.017932994574632332, valid_loss: 0.018089087679982185\n",
      "SEED: 14, FOLD: 0, EPOCH: 5,train_loss: 0.017839131282939426, valid_loss: 0.018413056920775595\n",
      "SEED: 14, FOLD: 0, EPOCH: 6,train_loss: 0.017885376307843388, valid_loss: 0.018228721503606615\n",
      "SEED: 14, FOLD: 0, EPOCH: 7,train_loss: 0.017849498266435188, valid_loss: 0.018019436228582087\n",
      "SEED: 14, FOLD: 0, EPOCH: 8,train_loss: 0.017904349211333454, valid_loss: 0.018216045272043523\n",
      "SEED: 14, FOLD: 0, EPOCH: 9,train_loss: 0.017822812149382156, valid_loss: 0.018175915267099354\n",
      "SEED: 14, FOLD: 0, EPOCH: 10,train_loss: 0.0178092362669607, valid_loss: 0.01859979462974212\n",
      "SEED: 14, FOLD: 0, EPOCH: 11,train_loss: 0.017731700585210237, valid_loss: 0.018113736583686927\n",
      "SEED: 14, FOLD: 0, EPOCH: 12,train_loss: 0.017711086502379698, valid_loss: 0.017935664146481192\n",
      "SEED: 14, FOLD: 0, EPOCH: 13,train_loss: 0.01756510293732087, valid_loss: 0.017670920200865057\n",
      "SEED: 14, FOLD: 0, EPOCH: 14,train_loss: 0.01748022626734514, valid_loss: 0.01764648303608684\n",
      "SEED: 14, FOLD: 0, EPOCH: 15,train_loss: 0.017324728742781757, valid_loss: 0.017765969257144368\n",
      "SEED: 14, FOLD: 0, EPOCH: 16,train_loss: 0.01716528425290101, valid_loss: 0.017461825792184648\n",
      "SEED: 14, FOLD: 0, EPOCH: 17,train_loss: 0.01689255413720789, valid_loss: 0.01752669465563753\n",
      "SEED: 14, FOLD: 0, EPOCH: 18,train_loss: 0.016660085879266262, valid_loss: 0.01742609981995295\n",
      "SEED: 14, FOLD: 0, EPOCH: 19,train_loss: 0.016338414222379957, valid_loss: 0.01732267296927817\n",
      "SEED: 14, FOLD: 0, EPOCH: 20,train_loss: 0.01591932724999345, valid_loss: 0.01734338185804732\n",
      "SEED: 14, FOLD: 0, EPOCH: 21,train_loss: 0.015458238263870928, valid_loss: 0.017367255627451575\n",
      "SEED: 14, FOLD: 0, EPOCH: 22,train_loss: 0.014962645564768194, valid_loss: 0.017212192856651896\n",
      "SEED: 14, FOLD: 0, EPOCH: 23,train_loss: 0.014528704834157143, valid_loss: 0.017221956760348642\n",
      "SEED: 14, FOLD: 0, EPOCH: 24,train_loss: 0.014265254659551209, valid_loss: 0.017247810631113893\n",
      "(17512, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7361351482189484, valid_loss: 0.7058438897132874\n",
      "SEED: 14, FOLD: 1, EPOCH: 0,train_loss: 0.4673545998487159, valid_loss: 0.023777415603399278\n",
      "SEED: 14, FOLD: 1, EPOCH: 1,train_loss: 0.020878512045218997, valid_loss: 0.01936002230005605\n",
      "SEED: 14, FOLD: 1, EPOCH: 2,train_loss: 0.019668880306238676, valid_loss: 0.01904020756483078\n",
      "SEED: 14, FOLD: 1, EPOCH: 3,train_loss: 0.018452843746347147, valid_loss: 0.0184149139427713\n",
      "SEED: 14, FOLD: 1, EPOCH: 4,train_loss: 0.018068503765185383, valid_loss: 0.018614029538418564\n",
      "SEED: 14, FOLD: 1, EPOCH: 5,train_loss: 0.017905421595830116, valid_loss: 0.018370768587504114\n",
      "SEED: 14, FOLD: 1, EPOCH: 6,train_loss: 0.017840801989727647, valid_loss: 0.01866754125803709\n",
      "SEED: 14, FOLD: 1, EPOCH: 7,train_loss: 0.0178644745440705, valid_loss: 0.01845027982656445\n",
      "SEED: 14, FOLD: 1, EPOCH: 8,train_loss: 0.017810886005198, valid_loss: 0.01824300227952855\n",
      "SEED: 14, FOLD: 1, EPOCH: 9,train_loss: 0.01781154725102395, valid_loss: 0.018175206360008037\n",
      "SEED: 14, FOLD: 1, EPOCH: 10,train_loss: 0.017763762646456703, valid_loss: 0.018153160411332334\n",
      "SEED: 14, FOLD: 1, EPOCH: 11,train_loss: 0.01770784375495719, valid_loss: 0.018143374499465736\n",
      "SEED: 14, FOLD: 1, EPOCH: 12,train_loss: 0.01762824699309838, valid_loss: 0.018305964767932892\n",
      "SEED: 14, FOLD: 1, EPOCH: 13,train_loss: 0.017546795294993985, valid_loss: 0.017980240232178143\n",
      "SEED: 14, FOLD: 1, EPOCH: 14,train_loss: 0.017463316794240128, valid_loss: 0.01798631197639874\n",
      "SEED: 14, FOLD: 1, EPOCH: 15,train_loss: 0.017278963020139367, valid_loss: 0.017770210467278957\n",
      "SEED: 14, FOLD: 1, EPOCH: 16,train_loss: 0.01707079629311814, valid_loss: 0.017832551178123268\n",
      "SEED: 14, FOLD: 1, EPOCH: 17,train_loss: 0.016823614621195044, valid_loss: 0.017701303932283606\n",
      "SEED: 14, FOLD: 1, EPOCH: 18,train_loss: 0.01663872866762163, valid_loss: 0.017610927112400532\n",
      "SEED: 14, FOLD: 1, EPOCH: 19,train_loss: 0.0162243913573614, valid_loss: 0.01751831224454301\n",
      "SEED: 14, FOLD: 1, EPOCH: 20,train_loss: 0.015844304508862705, valid_loss: 0.01748614287269967\n",
      "SEED: 14, FOLD: 1, EPOCH: 21,train_loss: 0.015399702348793945, valid_loss: 0.017498171968119484\n",
      "SEED: 14, FOLD: 1, EPOCH: 22,train_loss: 0.014895041221684783, valid_loss: 0.017481488787702153\n",
      "SEED: 14, FOLD: 1, EPOCH: 23,train_loss: 0.014445160427232729, valid_loss: 0.017440054406012807\n",
      "SEED: 14, FOLD: 1, EPOCH: 24,train_loss: 0.01422844793865063, valid_loss: 0.01744748641337667\n",
      "(17631, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7360703793988712, valid_loss: 0.7041927365695729\n",
      "SEED: 14, FOLD: 2, EPOCH: 0,train_loss: 0.46560124650705553, valid_loss: 0.022865187924574402\n",
      "SEED: 14, FOLD: 2, EPOCH: 1,train_loss: 0.021055672020799873, valid_loss: 0.018710094777976766\n",
      "SEED: 14, FOLD: 2, EPOCH: 2,train_loss: 0.01891536767715993, valid_loss: 0.018161532140391713\n",
      "SEED: 14, FOLD: 2, EPOCH: 3,train_loss: 0.018193635536168797, valid_loss: 0.0179707027204773\n",
      "SEED: 14, FOLD: 2, EPOCH: 4,train_loss: 0.017845528510709602, valid_loss: 0.01839355905266369\n",
      "SEED: 14, FOLD: 2, EPOCH: 5,train_loss: 0.017895729065049385, valid_loss: 0.018237720188849112\n",
      "SEED: 14, FOLD: 2, EPOCH: 6,train_loss: 0.017814233359219372, valid_loss: 0.018073157736045474\n",
      "SEED: 14, FOLD: 2, EPOCH: 7,train_loss: 0.017885045506114115, valid_loss: 0.017924950786811465\n",
      "SEED: 14, FOLD: 2, EPOCH: 8,train_loss: 0.017883391774165026, valid_loss: 0.017714175532626754\n",
      "SEED: 14, FOLD: 2, EPOCH: 9,train_loss: 0.017849970932887947, valid_loss: 0.01786630625343498\n",
      "SEED: 14, FOLD: 2, EPOCH: 10,train_loss: 0.017767849283805794, valid_loss: 0.017740666482816723\n",
      "SEED: 14, FOLD: 2, EPOCH: 11,train_loss: 0.017732994738912235, valid_loss: 0.017659339341608918\n",
      "SEED: 14, FOLD: 2, EPOCH: 12,train_loss: 0.017703327964451433, valid_loss: 0.01770911688971169\n",
      "SEED: 14, FOLD: 2, EPOCH: 13,train_loss: 0.017585240169495777, valid_loss: 0.01750100379371468\n",
      "SEED: 14, FOLD: 2, EPOCH: 14,train_loss: 0.017486843719160643, valid_loss: 0.017586398102781352\n",
      "SEED: 14, FOLD: 2, EPOCH: 15,train_loss: 0.017304436519634033, valid_loss: 0.01738728514379438\n",
      "SEED: 14, FOLD: 2, EPOCH: 16,train_loss: 0.01715910006179542, valid_loss: 0.017475634950267917\n",
      "SEED: 14, FOLD: 2, EPOCH: 17,train_loss: 0.016894315227704203, valid_loss: 0.017503516282886267\n",
      "SEED: 14, FOLD: 2, EPOCH: 18,train_loss: 0.01662725618487035, valid_loss: 0.017433778656756178\n",
      "SEED: 14, FOLD: 2, EPOCH: 19,train_loss: 0.016281836119520922, valid_loss: 0.017254215254284003\n",
      "SEED: 14, FOLD: 2, EPOCH: 20,train_loss: 0.015830983637251717, valid_loss: 0.01718468391610419\n",
      "SEED: 14, FOLD: 2, EPOCH: 21,train_loss: 0.015344241465293411, valid_loss: 0.017160390941973996\n",
      "SEED: 14, FOLD: 2, EPOCH: 22,train_loss: 0.014820557121403408, valid_loss: 0.017166482668150875\n",
      "SEED: 14, FOLD: 2, EPOCH: 23,train_loss: 0.01436965538026846, valid_loss: 0.01718112694866517\n",
      "SEED: 14, FOLD: 2, EPOCH: 24,train_loss: 0.01412334857319576, valid_loss: 0.017163495533168316\n",
      "(17507, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7364798758151757, valid_loss: 0.7013734034129552\n",
      "SEED: 14, FOLD: 3, EPOCH: 0,train_loss: 0.4676709476532075, valid_loss: 0.023329791692750793\n",
      "SEED: 14, FOLD: 3, EPOCH: 1,train_loss: 0.02122982193029275, valid_loss: 0.01870620096368449\n",
      "SEED: 14, FOLD: 3, EPOCH: 2,train_loss: 0.019079994641407562, valid_loss: 0.018170710732894283\n",
      "SEED: 14, FOLD: 3, EPOCH: 3,train_loss: 0.01816112593659302, valid_loss: 0.018083530850708483\n",
      "SEED: 14, FOLD: 3, EPOCH: 4,train_loss: 0.01787584979957255, valid_loss: 0.0180831856493439\n",
      "SEED: 14, FOLD: 3, EPOCH: 5,train_loss: 0.017878775117769294, valid_loss: 0.018071259877511434\n",
      "SEED: 14, FOLD: 3, EPOCH: 6,train_loss: 0.017826701827129744, valid_loss: 0.0181550141956125\n",
      "SEED: 14, FOLD: 3, EPOCH: 7,train_loss: 0.017873393215347817, valid_loss: 0.018014542146452834\n",
      "SEED: 14, FOLD: 3, EPOCH: 8,train_loss: 0.017854605250767548, valid_loss: 0.01802089884877205\n",
      "SEED: 14, FOLD: 3, EPOCH: 9,train_loss: 0.01787221747838015, valid_loss: 0.017898426497621196\n",
      "SEED: 14, FOLD: 3, EPOCH: 10,train_loss: 0.017736817812071228, valid_loss: 0.017997694920216287\n",
      "SEED: 14, FOLD: 3, EPOCH: 11,train_loss: 0.01768329055694333, valid_loss: 0.01800289052937712\n",
      "SEED: 14, FOLD: 3, EPOCH: 12,train_loss: 0.017643553673894734, valid_loss: 0.01799145732074976\n",
      "SEED: 14, FOLD: 3, EPOCH: 13,train_loss: 0.01756341652740745, valid_loss: 0.017712214349636008\n",
      "SEED: 14, FOLD: 3, EPOCH: 14,train_loss: 0.017403053378101684, valid_loss: 0.01781698116766555\n",
      "SEED: 14, FOLD: 3, EPOCH: 15,train_loss: 0.01732135325479899, valid_loss: 0.017588748410344125\n",
      "SEED: 14, FOLD: 3, EPOCH: 16,train_loss: 0.017097224481403828, valid_loss: 0.01760120200259345\n",
      "SEED: 14, FOLD: 3, EPOCH: 17,train_loss: 0.01685990467259701, valid_loss: 0.017605798478637424\n",
      "SEED: 14, FOLD: 3, EPOCH: 18,train_loss: 0.016604019628062735, valid_loss: 0.017494518203394753\n",
      "SEED: 14, FOLD: 3, EPOCH: 19,train_loss: 0.016215226748944635, valid_loss: 0.017511087097227575\n",
      "SEED: 14, FOLD: 3, EPOCH: 20,train_loss: 0.015749814981309167, valid_loss: 0.01740828968052353\n",
      "SEED: 14, FOLD: 3, EPOCH: 21,train_loss: 0.015286565656318281, valid_loss: 0.0174325093626976\n",
      "SEED: 14, FOLD: 3, EPOCH: 22,train_loss: 0.014781354450668296, valid_loss: 0.01740852567766394\n",
      "SEED: 14, FOLD: 3, EPOCH: 23,train_loss: 0.01435530108202548, valid_loss: 0.017398439294525555\n",
      "SEED: 14, FOLD: 3, EPOCH: 24,train_loss: 0.014105692811745361, valid_loss: 0.017399757674762182\n",
      "(17511, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7363336482187257, valid_loss: 0.7017004983765739\n",
      "SEED: 14, FOLD: 4, EPOCH: 0,train_loss: 0.4690565674626914, valid_loss: 0.023872869621430124\n",
      "SEED: 14, FOLD: 4, EPOCH: 1,train_loss: 0.020858754682606156, valid_loss: 0.01842881685921124\n",
      "SEED: 14, FOLD: 4, EPOCH: 2,train_loss: 0.019104856236355147, valid_loss: 0.018607790182743753\n",
      "SEED: 14, FOLD: 4, EPOCH: 3,train_loss: 0.01862025579070523, valid_loss: 0.017717513628304003\n",
      "SEED: 14, FOLD: 4, EPOCH: 4,train_loss: 0.018117661499520286, valid_loss: 0.01773095732288701\n",
      "SEED: 14, FOLD: 4, EPOCH: 5,train_loss: 0.018066148409606332, valid_loss: 0.017454745673707552\n",
      "SEED: 14, FOLD: 4, EPOCH: 6,train_loss: 0.017981800359476656, valid_loss: 0.017435404791363646\n",
      "SEED: 14, FOLD: 4, EPOCH: 7,train_loss: 0.018007605465768028, valid_loss: 0.01770222019404173\n",
      "SEED: 14, FOLD: 4, EPOCH: 8,train_loss: 0.017935540425135708, valid_loss: 0.017505529123757566\n",
      "SEED: 14, FOLD: 4, EPOCH: 9,train_loss: 0.017916508161727965, valid_loss: 0.0173975246027112\n",
      "SEED: 14, FOLD: 4, EPOCH: 10,train_loss: 0.017904814767794017, valid_loss: 0.017879267462662288\n",
      "SEED: 14, FOLD: 4, EPOCH: 11,train_loss: 0.017826764640418716, valid_loss: 0.01726670419531209\n",
      "SEED: 14, FOLD: 4, EPOCH: 12,train_loss: 0.01779001134101057, valid_loss: 0.01741610507347754\n",
      "SEED: 14, FOLD: 4, EPOCH: 13,train_loss: 0.017668983613541963, valid_loss: 0.017491372408611434\n",
      "SEED: 14, FOLD: 4, EPOCH: 14,train_loss: 0.01755955858142489, valid_loss: 0.01711343912673848\n",
      "SEED: 14, FOLD: 4, EPOCH: 15,train_loss: 0.017407342247719313, valid_loss: 0.01744910499879292\n",
      "SEED: 14, FOLD: 4, EPOCH: 16,train_loss: 0.01724549174906999, valid_loss: 0.017147954526756493\n",
      "SEED: 14, FOLD: 4, EPOCH: 17,train_loss: 0.016994401554230355, valid_loss: 0.017124761720853192\n",
      "SEED: 14, FOLD: 4, EPOCH: 18,train_loss: 0.016752105179059243, valid_loss: 0.01700639950909785\n",
      "SEED: 14, FOLD: 4, EPOCH: 19,train_loss: 0.01637237700531735, valid_loss: 0.016921084986201356\n",
      "SEED: 14, FOLD: 4, EPOCH: 20,train_loss: 0.015981319734323634, valid_loss: 0.017007379473320077\n",
      "SEED: 14, FOLD: 4, EPOCH: 21,train_loss: 0.015472200332059913, valid_loss: 0.016957188583910467\n",
      "SEED: 14, FOLD: 4, EPOCH: 22,train_loss: 0.014965807230476915, valid_loss: 0.016906659784061567\n",
      "SEED: 14, FOLD: 4, EPOCH: 23,train_loss: 0.01453588293851727, valid_loss: 0.01692806290728705\n",
      "SEED: 14, FOLD: 4, EPOCH: 24,train_loss: 0.01428239799383348, valid_loss: 0.016945188732019494\n",
      "(17536, 937)\n",
      "FOLD: 0, EPOCH: 0,train_loss: 0.7376549235225593, valid_loss: 0.709812787600926\n",
      "SEED: 15, FOLD: 0, EPOCH: 0,train_loss: 0.46624566856635746, valid_loss: 0.023241463197129112\n",
      "SEED: 15, FOLD: 0, EPOCH: 1,train_loss: 0.020801155997888884, valid_loss: 0.019296579834605965\n",
      "SEED: 15, FOLD: 0, EPOCH: 2,train_loss: 0.01909979578977736, valid_loss: 0.01864668298512697\n",
      "SEED: 15, FOLD: 0, EPOCH: 3,train_loss: 0.018205851656350778, valid_loss: 0.018234010892254966\n",
      "SEED: 15, FOLD: 0, EPOCH: 4,train_loss: 0.017916952844464432, valid_loss: 0.0185510749529515\n",
      "SEED: 15, FOLD: 0, EPOCH: 5,train_loss: 0.01781340947469873, valid_loss: 0.018310150850032056\n",
      "SEED: 15, FOLD: 0, EPOCH: 6,train_loss: 0.017798401360964253, valid_loss: 0.01847530406500612\n",
      "SEED: 15, FOLD: 0, EPOCH: 7,train_loss: 0.017848462661741858, valid_loss: 0.018443834595382215\n",
      "SEED: 15, FOLD: 0, EPOCH: 8,train_loss: 0.017820376596909805, valid_loss: 0.0183705278805324\n",
      "SEED: 15, FOLD: 0, EPOCH: 9,train_loss: 0.017837853544819964, valid_loss: 0.0182679859655244\n",
      "SEED: 15, FOLD: 0, EPOCH: 10,train_loss: 0.017774864983656546, valid_loss: 0.018103438961718763\n",
      "SEED: 15, FOLD: 0, EPOCH: 11,train_loss: 0.017726688360265138, valid_loss: 0.018406019812183722\n",
      "SEED: 15, FOLD: 0, EPOCH: 12,train_loss: 0.017610474149730517, valid_loss: 0.017911380396357604\n",
      "SEED: 15, FOLD: 0, EPOCH: 13,train_loss: 0.017511521588439924, valid_loss: 0.017870386796338216\n",
      "SEED: 15, FOLD: 0, EPOCH: 14,train_loss: 0.01739579870154823, valid_loss: 0.018148187707577434\n",
      "SEED: 15, FOLD: 0, EPOCH: 15,train_loss: 0.017232384546286, valid_loss: 0.018001042678952216\n",
      "SEED: 15, FOLD: 0, EPOCH: 16,train_loss: 0.017070192653332313, valid_loss: 0.017743448221257754\n",
      "SEED: 15, FOLD: 0, EPOCH: 17,train_loss: 0.016863867117051224, valid_loss: 0.017569086620850223\n",
      "SEED: 15, FOLD: 0, EPOCH: 18,train_loss: 0.016596369200596844, valid_loss: 0.017740210784333094\n",
      "SEED: 15, FOLD: 0, EPOCH: 19,train_loss: 0.016213042342042835, valid_loss: 0.017657427516366755\n",
      "SEED: 15, FOLD: 0, EPOCH: 20,train_loss: 0.01577042850128708, valid_loss: 0.017695734091103078\n",
      "SEED: 15, FOLD: 0, EPOCH: 21,train_loss: 0.015336111364682225, valid_loss: 0.017621818610600064\n",
      "SEED: 15, FOLD: 0, EPOCH: 22,train_loss: 0.014856289385607208, valid_loss: 0.017632064702255385\n",
      "SEED: 15, FOLD: 0, EPOCH: 23,train_loss: 0.014415698520240992, valid_loss: 0.017657360487750597\n",
      "SEED: 15, FOLD: 0, EPOCH: 24,train_loss: 0.014193690538297605, valid_loss: 0.017667615466884206\n",
      "(17541, 937)\n",
      "FOLD: 1, EPOCH: 0,train_loss: 0.7376892726490463, valid_loss: 0.7098238979067121\n",
      "SEED: 15, FOLD: 1, EPOCH: 0,train_loss: 0.46673729420518095, valid_loss: 0.023825046260442052\n",
      "SEED: 15, FOLD: 1, EPOCH: 1,train_loss: 0.020901915077390015, valid_loss: 0.019112011763666358\n",
      "SEED: 15, FOLD: 1, EPOCH: 2,train_loss: 0.019312035130417866, valid_loss: 0.02066106641931193\n",
      "SEED: 15, FOLD: 1, EPOCH: 3,train_loss: 0.018566053826361895, valid_loss: 0.018128314135330063\n",
      "SEED: 15, FOLD: 1, EPOCH: 4,train_loss: 0.018136319461400093, valid_loss: 0.018331519886851312\n",
      "SEED: 15, FOLD: 1, EPOCH: 5,train_loss: 0.01819855432309534, valid_loss: 0.01867175844631025\n",
      "SEED: 15, FOLD: 1, EPOCH: 6,train_loss: 0.018315476000956867, valid_loss: 0.018007727206817696\n",
      "SEED: 15, FOLD: 1, EPOCH: 7,train_loss: 0.01802306900313799, valid_loss: 0.0186343750251191\n",
      "SEED: 15, FOLD: 1, EPOCH: 8,train_loss: 0.01811237343033587, valid_loss: 0.018414652267737048\n",
      "SEED: 15, FOLD: 1, EPOCH: 9,train_loss: 0.018013551628783993, valid_loss: 0.017959759703704288\n",
      "SEED: 15, FOLD: 1, EPOCH: 10,train_loss: 0.018041091599920088, valid_loss: 0.018164569272526673\n",
      "SEED: 15, FOLD: 1, EPOCH: 11,train_loss: 0.018095889385195747, valid_loss: 0.018343430518039636\n",
      "SEED: 15, FOLD: 1, EPOCH: 12,train_loss: 0.017893337145231773, valid_loss: 0.018166678345629145\n",
      "SEED: 15, FOLD: 1, EPOCH: 13,train_loss: 0.017754340247399567, valid_loss: 0.017989267302410943\n",
      "SEED: 15, FOLD: 1, EPOCH: 14,train_loss: 0.017730623449914266, valid_loss: 0.017712224780448847\n",
      "SEED: 15, FOLD: 1, EPOCH: 15,train_loss: 0.017594278196169846, valid_loss: 0.01760301903954574\n",
      "SEED: 15, FOLD: 1, EPOCH: 16,train_loss: 0.017327009437038847, valid_loss: 0.017470468021929263\n",
      "SEED: 15, FOLD: 1, EPOCH: 17,train_loss: 0.01713264926566162, valid_loss: 0.01766403620796544\n",
      "SEED: 15, FOLD: 1, EPOCH: 18,train_loss: 0.016836345762662266, valid_loss: 0.017314951946692806\n",
      "SEED: 15, FOLD: 1, EPOCH: 19,train_loss: 0.01653085161756346, valid_loss: 0.017269272437053066\n",
      "SEED: 15, FOLD: 1, EPOCH: 20,train_loss: 0.016234809897192146, valid_loss: 0.017087342989231858\n",
      "SEED: 15, FOLD: 1, EPOCH: 21,train_loss: 0.01584201592250147, valid_loss: 0.01710760412471635\n",
      "SEED: 15, FOLD: 1, EPOCH: 22,train_loss: 0.015387080940485432, valid_loss: 0.017085112657930168\n",
      "SEED: 15, FOLD: 1, EPOCH: 23,train_loss: 0.015118160973424498, valid_loss: 0.017111271806061267\n",
      "SEED: 15, FOLD: 1, EPOCH: 24,train_loss: 0.014942715268420137, valid_loss: 0.017099269346467088\n",
      "(17620, 937)\n",
      "FOLD: 2, EPOCH: 0,train_loss: 0.7373423412226249, valid_loss: 0.7105596188236686\n",
      "SEED: 15, FOLD: 2, EPOCH: 0,train_loss: 0.46576006020810723, valid_loss: 0.023286946008310598\n",
      "SEED: 15, FOLD: 2, EPOCH: 1,train_loss: 0.020979112284123035, valid_loss: 0.01843488865586765\n",
      "SEED: 15, FOLD: 2, EPOCH: 2,train_loss: 0.019261165454551792, valid_loss: 0.01797318149029332\n",
      "SEED: 15, FOLD: 2, EPOCH: 3,train_loss: 0.01827575173228979, valid_loss: 0.017575785846394652\n",
      "SEED: 15, FOLD: 2, EPOCH: 4,train_loss: 0.017914160593426313, valid_loss: 0.017557847067056334\n",
      "SEED: 15, FOLD: 2, EPOCH: 5,train_loss: 0.017853471443758928, valid_loss: 0.01796295737628551\n",
      "SEED: 15, FOLD: 2, EPOCH: 6,train_loss: 0.017894184932220673, valid_loss: 0.0178441501715604\n",
      "SEED: 15, FOLD: 2, EPOCH: 7,train_loss: 0.017912944920523012, valid_loss: 0.0177481777363402\n",
      "SEED: 15, FOLD: 2, EPOCH: 8,train_loss: 0.017935838887764923, valid_loss: 0.01744059963590082\n",
      "SEED: 15, FOLD: 2, EPOCH: 9,train_loss: 0.017856082379602005, valid_loss: 0.017829012290081558\n",
      "SEED: 15, FOLD: 2, EPOCH: 10,train_loss: 0.01792179392920672, valid_loss: 0.01747706118861542\n",
      "SEED: 15, FOLD: 2, EPOCH: 11,train_loss: 0.01778149995547922, valid_loss: 0.017596627530806205\n",
      "SEED: 15, FOLD: 2, EPOCH: 12,train_loss: 0.017773599451596754, valid_loss: 0.017608819447238657\n",
      "SEED: 15, FOLD: 2, EPOCH: 13,train_loss: 0.017627954793473084, valid_loss: 0.01749254694646772\n",
      "SEED: 15, FOLD: 2, EPOCH: 14,train_loss: 0.017492888832761757, valid_loss: 0.017502872163758558\n",
      "SEED: 15, FOLD: 2, EPOCH: 15,train_loss: 0.01740032747603845, valid_loss: 0.017342778525370008\n",
      "SEED: 15, FOLD: 2, EPOCH: 16,train_loss: 0.01719789451285117, valid_loss: 0.017348477534730646\n",
      "SEED: 15, FOLD: 2, EPOCH: 17,train_loss: 0.01694603763061805, valid_loss: 0.017390842193408924\n",
      "SEED: 15, FOLD: 2, EPOCH: 18,train_loss: 0.016658979036129902, valid_loss: 0.017164911335224613\n",
      "SEED: 15, FOLD: 2, EPOCH: 19,train_loss: 0.016321283798880766, valid_loss: 0.01722884547951467\n",
      "SEED: 15, FOLD: 2, EPOCH: 20,train_loss: 0.015890258850286835, valid_loss: 0.017068659010178903\n",
      "SEED: 15, FOLD: 2, EPOCH: 21,train_loss: 0.015419743610950916, valid_loss: 0.017140055732691988\n",
      "SEED: 15, FOLD: 2, EPOCH: 22,train_loss: 0.014897370110333397, valid_loss: 0.0170487916261396\n",
      "SEED: 15, FOLD: 2, EPOCH: 23,train_loss: 0.014463844196196052, valid_loss: 0.017069479834069225\n",
      "SEED: 15, FOLD: 2, EPOCH: 24,train_loss: 0.01419994550878587, valid_loss: 0.017041405471151367\n",
      "(17538, 937)\n",
      "FOLD: 3, EPOCH: 0,train_loss: 0.7374413441056791, valid_loss: 0.7138678669929505\n",
      "SEED: 15, FOLD: 3, EPOCH: 0,train_loss: 0.46631716158025077, valid_loss: 0.025676655769348144\n",
      "SEED: 15, FOLD: 3, EPOCH: 1,train_loss: 0.02120939420833104, valid_loss: 0.01973083285348756\n",
      "SEED: 15, FOLD: 3, EPOCH: 2,train_loss: 0.019471315275607765, valid_loss: 0.02374982801931245\n",
      "SEED: 15, FOLD: 3, EPOCH: 3,train_loss: 0.019577595634736877, valid_loss: 0.019098907709121704\n",
      "SEED: 15, FOLD: 3, EPOCH: 4,train_loss: 0.01868732494936473, valid_loss: 0.01822459234723023\n",
      "SEED: 15, FOLD: 3, EPOCH: 5,train_loss: 0.018378496075561947, valid_loss: 0.018530422236238207\n",
      "SEED: 15, FOLD: 3, EPOCH: 6,train_loss: 0.018152974917134947, valid_loss: 0.018099034737263407\n",
      "SEED: 15, FOLD: 3, EPOCH: 7,train_loss: 0.018077800907464563, valid_loss: 0.01893417297729424\n",
      "SEED: 15, FOLD: 3, EPOCH: 8,train_loss: 0.018092474407529917, valid_loss: 0.017995366720216614\n",
      "SEED: 15, FOLD: 3, EPOCH: 9,train_loss: 0.01777518709001226, valid_loss: 0.017947665016566004\n",
      "SEED: 15, FOLD: 3, EPOCH: 10,train_loss: 0.01784677428962744, valid_loss: 0.018126871596489635\n",
      "SEED: 15, FOLD: 3, EPOCH: 11,train_loss: 0.017754418775439262, valid_loss: 0.018589643016457557\n",
      "SEED: 15, FOLD: 3, EPOCH: 12,train_loss: 0.01772407543562029, valid_loss: 0.01795307206256049\n",
      "SEED: 15, FOLD: 3, EPOCH: 13,train_loss: 0.017592179551855592, valid_loss: 0.017954922627125468\n",
      "SEED: 15, FOLD: 3, EPOCH: 14,train_loss: 0.017458344499270122, valid_loss: 0.018052093418581144\n",
      "SEED: 15, FOLD: 3, EPOCH: 15,train_loss: 0.017540249447135822, valid_loss: 0.01787129363843373\n",
      "SEED: 15, FOLD: 3, EPOCH: 16,train_loss: 0.017398611021538574, valid_loss: 0.017571179941296578\n",
      "SEED: 15, FOLD: 3, EPOCH: 17,train_loss: 0.017051027851530176, valid_loss: 0.017387708090245722\n",
      "SEED: 15, FOLD: 3, EPOCH: 18,train_loss: 0.016658727174111897, valid_loss: 0.017391295757676874\n",
      "SEED: 15, FOLD: 3, EPOCH: 19,train_loss: 0.016258117142200903, valid_loss: 0.017373136643852507\n",
      "SEED: 15, FOLD: 3, EPOCH: 20,train_loss: 0.01593337743880524, valid_loss: 0.017200252546795778\n",
      "SEED: 15, FOLD: 3, EPOCH: 21,train_loss: 0.015426528032707132, valid_loss: 0.017268266794937\n",
      "SEED: 15, FOLD: 3, EPOCH: 22,train_loss: 0.01488382144547675, valid_loss: 0.017240001527326448\n",
      "SEED: 15, FOLD: 3, EPOCH: 23,train_loss: 0.014689626712082089, valid_loss: 0.017273251632494584\n",
      "SEED: 15, FOLD: 3, EPOCH: 24,train_loss: 0.014367722690213417, valid_loss: 0.017276990493493422\n",
      "(17557, 937)\n",
      "FOLD: 4, EPOCH: 0,train_loss: 0.7374171718307163, valid_loss: 0.7118211524827139\n",
      "SEED: 15, FOLD: 4, EPOCH: 0,train_loss: 0.4667678267789492, valid_loss: 0.02310302582170282\n",
      "SEED: 15, FOLD: 4, EPOCH: 1,train_loss: 0.020865873946551827, valid_loss: 0.018828685714730193\n",
      "SEED: 15, FOLD: 4, EPOCH: 2,train_loss: 0.01894966534514358, valid_loss: 0.017823924416942256\n",
      "SEED: 15, FOLD: 4, EPOCH: 3,train_loss: 0.01831596865710141, valid_loss: 0.01787754464894533\n",
      "SEED: 15, FOLD: 4, EPOCH: 4,train_loss: 0.018049746853015993, valid_loss: 0.017816809378564356\n",
      "SEED: 15, FOLD: 4, EPOCH: 5,train_loss: 0.01793048713032318, valid_loss: 0.01779872107186488\n",
      "SEED: 15, FOLD: 4, EPOCH: 6,train_loss: 0.01803675786578569, valid_loss: 0.018305551393755844\n",
      "SEED: 15, FOLD: 4, EPOCH: 7,train_loss: 0.01798393835813023, valid_loss: 0.017886979984385626\n",
      "SEED: 15, FOLD: 4, EPOCH: 8,train_loss: 0.01791299710833076, valid_loss: 0.018154884316027166\n",
      "SEED: 15, FOLD: 4, EPOCH: 9,train_loss: 0.017952032933902483, valid_loss: 0.017844689610813345\n",
      "SEED: 15, FOLD: 4, EPOCH: 10,train_loss: 0.017882862378019785, valid_loss: 0.0178513551396983\n",
      "SEED: 15, FOLD: 4, EPOCH: 11,train_loss: 0.017803381433359522, valid_loss: 0.0178023686632514\n",
      "SEED: 15, FOLD: 4, EPOCH: 12,train_loss: 0.017753588258410277, valid_loss: 0.017608613813562053\n",
      "SEED: 15, FOLD: 4, EPOCH: 13,train_loss: 0.01771328878332523, valid_loss: 0.017654881892459732\n",
      "SEED: 15, FOLD: 4, EPOCH: 14,train_loss: 0.01752010327966317, valid_loss: 0.01742258577474526\n",
      "SEED: 15, FOLD: 4, EPOCH: 15,train_loss: 0.0173595506441442, valid_loss: 0.017618265748023988\n",
      "SEED: 15, FOLD: 4, EPOCH: 16,train_loss: 0.017259516382077032, valid_loss: 0.01733165918184178\n",
      "SEED: 15, FOLD: 4, EPOCH: 17,train_loss: 0.01704897427175572, valid_loss: 0.017237784207931588\n",
      "SEED: 15, FOLD: 4, EPOCH: 18,train_loss: 0.016650082131820745, valid_loss: 0.017209427883582457\n",
      "SEED: 15, FOLD: 4, EPOCH: 19,train_loss: 0.016308164278018303, valid_loss: 0.017227253637143544\n",
      "SEED: 15, FOLD: 4, EPOCH: 20,train_loss: 0.01599400775993, valid_loss: 0.01722417910184179\n",
      "SEED: 15, FOLD: 4, EPOCH: 21,train_loss: 0.015475602381849203, valid_loss: 0.017093767412006855\n",
      "SEED: 15, FOLD: 4, EPOCH: 22,train_loss: 0.015023850822362347, valid_loss: 0.017068336504910672\n",
      "SEED: 15, FOLD: 4, EPOCH: 23,train_loss: 0.01460673896919774, valid_loss: 0.017085408712072033\n",
      "SEED: 15, FOLD: 4, EPOCH: 24,train_loss: 0.01438290705445452, valid_loss: 0.0170723773006882\n"
     ]
    }
   ],
   "source": [
    "# Averaging on multiple SEEDS\n",
    "for seed in SEED:\n",
    "    seed_everything(seed=seed)\n",
    "    folds = train0.copy()\n",
    "    feature_cols = dp(feature_cols0)\n",
    "    \n",
    "    # kfold - leave drug out\n",
    "    target2 = target.copy()\n",
    "    dct1 = {}; dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n",
    "    tmp = target2.groupby('drug_id')[target_cols].mean().loc[vc1]\n",
    "    tmp_idx = tmp.index.tolist()\n",
    "    tmp_idx.sort()\n",
    "    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n",
    "    tmp = tmp.loc[tmp_idx2]\n",
    "    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values}\n",
    "        dct1.update(dd)\n",
    "\n",
    "    # STRATIFY DRUGS MORE THAN 19X\n",
    "    skf = MultilabelStratifiedKFold(n_splits = 5) # , shuffle = True, random_state = seed\n",
    "    tmp = target2.loc[target2.drug_id.isin(vc2)].reset_index(drop = True)\n",
    "    tmp_idx = tmp.index.tolist()\n",
    "    tmp_idx.sort()\n",
    "    tmp_idx2 = random.sample(tmp_idx,len(tmp_idx))\n",
    "    tmp = tmp.loc[tmp_idx2]\n",
    "    for fold,(idxT,idxV) in enumerate(skf.split(tmp,tmp[target_cols])):\n",
    "        dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "        dct2.update(dd)\n",
    "\n",
    "    target2['kfold'] = target2.drug_id.map(dct1)\n",
    "    target2.loc[target2.kfold.isna(),'kfold'] = target2.loc[target2.kfold.isna(),'sig_id'].map(dct2)\n",
    "    target2.kfold = target2.kfold.astype(int)\n",
    "\n",
    "    folds['kfold'] = target2['kfold'].copy()\n",
    "\n",
    "    train = folds.copy()\n",
    "    test_ = test.copy()\n",
    "\n",
    " \n",
    "    \n",
    "    tar_freq = np.array([np.min(list(g_table(train[target_cols].iloc[:,i]).values())) for i in range(len(target_cols))])\n",
    "    tar_weight0 = np.array([np.log(i+100) for i in tar_freq])\n",
    "    tar_weight0_min = dp(np.min(tar_weight0))\n",
    "    tar_weight = tar_weight0_min/tar_weight0\n",
    "    pos_weight = torch.tensor(tar_weight).to(DEVICE)\n",
    "\n",
    "\n",
    "    oof_, predictions_ = run_k_fold(NFOLDS, seed, train, test_, pos_weight)\n",
    "    oof += oof_ / len(SEED)\n",
    "    predictions += predictions_ / len(SEED)\n",
    "    \n",
    "    oof_tmp = dp(oof)\n",
    "    oof_tmp = oof_tmp * len(SEED) / (SEED.index(seed)+1)\n",
    "    sc_dic[seed] = np.mean([log_loss(train[target_cols].iloc[:,i],oof_tmp[:,i]) for i in range(len(target_cols))])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.017223512168052894, 1: 0.01697182150896404, 2: 0.016896567752147998, 3: 0.01684248535754461, 4: 0.016799085029176982, 5: 0.01677708318126701, 6: 0.016759477996880438, 7: 0.016755402930102734, 8: 0.01674692335089487, 9: 0.016741782538587168, 10: 0.016730602098595813, 11: 0.016726474930070373, 12: 0.01672244407588409, 13: 0.01672248669966805, 14: 0.0167219164503182, 15: 0.016717577179875657}\n"
     ]
    }
   ],
   "source": [
    "print(sc_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016717577179875657\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print(np.mean([log_loss(train[target_cols].iloc[:,i],oof[:,i]) for i in range(len(target_cols))]))\n",
    "\n",
    "train0[target_cols] = oof\n",
    "test[target_cols] = predictions\n",
    "\n",
    "### for blend test ###\n",
    "train0.to_csv('train_pred.csv', index=False)\n",
    "### for blend test ###\n",
    "\n",
    "sub = sample_submission.drop(columns=target_cols).merge(test[['sig_id']+target_cols], on='sig_id', how='left').fillna(0)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Newly added stuff here to test out the idea\n",
    "1. load the model\n",
    "2. take only the first layer of the input (after reshape)\n",
    "3. (since it a pseudo image) lets apply data augmentation, use all training data for this (there will be k-fold later but maybe we don't need to care rn)\n",
    "(branch choices)\n",
    "a. fine tune the FCN part by freezing the first MLP layer to reshape\n",
    "b. have a new model CNN model or something (check other kaggle)\n",
    "c. reconstruct it using encoder and feed it to tabNet or something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df and valid_df is dataframe ready to be trained after kfold is done \n",
    "# or it could also be the whole train dataset for data augmentation\n",
    "def preprocessData(x_train, x_valid=None, x_test=None):\n",
    "    assert x_train is not None, \"x_train must not be None\"\n",
    "    #------------ norm --------------\n",
    "    col_num = list(set(feat_dic['gene'] + feat_dic['cell']) & set(feature_cols))\n",
    "    col_num.sort()\n",
    "    x_train[col_num],ss = norm_fit(x_train[col_num],True,'quan')\n",
    "    \n",
    "    if x_valid is not None:\n",
    "        x_valid[col_num]    = norm_tra(x_valid[col_num],ss)\n",
    "        \n",
    "    if x_test is not None:\n",
    "        x_test[col_num]     = norm_tra(x_test[col_num],ss)\n",
    "\n",
    "    #------------ pca --------------\n",
    "    def pca_pre(tr,va,te,\n",
    "                n_comp,feat_raw,feat_new):\n",
    "        tr2 = None \n",
    "        va2 = None\n",
    "        te2 = None\n",
    "        pca = PCA(n_components=n_comp, random_state=42)\n",
    "        tr2 = pd.DataFrame(pca.fit_transform(tr[feat_raw]),columns=feat_new)\n",
    "        if va is not None:\n",
    "            va2 = pd.DataFrame(pca.transform(va[feat_raw]),columns=feat_new)\n",
    "\n",
    "        if te is not None:\n",
    "            te2 = pd.DataFrame(pca.transform(te[feat_raw]),columns=feat_new)\n",
    "\n",
    "        return(tr2,va2,te2)\n",
    "\n",
    "\n",
    "    pca_feat_g = [f'pca_G-{i}' for i in range(n_comp1)]\n",
    "    feat_dic['pca_g'] = pca_feat_g\n",
    "    x_tr_g_pca, x_va_g_pca, x_te_g_pca = pca_pre(x_train,x_valid,x_test,\n",
    "                                                n_comp1,feat_dic['gene'],pca_feat_g)\n",
    "    \n",
    "    x_train = pd.concat([x_train,x_tr_g_pca],axis = 1)\n",
    "    if x_valid is not None:\n",
    "        x_valid = pd.concat([x_valid,x_va_g_pca],axis = 1)\n",
    "\n",
    "    if x_test is not None:\n",
    "        x_test  = pd.concat([x_test,x_te_g_pca],axis = 1)\n",
    "\n",
    "    pca_feat_g = [f'pca_C-{i}' for i in range(n_comp2)]\n",
    "    feat_dic['pca_c'] = pca_feat_g\n",
    "    x_tr_c_pca,x_va_c_pca,x_te_c_pca = pca_pre(x_train,x_valid,x_test,\n",
    "                                                n_comp2,feat_dic['cell'],pca_feat_g)\n",
    "    \n",
    "    x_train_pre = None\n",
    "    x_valid_pre = None\n",
    "    x_test_pre = None\n",
    "\n",
    "    x_train = pd.concat([x_train,x_tr_c_pca],axis = 1)\n",
    "    x_train_pre = x_train.values\n",
    "\n",
    "    if x_valid is not None:\n",
    "        x_valid = pd.concat([x_valid,x_va_c_pca],axis = 1)\n",
    "        x_valid_pre = x_valid.values\n",
    "\n",
    "    if x_test is not None:\n",
    "        x_test  = pd.concat([x_test,x_te_c_pca], axis = 1)\n",
    "        x_test_pre = x_test.values\n",
    "\n",
    "    print(x_train_pre.shape)\n",
    "\n",
    "    # return preprocessed data \n",
    "    return x_train_pre, x_valid_pre, x_test_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 937)\n",
      "[[ 1.11131675  0.89035944 -0.43197694 ... -0.58240415 -1.26113787\n",
      "   0.09958907]\n",
      " [ 0.11782169  0.66961362  0.26188399 ... -0.15785287  0.58990842\n",
      "  -0.26198874]\n",
      " [ 0.78636997  0.95889742  1.43716156 ... -0.1033361   1.67417345\n",
      "  -0.99816694]\n",
      " ...\n",
      " [-1.94902713  0.56332567 -0.59266583 ...  1.56667931 -1.85958986\n",
      "   0.78132428]\n",
      " [ 0.73121725  0.26566306  0.32119296 ...  1.95293467  0.33389567\n",
      "  -0.1134507 ]\n",
      " [-1.25377336  1.56726322 -0.27624082 ...  0.56235807  2.95709886\n",
      "   0.28014344]]\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x708b595f4fa0>\n",
      "{'x': tensor([[-0.1676, -1.1309,  0.4490,  ..., -0.2744,  0.8637, -0.2961],\n",
      "        [ 0.8728, -0.0150, -0.6280,  ..., -2.1324, -0.8250, -0.5886],\n",
      "        [-0.2570, -0.2933,  0.3753,  ..., -1.5175, -0.0347,  0.6243],\n",
      "        ...,\n",
      "        [-0.2161, -0.0765,  0.5519,  ...,  0.7104,  1.8340,  0.7389],\n",
      "        [ 0.2131, -1.6337, -0.7205,  ...,  0.0070, -1.7594, -1.7497],\n",
      "        [-0.2761,  0.7741,  0.9154,  ...,  0.6843, -0.2516, -0.4210]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1537, -1.6827,  0.8938,  ..., -0.4786,  0.2020,  0.0299],\n",
      "        [-1.3163, -1.9838,  1.2226,  ...,  0.9216, -0.2517,  0.5610],\n",
      "        [-0.6377, -1.0890,  1.4211,  ...,  0.7123,  1.7108,  1.9423],\n",
      "        ...,\n",
      "        [-0.6832,  1.3384, -0.0431,  ...,  1.4195,  0.2963, -0.3737],\n",
      "        [ 0.7948,  0.2862, -1.4216,  ...,  2.0413,  0.0328,  2.1222],\n",
      "        [ 0.4794,  0.8316,  0.0547,  ...,  0.5539,  1.2558, -1.0951]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8871, -0.1162, -0.8581,  ..., -0.5707,  1.3990, -0.6354],\n",
      "        [-0.6884,  0.1911, -0.1794,  ..., -0.3893, -0.8203, -1.0859],\n",
      "        [-0.3965, -1.9519,  0.0033,  ..., -3.0387,  2.8020, -3.1898],\n",
      "        ...,\n",
      "        [ 0.4146,  1.0816,  0.0617,  ...,  0.0086,  1.5790, -0.6877],\n",
      "        [-0.8781, -0.8354, -0.3540,  ..., -0.7508, -1.5926, -0.0903],\n",
      "        [ 0.0680, -0.3452, -0.5349,  ...,  0.7790, -0.7666,  0.1018]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.1745,  0.8824, -0.4541,  ...,  2.0623, -1.6417,  1.7403],\n",
      "        [ 1.6410,  0.7374,  1.9693,  ...,  0.6092, -0.9787, -0.6887],\n",
      "        [ 0.3028,  0.3852,  0.8774,  ...,  0.7084,  0.0967, -0.4513],\n",
      "        ...,\n",
      "        [ 0.7940,  0.7554,  0.9276,  ...,  0.3519, -0.2416, -0.3521],\n",
      "        [ 0.7063,  0.2176,  0.5133,  ...,  0.4108, -0.9252, -1.1548],\n",
      "        [-0.5367, -0.2829, -0.1691,  ..., -0.5369,  0.9260, -0.2580]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-8.5734e-02, -1.2442e+00,  2.3018e+00,  ..., -9.1413e-01,\n",
      "         -1.8083e-01,  1.2957e-02],\n",
      "        [-1.1093e+00, -5.5601e-01,  7.0282e-01,  ...,  2.8518e-04,\n",
      "          4.1778e-01, -1.8705e+00],\n",
      "        [ 2.6223e-01,  2.2813e-01,  6.6063e-02,  ..., -5.0831e-01,\n",
      "          9.4711e-01, -6.9655e-01],\n",
      "        ...,\n",
      "        [ 2.6767e-01,  8.1112e-01, -5.3578e-01,  ...,  1.0695e+00,\n",
      "         -2.0002e+00, -1.0349e+00],\n",
      "        [-9.7088e-01,  2.3413e+00, -2.0007e-01,  ...,  1.2134e+00,\n",
      "         -5.3832e-01,  3.1143e-01],\n",
      "        [-1.2122e+00, -5.0455e-01,  1.0327e+00,  ...,  3.4256e-01,\n",
      "         -3.8388e-02, -2.1710e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5641, -0.6062, -0.5912,  ...,  0.0112, -2.2142,  0.3084],\n",
      "        [-0.3803,  1.3234,  0.6988,  ...,  0.1638,  0.6768,  0.2669],\n",
      "        [-0.3301, -0.4674, -0.0418,  ..., -0.3404,  0.4953,  0.0515],\n",
      "        ...,\n",
      "        [-0.4234, -0.0698, -0.4457,  ..., -0.8166, -0.4078, -0.8899],\n",
      "        [ 0.6373,  1.1186,  0.7860,  ..., -1.3834, -0.5351, -0.0791],\n",
      "        [ 0.2869, -0.5398, -1.3055,  ...,  1.3761, -1.0516, -0.6430]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.3852, -0.2974, -0.8071,  ...,  1.2895,  0.3795,  0.7989],\n",
      "        [-0.6830, -1.2454,  0.1537,  ..., -0.0830,  1.2742, -0.5997],\n",
      "        [ 1.2432, -0.3023, -2.2927,  ..., -0.0845, -0.2560,  0.4604],\n",
      "        ...,\n",
      "        [ 1.6084,  0.7670, -0.0313,  ...,  0.8772, -0.1745, -2.0247],\n",
      "        [ 0.0380,  0.6449, -0.6548,  ..., -0.4159, -0.7750,  1.5491],\n",
      "        [ 0.6565, -0.5597, -0.5145,  ..., -0.0715, -1.2942,  0.2407]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 2.3274, -0.8954,  0.6378,  ..., -0.4029,  3.9007, -1.1926],\n",
      "        [-0.7312,  0.8165,  0.5248,  ...,  0.8223,  0.1616, -0.1448],\n",
      "        [-0.0415,  0.2719, -0.7513,  ...,  1.0582,  0.4699,  0.2499],\n",
      "        ...,\n",
      "        [ 0.2750,  1.0808, -0.7895,  ..., -1.3910,  0.6896,  0.5847],\n",
      "        [-0.2942, -0.4733,  1.5893,  ..., -0.4933, -0.0146, -0.0688],\n",
      "        [-1.8028, -2.3884,  1.1571,  ..., -0.3533,  0.4506,  0.5682]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8666, -0.3049, -0.0454,  ...,  0.5622,  0.1285, -0.8888],\n",
      "        [ 1.1024,  1.6936,  1.3749,  ...,  0.0410, -2.6396,  1.4789],\n",
      "        [ 0.0760,  0.8680,  0.6033,  ...,  1.5215, -0.2353, -0.0665],\n",
      "        ...,\n",
      "        [ 0.3659, -0.8560,  0.6742,  ...,  1.5630, -1.6208,  0.1231],\n",
      "        [ 0.2575, -0.0687, -0.3922,  ..., -0.5070, -0.1904, -0.2426],\n",
      "        [ 0.0224,  0.1275, -0.5128,  ..., -0.1986, -0.2943, -1.7671]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-3.0616e-01,  2.3609e-01, -2.3010e-01,  ...,  7.8213e-01,\n",
      "         -3.9512e-05, -1.1349e+00],\n",
      "        [ 8.3126e-01,  6.5755e-01, -9.0606e-02,  ..., -1.5425e+00,\n",
      "          1.2188e+00, -1.7894e+00],\n",
      "        [ 7.3289e-01,  2.5814e-01, -1.2381e+00,  ..., -2.0583e+00,\n",
      "         -6.9156e-01, -1.4693e+00],\n",
      "        ...,\n",
      "        [ 1.0604e+00,  1.8553e-01,  4.3544e-01,  ...,  1.8118e+00,\n",
      "         -3.2492e-01,  9.8076e-01],\n",
      "        [ 1.1147e-01, -4.0116e-01,  4.2449e-01,  ...,  1.9171e+00,\n",
      "         -6.8174e-01,  1.8374e-01],\n",
      "        [-1.2647e+00,  1.5373e+00,  1.5890e-01,  ...,  5.6053e-02,\n",
      "         -8.2977e-01, -4.6972e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0656,  0.4804,  2.3567,  ...,  1.0082,  1.0349, -0.6784],\n",
      "        [-1.2279, -0.0671, -0.4717,  ...,  0.8690, -0.1679, -0.1527],\n",
      "        [ 0.1966,  0.5955,  1.0207,  ..., -0.6102,  0.3067,  0.5381],\n",
      "        ...,\n",
      "        [ 0.7976,  1.3748, -0.6953,  ...,  0.1969, -0.1603, -0.0611],\n",
      "        [-0.5080,  0.2514,  1.0518,  ..., -0.0497,  0.1189,  1.7518],\n",
      "        [ 0.5836,  0.4886, -0.5694,  ..., -1.6314,  0.2898, -1.4998]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.6006,  0.0301, -1.3647,  ..., -2.0968,  1.7222, -0.3747],\n",
      "        [ 0.2431,  0.2691,  0.7847,  ..., -1.1821, -0.5784,  1.0768],\n",
      "        [-0.4142,  0.4338,  0.7242,  ..., -0.1202, -1.0601, -1.2207],\n",
      "        ...,\n",
      "        [ 0.5411,  0.2413,  0.7954,  ...,  1.5335, -0.6634,  0.8921],\n",
      "        [-1.7234,  0.4594, -1.4642,  ...,  1.1273, -0.1204,  0.3269],\n",
      "        [-0.6024,  0.9005,  0.8734,  ..., -0.1872,  0.8219,  1.2177]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.9773,  0.4305,  0.9037,  ..., -1.4743, -0.0170,  0.7489],\n",
      "        [-0.3777,  0.2488, -0.4172,  ...,  0.4034,  0.5446,  0.1505],\n",
      "        [-1.4344, -0.5545,  0.5723,  ..., -0.8242,  2.4753,  0.0507],\n",
      "        ...,\n",
      "        [-0.0334, -1.6834, -0.1551,  ...,  0.8135, -0.7495, -1.2871],\n",
      "        [ 1.3802,  0.4237, -1.1743,  ...,  0.7963,  0.4512, -0.4782],\n",
      "        [ 0.4892,  1.5940, -0.1575,  ...,  0.6360,  1.9452,  0.2696]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4981, -1.6448,  0.9558,  ...,  0.7500, -1.5570,  1.6135],\n",
      "        [ 0.3741,  0.5230, -1.4530,  ..., -1.9228,  1.0490, -0.7710],\n",
      "        [-0.2062, -0.3673, -1.7284,  ..., -0.2176,  0.1209,  0.2803],\n",
      "        ...,\n",
      "        [-0.9434, -1.9196,  1.5680,  ..., -0.0125, -1.8018,  0.9299],\n",
      "        [-0.3276, -0.4566,  0.2201,  ..., -1.1766, -0.2678,  0.8246],\n",
      "        [ 1.0316,  0.9744,  1.3352,  ...,  0.9164,  0.1904, -0.8633]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0604,  0.6250,  0.7196,  ...,  1.3898,  0.0185, -0.3622],\n",
      "        [ 1.2621, -1.0906, -0.4501,  ..., -0.2920,  1.4220, -0.7301],\n",
      "        [-0.0459,  0.0640, -0.7061,  ..., -0.2647, -1.1937, -0.3639],\n",
      "        ...,\n",
      "        [ 1.6586,  2.0839,  0.7945,  ...,  0.2076,  0.2726, -1.2051],\n",
      "        [-0.8709, -0.5824,  1.7716,  ..., -0.5497, -0.0893, -0.5085],\n",
      "        [ 1.1552, -0.4953,  0.8911,  ..., -2.9842, -1.2664,  2.9066]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3974,  0.8756, -0.8418,  ..., -1.1222,  0.7612, -1.5127],\n",
      "        [ 0.8426, -1.1537,  1.9173,  ...,  1.2699, -0.8612, -0.5450],\n",
      "        [-0.8281,  0.6823,  0.7648,  ..., -1.7547, -0.8619, -0.0467],\n",
      "        ...,\n",
      "        [ 0.2513, -1.9687,  2.3423,  ...,  0.4580, -1.0523, -0.6272],\n",
      "        [-0.1701,  1.3596, -0.2098,  ..., -0.2001, -0.7693,  1.4714],\n",
      "        [ 0.4883, -0.2576, -0.6651,  ..., -0.1521, -2.0837, -0.2279]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4258, -0.0978, -0.9482,  ..., -0.5429,  0.6909, -1.7241],\n",
      "        [ 0.3161, -0.1727, -0.5097,  ...,  1.6733, -0.4432, -0.7674],\n",
      "        [-0.7589,  0.0592, -0.8554,  ..., -0.1498, -1.6040, -0.4648],\n",
      "        ...,\n",
      "        [-0.0411,  0.0398, -0.7042,  ..., -0.6802,  0.3776, -0.2959],\n",
      "        [-0.2415,  0.9404,  0.3203,  ..., -0.1212, -0.0191,  0.3758],\n",
      "        [-1.0898,  0.8537,  0.7921,  ..., -0.0560, -0.1017, -2.7404]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7979, -0.1014,  1.4001,  ...,  1.0086, -1.8104, -0.3349],\n",
      "        [-0.0349, -1.0264,  1.1924,  ..., -1.6372, -1.4010,  4.5633],\n",
      "        [-2.0325, -1.3637,  1.4734,  ..., -0.9761, -1.8304, -0.5099],\n",
      "        ...,\n",
      "        [ 0.2808,  1.6435,  2.2521,  ..., -1.9732, -0.2066, -1.8302],\n",
      "        [-0.9194, -0.7792, -0.3473,  ..., -1.9708, -0.5828, -0.5367],\n",
      "        [-0.5350, -1.5687,  0.1961,  ...,  0.0496,  0.5866,  0.1598]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.7999, -0.4587, -0.3760,  ...,  0.7255, -0.2572,  0.2113],\n",
      "        [ 1.8806,  1.2577,  0.3609,  ...,  1.1527, -1.6659,  0.0644],\n",
      "        [-0.2221, -1.3925, -1.0666,  ..., -1.2549,  0.7318, -0.0767],\n",
      "        ...,\n",
      "        [ 1.3113, -0.1453,  0.9503,  ..., -1.0767,  0.1269,  1.6970],\n",
      "        [ 0.9831, -1.0340,  0.2241,  ..., -0.3858, -0.5840, -0.2745],\n",
      "        [ 0.7651,  0.7698,  0.4709,  ...,  1.9911, -0.4228,  0.5141]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-2.0377, -0.4962, -0.0679,  ..., -1.0387,  0.0069, -0.0795],\n",
      "        [ 0.5826, -0.6972, -0.0654,  ...,  0.3423,  0.7022, -0.9559],\n",
      "        [-0.6979,  0.6783,  0.0039,  ...,  0.3221, -0.1039, -0.6200],\n",
      "        ...,\n",
      "        [-0.5419,  0.6225, -1.8447,  ..., -0.0049,  0.0988, -0.4730],\n",
      "        [-0.3478,  0.7081,  0.3747,  ..., -1.0990,  1.3757,  0.8296],\n",
      "        [-0.3221,  0.6984, -0.6405,  ...,  0.3097,  0.4442,  0.5700]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3263, -0.1337, -0.3488,  ..., -0.3754,  1.2724,  0.9158],\n",
      "        [ 1.6247,  0.1414,  0.6175,  ..., -0.7378, -2.0677, -2.1027],\n",
      "        [-0.0201, -0.8602, -0.8441,  ...,  0.0134, -0.0485,  0.9061],\n",
      "        ...,\n",
      "        [-0.1134,  1.0162,  0.0109,  ...,  0.2713, -0.5735,  0.0213],\n",
      "        [ 0.2412, -1.1432,  1.6250,  ...,  1.3395,  1.9525, -0.6847],\n",
      "        [-0.1314,  0.4772, -0.8581,  ..., -0.2778, -0.6113, -0.3672]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5913, -0.0502, -0.6710,  ...,  0.9753,  2.1660, -0.8266],\n",
      "        [ 1.3728,  0.2372, -0.7352,  ..., -0.2375, -1.8445, -1.6212],\n",
      "        [-1.7364, -1.7082, -2.3453,  ...,  2.7539, -0.4622, -0.2388],\n",
      "        ...,\n",
      "        [ 0.3701, -2.0284,  0.6923,  ...,  0.2830, -0.1993, -0.8949],\n",
      "        [ 1.3798, -0.5440,  2.0395,  ..., -0.0389,  0.3984, -0.4894],\n",
      "        [ 1.1553,  0.8471, -0.2125,  ..., -0.1892,  0.9689,  0.5903]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3012, -1.0498, -0.3313,  ..., -0.6000, -2.2232,  0.0094],\n",
      "        [-0.0886, -0.4253, -0.3815,  ...,  1.4806,  0.4634, -0.8615],\n",
      "        [ 0.1201, -1.2536,  0.2790,  ...,  0.0464,  0.6732,  0.1742],\n",
      "        ...,\n",
      "        [ 0.2164, -0.7075,  0.8940,  ...,  0.1879,  1.0103, -0.0054],\n",
      "        [ 1.6451,  1.6082,  0.8435,  ...,  1.1834,  0.5286, -0.1388],\n",
      "        [-0.8019, -0.0891, -1.0628,  ..., -0.1507,  1.7507,  0.8945]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8286,  2.0200, -0.2146,  ...,  0.3585,  0.2112, -0.2034],\n",
      "        [ 0.3545, -0.4183,  0.9715,  ..., -0.4430,  0.0265, -2.2588],\n",
      "        [-0.5769, -1.2491, -0.7603,  ...,  0.4571, -0.4104, -1.4082],\n",
      "        ...,\n",
      "        [ 0.8928,  2.0732, -1.2235,  ...,  0.1208,  0.5583, -1.0939],\n",
      "        [ 0.3669,  0.1772,  1.3831,  ..., -1.1407, -0.7621, -1.0988],\n",
      "        [ 0.4080,  0.5745,  0.9526,  ..., -0.1150, -0.8811, -0.8265]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0475,  0.6426, -0.0593,  ..., -0.5745, -0.9098, -0.2337],\n",
      "        [-0.3384, -0.1902,  0.3530,  ..., -0.7539,  0.7608,  0.4006],\n",
      "        [ 1.4371, -0.5835,  0.3602,  ..., -1.5013,  0.8485, -1.4068],\n",
      "        ...,\n",
      "        [ 0.7782,  1.1961, -0.6388,  ..., -0.5036,  0.4706, -0.1917],\n",
      "        [ 1.0491,  0.1525, -0.8450,  ...,  0.5647,  0.5399, -1.3220],\n",
      "        [-0.6087,  0.6763, -0.7584,  ...,  0.1566, -1.5270, -0.6833]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2166, -0.1375,  0.5140,  ...,  0.3099,  0.7499, -1.0253],\n",
      "        [-0.1200,  0.1239, -0.3071,  ...,  0.2107, -0.9336,  0.2743],\n",
      "        [ 0.4446, -0.7247,  0.8033,  ..., -0.2088, -0.1852,  1.2271],\n",
      "        ...,\n",
      "        [-0.9186,  1.1652,  0.5090,  ...,  1.4894, -2.4289,  0.6326],\n",
      "        [ 0.2318,  0.0396,  0.1383,  ..., -0.7904, -1.1025,  0.2273],\n",
      "        [-0.9757, -0.1450, -0.2873,  ..., -0.2245, -0.2039, -0.0559]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0407,  1.0492,  0.2174,  ..., -0.5843, -0.1454,  2.4267],\n",
      "        [-1.5884,  0.1912, -1.1197,  ..., -0.4944,  0.7833, -0.2989],\n",
      "        [-1.0298,  1.3265, -0.2485,  ..., -0.5463, -0.0128, -0.1623],\n",
      "        ...,\n",
      "        [ 2.3514,  2.4427,  0.9159,  ...,  1.0975, -1.0401, -0.5373],\n",
      "        [ 0.7717,  0.5197,  0.7858,  ..., -0.7949, -1.2451, -0.7827],\n",
      "        [-0.1470, -0.7907, -0.4672,  ..., -0.6565, -1.5431, -0.3455]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5652,  0.6840, -1.3681,  ..., -0.3294,  0.2947, -0.9341],\n",
      "        [-0.5809, -2.3575, -1.4824,  ..., -0.3792,  0.6762,  1.5167],\n",
      "        [-0.0618, -1.2797, -1.0194,  ...,  0.3015,  0.1939,  0.7489],\n",
      "        ...,\n",
      "        [ 0.2039, -1.6706,  0.9785,  ...,  1.8588, -0.3632, -1.7814],\n",
      "        [ 1.9550,  2.4508,  0.2268,  ..., -1.7418,  1.0838, -1.4655],\n",
      "        [ 0.7374,  1.4645,  1.2615,  ..., -0.4526, -1.6223,  1.3095]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1590, -1.2470,  0.7773,  ..., -0.9384, -0.3138,  0.1330],\n",
      "        [ 0.0380, -1.2393,  0.3527,  ...,  0.4412, -0.8814, -1.4955],\n",
      "        [ 0.6185,  0.0595,  1.5744,  ..., -0.5473,  1.3378,  1.0150],\n",
      "        ...,\n",
      "        [ 0.2307,  1.1399, -0.3976,  ...,  1.4385, -1.3240, -1.0982],\n",
      "        [ 0.2174, -0.7749,  0.5680,  ..., -0.2482,  0.8538, -0.6733],\n",
      "        [ 2.1836,  2.3555, -0.3540,  ..., -0.8760,  0.3657, -0.8379]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0324,  0.8974, -1.0192,  ..., -0.0045,  0.1388, -0.3231],\n",
      "        [ 1.1076, -0.0693,  0.0892,  ...,  0.0749,  0.9908,  0.2893],\n",
      "        [-2.2876, -0.6363,  0.2194,  ...,  0.6968,  1.9451,  0.4733],\n",
      "        ...,\n",
      "        [ 0.2316, -0.5434,  0.6934,  ...,  1.4103, -1.1481, -0.3845],\n",
      "        [-1.0547, -0.2807, -0.0488,  ...,  1.2920, -0.7662, -0.2876],\n",
      "        [ 0.8497,  1.2125, -0.1186,  ...,  1.1332,  0.9014,  0.3307]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8978,  0.4563, -0.8361,  ..., -0.7791, -0.5582,  0.7936],\n",
      "        [ 0.6491, -0.2261,  0.5915,  ..., -1.0886,  1.6641,  0.5041],\n",
      "        [ 2.1145,  2.0521,  1.6389,  ...,  1.6429, -1.5958,  0.3141],\n",
      "        ...,\n",
      "        [-1.8146, -0.9932, -1.3448,  ...,  0.7789,  1.0310, -0.0051],\n",
      "        [ 1.6931,  1.2403, -0.8483,  ...,  2.5595, -0.5622, -0.6582],\n",
      "        [-0.1048,  0.2196, -0.0935,  ..., -2.4764, -0.5175, -0.4541]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1996,  0.2896,  0.4926,  ...,  0.8193,  0.5969, -0.0857],\n",
      "        [-0.6673,  0.0978,  0.4261,  ...,  1.1211,  1.5448, -0.4268],\n",
      "        [ 0.6104, -0.9405,  0.3001,  ...,  0.5102,  0.8072, -1.8734],\n",
      "        ...,\n",
      "        [ 0.3914,  1.4667,  0.9213,  ..., -0.8311,  0.9738,  0.6439],\n",
      "        [ 1.2319, -0.2107, -0.3117,  ...,  3.2293,  1.1387, -0.3179],\n",
      "        [ 0.0171, -0.0359,  0.3630,  ..., -2.5891,  0.0971,  0.2507]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 2.3207,  0.2851,  1.6274,  ...,  1.8327, -0.8565,  0.1936],\n",
      "        [ 0.0561, -1.1458, -0.6264,  ...,  1.1205, -0.8831, -1.1297],\n",
      "        [ 0.9519,  1.2335, -1.2202,  ..., -0.6710, -1.0830, -0.6020],\n",
      "        ...,\n",
      "        [-1.6417,  1.0631,  0.5201,  ...,  1.5353,  0.4297,  1.2746],\n",
      "        [-0.2416, -0.2925,  0.8254,  ...,  0.3021,  0.4328, -0.4198],\n",
      "        [-0.7355,  0.1490, -0.8527,  ...,  0.6191,  0.4523, -0.3985]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7025, -0.4266,  0.0981,  ..., -0.6134, -0.4892, -0.2478],\n",
      "        [ 0.4325,  0.3611,  0.8583,  ...,  0.1770,  0.7318, -0.6050],\n",
      "        [ 0.8175,  1.3402,  1.4575,  ...,  0.4968, -0.3910,  0.7945],\n",
      "        ...,\n",
      "        [ 1.3376, -1.3995, -1.0955,  ...,  0.5107, -0.6201, -1.9298],\n",
      "        [-2.3255, -1.3469,  0.8782,  ..., -0.6726,  0.6206, -1.1140],\n",
      "        [-0.2917, -1.2023,  1.0720,  ...,  0.5598,  0.3319,  0.5552]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.6638, -1.1182,  2.1431,  ..., -0.3427,  1.0927,  0.4049],\n",
      "        [-0.4345,  0.3009, -0.7200,  ..., -0.6043, -0.7567, -0.0393],\n",
      "        [ 0.7449,  2.1061,  0.5559,  ...,  0.3202,  0.9906,  0.0130],\n",
      "        ...,\n",
      "        [ 0.0697,  0.1820, -1.9312,  ...,  1.1377, -0.9619,  1.2183],\n",
      "        [ 1.0991,  1.8228, -0.1482,  ...,  1.0317, -0.5398,  0.8420],\n",
      "        [-0.3413,  0.1731,  0.6446,  ...,  0.4358,  0.1990, -0.7528]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.7142,  0.2367, -0.8144,  ..., -1.2192, -0.4969, -0.4134],\n",
      "        [ 0.8081, -0.9457,  0.8579,  ...,  0.5115, -0.1371,  0.7845],\n",
      "        [ 0.3879,  0.3332, -0.1652,  ...,  0.1946,  0.2926,  0.3968],\n",
      "        ...,\n",
      "        [-0.7595,  0.8939, -0.6009,  ...,  0.3831,  1.4369, -0.0919],\n",
      "        [-1.2100,  1.2819, -0.0705,  ...,  0.5138, -0.4472, -0.0309],\n",
      "        [-1.1209,  0.0252, -0.0990,  ..., -0.8825,  4.5267,  4.0042]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5458,  0.1256,  1.1834,  ..., -2.1949, -0.8138,  0.6670],\n",
      "        [ 1.9242, -0.6687,  0.4855,  ...,  1.8807,  0.1908, -0.3510],\n",
      "        [ 0.2145,  0.8951, -0.7141,  ..., -0.0541, -0.5888, -0.1856],\n",
      "        ...,\n",
      "        [-1.2646, -1.7237, -1.3081,  ..., -1.0941, -0.4418, -1.4998],\n",
      "        [ 0.7951,  1.5678, -0.2723,  ..., -0.3467,  0.5273, -1.9067],\n",
      "        [-0.3788,  0.5666,  0.2730,  ...,  1.4957,  0.2362,  1.6952]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9489,  0.4529,  0.9811,  ..., -0.0066,  0.4997, -0.4213],\n",
      "        [ 1.2465,  0.2308, -0.4117,  ..., -0.3090,  1.9081, -0.3432],\n",
      "        [ 2.0285,  2.0909,  0.1166,  ..., -0.6703, -0.4618,  0.5724],\n",
      "        ...,\n",
      "        [-0.9852,  0.2698,  0.1870,  ...,  0.6589,  0.8383,  0.7144],\n",
      "        [-1.7523, -0.5260,  0.8208,  ...,  0.3717, -0.6670, -1.1329],\n",
      "        [-0.1672, -0.1639,  1.5171,  ...,  1.6049, -1.1748,  1.1362]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8848,  1.4047, -1.0434,  ..., -0.0046,  0.3579, -0.5046],\n",
      "        [ 0.1738, -1.4501, -0.9286,  ...,  0.3153, -0.0232, -0.6980],\n",
      "        [-1.3843, -0.7080,  0.0299,  ..., -0.9613,  0.2782, -1.9853],\n",
      "        ...,\n",
      "        [-2.1660, -1.3272,  1.0210,  ..., -1.2949,  0.9073, -0.3982],\n",
      "        [ 2.0411,  1.8631,  1.6159,  ...,  0.8496, -1.0338, -2.9075],\n",
      "        [ 0.8607,  0.3715, -0.2869,  ..., -0.8803, -0.5627,  0.0994]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2131, -1.2471, -0.4348,  ..., -0.3942, -0.1558,  0.2926],\n",
      "        [ 0.1483,  0.1030,  0.9709,  ..., -0.5148, -0.1761, -0.5147],\n",
      "        [ 1.8936,  2.6399, -0.5161,  ...,  1.7418,  0.4185,  0.0657],\n",
      "        ...,\n",
      "        [ 1.9278,  0.3153,  0.8995,  ...,  0.3068,  0.8912,  0.0208],\n",
      "        [ 0.0423,  0.4040,  0.0381,  ...,  0.6622,  0.8635, -0.4172],\n",
      "        [-0.1531, -1.1261,  0.2625,  ...,  0.9727, -0.7361, -1.4362]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.6077, -2.1389, -0.3306,  ...,  2.1417, -0.6284, -2.0745],\n",
      "        [ 1.0266,  1.5758, -0.3938,  ...,  0.9703,  0.2432, -1.1451],\n",
      "        [-0.2704, -0.8996,  0.6853,  ...,  0.6861, -0.5682,  0.8049],\n",
      "        ...,\n",
      "        [ 0.8029, -1.5911,  1.2580,  ...,  0.7652,  0.6517,  1.5533],\n",
      "        [-0.5123, -0.2217, -0.2086,  ...,  2.3334, -0.5154,  0.1190],\n",
      "        [-1.5077, -1.8419, -0.1411,  ...,  0.2360,  0.0936,  0.1174]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3301,  0.1114, -1.4074,  ...,  0.8600, -0.4264,  0.3562],\n",
      "        [-0.6035, -0.7964, -0.7042,  ..., -1.8112, -0.3036,  0.0767],\n",
      "        [ 1.1282,  1.4364,  0.8951,  ...,  0.4375, -1.2582, -0.1693],\n",
      "        ...,\n",
      "        [-0.3997,  0.3807, -0.2099,  ..., -0.7940,  1.4025, -0.3731],\n",
      "        [-0.5001, -2.0664, -0.0973,  ..., -0.4345, -0.3341,  0.9720],\n",
      "        [ 0.7693, -0.7021,  0.1070,  ..., -0.8881, -1.1467, -1.4354]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5687, -1.0207,  0.4710,  ...,  0.9950,  0.2688,  0.3436],\n",
      "        [ 0.2772, -0.4878, -0.1842,  ..., -0.1836, -0.6122,  0.6999],\n",
      "        [-0.3796, -0.5857,  0.5995,  ..., -0.4844,  0.1118, -1.2883],\n",
      "        ...,\n",
      "        [-0.0100, -1.1440, -1.8628,  ..., -2.8793, -0.3645, -1.1074],\n",
      "        [-0.0432, -0.5158,  0.3111,  ..., -1.3227,  0.1782,  1.1117],\n",
      "        [ 1.3997,  1.0894, -0.2369,  ..., -1.7364,  0.3934, -1.8756]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5303,  0.1005,  0.8639,  ..., -1.1511,  0.1796,  0.1745],\n",
      "        [-0.1203, -1.5055, -1.0526,  ..., -0.0247, -0.5113, -0.1734],\n",
      "        [-1.0254, -1.5507, -1.2288,  ...,  0.1665, -0.3176, -1.1687],\n",
      "        ...,\n",
      "        [-0.5351, -0.0914, -0.4513,  ...,  0.0192,  0.1742, -0.4781],\n",
      "        [-0.1436, -0.8112, -0.2396,  ...,  0.0320,  0.1989, -2.6537],\n",
      "        [-0.4141, -0.0300,  2.0087,  ...,  0.1111, -0.6925, -1.1161]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3661,  0.1622, -0.7376,  ..., -0.5528,  0.4382,  0.1114],\n",
      "        [-0.6359,  0.5785,  0.6869,  ..., -0.4114, -1.1465,  0.3489],\n",
      "        [-0.1993,  0.6360,  1.3887,  ..., -0.2407,  0.9498, -0.0528],\n",
      "        ...,\n",
      "        [ 0.2488,  0.3488,  1.8383,  ..., -1.3600,  0.7929,  0.2276],\n",
      "        [-0.7007, -0.4434,  0.6690,  ...,  0.8798, -0.9539,  0.2881],\n",
      "        [ 0.6201,  0.0763, -0.0140,  ..., -1.3101, -0.8533, -0.7119]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8423,  0.0766, -0.3002,  ...,  0.2873, -0.5448, -0.8459],\n",
      "        [-0.8620, -0.0780,  1.9119,  ..., -0.2814,  0.7274,  0.3256],\n",
      "        [ 0.2377, -0.9525, -0.0440,  ..., -0.5928,  0.3900, -0.8500],\n",
      "        ...,\n",
      "        [ 0.7011,  1.2005, -0.6090,  ..., -1.0576,  1.0376,  0.2866],\n",
      "        [ 0.6841, -0.2685,  1.9070,  ...,  1.2358,  0.2286,  1.1210],\n",
      "        [-0.4663, -1.0845,  0.3817,  ..., -1.6601,  0.0176,  0.0677]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.9513e-01,  1.5851e+00,  1.5230e+00,  ..., -3.5898e-01,\n",
      "          7.1273e-01, -7.8540e-01],\n",
      "        [-4.1170e-01, -5.1315e-01, -9.9992e-01,  ..., -1.6277e-03,\n",
      "          2.2389e-01,  1.2276e+00],\n",
      "        [ 1.6478e-01, -8.2403e-01,  7.0092e-01,  ...,  9.3445e-02,\n",
      "          1.5608e-01, -1.1137e+00],\n",
      "        ...,\n",
      "        [-2.2393e-01, -9.0240e-01, -1.8764e+00,  ...,  8.7693e-02,\n",
      "          4.6506e-03, -8.7851e-01],\n",
      "        [-8.5068e-01,  5.0724e-01, -1.0798e+00,  ..., -1.7810e+00,\n",
      "         -1.3148e+00, -6.7706e-01],\n",
      "        [-9.2801e-01, -2.5326e-01, -2.1096e-01,  ..., -1.5971e+00,\n",
      "         -3.3418e-01, -8.5763e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.9394, -0.7408, -1.4373,  ...,  1.0051,  0.2451,  1.8516],\n",
      "        [-0.7445, -0.6078,  0.4747,  ...,  1.6082,  1.0092, -0.3222],\n",
      "        [ 0.0229,  0.6766, -0.7374,  ...,  0.2758,  1.2610,  0.1348],\n",
      "        ...,\n",
      "        [-1.3241, -1.3041,  0.0972,  ..., -0.8389, -0.2118,  0.6232],\n",
      "        [-0.5210, -0.9646,  0.3137,  ..., -0.8659, -0.3715, -0.2089],\n",
      "        [ 0.7092,  1.5468,  1.0359,  ..., -1.1880,  0.2059,  0.4996]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2012, -1.0768,  0.2798,  ..., -0.5983, -0.9374, -0.6885],\n",
      "        [-0.3839,  0.0064,  0.6345,  ..., -0.5400,  1.4838, -0.2682],\n",
      "        [ 0.5008,  1.1719,  2.0987,  ..., -1.5527, -0.5738, -0.0596],\n",
      "        ...,\n",
      "        [-0.0101,  0.0133,  0.6697,  ...,  3.5278, -0.5743,  1.2464],\n",
      "        [-2.1697, -1.0035, -0.8823,  ...,  3.0066, -0.2675, -0.4030],\n",
      "        [-0.8629, -0.7741,  0.7576,  ..., -0.3360,  0.4466, -0.4020]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4002, -0.4558,  0.7436,  ...,  0.7723, -0.2322,  0.9344],\n",
      "        [-0.4932,  0.3252,  1.1846,  ..., -0.5714,  0.7008, -0.2022],\n",
      "        [ 1.5599,  1.1417, -1.2330,  ...,  1.3067,  0.7609, -0.1726],\n",
      "        ...,\n",
      "        [ 1.9376,  1.2221,  0.9456,  ...,  0.2407, -0.9204,  1.8584],\n",
      "        [ 0.4144, -1.0170,  2.0287,  ...,  1.0592, -0.0050,  1.2001],\n",
      "        [-0.4660,  0.2514, -0.9639,  ..., -1.2819,  0.2130, -0.2427]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5533, -0.1923, -0.6673,  ..., -0.0906, -1.4953, -0.8142],\n",
      "        [-1.4702, -0.5719, -0.9937,  ..., -0.2904,  0.4501,  0.3482],\n",
      "        [-0.7374, -0.2008,  0.3195,  ...,  1.4191,  1.6437, -0.4792],\n",
      "        ...,\n",
      "        [ 1.7225,  1.1325, -0.9347,  ..., -0.1690, -1.6786, -1.1092],\n",
      "        [ 1.0064,  0.3560, -1.0390,  ...,  0.7834, -0.5213, -0.6376],\n",
      "        [-0.1841,  0.9766, -0.0385,  ...,  0.2280,  0.0742, -0.0140]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.6897,  2.0694, -0.3220,  ..., -0.5886, -0.6016,  1.3798],\n",
      "        [-1.2911, -0.2165, -0.2819,  ..., -0.3298,  0.6910, -1.3166],\n",
      "        [-0.7175,  1.6421,  0.3603,  ..., -2.1908, -1.1076, -0.4237],\n",
      "        ...,\n",
      "        [ 1.3941,  0.7194,  1.2992,  ...,  0.1064, -0.9523, -0.8701],\n",
      "        [ 1.8449,  1.3482, -0.0133,  ...,  1.0345, -0.9722, -1.8057],\n",
      "        [ 0.5617,  1.8489,  1.1124,  ..., -1.0165, -0.9600, -0.4685]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.7412, -0.1125, -0.5028,  ...,  1.2382, -0.4651, -0.8568],\n",
      "        [ 1.6118,  0.5957,  0.5316,  ...,  0.5877, -1.4640,  2.0371],\n",
      "        [ 0.6635,  0.6637, -0.0060,  ...,  0.2294, -0.6445, -0.3288],\n",
      "        ...,\n",
      "        [ 0.4560,  0.7506, -0.2271,  ..., -0.1257, -0.8916, -0.1450],\n",
      "        [ 1.9537, -1.4979,  1.7106,  ...,  1.1894, -2.1928, -0.3864],\n",
      "        [-0.5657,  0.0553, -1.4176,  ...,  1.5899, -0.1814, -0.0756]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.5151, -2.1286,  2.3492,  ...,  0.2880,  1.4474,  1.2451],\n",
      "        [-0.8611,  1.3117, -1.8234,  ..., -2.3782, -1.8257, -1.5727],\n",
      "        [-0.3142, -0.2630, -1.6719,  ..., -0.4382,  0.4160,  0.9590],\n",
      "        ...,\n",
      "        [-1.1964, -0.6507, -0.0792,  ...,  0.7356,  1.0238, -0.7141],\n",
      "        [-0.1081,  1.5658, -1.4375,  ...,  0.3566,  0.2547, -0.0035],\n",
      "        [ 0.0468, -0.3115,  2.2979,  ..., -0.2806,  0.4342,  1.1674]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.7788, -0.8176,  2.4209,  ...,  1.9084, -0.5699, -0.1784],\n",
      "        [-1.0520, -1.1945, -1.6441,  ..., -0.9991,  0.1483,  0.0599],\n",
      "        [ 1.6601,  0.5841,  1.3244,  ...,  0.7977,  1.6948, -2.7064],\n",
      "        ...,\n",
      "        [-1.5114, -0.2080,  2.3283,  ..., -0.5684,  0.1186, -0.3411],\n",
      "        [-0.9290, -0.1814,  0.7482,  ..., -0.9947, -0.0156, -0.8150],\n",
      "        [-0.5602,  0.5433,  1.2671,  ...,  0.9213,  0.5281, -2.0233]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 2.4353, -1.7405, -0.2278,  ...,  1.6122, -3.3245, -1.2060],\n",
      "        [ 0.7014, -1.0681,  1.4552,  ...,  0.1647, -1.2201, -0.4312],\n",
      "        [ 0.9935, -0.1296,  1.2409,  ...,  0.6733, -0.2873, -0.7411],\n",
      "        ...,\n",
      "        [ 0.3758, -0.2063,  1.3029,  ..., -0.9911, -0.9842,  0.1269],\n",
      "        [-1.0786, -1.9958, -0.9766,  ...,  0.4004, -0.2556, -1.3703],\n",
      "        [ 0.5957,  0.6769,  0.1359,  ...,  0.6082, -0.2830,  0.5220]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1496, -0.0797,  0.2547,  ...,  0.4358, -2.4265,  0.2986],\n",
      "        [-0.5346, -0.6339,  1.5773,  ..., -1.5657,  0.7062, -0.5530],\n",
      "        [-0.6522, -0.9387, -2.1994,  ...,  1.3977, -1.1325,  2.2058],\n",
      "        ...,\n",
      "        [-0.2839, -0.1138, -0.1529,  ..., -0.6099, -0.3610, -0.4125],\n",
      "        [-2.3658, -1.3088,  2.2554,  ..., -0.6378,  0.2650,  1.6308],\n",
      "        [-0.0705,  0.2326, -1.0759,  ..., -0.9893,  1.5581, -1.8812]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.8642, -1.1024, -0.7347,  ...,  1.7290,  0.4026, -0.6608],\n",
      "        [ 0.5601,  0.7815,  0.8110,  ..., -0.3194,  0.6413, -1.7156],\n",
      "        [-1.2902, -0.0286,  1.4183,  ..., -1.2075, -0.9321, -0.3766],\n",
      "        ...,\n",
      "        [-2.0804, -0.5330,  1.4705,  ...,  0.4594,  0.0211, -0.2460],\n",
      "        [-0.2535, -0.7704, -2.3149,  ...,  0.6190, -0.8189,  0.8459],\n",
      "        [-0.8060, -0.8065,  1.5923,  ..., -1.4747, -1.0862, -0.6802]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0619, -1.9276,  2.0355,  ..., -1.7036,  0.0783, -0.4489],\n",
      "        [-0.1878, -0.7651,  0.4874,  ..., -0.0849,  1.1351,  0.4216],\n",
      "        [-0.5854,  0.1923,  0.2397,  ..., -0.5981,  0.0531, -0.2317],\n",
      "        ...,\n",
      "        [-1.2146,  0.1759, -1.1684,  ...,  0.1078,  0.4492, -0.3366],\n",
      "        [ 2.0298,  1.7753,  1.6553,  ..., -0.1657, -1.5335, -3.5340],\n",
      "        [-0.1851,  0.6882,  0.6574,  ..., -0.5615, -0.8807,  0.3949]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3736, -0.5146, -1.2824,  ..., -0.9365,  1.3134,  0.6275],\n",
      "        [-1.7086,  0.7357,  0.2219,  ..., -0.7632, -1.0697, -2.2754],\n",
      "        [-1.6802, -0.6987, -0.2481,  ...,  0.5864,  1.8371,  0.2331],\n",
      "        ...,\n",
      "        [ 0.5579, -0.9402, -1.3690,  ..., -0.3078,  0.3584, -1.1211],\n",
      "        [ 0.9077, -2.0704,  1.1578,  ..., -0.3572,  0.9414,  0.6169],\n",
      "        [-0.3067,  0.3350, -0.0360,  ..., -0.2547,  0.1060, -0.0820]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6231,  0.6495,  0.0666,  ...,  0.5197,  1.8276,  1.3268],\n",
      "        [ 1.7502,  2.3965,  1.3625,  ...,  1.0164,  2.8306,  0.3190],\n",
      "        [-1.1384,  0.1348, -1.7598,  ...,  0.2337,  0.4575, -0.0121],\n",
      "        ...,\n",
      "        [-0.9785,  2.4256, -2.2153,  ...,  0.2858, -1.4807,  0.7240],\n",
      "        [-1.1465,  1.0650,  0.7654,  ..., -0.5109, -0.8319,  2.1619],\n",
      "        [-0.3047,  0.3125,  1.1531,  ...,  0.1663, -0.7605,  0.2309]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.7513,  0.5607,  1.7084,  ..., -1.5004,  0.3741, -1.6782],\n",
      "        [ 1.3600,  0.7655,  0.7039,  ...,  0.5345,  1.4164, -0.8814],\n",
      "        [-1.6072, -1.0117,  1.0241,  ...,  0.4241, -0.1257, -0.2292],\n",
      "        ...,\n",
      "        [-0.1178,  1.3588,  0.0243,  ..., -0.4661,  0.3865,  0.4152],\n",
      "        [ 0.3889,  0.7229, -1.0228,  ...,  0.1958,  0.2346, -0.3276],\n",
      "        [ 0.7771,  0.7089,  0.2230,  ...,  0.3642, -1.8127,  1.4139]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1390,  0.5169,  0.0177,  ...,  2.9405, -0.6360, -0.4324],\n",
      "        [-1.3805, -0.1373,  0.0783,  ...,  0.8355,  1.6680, -0.4392],\n",
      "        [ 0.6428, -2.2742, -1.5786,  ..., -0.6759,  1.9972, -0.6851],\n",
      "        ...,\n",
      "        [-0.3634,  0.3607,  0.3822,  ...,  1.5989, -0.2330,  1.3325],\n",
      "        [-0.6401, -0.6873, -0.4334,  ...,  0.5401,  0.4153, -3.0236],\n",
      "        [-1.8170,  1.5717, -1.1456,  ..., -0.6140,  1.0491, -0.0703]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1674,  0.7144, -1.2053,  ..., -0.6018,  0.9885, -0.8873],\n",
      "        [-0.0101,  0.9177,  0.4027,  ..., -0.3202, -0.4237, -0.2087],\n",
      "        [ 0.7823, -0.6535, -0.2850,  ..., -0.7755, -0.7141,  1.8488],\n",
      "        ...,\n",
      "        [-1.4106, -1.1126,  0.0880,  ...,  0.2261, -1.1389,  0.6449],\n",
      "        [ 1.7941, -0.3597,  0.2554,  ...,  2.5179,  0.7742, -0.2467],\n",
      "        [-0.0372, -1.6128,  1.6014,  ...,  0.4285, -0.3105, -0.1530]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.9365,  0.0055,  1.1614,  ..., -0.4330, -0.0720,  0.2227],\n",
      "        [ 1.4520, -0.5410, -0.2506,  ...,  0.3453, -0.9894,  0.0515],\n",
      "        [ 0.8299, -0.5089,  0.1494,  ...,  0.8294,  2.0567,  0.3039],\n",
      "        ...,\n",
      "        [ 2.2080,  1.0709,  0.9557,  ...,  1.2431, -1.4500,  2.3044],\n",
      "        [ 1.9012,  2.2533,  2.0863,  ...,  0.9450,  1.9490,  0.6354],\n",
      "        [-0.9755, -1.8022, -0.6918,  ..., -1.1545,  0.3384, -0.6390]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1656, -1.0175, -0.3352,  ...,  0.2598,  0.2575, -0.4741],\n",
      "        [-0.9060, -0.4811, -0.2986,  ..., -0.8469,  0.6125, -0.1874],\n",
      "        [-0.6923, -0.0528, -0.5742,  ...,  0.8033,  1.1893, -0.3581],\n",
      "        ...,\n",
      "        [-0.8457, -0.2915, -0.6129,  ..., -0.1997,  0.8294, -0.8497],\n",
      "        [ 0.3760, -1.1785, -0.2321,  ...,  1.4234, -2.5739,  1.7837],\n",
      "        [-0.2909, -1.6574,  0.7293,  ..., -0.1390,  0.7652,  1.2956]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2358, -0.0908, -0.2384,  ..., -1.2504,  0.4399, -0.3581],\n",
      "        [-1.1242,  0.4470,  0.4301,  ..., -1.6441,  0.4076, -0.7811],\n",
      "        [-0.0096, -1.1191, -1.3855,  ..., -1.0081,  0.4479,  2.1457],\n",
      "        ...,\n",
      "        [-1.3704, -1.1933, -1.6501,  ..., -2.8272,  0.6713, -0.4052],\n",
      "        [-0.7247, -1.0323, -0.9075,  ..., -0.1652,  0.4654, -0.4830],\n",
      "        [ 1.3837, -0.7831,  0.3384,  ..., -1.0342,  0.1810,  0.5558]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8269, -0.4618, -0.8793,  ...,  0.8302,  1.5194, -0.1696],\n",
      "        [-0.2132, -0.0312,  1.7057,  ...,  0.4538, -0.2553, -0.4804],\n",
      "        [ 0.1447,  0.8654,  0.6421,  ..., -0.8917, -1.4185, -0.3672],\n",
      "        ...,\n",
      "        [-0.3514, -0.1951,  0.8556,  ..., -0.3670,  2.3871, -1.8268],\n",
      "        [-0.2389, -1.8671, -0.9107,  ...,  1.0127,  0.9096, -0.8987],\n",
      "        [-0.6434,  1.5686, -1.1070,  ..., -0.5960,  0.9265,  2.0623]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.6968,  2.4976, -0.1131,  ..., -1.0556,  1.5879, -1.9572],\n",
      "        [-0.2985,  0.2657, -0.4258,  ..., -0.4906,  1.0962, -1.1020],\n",
      "        [-0.6914,  0.8474, -0.0346,  ...,  0.4759,  0.4937, -1.6133],\n",
      "        ...,\n",
      "        [-1.2389,  0.3335,  1.2157,  ..., -0.0391, -0.3975, -0.9003],\n",
      "        [-0.8601,  0.5164,  0.5888,  ..., -2.3405,  1.5375,  1.0386],\n",
      "        [ 0.9772, -1.1072,  0.3673,  ..., -0.6160,  0.1568, -0.6287]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1812,  0.7609, -1.4418,  ..., -0.5183, -0.5222,  0.6020],\n",
      "        [ 0.4357, -1.4507, -0.5433,  ..., -0.0256, -0.2609,  0.6867],\n",
      "        [ 1.2633, -1.2260, -0.5444,  ...,  1.6536,  1.8430,  1.4815],\n",
      "        ...,\n",
      "        [ 0.6247, -0.1851,  0.7313,  ...,  0.9687, -1.0399, -0.2904],\n",
      "        [ 0.0286,  0.7266, -2.3420,  ...,  1.5039, -0.0791, -0.4141],\n",
      "        [-0.1550, -0.3892, -0.0867,  ...,  0.2286, -0.1014, -0.0387]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1408,  0.2640,  1.6852,  ...,  0.3636, -0.9802, -0.0456],\n",
      "        [ 0.8325,  0.3479, -0.7022,  ...,  0.2053, -0.4587,  0.7771],\n",
      "        [-1.1916, -0.2115, -1.9143,  ..., -0.3521,  0.3516,  0.3333],\n",
      "        ...,\n",
      "        [-0.5109, -0.3431,  0.6049,  ..., -0.6430,  0.6334,  0.8647],\n",
      "        [-0.6125, -0.0409, -0.9622,  ...,  1.4626,  1.8526, -0.6226],\n",
      "        [ 1.3383, -0.9501, -0.9100,  ...,  0.6685,  0.6351,  0.8907]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.1531,  0.8190, -0.4694,  ..., -0.5502,  0.2874,  1.5080],\n",
      "        [-0.2935,  1.2237, -0.5390,  ..., -0.4681,  1.7481,  0.3143],\n",
      "        [-0.1397, -0.2367, -0.4917,  ...,  1.1135,  0.7099, -0.5679],\n",
      "        ...,\n",
      "        [-0.2966,  0.2998, -0.3808,  ..., -0.9925, -0.5916, -0.0431],\n",
      "        [ 0.4942,  0.8992,  0.4919,  ...,  0.4543, -1.0005, -1.3715],\n",
      "        [-1.3818,  0.3875, -0.9668,  ..., -0.5649,  0.3777, -0.6999]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.6276,  0.0761, -0.7826,  ..., -1.6299,  0.0788,  1.1876],\n",
      "        [-1.1464, -1.5922, -1.1597,  ...,  0.1775,  0.2862,  0.5679],\n",
      "        [ 0.5992, -1.6139,  0.3044,  ...,  0.2761,  0.4145, -0.0473],\n",
      "        ...,\n",
      "        [ 0.0393,  0.1116,  0.9054,  ..., -0.5347,  0.1980, -0.1919],\n",
      "        [ 1.0599,  1.5319, -1.9839,  ..., -1.8801, -0.3269,  0.1713],\n",
      "        [ 0.4333, -0.8809,  0.4998,  ..., -0.8487,  2.5700, -0.9016]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4712, -0.8085, -1.4084,  ...,  0.5368, -0.2925,  0.9480],\n",
      "        [-0.0997, -0.7767,  0.5909,  ..., -0.8119,  0.4988,  0.7530],\n",
      "        [-0.1650, -1.1038, -0.0250,  ...,  0.6388, -0.7671,  0.3771],\n",
      "        ...,\n",
      "        [-0.0650,  1.1066,  0.1118,  ..., -0.2100,  0.4729, -1.1549],\n",
      "        [ 0.3200,  0.0769,  0.1642,  ..., -0.6312,  1.3263, -1.2450],\n",
      "        [-1.2389, -1.6376, -0.9676,  ...,  0.0686,  0.6703, -0.8653]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2678, -0.8250,  1.2883,  ...,  0.3832,  0.2191,  1.3931],\n",
      "        [ 0.8073, -1.9110,  0.9923,  ...,  0.3966,  0.9871,  0.1726],\n",
      "        [-1.7239, -0.9863,  0.3339,  ..., -1.3573, -1.2491,  0.0488],\n",
      "        ...,\n",
      "        [-0.5871,  1.1571, -0.3294,  ...,  0.1017,  0.4007,  0.8429],\n",
      "        [ 0.9297,  1.3330, -0.8356,  ..., -0.3477, -0.2044, -0.5887],\n",
      "        [-0.0672,  0.0127,  0.5806,  ..., -0.2883, -0.6306, -0.0516]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2881, -1.4291, -0.8556,  ..., -0.7966,  1.0190,  1.1472],\n",
      "        [ 0.8300,  0.3685,  0.3404,  ..., -0.4941,  0.6398,  0.4896],\n",
      "        [-1.1220, -0.2367,  0.1262,  ..., -0.0129, -0.5749, -0.9813],\n",
      "        ...,\n",
      "        [-0.7715, -1.2667,  0.7213,  ..., -0.1114,  0.3406,  1.2907],\n",
      "        [ 0.2045, -0.8656,  0.9046,  ...,  0.4593, -1.4792, -0.6309],\n",
      "        [ 0.4263, -0.0767,  0.2549,  ...,  0.5754, -0.4231,  1.2955]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1148, -0.2467,  0.3426,  ..., -0.3289, -0.2377, -1.7517],\n",
      "        [ 0.2711,  0.2851,  0.8699,  ..., -0.4786, -0.4375, -0.8869],\n",
      "        [-0.8169, -1.0077,  0.2545,  ...,  0.8016, -0.5733, -1.2637],\n",
      "        ...,\n",
      "        [ 0.7089,  0.1047,  0.3894,  ..., -2.3572, -1.3561,  0.2077],\n",
      "        [ 0.7710,  1.0764,  0.1675,  ..., -0.0154,  0.8533, -2.3993],\n",
      "        [-0.0278,  1.1460, -1.6305,  ...,  1.2388, -0.0183, -1.1421]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4743,  1.1448, -0.6475,  ...,  0.2963,  0.8799,  1.0728],\n",
      "        [ 1.1192, -1.2882,  1.1629,  ..., -1.3577, -1.3165,  0.5679],\n",
      "        [-1.4201, -0.0043,  0.0935,  ...,  0.2407, -0.1601,  0.1390],\n",
      "        ...,\n",
      "        [-0.2494,  0.1044,  0.3213,  ...,  1.3722,  1.5110,  0.5664],\n",
      "        [-0.1616,  1.3886, -1.5172,  ..., -0.6124,  0.1224,  1.7241],\n",
      "        [-1.5312,  2.0722, -0.8507,  ...,  3.9175,  2.0705,  0.9052]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 9.0834e-01, -1.9986e-01,  1.6403e+00,  ...,  9.1576e-01,\n",
      "         -1.5118e+00, -9.0750e-01],\n",
      "        [-1.0516e+00, -1.1469e-01,  1.7532e+00,  ..., -1.0965e+00,\n",
      "          1.6465e+00, -8.0570e-01],\n",
      "        [ 3.2183e-01, -9.4575e-02,  1.8288e-01,  ..., -4.7098e-01,\n",
      "          3.1517e-01, -1.2214e+00],\n",
      "        ...,\n",
      "        [-2.4162e+00, -8.6541e-01, -1.2082e+00,  ..., -1.4991e-01,\n",
      "          3.1287e+00,  2.5597e+00],\n",
      "        [ 1.4876e-01,  1.0332e-01,  6.4011e-01,  ..., -1.0086e+00,\n",
      "          1.6165e-01,  7.0172e-01],\n",
      "        [-1.4371e+00,  9.5153e-02, -1.1330e+00,  ..., -1.3975e+00,\n",
      "          1.6220e+00,  1.1568e-05]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3996, -0.4723,  0.5356,  ...,  0.4792,  0.6583,  0.6744],\n",
      "        [-0.2961, -0.7298,  0.3172,  ..., -0.7626,  0.8504, -0.7158],\n",
      "        [-0.6866, -2.0927,  0.6580,  ...,  1.7768,  0.7441, -0.0503],\n",
      "        ...,\n",
      "        [ 0.0367,  0.1904,  0.8703,  ..., -1.6680, -0.6158,  0.5504],\n",
      "        [ 0.7098, -0.0591,  0.8803,  ..., -1.5823,  1.6497, -0.5885],\n",
      "        [-0.8331, -0.3148, -0.3054,  ...,  0.7043,  0.2036,  0.1767]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.6360e+00,  2.3484e+00,  2.5524e-01,  ...,  9.5607e-01,\n",
      "          4.4842e+00,  7.6820e-03],\n",
      "        [-3.5783e-03, -1.8863e-01, -1.3545e+00,  ..., -2.9962e-01,\n",
      "          6.4350e-01,  6.6481e-01],\n",
      "        [ 7.1286e-01, -1.0213e-01, -4.1476e-01,  ...,  1.2342e+00,\n",
      "          8.6205e-01, -6.4944e-01],\n",
      "        ...,\n",
      "        [ 6.7167e-01, -1.7129e-01,  9.7622e-01,  ...,  1.2674e+00,\n",
      "         -4.1704e-01,  7.6613e-01],\n",
      "        [-1.4066e+00, -3.9917e-01, -5.2512e-01,  ..., -4.9515e-01,\n",
      "          1.3628e+00, -1.4820e-01],\n",
      "        [ 7.4902e-01, -6.7855e-01, -4.9977e-01,  ..., -5.9078e-01,\n",
      "          1.7746e-02,  8.9344e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7016, -0.4107, -0.5160,  ..., -0.6633, -0.7931,  0.9163],\n",
      "        [-0.3408,  0.2383, -0.5174,  ..., -1.3928,  0.0580,  1.0610],\n",
      "        [-0.7372,  1.2653,  1.1594,  ...,  0.3324, -1.0131, -0.7693],\n",
      "        ...,\n",
      "        [ 1.2940,  0.0145,  0.2750,  ..., -0.6169, -0.2920,  1.1070],\n",
      "        [-0.9336, -0.0154, -0.0257,  ..., -1.9840,  1.6144,  0.3538],\n",
      "        [ 1.0592,  0.1912, -0.0172,  ..., -2.7891, -1.6243, -0.9228]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 8.4879e-01,  1.6032e+00, -1.7093e+00,  ...,  5.2561e-01,\n",
      "          3.0515e-01, -1.1445e+00],\n",
      "        [ 9.3076e-02, -1.0592e+00,  2.4247e-01,  ..., -1.2624e+00,\n",
      "          1.5506e+00,  1.1461e+00],\n",
      "        [-1.9387e+00, -1.6240e+00,  2.6302e+00,  ..., -1.5690e+00,\n",
      "         -1.2846e+00, -8.3218e-04],\n",
      "        ...,\n",
      "        [ 3.0014e-01,  7.3699e-02, -5.4793e-01,  ...,  1.0506e+00,\n",
      "         -1.2039e+00, -2.3710e+00],\n",
      "        [ 8.3644e-01,  7.2686e-01, -2.4014e+00,  ..., -3.5187e+00,\n",
      "          1.1784e+00, -3.1831e+00],\n",
      "        [ 3.3395e-01,  6.7918e-01,  1.1432e-01,  ..., -6.1188e-01,\n",
      "          4.2652e-01,  6.8840e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6707,  1.1578,  0.8116,  ...,  0.8579, -1.1730,  0.4799],\n",
      "        [-0.5185, -0.2786,  0.7528,  ...,  1.0557, -0.6037,  0.0618],\n",
      "        [-1.5075,  0.2253, -0.1017,  ..., -0.7774, -0.6080, -1.0061],\n",
      "        ...,\n",
      "        [-0.6021,  0.1103, -0.6650,  ...,  0.1983,  1.0329,  0.3786],\n",
      "        [ 0.0776,  0.6142,  0.7728,  ..., -0.8095,  0.6078,  0.0339],\n",
      "        [ 0.4977, -0.6617, -0.6245,  ..., -1.1712, -0.1497, -0.7545]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1993,  0.8457,  1.8033,  ..., -0.2040, -0.0793,  0.5456],\n",
      "        [ 0.0908, -0.4197,  0.9647,  ..., -0.0977,  0.7176, -0.1355],\n",
      "        [ 1.0704,  0.5966,  0.9609,  ...,  0.7355, -2.3074,  0.3697],\n",
      "        ...,\n",
      "        [-0.4734, -0.1706,  1.0125,  ...,  0.1587, -0.8986, -0.4797],\n",
      "        [-0.6069, -1.0408, -0.4830,  ..., -1.3766,  0.2237,  0.0483],\n",
      "        [ 0.8589, -0.3117,  0.1360,  ..., -0.1354, -0.4039, -0.1497]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7830,  0.5137,  0.2809,  ..., -0.0401, -2.2913,  1.9874],\n",
      "        [ 0.6627,  0.3072,  1.0066,  ..., -0.9975, -0.6332, -0.5187],\n",
      "        [-0.5444, -0.0234,  0.7086,  ..., -0.3114,  0.2672, -0.0855],\n",
      "        ...,\n",
      "        [-0.6797, -0.7127, -0.9389,  ..., -1.2174,  0.4927, -0.9550],\n",
      "        [-0.0233,  0.3164,  1.4057,  ..., -1.2514,  0.2684,  0.5148],\n",
      "        [ 0.1649,  0.9332, -3.0154,  ...,  0.5408, -1.5484,  0.3235]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4030, -0.4091,  1.0046,  ..., -2.0342, -1.3173, -0.1602],\n",
      "        [-0.1371, -1.3006, -0.4906,  ..., -0.8656, -0.1971, -0.3801],\n",
      "        [ 0.4405, -0.5108, -1.2676,  ...,  0.5808, -0.8134,  0.8328],\n",
      "        ...,\n",
      "        [-0.9683,  0.0385, -0.4398,  ...,  1.2591, -0.1693,  0.0971],\n",
      "        [ 0.9159,  0.9158, -1.1901,  ...,  1.6544, -0.1715,  1.0290],\n",
      "        [-0.5018,  0.6012, -0.7317,  ...,  0.3800, -1.2744, -0.0223]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2589,  0.2428,  1.0269,  ...,  0.5722,  0.3856,  0.1120],\n",
      "        [ 1.0972,  0.0820,  0.7799,  ...,  1.0098, -1.1572,  2.0568],\n",
      "        [-1.3372, -1.3709,  0.1742,  ..., -0.8951, -0.6492, -0.1035],\n",
      "        ...,\n",
      "        [-0.3820,  0.2149, -0.0306,  ..., -1.0591, -0.9780, -0.2402],\n",
      "        [-1.0803, -0.9693, -0.7662,  ..., -1.2158,  1.6331, -0.3811],\n",
      "        [ 0.4053,  0.3066, -1.2165,  ...,  0.2183, -1.8950,  0.0059]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.9724,  1.1127, -0.2691,  ..., -0.2047,  1.0527, -0.8868],\n",
      "        [-0.5599, -0.7818,  0.8258,  ...,  0.4953,  0.3661, -0.4474],\n",
      "        [-0.1597,  0.5217,  0.7444,  ...,  0.2106, -1.3214,  0.7077],\n",
      "        ...,\n",
      "        [ 0.8996, -0.4288, -0.5083,  ..., -0.6307,  0.4895, -1.1722],\n",
      "        [-0.3741,  0.1315,  0.2101,  ...,  1.6013,  0.0586, -0.5078],\n",
      "        [ 0.8242,  0.6926, -0.9351,  ..., -0.0228,  0.7466,  1.3826]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4476,  0.6992, -0.9889,  ...,  0.5860, -1.5701, -0.1495],\n",
      "        [-2.3422, -2.3857, -1.3933,  ...,  1.6685,  0.9278, -0.5077],\n",
      "        [ 2.4562, -1.8225,  0.7432,  ..., -0.9538, -1.3552, -0.2352],\n",
      "        ...,\n",
      "        [-0.0500, -1.0674, -0.5206,  ...,  1.4379, -0.3553,  0.3592],\n",
      "        [ 0.0327,  0.4125,  1.5653,  ..., -0.9088, -0.1686, -0.3231],\n",
      "        [-0.3779, -1.5746, -0.6239,  ..., -0.4383,  0.1669,  1.0867]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1492, -1.4156, -0.4151,  ...,  1.1261,  1.5819,  0.4928],\n",
      "        [ 0.1137,  0.4432,  0.6242,  ..., -1.1299,  0.7021, -0.2005],\n",
      "        [-0.7812,  0.0556,  1.4513,  ...,  0.8628,  1.1692, -0.5998],\n",
      "        ...,\n",
      "        [-0.9289, -1.0254,  0.4491,  ..., -1.0915,  0.2753,  0.2589],\n",
      "        [-1.0476, -1.6350,  1.3720,  ...,  0.0299, -0.7848, -1.6132],\n",
      "        [ 1.0704, -0.2192,  0.3750,  ...,  0.3340, -0.8078,  0.7386]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.7840, -1.6749, -1.3136,  ..., -0.5205,  1.0411,  0.1402],\n",
      "        [-1.2772, -1.6240, -0.4766,  ...,  0.4455, -0.1130,  0.0425],\n",
      "        [-1.4492,  0.1456, -1.3009,  ...,  1.1530,  0.0773,  0.0365],\n",
      "        ...,\n",
      "        [ 1.7013,  1.1995,  0.6103,  ..., -1.3814, -0.0504, -0.3627],\n",
      "        [-0.7826, -0.1909,  0.6727,  ...,  3.0254, -2.3005, -0.7248],\n",
      "        [ 1.2613, -0.3362, -0.1566,  ..., -0.1145, -0.0249, -0.7794]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.4530, -0.0990,  1.1390,  ...,  0.4872, -1.1573,  0.5168],\n",
      "        [-0.5179,  1.0040, -0.5860,  ..., -0.3534,  0.9161,  0.2600],\n",
      "        [-0.6163, -1.7932, -0.2838,  ...,  1.3536, -0.2158,  0.5350],\n",
      "        ...,\n",
      "        [-1.2814, -0.4237, -0.2725,  ...,  0.6457, -0.2886,  0.4643],\n",
      "        [-0.9585,  0.4145,  1.4294,  ..., -0.8126,  0.1774,  0.8013],\n",
      "        [ 0.5024, -0.6747, -0.8274,  ...,  2.2680,  0.5904, -1.1481]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2182, -1.5229,  0.7828,  ..., -1.2521,  1.1134,  0.7065],\n",
      "        [ 1.1162,  2.3616, -0.2291,  ..., -0.4137,  1.4427,  0.2650],\n",
      "        [ 2.1636,  1.9238,  1.1669,  ...,  0.5777,  0.0680, -0.1248],\n",
      "        ...,\n",
      "        [-0.7144, -0.7961, -0.8830,  ..., -0.3736, -1.9134,  1.2268],\n",
      "        [ 0.7982, -1.1218, -1.9562,  ...,  1.1997, -0.2528, -1.3045],\n",
      "        [-0.0343, -0.8815, -0.8063,  ..., -0.0171,  0.3520,  0.8766]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5883, -1.0281, -1.6827,  ...,  0.9781,  2.3493, -0.7531],\n",
      "        [ 0.1505, -0.2048, -0.7907,  ..., -0.5211, -0.9637,  1.2939],\n",
      "        [-0.0637, -1.0356, -0.0537,  ..., -0.4040, -0.2489,  0.6032],\n",
      "        ...,\n",
      "        [-0.2657, -0.0126, -0.7613,  ...,  0.7856, -0.7526,  0.6674],\n",
      "        [-0.1600,  0.2143, -1.2762,  ...,  0.2825, -0.4691,  0.2544],\n",
      "        [ 2.4560,  1.8033,  1.8483,  ...,  0.9843, -1.2585,  0.3056]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2460, -0.6606,  1.1688,  ..., -0.6026,  0.2616,  0.0478],\n",
      "        [ 1.2021, -0.7173,  1.2176,  ..., -2.1068,  1.9302,  0.5262],\n",
      "        [ 1.8052, -1.3903,  0.7010,  ...,  1.8113, -0.5002, -0.1043],\n",
      "        ...,\n",
      "        [ 0.8711, -1.2656,  0.6545,  ..., -0.6330, -0.3716,  1.0229],\n",
      "        [ 0.5992, -0.9888, -1.1461,  ..., -1.1749, -0.2729,  1.2115],\n",
      "        [ 0.0604, -0.5509,  0.9053,  ...,  1.1005,  0.3288,  0.2077]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.8997,  0.1637,  1.9621,  ...,  0.3133, -0.5816,  0.1825],\n",
      "        [ 0.6790,  0.0498,  0.3245,  ..., -0.1059,  1.4118, -0.2484],\n",
      "        [ 1.4246, -0.6564,  2.2193,  ...,  0.0414,  4.3374,  0.0834],\n",
      "        ...,\n",
      "        [-0.4007, -1.7816, -1.6880,  ..., -1.5142, -1.1457, -0.3658],\n",
      "        [ 1.8311,  1.4353,  1.1249,  ..., -3.0210,  0.0171,  0.2327],\n",
      "        [ 0.4116, -0.3947,  0.2720,  ..., -0.0951, -0.8460,  1.0801]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3548,  0.2144, -0.0980,  ...,  1.8111, -2.2250, -0.3721],\n",
      "        [-0.1109, -1.9175, -0.2776,  ...,  2.8513, -1.3046, -1.6113],\n",
      "        [ 1.4340, -0.6819, -0.4583,  ..., -0.3627,  1.3545,  0.4542],\n",
      "        ...,\n",
      "        [-0.7780,  0.3588, -0.6269,  ...,  0.4362, -0.5179,  0.6892],\n",
      "        [ 0.2031, -1.0313,  0.1186,  ...,  0.0244,  0.6192,  2.3308],\n",
      "        [-0.1748,  1.7264,  0.9032,  ..., -0.5085,  0.1210,  1.0128]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.8049, -0.4680, -0.8498,  ...,  2.1547,  0.6562, -0.6778],\n",
      "        [-0.2732,  0.1733, -0.1633,  ...,  0.2324,  0.3139, -1.1798],\n",
      "        [-1.2338,  0.8310,  0.8579,  ...,  0.3182,  0.0801,  1.3127],\n",
      "        ...,\n",
      "        [ 1.1780,  0.3758, -0.1908,  ...,  0.0247,  0.0213,  0.2967],\n",
      "        [-1.2409, -0.9379, -0.0062,  ...,  1.6380, -0.9901, -0.8367],\n",
      "        [ 0.8391,  0.9025, -0.7670,  ...,  0.5917,  0.3579,  1.0981]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1107,  1.4359,  0.6275,  ..., -0.1699, -0.2045,  0.4999],\n",
      "        [-0.6073, -1.5364, -0.1458,  ...,  0.2502,  0.8082, -0.2368],\n",
      "        [ 2.2241, -2.3725,  1.6897,  ..., -0.9087, -0.6371,  2.1779],\n",
      "        ...,\n",
      "        [-0.1858,  0.7336,  0.6677,  ...,  0.1531,  1.5571, -0.5608],\n",
      "        [-1.2250, -1.2168, -0.2195,  ..., -0.0515,  0.6676,  1.3640],\n",
      "        [ 0.6729, -0.8902,  1.3797,  ...,  0.1944, -0.7644, -1.6036]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6962, -0.4369, -1.5498,  ..., -2.6926, -2.6009,  2.3324],\n",
      "        [ 1.3958, -0.7825, -0.2877,  ..., -0.2962, -1.0427,  0.1226],\n",
      "        [ 0.3215, -0.6236,  0.1929,  ..., -0.3192, -0.1105,  0.1371],\n",
      "        ...,\n",
      "        [ 0.7192,  0.3543, -0.6379,  ...,  0.9941,  0.7395, -0.3951],\n",
      "        [ 0.4969,  0.8817, -2.4760,  ...,  0.1216,  1.8300,  0.3200],\n",
      "        [ 0.0694, -0.3968, -0.7277,  ..., -0.3029,  2.0495,  1.3840]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 2.3891, -2.4112,  1.5662,  ...,  0.2944, -0.3107,  0.9701],\n",
      "        [-0.5235,  1.3710, -0.4139,  ..., -1.4969, -0.5139,  0.7743],\n",
      "        [ 0.0241, -2.2505,  0.9076,  ...,  0.3827, -2.3740, -2.5014],\n",
      "        ...,\n",
      "        [-0.9976, -0.5370, -1.9290,  ...,  0.1578, -1.7319, -0.9453],\n",
      "        [-0.3656,  0.0480, -0.5835,  ..., -1.0708, -0.9228, -0.0816],\n",
      "        [-0.5371, -0.2843,  0.5894,  ..., -0.5983,  2.0338,  0.0669]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8726,  0.7130,  0.2521,  ...,  1.1942, -1.0338, -0.3554],\n",
      "        [ 0.2154,  1.5551,  0.5981,  ..., -0.0557,  2.6635,  0.0909],\n",
      "        [-0.5152, -0.1102, -0.2128,  ...,  0.1756, -0.0613,  1.9973],\n",
      "        ...,\n",
      "        [-0.2640, -0.4808, -0.9555,  ...,  2.9139,  0.2399,  0.8082],\n",
      "        [-0.1198, -0.2307,  1.9496,  ..., -0.5690,  0.0394,  1.0192],\n",
      "        [ 1.3418,  1.3819, -0.4399,  ..., -0.3899,  0.9431, -0.2518]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.5695,  0.1796,  1.0526,  ...,  1.4716, -0.1241,  0.3454],\n",
      "        [-0.0379,  0.6500,  0.4687,  ..., -0.4176,  1.7634, -0.4225],\n",
      "        [ 1.5112, -0.8116,  0.1475,  ..., -1.2559,  1.2431,  1.1581],\n",
      "        ...,\n",
      "        [ 0.3010, -0.2730,  0.4731,  ..., -0.4561,  0.6101, -0.4323],\n",
      "        [-0.5495, -1.8353, -0.2839,  ..., -0.8557,  0.4219, -0.9855],\n",
      "        [-0.0058,  0.8671,  0.7908,  ...,  0.7774, -0.2569,  0.1126]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2687,  0.9580,  0.3356,  ...,  2.7235,  0.9921, -0.7391],\n",
      "        [ 0.7516, -0.0132, -1.1938,  ...,  1.3741, -0.5739,  0.0753],\n",
      "        [ 0.0933, -0.0356,  0.1318,  ..., -0.8039,  0.5044,  0.1361],\n",
      "        ...,\n",
      "        [-0.9547, -0.2846, -0.5328,  ...,  1.6416,  1.7176, -0.1506],\n",
      "        [ 0.7005, -1.0106, -0.0310,  ..., -0.2993, -0.7758, -1.3720],\n",
      "        [-0.2341,  0.4539,  0.0631,  ..., -0.0790,  0.2281, -1.7778]]), 'y': tensor([[0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1043,  1.1389, -0.4174,  ..., -0.3506,  1.1973,  0.4007],\n",
      "        [-1.1442, -1.5462,  0.3988,  ...,  0.1741,  0.0376,  1.6149],\n",
      "        [-1.0952, -2.0687,  0.6013,  ...,  0.4934, -0.2081,  2.1610],\n",
      "        ...,\n",
      "        [ 0.3431,  0.8487, -0.7221,  ..., -0.6994,  0.5103,  0.2045],\n",
      "        [ 1.0197,  0.6429, -0.5418,  ..., -0.1993,  0.2794,  0.1249],\n",
      "        [ 2.3800,  1.7819,  0.7484,  ...,  0.8556, -0.6156, -0.3892]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2543,  1.6592,  0.5521,  ..., -1.6313,  0.4250,  0.5034],\n",
      "        [ 1.2864,  1.2442,  0.7352,  ...,  3.4681,  1.1328, -1.9258],\n",
      "        [-0.8193,  0.3312, -0.5968,  ...,  1.2367,  0.5098, -0.3950],\n",
      "        ...,\n",
      "        [ 1.8375, -1.3194,  1.3042,  ...,  1.1052, -1.8107,  0.2042],\n",
      "        [-1.7223, -0.9057, -0.2081,  ..., -0.9631,  0.4711,  0.0429],\n",
      "        [-0.5366,  0.9171, -1.4887,  ...,  4.2182, -1.0700, -0.2885]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0961,  0.8737,  1.4955,  ..., -1.0959, -1.7668, -1.3683],\n",
      "        [-0.5612,  0.2986, -1.1989,  ...,  0.4136,  1.1846, -0.0766],\n",
      "        [-0.1278,  0.4649, -0.6029,  ...,  0.4392, -0.1476,  0.0457],\n",
      "        ...,\n",
      "        [-1.2594, -0.2381, -0.7763,  ...,  1.1492, -0.7294, -0.2949],\n",
      "        [ 0.7626, -0.9717,  0.5606,  ..., -0.4642,  0.3793, -0.7625],\n",
      "        [-0.2780,  0.6900, -2.4047,  ..., -0.5173,  0.1802,  1.6511]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0091, -0.5530, -0.5686,  ...,  1.3149, -0.0615,  1.2808],\n",
      "        [-1.0332, -0.4008,  2.1049,  ..., -1.0113,  0.5287,  0.6405],\n",
      "        [ 0.9086,  0.3191,  1.5930,  ...,  0.5726, -0.5778,  1.7361],\n",
      "        ...,\n",
      "        [-2.1028, -1.4525, -0.4789,  ...,  0.5659, -0.7453, -0.6218],\n",
      "        [-0.4495, -0.1943,  2.0212,  ..., -1.9528, -1.4311,  0.4560],\n",
      "        [ 0.1272,  0.0065, -1.7302,  ..., -1.1596, -1.5684,  0.6042]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.6903, -1.6060, -0.8828,  ...,  1.6255,  0.8420,  1.1924],\n",
      "        [ 0.5976,  0.1228, -1.3294,  ...,  0.3510,  0.4192,  2.0780],\n",
      "        [-1.1437, -0.3354, -0.9703,  ...,  0.4393, -0.5317,  0.1230],\n",
      "        ...,\n",
      "        [ 0.0939,  0.2746,  0.4032,  ..., -0.5729,  0.6486, -1.8437],\n",
      "        [-0.0696,  1.2793,  0.4232,  ..., -0.9921, -1.4863, -0.1059],\n",
      "        [ 0.0826, -0.3362, -1.9142,  ..., -0.9131,  0.4923, -0.1223]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4324, -0.1133,  1.7083,  ...,  0.3658,  0.4350, -0.6798],\n",
      "        [ 0.2359,  1.5076,  0.7064,  ...,  0.6492, -1.2053,  0.1140],\n",
      "        [-2.3406, -1.6545,  1.0345,  ...,  0.0899,  0.3525,  0.7581],\n",
      "        ...,\n",
      "        [-0.9495,  1.6199, -0.9538,  ...,  0.6655,  1.2925, -0.7369],\n",
      "        [ 0.8921, -0.9010,  1.2019,  ...,  1.0911, -1.1095,  0.4686],\n",
      "        [-0.1822, -0.7855,  0.1480,  ..., -0.0517,  0.6502,  2.6471]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3365, -0.7618,  0.7947,  ..., -0.8797,  0.1697, -1.2251],\n",
      "        [-0.2853,  1.0904,  0.6244,  ...,  0.7159, -2.2832,  0.6419],\n",
      "        [ 0.1699, -1.6226,  0.0248,  ...,  1.1620,  0.1703,  0.7277],\n",
      "        ...,\n",
      "        [ 0.4103,  0.8374, -0.8200,  ...,  0.8033, -0.5937, -0.4706],\n",
      "        [-1.0434, -1.0434, -2.0186,  ...,  1.0170,  0.0202,  1.7773],\n",
      "        [-0.3551, -1.5766, -1.0827,  ..., -0.5131,  1.4807, -0.3890]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.3943,  1.5683, -1.2934,  ...,  0.9112, -1.0506,  0.8400],\n",
      "        [ 0.3184,  0.8868,  0.6744,  ...,  1.4160, -0.3600, -0.9690],\n",
      "        [ 0.2045,  0.0554, -1.6673,  ...,  0.5077, -0.9022, -0.4309],\n",
      "        ...,\n",
      "        [ 1.6976, -2.4397,  0.0598,  ...,  0.6054,  1.0603, -1.5713],\n",
      "        [-0.0221, -1.0057, -0.2625,  ..., -2.7889,  0.8261, -1.4587],\n",
      "        [-1.1479,  0.2829,  0.2046,  ..., -0.9534,  0.1794, -0.9941]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0498,  1.2101,  0.9697,  ..., -0.3175,  0.3411, -0.8186],\n",
      "        [ 0.5857,  0.6724,  0.1350,  ..., -1.4255, -0.3915,  0.6680],\n",
      "        [ 0.7478,  1.1069,  0.2225,  ...,  1.6292,  0.3217, -0.4406],\n",
      "        ...,\n",
      "        [-0.0625, -1.2712,  0.0076,  ..., -2.8635,  0.6296, -0.4838],\n",
      "        [-0.9982,  1.1587, -0.5467,  ...,  0.1467,  0.5338,  1.3035],\n",
      "        [ 0.3495, -1.1854,  0.8582,  ...,  0.1294, -0.1927, -0.3814]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9008,  1.2600,  0.2365,  ...,  1.8940, -2.3443, -0.9925],\n",
      "        [ 0.6123,  2.3570, -1.0290,  ..., -0.0913, -0.9675, -0.8811],\n",
      "        [-0.0120,  0.0285,  0.8038,  ..., -1.2706,  0.8574, -0.2309],\n",
      "        ...,\n",
      "        [-1.4902,  1.6137,  0.1047,  ..., -2.0445,  0.3413, -1.8821],\n",
      "        [ 0.9750, -1.4248,  1.0518,  ..., -1.6906,  1.1558,  2.9710],\n",
      "        [ 1.3582,  1.6569, -0.3916,  ..., -0.8865, -0.3474,  1.7636]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6034,  0.8710, -1.4037,  ..., -0.4293,  1.0436, -1.0621],\n",
      "        [-0.6187,  1.5039,  0.3887,  ...,  1.5608,  0.3529,  0.1216],\n",
      "        [ 0.0819,  0.9608,  0.4196,  ..., -0.0811, -0.1880, -0.3220],\n",
      "        ...,\n",
      "        [-0.1959,  0.4396, -0.5158,  ...,  0.0025,  1.0333, -0.7676],\n",
      "        [-0.2159,  0.3379,  0.2323,  ...,  0.3113, -0.0081, -1.5711],\n",
      "        [-0.3959, -1.3567, -0.3079,  ...,  0.4775,  0.2068, -1.6340]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0610,  1.2766,  1.1396,  ..., -0.8757,  2.2720, -0.5400],\n",
      "        [ 0.0245, -0.5413, -1.0219,  ...,  0.2649, -1.5046,  0.5430],\n",
      "        [-0.5301,  0.3211,  0.8470,  ..., -0.3930,  0.6358, -1.1245],\n",
      "        ...,\n",
      "        [-0.6638, -1.1291,  0.1458,  ..., -0.4892, -0.4949, -0.1931],\n",
      "        [ 0.0661,  0.4641,  0.0999,  ...,  0.8845,  0.8904, -0.5070],\n",
      "        [-0.7301, -0.8224, -1.0118,  ...,  1.1193,  0.3870,  0.3899]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3216, -0.4150,  0.7028,  ..., -1.7135,  1.2227, -0.1113],\n",
      "        [-0.5427, -0.4211, -0.8772,  ..., -0.6567,  0.4379, -1.7548],\n",
      "        [ 0.0815, -0.5162,  1.1317,  ...,  1.5617,  0.6457, -0.2618],\n",
      "        ...,\n",
      "        [ 1.0463, -0.5320, -1.6526,  ...,  0.8998, -0.2504, -1.5183],\n",
      "        [ 0.2997,  0.4000, -1.0689,  ...,  2.4256,  0.3133, -1.2635],\n",
      "        [ 0.5246,  1.0444, -1.9296,  ...,  0.8606, -0.1659,  0.0865]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2375, -0.8407,  1.0209,  ...,  0.0942, -0.0605, -0.2422],\n",
      "        [ 0.5949,  1.6153, -0.3426,  ..., -0.3036, -0.1111, -0.7449],\n",
      "        [ 0.0352,  0.1303, -1.3944,  ..., -0.2439,  2.0117, -0.9027],\n",
      "        ...,\n",
      "        [-0.7667, -1.5844,  0.9433,  ...,  1.5426,  0.5937, -0.0048],\n",
      "        [ 0.6287, -1.0350,  0.4019,  ...,  1.2298,  1.1333, -1.5028],\n",
      "        [-1.1146,  0.2576, -1.3128,  ..., -0.7683, -0.9263, -0.1751]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.9534,  0.3157,  0.0111,  ..., -0.3068,  0.9444, -0.8255],\n",
      "        [ 1.6247,  0.1108,  0.4618,  ..., -0.7802,  1.9362, -0.6616],\n",
      "        [-0.0775, -1.1413,  0.9707,  ...,  1.5879, -0.4555,  1.0860],\n",
      "        ...,\n",
      "        [ 1.6743,  1.2036,  0.2984,  ...,  2.2447, -1.1211, -3.3801],\n",
      "        [-0.4277, -1.1635, -0.1058,  ...,  0.4172,  1.6275, -0.3085],\n",
      "        [-0.6000, -0.5199, -0.8469,  ...,  0.2600, -0.8535, -0.4457]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.9930e+00, -7.9583e-01, -1.4754e-01,  ...,  3.8215e-01,\n",
      "          7.4240e-01, -1.5101e+00],\n",
      "        [ 5.9343e-01, -1.0396e+00, -2.5048e-01,  ...,  5.2272e-01,\n",
      "          2.4215e-01,  3.7680e-01],\n",
      "        [-6.0387e-02, -4.4634e-01, -1.3610e+00,  ..., -1.3413e+00,\n",
      "         -3.6767e-02, -2.9204e-01],\n",
      "        ...,\n",
      "        [ 1.1408e+00,  9.3993e-01,  1.4539e-02,  ..., -1.0545e+00,\n",
      "         -4.7301e-02, -1.2289e+00],\n",
      "        [-7.8296e-01,  1.2240e-01,  1.3512e+00,  ..., -4.0588e-01,\n",
      "         -5.9575e-01, -8.3806e-01],\n",
      "        [-1.4705e-01,  1.6037e+00, -1.2336e+00,  ...,  1.8540e-03,\n",
      "         -3.3129e-02, -1.3721e-01]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.4155,  0.6718,  0.2701,  ..., -0.1607, -0.3937, -2.0322],\n",
      "        [-0.1130, -0.1733,  0.1036,  ...,  0.6415,  0.6961,  0.5618],\n",
      "        [ 0.9983,  1.1237,  2.1360,  ..., -0.1074, -0.4104, -1.2728],\n",
      "        ...,\n",
      "        [ 0.4037, -1.0052, -0.0186,  ...,  0.5398,  1.8158, -0.3331],\n",
      "        [-0.1839,  0.6306,  0.1357,  ..., -0.7345, -1.1064,  0.2746],\n",
      "        [-0.4481,  1.3070, -2.0455,  ...,  0.5249,  1.3486, -0.2927]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7397,  0.3925,  1.5948,  ..., -0.3240, -1.1873,  0.3594],\n",
      "        [ 0.2149, -1.2456, -1.7547,  ..., -1.6407, -1.4103, -1.6072],\n",
      "        [-0.1890,  0.9340,  1.2027,  ...,  2.3335,  0.4615,  1.2473],\n",
      "        ...,\n",
      "        [ 1.4735, -0.1391,  1.0639,  ...,  1.3344,  1.4154,  1.1791],\n",
      "        [-0.3091, -0.8077,  0.1693,  ...,  1.5258, -0.8488, -0.9748],\n",
      "        [-0.0276,  0.3434,  0.3311,  ...,  0.6627,  0.3883, -1.1249]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0441,  1.9147, -1.6001,  ..., -0.6166,  1.7222, -1.5452],\n",
      "        [-0.1680, -0.8748,  0.4845,  ...,  0.3137,  1.0298, -0.5594],\n",
      "        [ 0.4440,  0.3109,  1.2330,  ...,  1.7090,  0.3203, -0.0034],\n",
      "        ...,\n",
      "        [ 0.2887, -0.0430,  0.3227,  ..., -2.1963, -0.4424,  0.4134],\n",
      "        [ 1.1561, -0.6291,  1.1082,  ..., -3.1551, -1.3558,  2.7388],\n",
      "        [ 0.7315, -0.3982,  0.1217,  ...,  0.6390,  0.5027,  0.6569]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8994,  0.3518, -0.8211,  ...,  0.5574,  0.9535,  0.2627],\n",
      "        [ 0.2721, -0.1096,  1.6597,  ..., -0.5422, -0.1603, -0.9858],\n",
      "        [-0.5101,  0.8404, -0.7902,  ..., -0.5283, -2.4081, -0.5122],\n",
      "        ...,\n",
      "        [-0.5766,  0.5908, -0.9783,  ...,  0.6002,  0.0838,  0.7804],\n",
      "        [-0.3360, -0.2741,  1.4825,  ...,  1.7440, -0.9361, -0.3006],\n",
      "        [-1.3334, -1.3967,  1.3962,  ..., -1.0589,  1.4029, -1.2212]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2725, -0.1407, -0.0186,  ..., -1.3240, -0.3635, -0.0543],\n",
      "        [-2.3274, -1.0435,  0.6188,  ..., -1.1398,  0.1548, -0.4275],\n",
      "        [ 0.7076, -0.2720,  1.0732,  ..., -2.0352, -1.7870, -0.4286],\n",
      "        ...,\n",
      "        [ 1.5397, -1.1633,  0.2666,  ...,  4.3209,  1.4102, -3.6024],\n",
      "        [-1.2973, -0.1783, -2.1261,  ...,  2.2834,  0.0756, -1.7759],\n",
      "        [-1.0953, -1.6649,  0.8910,  ...,  2.5082,  2.1214, -0.8135]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3220,  0.2558,  0.4552,  ...,  0.1108,  1.8135,  0.4284],\n",
      "        [ 0.6792,  1.1540,  1.3280,  ...,  0.3265,  1.0318,  1.2481],\n",
      "        [-1.3687, -0.7677, -0.7056,  ..., -1.4054, -0.0231, -2.6078],\n",
      "        ...,\n",
      "        [-2.0241,  0.4980, -0.8292,  ..., -0.4742, -0.7805, -1.7622],\n",
      "        [ 1.4189,  1.3530,  0.7425,  ...,  0.0231, -1.1619,  1.0243],\n",
      "        [ 0.4115,  0.5599, -0.4291,  ..., -0.2920, -0.8881, -2.2486]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0844,  1.6906,  0.0458,  ...,  1.6727,  0.9953,  1.2115],\n",
      "        [ 0.8487, -0.0274, -0.7872,  ...,  1.2292,  0.4694,  1.0617],\n",
      "        [-1.2272,  1.1136,  0.2012,  ...,  0.4252,  0.0107,  1.8494],\n",
      "        ...,\n",
      "        [-0.3513, -0.0908,  1.6219,  ...,  0.4775,  1.3252,  0.8095],\n",
      "        [ 0.1179, -0.5190, -0.0102,  ...,  0.9559, -1.1288,  0.2501],\n",
      "        [-0.3764, -0.9943,  0.7168,  ...,  0.2453, -0.0257,  0.9531]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.1699, -1.3566,  0.3402,  ...,  0.8948,  0.6370,  2.0363],\n",
      "        [-1.2735, -0.7027, -0.1463,  ...,  2.4664, -0.7838,  1.1576],\n",
      "        [-0.6423, -0.8545, -2.4021,  ...,  0.4259,  0.7138,  0.6385],\n",
      "        ...,\n",
      "        [-0.8148, -1.7929,  0.8005,  ..., -0.5593, -0.9691,  1.0946],\n",
      "        [-0.0246, -0.0447, -1.1430,  ..., -1.3780, -0.3601,  0.1604],\n",
      "        [-0.3399,  0.1422,  0.4565,  ..., -1.5697, -0.0202,  0.2819]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8040,  0.0257,  1.9143,  ...,  0.5385, -0.5061,  0.8218],\n",
      "        [-0.7126,  1.1517,  2.1325,  ...,  0.2211,  0.0982, -0.6557],\n",
      "        [-0.9204, -0.0413,  1.7908,  ...,  0.3141,  0.3326,  0.3008],\n",
      "        ...,\n",
      "        [-0.8267,  1.4692,  0.2423,  ..., -0.6393,  0.9052,  1.3907],\n",
      "        [ 0.4723,  0.1951, -1.3924,  ..., -1.0980,  0.1532,  0.2964],\n",
      "        [-0.7355, -0.5326,  0.5249,  ..., -0.4231, -0.8231,  0.2248]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.1280,  0.0820,  0.4427,  ..., -2.1085,  0.5637, -0.4795],\n",
      "        [ 1.6679,  1.2497, -0.1516,  ...,  1.9221, -3.5169,  1.0056],\n",
      "        [-0.5699,  0.9650, -0.7349,  ..., -0.7833, -1.4314,  0.1120],\n",
      "        ...,\n",
      "        [-0.8204,  0.5944,  0.3961,  ..., -2.8003, -1.1870,  0.2757],\n",
      "        [-1.0974, -1.6093, -0.2201,  ..., -0.3496, -1.3452, -0.0988],\n",
      "        [ 0.1960,  0.9785, -1.1206,  ..., -0.1730, -0.7826, -0.4736]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0712, -0.3468,  0.9165,  ..., -0.4681, -1.0492, -0.0348],\n",
      "        [ 0.4167, -0.5999,  1.0207,  ...,  2.2148,  1.4099, -0.5884],\n",
      "        [-0.8131, -0.2808, -0.8949,  ..., -1.0517, -0.9913,  1.0783],\n",
      "        ...,\n",
      "        [-1.1299,  0.1762,  0.2247,  ...,  0.3528,  0.3568,  0.3573],\n",
      "        [ 0.0037, -0.1547, -0.8648,  ..., -0.1015,  1.2555,  1.1878],\n",
      "        [-1.4539,  1.4970, -0.5658,  ..., -0.3606, -0.0700, -0.0124]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4331,  0.9346, -0.6283,  ..., -0.5502, -1.2174,  0.0934],\n",
      "        [ 1.2770, -0.1984,  0.2470,  ...,  3.5837, -0.9537, -0.5586],\n",
      "        [-0.6712, -0.5636,  0.7481,  ..., -1.2139, -1.1533,  0.7127],\n",
      "        ...,\n",
      "        [ 0.2836,  1.1264, -0.1316,  ..., -0.8400, -1.6281,  0.9081],\n",
      "        [ 0.8280,  1.1099, -0.4780,  ...,  0.8316, -0.3937,  0.6881],\n",
      "        [-2.0425,  0.7349,  0.4627,  ..., -2.2773,  0.3798, -1.1775]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3609, -0.6212, -0.1140,  ...,  1.2798, -0.1688, -0.2536],\n",
      "        [ 0.0406, -1.0671, -0.4366,  ...,  0.6865, -0.5300,  0.6149],\n",
      "        [-1.2155, -0.5964,  0.7582,  ...,  1.2323,  1.1984,  0.7919],\n",
      "        ...,\n",
      "        [-0.8120,  0.3967, -0.2296,  ..., -1.0679, -0.8944,  0.3272],\n",
      "        [-0.5180,  0.5966,  0.8746,  ..., -1.3865,  0.1483, -0.2860],\n",
      "        [-1.2310, -0.8900, -0.9876,  ...,  0.8655, -0.3090, -0.0836]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8833,  0.1294,  0.5530,  ..., -0.2636,  0.3490,  1.1347],\n",
      "        [-0.2339, -0.2037,  0.5730,  ...,  0.5884,  0.2114,  0.2067],\n",
      "        [-0.2171, -0.1268,  1.6549,  ..., -0.8394,  1.0335, -0.2294],\n",
      "        ...,\n",
      "        [-0.3868,  0.2039, -0.1989,  ..., -0.5108,  0.8251, -0.7392],\n",
      "        [-1.1008, -1.6740, -0.1406,  ...,  0.2643,  1.5606,  1.1010],\n",
      "        [ 1.0033, -1.9893, -1.7877,  ..., -0.8472,  2.1783,  1.2146]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 2.4967,  1.9216,  2.3435,  ...,  1.7992, -0.4231,  0.2873],\n",
      "        [-0.4081,  0.5905,  0.2203,  ...,  0.7765,  0.7187,  0.5808],\n",
      "        [ 0.0977,  0.9919, -0.7996,  ..., -0.1112,  0.0511,  1.4741],\n",
      "        ...,\n",
      "        [-0.1794,  1.3304, -1.6912,  ..., -0.3210, -0.6705, -0.9711],\n",
      "        [ 0.3135,  0.5952,  1.5929,  ...,  0.5067, -0.5096, -0.4867],\n",
      "        [-0.0225, -0.0712, -0.9508,  ..., -0.3694,  0.2010,  1.0505]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2063, -0.9756, -1.0163,  ..., -1.5389,  0.2320, -1.1896],\n",
      "        [-0.5498, -1.0351, -0.3968,  ..., -0.0284, -1.2559, -2.1646],\n",
      "        [ 1.3008,  1.9771,  0.7253,  ..., -0.5159, -0.3370,  0.0154],\n",
      "        ...,\n",
      "        [ 0.2138,  1.0690,  0.1993,  ...,  0.6930,  1.2623, -1.7998],\n",
      "        [ 1.3069, -0.8747,  0.6715,  ..., -0.4596, -0.9457,  0.1646],\n",
      "        [ 0.4385,  1.0764, -0.0960,  ..., -0.3715, -0.7236,  1.4123]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.6185, -0.7581,  0.2480,  ..., -0.7675,  0.5538,  0.4776],\n",
      "        [ 0.7916,  0.6791,  2.0715,  ...,  2.1574, -0.4805, -0.3579],\n",
      "        [ 1.3733, -1.3237, -0.9070,  ..., -2.0087,  2.1703, -2.8349],\n",
      "        ...,\n",
      "        [-0.6811, -0.6062,  0.7225,  ..., -0.3838, -0.6987, -0.8478],\n",
      "        [-0.2668, -0.7475,  1.0360,  ..., -0.6702, -0.4968, -1.2818],\n",
      "        [-0.3461, -0.0830, -1.2325,  ...,  0.6478, -0.5056,  0.1982]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.1357,  0.5769, -0.5934,  ...,  3.2430, -0.4489, -1.0619],\n",
      "        [-0.1317, -0.4055, -0.3143,  ...,  0.9657,  0.0298, -2.3511],\n",
      "        [-0.1016, -0.2634, -0.2011,  ..., -0.4931, -0.9041, -0.3445],\n",
      "        ...,\n",
      "        [-0.1167,  0.1625,  0.1501,  ..., -0.4526, -1.1540, -0.2873],\n",
      "        [-0.7817,  1.9275, -1.2199,  ...,  0.2787,  0.6205,  0.5632],\n",
      "        [-0.6526, -0.7743, -0.4998,  ..., -1.3927, -0.8252, -0.0992]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-4.5349e-02, -8.2792e-01, -4.3014e-01,  ...,  8.3253e-01,\n",
      "          7.7420e-04,  1.0595e+00],\n",
      "        [ 1.3265e+00, -3.8094e-01,  2.7224e-01,  ...,  2.9416e+00,\n",
      "          2.7170e-01, -1.7426e+00],\n",
      "        [ 1.4387e-01, -5.0620e-01,  1.2896e+00,  ..., -1.0716e+00,\n",
      "          4.6106e-01,  6.2737e-01],\n",
      "        ...,\n",
      "        [-1.2115e+00,  2.4550e-01,  1.8585e+00,  ...,  1.6746e+00,\n",
      "          1.3808e+00,  4.5968e-01],\n",
      "        [-6.3871e-01, -6.6424e-01, -1.1779e+00,  ...,  4.4859e-02,\n",
      "         -6.8007e-01,  5.5011e-01],\n",
      "        [ 1.5438e+00,  7.4399e-02, -7.0160e-01,  ...,  3.6505e-01,\n",
      "          4.2770e-01,  1.2199e-02]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.7795,  1.4499, -0.4923,  ...,  0.6973,  0.1658, -0.7652],\n",
      "        [-1.1563, -0.9742, -1.3552,  ...,  0.4672,  0.8957, -1.5224],\n",
      "        [-0.0362, -0.0113,  0.8481,  ..., -2.0004, -0.6170, -0.5294],\n",
      "        ...,\n",
      "        [-1.3581, -1.2247,  1.5189,  ...,  0.8829,  3.1444,  1.3806],\n",
      "        [-1.1455,  1.1410, -0.7564,  ...,  0.4518,  0.3056, -2.8795],\n",
      "        [ 0.6980,  0.3224, -0.2131,  ...,  0.0625, -0.2957,  0.7269]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9368,  0.6271,  0.0488,  ...,  1.5071, -0.1836, -1.4418],\n",
      "        [-0.3350,  0.1892, -0.5342,  ..., -1.0434, -1.1523, -1.2011],\n",
      "        [ 0.2627,  0.2586,  0.8167,  ...,  0.1186, -1.4319,  0.2717],\n",
      "        ...,\n",
      "        [ 0.3757,  2.0062, -1.7878,  ...,  0.7956,  0.4288, -0.9818],\n",
      "        [ 2.3903, -1.6791,  0.2631,  ...,  2.3765, -0.6573, -0.0453],\n",
      "        [ 0.0037,  0.5685, -2.4363,  ...,  1.0712,  2.2130,  1.0625]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.8269, -1.3755, -1.1372,  ..., -0.6788, -0.1840,  3.8757],\n",
      "        [ 0.1967, -0.9989,  1.6637,  ..., -1.4903, -0.9354,  0.2217],\n",
      "        [-1.8814, -0.6210, -0.1549,  ..., -0.5524,  0.9963,  0.3660],\n",
      "        ...,\n",
      "        [-0.3045, -1.1624,  0.9335,  ...,  1.4080,  0.0257,  0.2948],\n",
      "        [ 1.2962, -2.0470,  1.3827,  ...,  0.2584,  0.7527,  0.7661],\n",
      "        [-0.0155,  0.8745, -1.4545,  ..., -0.9353, -0.6145,  0.6717]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5981,  0.7729, -0.0193,  ..., -1.0326, -0.7588,  0.9729],\n",
      "        [-0.4485, -0.6475, -1.9670,  ...,  2.4030,  2.5610,  0.4029],\n",
      "        [ 0.7816,  0.7837,  0.2974,  ...,  0.6711, -0.5431,  0.5595],\n",
      "        ...,\n",
      "        [-2.0542,  0.3234, -2.3352,  ...,  0.9461,  0.4756,  0.2757],\n",
      "        [-0.4276, -2.2740, -0.3446,  ...,  1.7804, -0.6236,  0.9586],\n",
      "        [ 0.5378,  0.6881,  0.0902,  ...,  0.3507,  0.7256, -1.1626]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3723, -1.0736, -0.7663,  ...,  0.3337,  0.6537,  0.6974],\n",
      "        [-0.6856,  0.9770, -0.2959,  ..., -0.0152,  1.3760, -1.3311],\n",
      "        [-1.6525, -0.3712, -0.4536,  ..., -0.4785,  1.1171,  0.9228],\n",
      "        ...,\n",
      "        [ 2.8744,  2.2489,  1.6933,  ...,  0.2221,  0.4607, -0.6960],\n",
      "        [ 0.7010,  0.3012,  1.5954,  ...,  1.2087,  0.5951, -0.2385],\n",
      "        [-0.8252, -0.3896,  1.0814,  ..., -2.1838,  0.8423, -0.1276]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0353, -0.4077,  0.8806,  ..., -0.3504, -1.0551,  0.2931],\n",
      "        [-0.7353,  0.5534,  0.6211,  ..., -1.8381,  0.8172,  0.8042],\n",
      "        [ 0.1604, -0.0277,  0.5248,  ...,  1.4364, -1.4485, -0.4717],\n",
      "        ...,\n",
      "        [-0.1962,  0.6442, -2.3075,  ..., -0.2757,  0.0704,  1.4960],\n",
      "        [-0.9261, -1.1602, -0.6441,  ...,  0.2961,  0.5028, -0.4349],\n",
      "        [-0.5335,  0.7193,  0.3495,  ...,  0.9392,  0.5225,  1.1557]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2562,  1.4538, -0.2933,  ..., -1.3333,  0.0126, -0.7442],\n",
      "        [-1.0814,  0.0412, -1.9763,  ...,  0.9706, -0.2830,  0.5128],\n",
      "        [-0.1635,  0.9072,  0.2845,  ...,  0.1724,  0.1105, -0.9154],\n",
      "        ...,\n",
      "        [ 2.0090, -2.4184,  1.7634,  ...,  1.8470, -0.5162, -0.4707],\n",
      "        [ 0.6902,  1.0955, -0.0208,  ...,  0.9267, -0.5947,  0.6510],\n",
      "        [ 0.4337, -1.0636, -1.5046,  ..., -1.0158,  0.0642, -0.6616]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-2.3332,  0.6178, -0.7549,  ..., -0.9708, -1.7027,  2.2467],\n",
      "        [ 0.3635,  0.2856, -1.1893,  ...,  0.3378,  0.6439,  0.4478],\n",
      "        [ 0.2421,  0.7540, -0.1843,  ..., -0.6053,  0.1753, -1.4237],\n",
      "        ...,\n",
      "        [ 0.2318, -0.4659,  0.5561,  ..., -1.2930, -0.0118, -0.3738],\n",
      "        [ 0.3255, -0.9349, -0.1037,  ...,  0.9149, -0.4445,  1.0155],\n",
      "        [-0.6568,  1.1023,  1.8613,  ..., -0.5534,  0.3801, -0.3254]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.4458, -0.5393, -0.2655,  ..., -1.2356, -0.4749, -0.8138],\n",
      "        [ 0.0299, -0.0156,  0.2200,  ..., -1.2403, -0.8829, -0.1920],\n",
      "        [ 1.7438, -2.0680,  2.0269,  ...,  2.0989, -1.9593,  0.5110],\n",
      "        ...,\n",
      "        [-0.7789, -0.6867,  0.8078,  ...,  1.4664,  0.2251, -0.9588],\n",
      "        [ 0.4499,  0.4816,  0.6120,  ...,  0.3347, -1.4270, -0.4988],\n",
      "        [-1.2089,  0.2145, -0.6887,  ...,  3.2068, -0.2245,  0.2837]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.2554,  1.3835, -0.5368,  ...,  0.9194, -0.6058, -0.8797],\n",
      "        [-1.8471, -1.2107, -0.9836,  ...,  1.0377,  2.9820,  0.0981],\n",
      "        [ 0.7135,  1.0249, -0.1966,  ..., -0.9916, -0.4605,  0.1389],\n",
      "        ...,\n",
      "        [-1.7147, -1.2605, -0.0329,  ..., -0.0660,  0.5771,  2.0200],\n",
      "        [-0.8128, -2.0236, -1.1076,  ...,  0.8402,  1.0590, -1.0998],\n",
      "        [ 0.6574,  0.2196, -0.9519,  ...,  0.3808,  1.3208, -0.6933]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-2.3226,  0.9930, -0.6652,  ...,  1.1401, -1.1690,  1.4980],\n",
      "        [ 0.9404, -1.0282,  0.8036,  ..., -0.8111, -0.8446,  1.0304],\n",
      "        [-0.2555, -0.0229, -0.3268,  ...,  0.0195, -1.2992,  1.1370],\n",
      "        ...,\n",
      "        [-1.9486, -0.4921, -0.5901,  ..., -0.2637,  0.1203,  1.7789],\n",
      "        [-1.4957,  0.3717,  0.5743,  ...,  0.5241,  0.2181,  0.1714],\n",
      "        [-1.2145, -0.4745,  0.0106,  ...,  0.3674, -0.5364,  0.9310]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 1.0155,  0.4331, -0.6975,  ...,  0.7068,  0.6688,  0.4195],\n",
      "        [ 1.9500, -2.1412,  2.4549,  ...,  1.3245, -0.1593,  0.2390],\n",
      "        [ 0.5396, -2.1326, -0.3389,  ...,  2.3115, -1.2313,  2.5733],\n",
      "        ...,\n",
      "        [-0.4731, -1.1612,  0.7788,  ...,  0.4131, -0.9526, -0.9975],\n",
      "        [-0.7517,  0.9878,  0.1086,  ...,  0.4678, -0.2659,  0.4512],\n",
      "        [ 0.8956, -1.4030,  0.3204,  ...,  0.0120, -0.5464, -0.4094]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.3154, -0.7661, -1.1222,  ..., -0.0969,  0.5092, -0.4356],\n",
      "        [ 1.1547,  0.7241,  0.5371,  ..., -2.9315, -2.6956, -2.0061],\n",
      "        [-0.2685, -0.1397,  0.8036,  ...,  2.0641, -0.4325,  0.7379],\n",
      "        ...,\n",
      "        [-0.9191, -0.9284, -0.4113,  ..., -0.5219, -0.5553,  1.3892],\n",
      "        [ 0.6528, -0.2751,  0.4470,  ...,  0.5177,  0.5685,  0.2015],\n",
      "        [ 0.7214, -0.8031, -1.6352,  ...,  2.4089,  1.4485, -0.3965]]), 'y': tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.6125,  0.4549,  1.0902,  ...,  0.9743,  0.3850, -1.1063],\n",
      "        [-1.0636, -0.7341,  0.9841,  ...,  1.4612, -1.0557, -0.6287],\n",
      "        [-0.6533,  0.3290,  0.6292,  ...,  0.8851, -0.9999,  0.0034],\n",
      "        ...,\n",
      "        [ 0.3954,  0.4341, -0.0296,  ..., -1.2327, -0.5737,  1.3298],\n",
      "        [-0.5504, -0.9848, -1.3090,  ...,  1.3890, -1.1073,  1.1742],\n",
      "        [ 1.7887, -0.1814,  0.9200,  ...,  2.2634,  0.5036,  1.0847]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.6451,  0.3068, -0.2446,  ...,  0.8197, -0.9190, -1.9391],\n",
      "        [-0.0251, -0.5214, -0.9076,  ..., -0.3234,  0.2987,  1.3422],\n",
      "        [ 1.6524,  2.3558, -0.0944,  ...,  0.0755,  0.3495, -0.5718],\n",
      "        ...,\n",
      "        [-0.0331, -0.2527,  0.5391,  ..., -0.1661, -0.5654, -0.6396],\n",
      "        [-1.2380, -0.8280,  0.3701,  ..., -0.1598,  0.6570,  1.5165],\n",
      "        [-0.0826,  0.3090, -0.7334,  ..., -1.7523,  0.9858, -0.3362]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.0765,  0.0784, -0.8073,  ...,  0.3720, -0.8128, -0.2140],\n",
      "        [ 0.1147, -0.9824, -1.0862,  ..., -0.9732,  0.8494, -0.2343],\n",
      "        [ 0.5288,  0.9074,  0.3503,  ..., -0.7314,  0.8039,  0.5703],\n",
      "        ...,\n",
      "        [-0.8446, -0.4318,  0.0928,  ..., -0.8724, -2.3615,  0.9705],\n",
      "        [ 1.3834, -0.9130,  0.8896,  ...,  1.4475, -1.0188, -1.0306],\n",
      "        [-0.8625, -0.8794, -0.7986,  ..., -1.5800, -0.5338, -1.3481]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.9085,  1.2640, -0.1177,  ...,  0.0346, -0.7893,  1.2221],\n",
      "        [ 1.1271, -0.2871, -0.4485,  ..., -0.9032,  0.5813, -0.4654],\n",
      "        [ 1.1742,  0.8527, -2.3019,  ..., -1.3393,  1.8879,  1.2966],\n",
      "        ...,\n",
      "        [ 0.3817, -0.7995, -1.3243,  ..., -0.3535, -0.5824,  0.7544],\n",
      "        [ 0.6799,  1.1994,  1.3525,  ..., -0.5066,  0.3416,  0.0174],\n",
      "        [-0.3975, -0.5293, -1.1011,  ..., -1.0730,  1.1926, -0.7811]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.5623, -1.1020,  0.5209,  ...,  0.2571,  0.3347, -0.0559],\n",
      "        [ 0.8686, -1.4427,  1.2836,  ...,  0.6212, -0.1284, -0.1489],\n",
      "        [ 2.3546,  0.7036,  0.7663,  ...,  1.0376, -0.9307,  0.2043],\n",
      "        ...,\n",
      "        [-1.7281, -0.9841, -0.7068,  ...,  0.7305,  0.1914,  1.0640],\n",
      "        [ 1.0017,  0.2625, -0.0335,  ..., -0.5232,  0.6968,  0.5409],\n",
      "        [ 0.5054,  0.1855, -1.1790,  ...,  0.7225,  0.7452, -0.7189]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.7720, -1.6030, -0.6007,  ..., -1.3079,  1.0122, -1.1561],\n",
      "        [ 2.2469,  1.0249,  0.1685,  ..., -0.4356,  0.4192, -0.0239],\n",
      "        [-0.2782, -0.6305, -0.5828,  ..., -1.7311, -0.4030,  1.1885],\n",
      "        ...,\n",
      "        [-0.7716, -0.4698, -1.0446,  ...,  0.7185, -0.6023, -0.9769],\n",
      "        [-0.9365, -0.4760, -0.1931,  ..., -1.1541,  0.5499,  0.3494],\n",
      "        [ 0.2148, -1.3606, -0.4552,  ...,  0.6783, -1.2622,  0.7527]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.0360, -0.0025,  0.1358,  ..., -0.8274, -1.5691,  0.1076],\n",
      "        [ 0.8405, -0.0211, -0.5844,  ...,  1.3559, -0.6119,  2.2855],\n",
      "        [-0.6637, -0.1028,  0.1821,  ...,  0.7422, -1.1289, -0.4914],\n",
      "        ...,\n",
      "        [-0.7768, -0.2376, -0.6040,  ..., -0.8861, -0.0919,  0.7935],\n",
      "        [ 1.8385,  2.2854, -2.3144,  ..., -0.2749,  1.5356, -0.2323],\n",
      "        [-1.9686,  0.6852, -0.7901,  ..., -0.5724,  0.5177,  0.7062]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-7.2780e-01,  7.6763e-01, -1.8136e+00,  ...,  4.1829e-02,\n",
      "         -8.1089e-01, -1.3477e+00],\n",
      "        [-1.5012e+00, -5.8677e-01,  2.9103e-01,  ...,  1.8580e-02,\n",
      "          6.4783e-02,  1.0611e-03],\n",
      "        [-4.0574e-01,  2.5990e-01,  7.6792e-01,  ...,  6.1695e-01,\n",
      "         -7.7412e-02, -9.0377e-01],\n",
      "        ...,\n",
      "        [-5.7347e-01, -6.9399e-01, -8.2497e-01,  ...,  3.1694e-01,\n",
      "         -1.7575e-01,  9.3620e-01],\n",
      "        [ 7.1622e-01,  3.8107e-01,  6.8567e-01,  ..., -1.2481e+00,\n",
      "          5.1807e-01,  7.4483e-01],\n",
      "        [-1.8041e-02, -2.4972e-01,  8.1968e-01,  ..., -5.7571e-01,\n",
      "          1.1111e+00, -2.4707e+00]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.7127, -0.4823,  1.5000,  ..., -0.8309, -0.1242, -0.0924],\n",
      "        [-0.5349, -1.0300,  0.5962,  ..., -0.1534,  0.6792,  0.6729],\n",
      "        [-0.1928,  0.4741, -0.2773,  ...,  1.0488,  0.2771,  0.3849],\n",
      "        ...,\n",
      "        [-2.0598, -1.6465,  0.8245,  ..., -0.2430,  0.3144,  1.9162],\n",
      "        [ 0.2254, -0.1976,  0.1037,  ...,  1.6653,  0.6909,  0.8766],\n",
      "        [-1.2113, -0.7747, -0.3108,  ..., -1.9085,  1.8114,  0.5500]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.3484, -0.8958, -0.9885,  ..., -0.4811,  0.2836, -0.3098],\n",
      "        [-0.6054,  0.7217, -0.4922,  ..., -0.0687,  1.6728, -0.5683],\n",
      "        [-1.3601, -1.5994,  0.1762,  ...,  1.0541, -0.9733, -0.9969],\n",
      "        ...,\n",
      "        [-1.3403, -0.6825, -0.2429,  ...,  0.1948,  0.7907, -0.9785],\n",
      "        [-1.2273,  0.1376, -0.4689,  ...,  1.2044, -1.7615, -0.2519],\n",
      "        [-1.0163, -0.7963,  0.3479,  ..., -0.8846,  0.0137, -0.0699]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.5097,  0.1278, -0.9716,  ...,  0.1852, -0.4858, -2.1491],\n",
      "        [ 0.5187, -0.4929, -0.1133,  ...,  0.1885, -1.3760,  0.0569],\n",
      "        [-0.5054, -0.8946, -1.7366,  ..., -0.3628, -1.5032,  0.1610],\n",
      "        ...,\n",
      "        [-0.4515, -0.1010,  1.3870,  ...,  1.5347,  0.6440,  0.3916],\n",
      "        [ 0.0877, -1.1326,  0.8001,  ..., -0.4067, -0.4886,  0.0211],\n",
      "        [ 0.3254,  0.6644, -0.4120,  ..., -1.4342, -1.0361, -0.2718]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-9.4639e-01, -3.9207e-01, -3.9965e-01,  ..., -1.8269e-03,\n",
      "         -8.2828e-01, -3.8564e-01],\n",
      "        [ 7.6116e-01, -7.9867e-01,  2.3373e+00,  ...,  5.1197e-01,\n",
      "         -5.7827e-01, -3.7141e-02],\n",
      "        [-7.3678e-01,  1.9408e+00,  2.7757e-01,  ...,  1.2616e+00,\n",
      "          8.9075e-01, -1.0734e-01],\n",
      "        ...,\n",
      "        [-1.5843e+00, -2.0818e+00, -2.6851e-01,  ...,  1.7237e+00,\n",
      "          1.0635e+00,  4.7968e-01],\n",
      "        [-5.4143e-01,  1.0322e+00, -1.4590e+00,  ...,  7.1527e-01,\n",
      "         -1.1335e+00, -4.8472e-01],\n",
      "        [-1.6064e+00,  1.5998e+00,  6.7693e-01,  ...,  2.8628e+00,\n",
      "          1.0997e+00, -1.0190e+00]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.6153,  1.6546,  0.8841,  ...,  0.3427,  0.5482,  0.6452],\n",
      "        [-1.9183, -0.1168,  0.1585,  ...,  0.5104, -1.3421,  0.4672],\n",
      "        [-0.4635, -0.2580, -0.2622,  ...,  0.0125,  1.3604,  0.2116],\n",
      "        ...,\n",
      "        [ 0.8954,  1.9991, -0.7202,  ...,  0.1817, -1.0474, -0.4079],\n",
      "        [-0.3844,  1.3527,  0.5745,  ...,  1.8524,  3.4133, -1.0038],\n",
      "        [-0.9899,  1.6593, -0.1360,  ...,  1.5479, -0.2499, -0.5902]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5408, -0.1957, -0.4632,  ..., -0.5334, -0.3915, -1.0362],\n",
      "        [ 1.2692, -1.0472,  1.1500,  ..., -1.0601,  1.8251,  0.6964],\n",
      "        [ 0.8201, -1.2383,  0.4133,  ...,  0.4070,  0.1546, -1.7182],\n",
      "        ...,\n",
      "        [ 0.1062,  1.4475, -0.1610,  ...,  0.8446,  0.1754,  1.2518],\n",
      "        [-0.3500, -1.0654, -0.6601,  ..., -1.5082, -1.1657, -1.2850],\n",
      "        [ 0.2567, -0.8449, -0.0711,  ...,  0.5132, -0.1207, -0.2339]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.5659, -0.2021,  0.5334,  ...,  0.5572, -0.8450, -1.4899],\n",
      "        [ 0.3942,  1.0134,  0.2627,  ..., -0.8403, -2.3341,  0.3252],\n",
      "        [-0.7558, -0.6972, -0.5941,  ..., -0.8119, -0.3851, -0.9125],\n",
      "        ...,\n",
      "        [-0.2485,  0.5302, -0.3217,  ...,  0.0793,  2.5424, -1.6390],\n",
      "        [ 0.4109,  0.9719, -1.3137,  ..., -0.6576,  0.5614, -0.8743],\n",
      "        [-0.2464, -0.4250, -0.0732,  ..., -1.0081,  0.5216, -0.9483]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.2775,  1.1214, -0.3468,  ...,  0.4320,  0.5394,  0.6771],\n",
      "        [-1.9582, -1.3895, -1.2840,  ..., -1.0165,  0.2135, -0.5267],\n",
      "        [ 1.4100, -1.1084,  0.6480,  ...,  0.5444,  0.9058,  0.3765],\n",
      "        ...,\n",
      "        [ 1.1966,  1.3038, -0.1094,  ..., -0.6780, -0.2934, -0.3705],\n",
      "        [ 3.1995,  2.1676,  2.2327,  ...,  1.2125, -0.6705, -0.3077],\n",
      "        [-0.0109,  0.0683, -0.4424,  ..., -1.8451,  1.0130, -1.1373]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-1.2774, -1.5581, -0.2672,  ...,  0.8422,  0.6597,  0.4438],\n",
      "        [ 0.6441,  0.0254, -1.0521,  ...,  1.1822, -1.1703, -0.5300],\n",
      "        [-1.2038, -0.5680,  0.5091,  ..., -0.5779, -0.7030,  0.4338],\n",
      "        ...,\n",
      "        [ 0.9778, -0.3081, -0.5306,  ..., -0.3408, -0.8311, -1.4394],\n",
      "        [ 0.0790, -0.8282,  0.8415,  ..., -0.3718,  0.9759, -0.9487],\n",
      "        [ 0.9094, -1.1462,  1.2383,  ...,  0.2766, -0.0257,  0.3121]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[ 0.8571,  1.9190,  0.7760,  ..., -1.0802,  1.0203, -0.6344],\n",
      "        [-1.0168, -0.5512,  0.2142,  ...,  0.6122, -0.7202,  0.0210],\n",
      "        [-0.7073, -1.2096, -1.0585,  ...,  2.4519,  0.3341,  0.5515],\n",
      "        ...,\n",
      "        [-0.5157,  0.6110, -0.1447,  ...,  0.0355, -0.0536, -0.2143],\n",
      "        [-0.2154, -0.0302, -0.9460,  ...,  0.4056, -0.3878, -1.1402],\n",
      "        [ 0.2266,  0.8007, -0.1745,  ..., -3.0949, -0.2528,  0.5035]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([128, 256, 16])\n",
      "{'x': tensor([[-0.9598, -1.3641, -0.4924,  ..., -0.1817, -0.6858, -0.4411],\n",
      "        [ 1.8563,  1.1680,  0.5311,  ..., -0.1547, -1.7264,  0.6742],\n",
      "        [ 0.4606, -0.2859, -1.1833,  ..., -0.8960, -1.5898, -0.5128],\n",
      "        ...,\n",
      "        [ 0.8058,  0.4727,  0.2495,  ..., -0.4911,  1.1458,  0.5817],\n",
      "        [ 0.6560,  0.9442,  0.4564,  ...,  0.8891,  3.0306,  1.4754],\n",
      "        [ 0.1951,  2.0221,  0.8572,  ...,  0.4119, -0.5087, -0.7963]]), 'y': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])}\n",
      "torch.Size([60, 256, 16])\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = Model(\n",
    "            num_features=num_features,\n",
    "            num_targets=num_targets,\n",
    "            hidden_size=hidden_size,\n",
    "        )\n",
    "# previous method they averaged each prediction result or something from the fold in k-fold\n",
    "# what we're gonna do here is try testing a dummy model first, then maybe implement that\n",
    "# by loading all state model, and do data augmentation on all of that, or if no time we just report result \n",
    "# with one model, and how it improves ? \n",
    "seed = 15\n",
    "fold = 4\n",
    "mod_name = f'FOLD_mod11_{seed}_{fold}_.pth'\n",
    "model.load_state_dict(torch.load(mod_name))\n",
    "\n",
    "# summary(model, )\n",
    "# print(model)\n",
    "\n",
    "# output the extracted feature (image based for 1D-CNN)\n",
    "# 1. prepare training data (use full training data)\n",
    "train_df = train.reset_index(drop=True).copy()\n",
    "\n",
    "# split into X and y train\n",
    "x_train, y_train, y_train_ns = train_df[feature_cols], train_df[target_cols].values,train_df[target_nonsc_cols2].values\n",
    "# x_valid, y_valid, y_valid_ns  = valid_df[feature_cols], valid_df[target_cols].values,valid_df[target_nonsc_cols2].values\n",
    "\n",
    "\n",
    "# print(x_train.shape)\n",
    "# print(y_train.shape)\n",
    "\n",
    "# preprocess x_train\n",
    "x_train, _, _ = preprocessData(x_train, None, None)\n",
    "train_dataset = TrainDataset(x_train, y_train)\n",
    "\n",
    "# valid_dataset = TrainDataset(x_valid, y_valid)\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# validloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(trainloader)\n",
    "\n",
    "\n",
    "all_feats = []\n",
    "all_labels = []\n",
    "# 2. Extract features\n",
    "extracted_feats = []\n",
    "model.eval()\n",
    "model.to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    for data in trainloader:   \n",
    "        x_data = data['x'].to(DEVICE)\n",
    "        y_data = data['y'].to(DEVICE)\n",
    "        print(data)\n",
    "        \n",
    "        extracted_feat = model.extractImageFeat(x_data)\n",
    "        all_feats.append(extracted_feat.cpu().numpy())\n",
    "        all_labels.append(y_data.cpu().numpy())\n",
    "        print(extracted_feat.shape)\n",
    "\n",
    "\n",
    "        # # shape will be (batch_size, 256, hidden_size (4096) / 256 = 16)\n",
    "        # extracted_feats.append(extracted_feat) \n",
    "\n",
    "x_arr = np.concatenate(all_feats, axis=0)\n",
    "y_arr = np.concatenate(all_labels, axis=0)\n",
    "# store extracted_feats as npz\n",
    "\n",
    "np.savez_compressed(\"extracted_features.npz\", x=x_arr, y=y_arr)\n",
    "\n",
    "\n",
    "# 3. apply data augmentation\n",
    "# generate augmented data + original data and save it to disk \n",
    "# done in data_augmentation.py right now\n",
    "\n",
    "# make it into the same format as train_df[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import augmentation library here \n",
    "\n",
    "# maybe do some modification here and only load cutout etc\n",
    "\n",
    "# or do it couple of times here and can set parameters here, and also ratio , basically setable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-1.00557448e-03  4.42473497e-03 -1.52753585e-03 ... -1.83616541e-02\n",
      "   -7.14211818e-03 -4.11044247e-03]\n",
      "  [-6.56441320e-03 -9.27971303e-03  3.20342090e-03 ...  4.86232340e-03\n",
      "    4.99416562e-03  2.79481546e-03]\n",
      "  [-2.48408305e-05 -1.02598928e-02 -4.02367114e-05 ...  9.78521444e-03\n",
      "   -6.96295360e-03  6.80519175e-03]\n",
      "  ...\n",
      "  [-2.16853735e-03 -6.97554555e-03 -8.78027920e-03 ... -2.55005658e-02\n",
      "   -1.45354411e-02  3.53795174e-03]\n",
      "  [ 4.53084800e-03 -6.38141856e-03 -3.80743854e-03 ...  7.86777702e-04\n",
      "   -3.01365857e-03 -1.94047799e-03]\n",
      "  [ 1.13142058e-04 -4.61847754e-03 -1.20552781e-03 ...  1.78245583e-03\n",
      "    7.02789170e-04 -2.74628517e-03]]\n",
      "\n",
      " [[-1.77538814e-03  3.44247581e-03  3.46450950e-03 ... -1.83070917e-02\n",
      "   -8.66016094e-03 -7.50133581e-03]\n",
      "  [-7.02879718e-03 -1.07407281e-02  2.05254136e-03 ...  3.32349143e-03\n",
      "    1.53291202e-03  2.78197532e-03]\n",
      "  [-1.00854224e-04 -7.90468883e-03  3.75686702e-03 ...  4.20470349e-03\n",
      "   -7.05911126e-03  6.79879403e-03]\n",
      "  ...\n",
      "  [-3.98627156e-03 -9.39525198e-03 -1.14069926e-02 ... -1.64941456e-02\n",
      "   -1.30971540e-02  2.07999279e-03]\n",
      "  [ 4.26754868e-03 -6.30170014e-03 -2.50876299e-03 ...  2.80913711e-03\n",
      "   -2.90492387e-03 -1.71634636e-03]\n",
      "  [ 1.05674344e-03 -1.95526425e-03  1.18230609e-03 ...  7.17472227e-04\n",
      "    1.12447073e-03 -3.46550439e-03]]\n",
      "\n",
      " [[-6.74235448e-03  1.32715544e-02  1.01581579e-02 ... -1.32426489e-02\n",
      "   -7.50585785e-03 -4.89560002e-03]\n",
      "  [-5.64131839e-03 -8.19075108e-03  3.06738797e-03 ...  2.31434498e-03\n",
      "    2.95022503e-04  2.75971438e-03]\n",
      "  [-1.83176994e-03 -1.12537481e-02 -9.02756408e-04 ...  2.69450899e-03\n",
      "   -7.15393759e-03  7.00423168e-03]\n",
      "  ...\n",
      "  [-4.54475638e-03 -3.12996609e-03  1.01647098e-02 ... -4.18483606e-03\n",
      "   -1.04305707e-02  2.53370916e-03]\n",
      "  [ 2.85929674e-03 -8.06227699e-03 -6.44652452e-03 ...  5.45623247e-04\n",
      "   -2.77789240e-03 -2.04133976e-04]\n",
      "  [ 8.51215096e-04 -1.64175860e-03  8.84864829e-04 ...  1.66886090e-03\n",
      "    2.53129238e-03 -1.66478276e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-3.02453758e-03  7.20532611e-03  1.16468482e-02 ... -1.37345549e-02\n",
      "   -7.13030202e-03 -4.62649949e-03]\n",
      "  [-7.19267968e-03 -9.08453111e-03  1.25487777e-03 ...  2.22925167e-03\n",
      "    1.91797561e-03  2.53134547e-03]\n",
      "  [-8.75662547e-04 -8.83380510e-03  7.49889528e-04 ...  4.13423311e-03\n",
      "   -6.84719672e-03  7.13087898e-03]\n",
      "  ...\n",
      "  [-3.52110388e-03 -2.78570293e-03  1.01578031e-02 ... -1.43577578e-03\n",
      "   -8.08273256e-03  2.80377036e-03]\n",
      "  [ 3.29836900e-03 -7.01425876e-03 -2.51643779e-03 ...  3.07941739e-03\n",
      "   -3.09686409e-03 -1.94343564e-03]\n",
      "  [-1.53088686e-03 -2.04698672e-03  3.73248477e-04 ...  1.05831353e-03\n",
      "    2.58233515e-04 -3.33135715e-03]]\n",
      "\n",
      " [[ 8.15869542e-04  5.67330653e-03  4.36050259e-03 ... -1.91862956e-02\n",
      "   -8.00252426e-03 -7.25327944e-03]\n",
      "  [-6.23740163e-03 -1.01166731e-02  1.15893735e-03 ...  3.45197134e-03\n",
      "    7.94803491e-04  2.70604063e-03]\n",
      "  [-8.32450387e-05 -8.00155848e-03  7.37458933e-03 ...  7.75392074e-03\n",
      "   -7.21653318e-03  6.62657572e-03]\n",
      "  ...\n",
      "  [-3.65312933e-03 -7.40123726e-03 -2.84374226e-03 ... -1.53687280e-02\n",
      "   -1.43524818e-02  3.25203966e-03]\n",
      "  [ 4.52646101e-03 -6.22014282e-03 -2.22369432e-04 ...  2.33770022e-03\n",
      "   -3.05062649e-03 -1.78795692e-03]\n",
      "  [ 9.48938949e-04  7.70157931e-05  1.66570605e-03 ...  1.72062300e-03\n",
      "    8.65898328e-04 -3.46418377e-03]]\n",
      "\n",
      " [[-1.66341302e-03  9.81959421e-03  7.88732618e-03 ... -1.63105335e-02\n",
      "   -6.99040527e-03 -3.88425332e-03]\n",
      "  [-6.41435245e-03 -9.12024360e-03  4.20088042e-03 ...  2.67169019e-03\n",
      "    1.73730543e-03  2.87511013e-03]\n",
      "  [-3.14962854e-05 -9.95221827e-03 -2.89313786e-04 ... -4.90976218e-03\n",
      "   -7.23958574e-03  7.02980068e-03]\n",
      "  ...\n",
      "  [-3.19724320e-03 -6.26498554e-03 -1.00213373e-02 ... -1.43798944e-02\n",
      "   -7.81633984e-03  3.00237164e-03]\n",
      "  [ 4.42095473e-03 -5.79037052e-03 -5.53376880e-03 ...  1.09272893e-04\n",
      "   -2.67156959e-03  6.13688608e-04]\n",
      "  [ 1.76157360e-03  2.62900314e-04  1.38405466e-03 ...  1.90825935e-03\n",
      "    1.34536531e-03 -3.20383790e-03]]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# load the augmented file here \n",
    "new_train_data = np.load(\"train_augmented.npz\")\n",
    "\n",
    "new_x_train = new_train_data['x']\n",
    "new_y_train = new_train_data['y']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
